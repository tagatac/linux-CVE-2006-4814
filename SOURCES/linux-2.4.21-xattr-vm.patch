diff -urNp linux-5570/fs/buffer.c linux-5580/fs/buffer.c
--- linux-5570/fs/buffer.c
+++ linux-5580/fs/buffer.c
@@ -49,6 +49,7 @@
 #include <linux/completion.h>
 #include <linux/mm_inline.h>
 #include <linux/bootmem.h>
+#include <linux/cache_def.h>
 
 #include <asm/uaccess.h>
 #include <asm/io.h>
@@ -811,11 +812,20 @@ void __invalidate_buffers(kdev_t dev, in
 	}
 }
 
-static void free_more_memory(void)
+static void free_more_memory(int async)
 {
 	balance_dirty();
 	wakeup_bdflush();
 	try_to_free_pages(GFP_NOIO);
+	if (async) {
+		shrink_dcache_memory(1, GFP_NOIO);
+		shrink_icache_memory(1, GFP_NOIO);
+#ifdef CONFIG_QUOTA
+		shrink_dqcache_memory(1, GFP_NOIO);
+#endif
+		shrink_other_caches(1, GFP_NOIO);
+		try_to_reclaim_buffers(0, GFP_NOIO);
+	}
 	run_task_queue(&tq_disk);
 	yield();
 }
@@ -1049,7 +1059,7 @@ struct buffer_head * getblk(kdev_t dev, 
 		}
 
 		if (!grow_buffers(dev, block, size))
-			free_more_memory();
+			free_more_memory(0);
 	}
 }
 
@@ -1377,7 +1387,7 @@ no_grow:
 	 */
 	run_task_queue(&tq_disk);
 
-	free_more_memory();
+	free_more_memory(async);
 	goto try_again;
 }
 
diff -urNp linux-5570/fs/mbcache.c linux-5580/fs/mbcache.c
--- linux-5570/fs/mbcache.c
+++ linux-5580/fs/mbcache.c
@@ -101,7 +101,7 @@ mb_cache_indexes(struct mb_cache *cache)
  * What the mbcache registers as to get shrunk dynamically.
  */
 
-static void
+static int
 mb_cache_memory_pressure(int priority, unsigned int gfp_mask);
 
 static struct cache_definition mb_cache_definition = {
@@ -174,12 +174,12 @@ __mb_cache_entry_release_unlock(struct m
  * @priority: Amount by which to shrink the cache (0 = highes priority)
  * @gfp_mask: (ignored)
  */
-static void
+static int
 mb_cache_memory_pressure(int priority, unsigned int gfp_mask)
 {
 	LIST_HEAD(free_list);
 	struct list_head *l, *ltmp;
-	int count = 0;
+	int count = 0, ret = 0;
 
 	spin_lock(&mb_cache_spinlock);
 	list_for_each(l, &mb_cache_list) {
@@ -203,9 +203,12 @@ mb_cache_memory_pressure(int priority, u
 	}
 	spin_unlock(&mb_cache_spinlock);
 	list_for_each_safe(l, ltmp, &free_list) {
+		ret = 1;
 		__mb_cache_entry_forget(list_entry(l, struct mb_cache_entry,
 						   e_lru_list), gfp_mask);
 	}
+
+	return ret;
 }
 
 
@@ -294,18 +297,21 @@ fail:
 /*
  * mb_cache_shrink()
  *
- * Removes all cache entires of a device from the cache. All cache entries
- * currently in use cannot be freed, and thus remain in the cache.
+ * Removes all cache entires of a device from the cache. All cache
+ * entries currently in use cannot be freed, and thus remain in the
+ * cache.  Should return the number of pages freed, but we don't
+ * have that info easily to hand.  Just return 1 if we made progress.
  *
  * @cache: which cache to shrink
  * @dev: which device's cache entries to shrink
  */
-void
+int
 mb_cache_shrink(struct mb_cache *cache, kdev_t dev)
 {
 	LIST_HEAD(free_list);
 	struct list_head *l, *ltmp;
-
+	int ret = 0;
+	
 	spin_lock(&mb_cache_spinlock);
 	list_for_each_safe(l, ltmp, &mb_cache_lru_list) {
 		struct mb_cache_entry *ce =
@@ -320,7 +326,9 @@ mb_cache_shrink(struct mb_cache *cache, 
 	list_for_each_safe(l, ltmp, &free_list) {
 		__mb_cache_entry_forget(list_entry(l, struct mb_cache_entry,
 						   e_lru_list), GFP_KERNEL);
+		ret = 1;
 	}
+	return ret;
 }
 
 
diff -urNp linux-5570/include/linux/cache_def.h linux-5580/include/linux/cache_def.h
--- linux-5570/include/linux/cache_def.h
+++ linux-5580/include/linux/cache_def.h
@@ -7,9 +7,10 @@
 
 struct cache_definition {
 	const char *name;
-	void (*shrink)(int, unsigned int);
+	int (*shrink)(int, unsigned int);
 	struct list_head link;
 };
 
 extern void register_cache(struct cache_definition *);
 extern void unregister_cache(struct cache_definition *);
+extern int shrink_other_caches(unsigned int priority, int gfp_mask);
diff -urNp linux-5570/include/linux/mbcache.h linux-5580/include/linux/mbcache.h
--- linux-5570/include/linux/mbcache.h
+++ linux-5580/include/linux/mbcache.h
@@ -46,7 +46,7 @@ struct mb_cache_entry {
 
 struct mb_cache * mb_cache_create(const char *, struct mb_cache_op *, size_t,
 				  int, int);
-void mb_cache_shrink(struct mb_cache *, kdev_t);
+int mb_cache_shrink(struct mb_cache *, kdev_t);
 void mb_cache_destroy(struct mb_cache *);
 
 /* Functions on cache entries */
diff -urNp linux-5570/mm/vmscan.c linux-5580/mm/vmscan.c
--- linux-5570/mm/vmscan.c
+++ linux-5580/mm/vmscan.c
@@ -67,20 +67,22 @@ void unregister_cache(struct cache_defin
 	up(&other_caches_sem);
 }
 
-static void shrink_other_caches(unsigned int priority, int gfp_mask)
+int shrink_other_caches(unsigned int priority, int gfp_mask)
 {
 	struct list_head *p;
-
+	int ret = 0;
+	
 	if (down_trylock(&other_caches_sem))
-		return;
+		return 0;
 
 	list_for_each_prev(p, &other_caches) {
 		struct cache_definition *cache =
 			list_entry(p, struct cache_definition, link);
 
-		cache->shrink(priority, gfp_mask);
+		ret += cache->shrink(priority, gfp_mask);
 	}
 	up(&other_caches_sem);
+	return ret;
 }
 
 static inline void age_page_up_nolock(struct page *page, int old_age)
@@ -1030,7 +1032,7 @@ static int do_try_to_free_pages(unsigned
 #ifdef CONFIG_QUOTA
 	ret += shrink_dqcache_memory(DEF_PRIORITY, gfp_mask);
 #endif
-	shrink_other_caches(priority, gfp_mask);
+	ret += shrink_other_caches(DEF_PRIORITY, gfp_mask);
 
 #ifdef CONFIG_HIGHMEM
 	/* reclaim bufferheaders on highmem systems with lowmem exhaustion */
@@ -1099,6 +1101,7 @@ static int do_try_to_free_pages_kswapd(u
 #ifdef CONFIG_QUOTA
 			ret += shrink_dqcache_memory(DEF_PRIORITY, gfp_mask);
 #endif
+			ret += shrink_other_caches(DEF_PRIORITY, gfp_mask);
 			ret += kmem_cache_reap(gfp_mask);
 			break;
 		}
