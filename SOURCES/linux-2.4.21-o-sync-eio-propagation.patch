diff -urNp linux-6210/fs/buffer.c linux-6220/fs/buffer.c
--- linux-6210/fs/buffer.c
+++ linux-6220/fs/buffer.c
@@ -686,12 +686,48 @@ void buffer_insert_list(struct buffer_he
 	spin_unlock(&lru_list_lock);
 }
 
+int get_and_clear_as_eio_error(struct address_space *m)
+{
+	int ret = 0;
+
+	spin_lock(&lru_list_lock);
+	if (m->gfp_mask & AS_EIO_MASK) {
+		m->gfp_mask &= ~AS_EIO_MASK;
+		ret = -EIO;
+	}
+	spin_unlock(&lru_list_lock);
+	return ret;
+}
+
+static inline void push_bh_error_state(struct buffer_head *bh) 
+{
+	struct page *page;
+	struct address_space *mapping;
+	
+	page = bh->b_page;
+	if (!page || !page->mapping) 
+		return;
+	if (!TryLockPage(page)) {
+		mapping = page->mapping;
+		if (mapping)
+			mapping->gfp_mask |= AS_EIO_MASK;
+		UnlockPage(page);
+	}
+}
+
 /*
  * The caller must have the lru_list lock before calling the 
  * remove_inode_queue functions.
  */
 static void __remove_inode_queue(struct buffer_head *bh)
 {
+	/* Nasty: if some inode is waiting for error
+	 * state notification on the buffer in
+	 * fsync/osync, and we remove the bh from the
+	 * inode's queue, it may lose EIO information.
+	 * Try to propagate that into the inode now. */
+	if (buffer_mapped(bh) && !buffer_uptodate(bh) && !buffer_locked(bh))
+		push_bh_error_state(bh);
 	list_del(&bh->b_inode_buffers);
 	clear_buffer_attached(bh);
 }
diff -urNp linux-6210/fs/ext3/fsync.c linux-6220/fs/ext3/fsync.c
--- linux-6210/fs/ext3/fsync.c
+++ linux-6220/fs/ext3/fsync.c
@@ -69,7 +69,7 @@ int ext3_sync_file(struct file * file, s
 	if (test_opt(inode->i_sb, DATA_FLAGS) == EXT3_MOUNT_WRITEBACK_DATA)
 		ret |= fsync_inode_data_buffers(inode);
 
-	ext3_force_commit(inode->i_sb);
+	ret |= ext3_force_commit(inode->i_sb);
 
 	return ret;
 }
diff -urNp linux-6210/fs/ext3/super.c linux-6220/fs/ext3/super.c
--- linux-6210/fs/ext3/super.c
+++ linux-6220/fs/ext3/super.c
@@ -1642,12 +1642,13 @@ void ext3_write_super (struct super_bloc
 
 static int ext3_sync_fs(struct super_block *sb)
 {
+	int err;
 	tid_t target;
 	
 	sb->s_dirt = 0;
 	target = log_start_commit(EXT3_SB(sb)->s_journal, NULL);
-	log_wait_commit(EXT3_SB(sb)->s_journal, target);
-	return 0;
+	err = log_wait_commit(EXT3_SB(sb)->s_journal, target);
+	return err;
 }
 
 /*
diff -urNp linux-6210/fs/inode.c linux-6220/fs/inode.c
--- linux-6210/fs/inode.c
+++ linux-6220/fs/inode.c
@@ -564,6 +564,7 @@ void write_inode_now(struct inode *inode
 int generic_osync_inode(struct inode *inode, int what)
 {
 	int err = 0, err2 = 0, need_write_inode_now = 0;
+	struct address_space *mapping;
 	
 	/* 
 	 * WARNING
@@ -604,6 +605,13 @@ int generic_osync_inode(struct inode *in
 	else
 		wait_on_inode(inode);
 
+	mapping = inode->i_mapping;
+	if (mapping) {
+		err2 = mapping_get_error(mapping);
+		if (!err)
+			err = err2;
+	}
+	
 	return err;
 }
 
diff -urNp linux-6210/fs/jbd/commit.c linux-6220/fs/jbd/commit.c
--- linux-6210/fs/jbd/commit.c
+++ linux-6220/fs/jbd/commit.c
@@ -47,7 +47,7 @@ void journal_commit_transaction(journal_
 	struct buffer_head *wbuf[64];
 	int bufs;
 	int flags;
-	int err;
+	int err = 0;
 	unsigned long blocknr;
 	char *tagp = NULL;
 	journal_header_t *header;
@@ -496,6 +496,8 @@ start_journal_io:
 		if (buffer_locked(bh)) {
 			unlock_journal(journal);
 			wait_on_buffer(bh);
+			if (unlikely(!buffer_uptodate(bh)))
+				err = -EIO;
 			lock_journal(journal);
 			goto wait_for_iobuf;
 		}
@@ -557,6 +559,8 @@ start_journal_io:
 		if (buffer_locked(bh)) {
 			unlock_journal(journal);
 			wait_on_buffer(bh);
+			if (unlikely(!buffer_uptodate(bh)))
+				err = -EIO;
 			lock_journal(journal);
 			goto wait_for_ctlbuf;
 		}
@@ -605,6 +609,8 @@ start_journal_io:
 		bh->b_end_io = journal_end_buffer_io_sync;
 		submit_bh(WRITE, bh);
 		wait_on_buffer(bh);
+		if (unlikely(!buffer_uptodate(bh)))
+			err = -EIO;
 		put_bh(bh);		/* One for getblk() */
 		journal_unlock_journal_head(descriptor);
 	}
@@ -616,6 +622,12 @@ start_journal_io:
 
 skip_commit: /* The journal should be unlocked by now. */
 
+	if (err) {
+		printk(KERN_ERR "Error (%d) on journal on device %s\n",
+		       err, kdevname(journal->j_dev));
+		__journal_abort_hard(journal);
+	}
+	
 	/* Call any callbacks that had been registered for handles in this
 	 * transaction.  It is up to the callback to free any allocated
 	 * memory.
diff -urNp linux-6210/fs/jbd/journal.c linux-6220/fs/jbd/journal.c
--- linux-6210/fs/jbd/journal.c
+++ linux-6220/fs/jbd/journal.c
@@ -579,8 +579,10 @@ out:
  * Wait for a specified commit to complete.
  * The caller may not hold the journal lock.
  */
-void log_wait_commit (journal_t *journal, tid_t tid)
+int log_wait_commit (journal_t *journal, tid_t tid)
 {
+	int err = 0;
+
 	lock_kernel();
 #ifdef CONFIG_JBD_DEBUG
 	lock_journal(journal);
@@ -597,6 +599,12 @@ void log_wait_commit (journal_t *journal
 		sleep_on(&journal->j_wait_done_commit);
 	}
 	unlock_kernel();
+
+	if (unlikely(is_journal_aborted(journal))) {
+		printk(KERN_EMERG "journal commit I/O error\n");
+		err = -EIO;
+	}
+	return err;
 }
 
 /*
@@ -1322,7 +1330,7 @@ int journal_flush (journal_t *journal)
 
 	/* Wait for the log commit to complete... */
 	if (transaction)
-		log_wait_commit(journal, transaction->t_tid);
+		err = log_wait_commit(journal, transaction->t_tid);
 
 	/* ...and flush everything in the log out to disk. */
 	lock_journal(journal);
diff -urNp linux-6210/fs/jbd/transaction.c linux-6220/fs/jbd/transaction.c
--- linux-6210/fs/jbd/transaction.c
+++ linux-6220/fs/jbd/transaction.c
@@ -1474,7 +1474,7 @@ int journal_stop(handle_t *handle)
 		 * to wait for the commit to complete.  
 		 */
 		if (handle->h_sync && !(current->flags & PF_MEMALLOC))
-			log_wait_commit(journal, tid);
+			err = log_wait_commit(journal, tid);
 	}
 	kfree(handle);
 	return err;
@@ -1499,7 +1499,7 @@ int journal_force_commit(journal_t *jour
 		goto out;
 	}
 	handle->h_sync = 1;
-	journal_stop(handle);
+	ret = journal_stop(handle);
 out:
 	unlock_kernel();
 	return ret;
diff -urNp linux-6210/fs/open.c linux-6220/fs/open.c
--- linux-6210/fs/open.c
+++ linux-6220/fs/open.c
@@ -15,6 +15,7 @@
 #include <linux/slab.h>
 #include <linux/tty.h>
 #include <linux/iobuf.h>
+#include <linux/pagemap.h>
 
 #include <asm/uaccess.h>
 
@@ -939,7 +940,7 @@ asmlinkage long sys_creat(const char * p
  */
 int filp_close(struct file *filp, fl_owner_t id)
 {
-	int retval;
+	int err, retval;
 
 	if (!file_count(filp)) {
 		printk(KERN_ERR "VFS: Close: file count is 0\n");
@@ -951,6 +952,13 @@ int filp_close(struct file *filp, fl_own
 		retval = filp->f_op->flush(filp);
 		unlock_kernel();
 	}
+	if (filp->f_dentry && filp->f_dentry->d_inode && 
+	    filp->f_dentry->d_inode->i_mapping) {
+		struct address_space *mapping = filp->f_dentry->d_inode->i_mapping;
+		err = mapping_get_error(mapping);
+		if (err && !retval)
+			retval = err;
+	}
 	dnotify_flush(filp, id);
 	locks_remove_posix(filp, id);
 	fput(filp);
diff -urNp linux-6210/include/linux/fs.h linux-6220/include/linux/fs.h
--- linux-6210/include/linux/fs.h
+++ linux-6220/include/linux/fs.h
@@ -439,7 +439,7 @@ struct address_space {
 	struct vm_area_struct	*i_mmap;	/* list of private mappings */
 	struct vm_area_struct	*i_mmap_shared; /* list of shared mappings */
 	spinlock_t		i_shared_lock;  /* and spinlock protecting it */
-	int			gfp_mask;	/* how to allocate the pages */
+	int			gfp_mask;	/* error bits/gfp mask */
 };
 
 struct char_device {
diff -urNp linux-6210/include/linux/jbd.h linux-6220/include/linux/jbd.h
--- linux-6210/include/linux/jbd.h
+++ linux-6220/include/linux/jbd.h
@@ -852,7 +852,7 @@ extern void	   journal_brelse_array(stru
 
 extern int	log_space_left (journal_t *); /* Called with journal locked */
 extern tid_t	log_start_commit (journal_t *, transaction_t *);
-extern void	log_wait_commit (journal_t *, tid_t);
+extern int	log_wait_commit (journal_t *, tid_t);
 extern int	log_do_checkpoint (journal_t *, int);
 
 extern void	log_wait_for_space(journal_t *, int nblocks);
diff -urNp linux-6210/include/linux/mm.h linux-6220/include/linux/mm.h
--- linux-6210/include/linux/mm.h
+++ linux-6220/include/linux/mm.h
@@ -841,6 +841,9 @@ extern struct page *filemap_nopage(struc
 #define __GFP_WIRED	0x200   /* Highmem bias and wired */
 #define __GFP_NUMA	0x400	/* NUMA allocation */
 
+#define __GFP_BITS_SHIFT 16	/* Room for 16 __GFP_FOO bits */
+#define __GFP_BITS_MASK ((1 << __GFP_BITS_SHIFT) - 1)
+
 #define GFP_NOHIGHIO	(__GFP_HIGH | __GFP_WAIT | __GFP_IO)
 #define GFP_NOIO	(__GFP_HIGH | __GFP_WAIT)
 #define GFP_NOFS	(__GFP_HIGH | __GFP_WAIT | __GFP_IO | __GFP_HIGHIO)
diff -urNp linux-6210/include/linux/pagemap.h linux-6220/include/linux/pagemap.h
--- linux-6210/include/linux/pagemap.h
+++ linux-6220/include/linux/pagemap.h
@@ -16,6 +16,21 @@
 #include <linux/highmem.h>
 
 /*
+ * Bits in mapping->flags.  The lower __GFP_BITS_SHIFT bits are the page
+ * allocation mode flags.
+ */
+#define AS_EIO		(__GFP_BITS_SHIFT + 0)	/* IO error on async write */
+#define AS_EIO_MASK	(1 << AS_EIO)
+
+/* 2.6 does this in wait_on_page_writeback_range() only. */
+static inline int mapping_get_error(struct address_space *m) 
+{
+	extern int get_and_clear_as_eio_error(struct address_space *m);
+	
+	return (m->gfp_mask & AS_EIO_MASK) ? get_and_clear_as_eio_error(m) : 0;
+}
+
+/*
  * The page cache can done in larger chunks than
  * one page, because it allows for more efficient
  * throughput (it can then be mapped into user
diff -urNp linux-6210/mm/filemap.c linux-6220/mm/filemap.c
--- linux-6210/mm/filemap.c
+++ linux-6220/mm/filemap.c
@@ -609,7 +609,7 @@ int filemap_fdatasync(struct address_spa
  */
 int filemap_fdatawait(struct address_space * mapping)
 {
-	int ret = 0;
+	int err, ret = 0;
 
 	lock_pagecache();
 
@@ -617,10 +617,16 @@ int filemap_fdatawait(struct address_spa
 		struct page *page = list_entry(mapping->locked_pages.next, struct page, list);
 
 		list_del(&page->list);
-		list_add(&page->list, &mapping->clean_pages);
+		if (PageDirty(page))
+			list_add(&page->list, &mapping->dirty_pages);
+		else
+			list_add(&page->list, &mapping->clean_pages);
 
-		if (!PageLocked(page))
+		if (!PageLocked(page)) {
+			if (PageError(page))
+				ret = -EIO;
 			continue;
+		}
 
 		page_cache_get(page);
 		unlock_pagecache();
@@ -633,6 +639,11 @@ int filemap_fdatawait(struct address_spa
 		lock_pagecache();
 	}
 	unlock_pagecache();
+
+	err = mapping_get_error(mapping);
+	if (!ret)
+		ret = err;
+
 	return ret;
 }
 
@@ -3436,8 +3447,13 @@ done:
 	/* For now, when the user asks for O_SYNC, we'll actually
 	 * provide O_DSYNC. */
 	if (status >= 0) {
-		if ((file->f_flags & O_SYNC) || IS_SYNC(inode))
+		if ((file->f_flags & O_SYNC) || IS_SYNC(inode)) {
 			status = generic_osync_inode(inode, OSYNC_METADATA|OSYNC_DATA);
+			/* If that failed, we don't know _where_ it failed so
+			 * we really need to fail the whole IO. */
+			if (status)
+				written = 0;
+		}
 	}
 	
 	err = written ? written : status;
diff -urNp linux-6210/mm/page_alloc.c linux-6220/mm/page_alloc.c
--- linux-6210/mm/page_alloc.c
+++ linux-6220/mm/page_alloc.c
@@ -526,6 +526,13 @@ struct page * __alloc_pages(unsigned int
 	 */
 
 	/*
+	 * Clear any possible error bits that might have been propagated
+	 * from the "gfp_mask" field of the "address_space" structure via
+	 * page_cache_alloc() or grab_cache_page().
+	 */
+	gfp_mask &= __GFP_BITS_MASK;
+
+	/*
 	 * Can we take pages directly from the inactive_clean
 	 * list?
 	 */
