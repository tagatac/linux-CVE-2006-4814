diff -urNp linux-1140/include/asm-generic/tlb.h linux-1141/include/asm-generic/tlb.h
--- linux-1140/include/asm-generic/tlb.h
+++ linux-1141/include/asm-generic/tlb.h
@@ -50,7 +50,7 @@ static inline mmu_gather_t *tlb_gather_m
 }
 
 /* void tlb_remove_page(mmu_gather_t *tlb, pte_t *ptep, unsigned long addr)
- *	Must perform the equivalent to __free_pte(pte_get_and_clear(ptep)), while
+ *	Must perform the equivalent to __free_pte(ptep_get_and_clear(ptep)), while
  *	handling the additional races in SMP caused by other CPUs caching valid
  *	mappings in their TLBs.
  */
diff -urNp linux-1140/include/asm-i386/pgtable-3level.h linux-1141/include/asm-i386/pgtable-3level.h
--- linux-1140/include/asm-i386/pgtable-3level.h
+++ linux-1141/include/asm-i386/pgtable-3level.h
@@ -40,7 +40,7 @@ static inline int pgd_present(pgd_t pgd)
 /* Rules for using set_pte: the pte being assigned *must* be
  * either not present or in a state where the hardware will
  * not attempt to update the pte.  In places where this is
- * not possible, use pte_get_and_clear to obtain the old pte
+ * not possible, use ptep_get_and_clear to obtain the old pte
  * value and then use set_pte to update it.  -ben
  */
 static inline void set_pte(pte_t *ptep, pte_t pte)
diff -urNp linux-1140/mm/memory.c linux-1141/mm/memory.c
--- linux-1140/mm/memory.c
+++ linux-1141/mm/memory.c
@@ -1165,8 +1165,14 @@ int remap_page_range(struct vm_area_stru
  */
 static inline void establish_pte(struct vm_area_struct * vma, unsigned long address, pte_t *page_table, pte_t entry)
 {
-	set_pte(page_table, entry);
+	pte_t old_pte;
+
+	if (!pte_none(*page_table)) {
+		old_pte = ptep_get_and_clear(page_table);
+		vm_account_remove(vma, old_pte, address);
+	}
 	flush_tlb_page(vma, address);
+	vm_set_pte(vma, address, page_table, entry);
 	update_mmu_cache(vma, address, entry);
 }
 
@@ -1207,6 +1213,7 @@ static int do_wp_page(struct mm_struct *
 {
 	struct page *old_page, *new_page;
 	struct pte_chain * pte_chain = NULL;
+	int old_page_locked = 0;
 
 	old_page = pte_page(pte);
 	if (!VALID_PAGE(old_page))
@@ -1214,8 +1221,9 @@ static int do_wp_page(struct mm_struct *
 
 	if (!TryLockPage(old_page)) {
 		int reuse = can_share_swap_page(old_page);
-		unlock_page(old_page);
+		old_page_locked = 1;
 		if (reuse) {
+			unlock_page(old_page);
 			flush_cache_page(vma, address);
 			establish_pte(vma, address, page_table, pte_mkyoung(pte_mkdirty(pte_mkwrite(pte))));
 			pte_unmap(page_table);
@@ -1257,6 +1265,8 @@ static int do_wp_page(struct mm_struct *
 	}
 	pte_unmap(page_table);
 	spin_unlock(&mm->page_table_lock);
+	if (old_page_locked)
+		unlock_page(old_page);
 	page_cache_release(new_page);
 	page_cache_release(old_page);
 	pte_chain_free(pte_chain);
@@ -1268,6 +1278,8 @@ bad_wp_page:
 	printk("do_wp_page: bogus page at address %08lx (page 0x%lx)\n",address,(unsigned long)old_page);
 	return -1;
 no_mem:
+	if (old_page_locked)
+		unlock_page(old_page);
 	page_cache_release(old_page);
 	pte_chain_free(pte_chain);
 	return -1;
