diff -urNp linux-371/arch/ppc64/kernel/irq.c linux-372/arch/ppc64/kernel/irq.c
--- linux-371/arch/ppc64/kernel/irq.c
+++ linux-372/arch/ppc64/kernel/irq.c
@@ -74,7 +74,6 @@ irq_desc_t irq_desc[NR_IRQS] __cacheline
 	{ [0 ... NR_IRQS-1] = { 0, NULL, NULL, 0, SPIN_LOCK_UNLOCKED}};
 	
 int ppc_spurious_interrupts = 0;
-struct irqaction *ppc_irq_action[NR_IRQS];
 unsigned long lpEvent_count = 0;
 #ifdef CONFIG_XMON
 extern void xmon(struct pt_regs *regs);
@@ -152,6 +151,10 @@ setup_irq(unsigned int irq, struct irqac
 		rand_initialize_irq(irq);
 	}
 
+	/* Call the controller's startup function for this irq */
+	if (desc->handler && desc->handler->startup)
+		desc->handler->startup(irq);
+
 	/*
 	 * The following block of code has to be executed atomically
 	 */
@@ -640,7 +643,6 @@ void __init init_IRQ(void)
 		once++;
 	
 	ppc_md.init_IRQ();
-	if(ppc_md.init_ras_IRQ) ppc_md.init_ras_IRQ(); 
 }
 
 #ifdef CONFIG_SMP
@@ -932,10 +934,18 @@ static void register_irq_proc (unsigned 
 
 	/* create /proc/irq/1234 */
 	irq_dir[irq] = proc_mkdir(name, root_irq_dir);
+	if (irq_dir[irq] == NULL) {
+		printk(KERN_ERR "register_irq_proc: proc_mkdir failed.\n");
+		return;
+	}
 
 	/* create /proc/irq/1234/smp_affinity */
 	entry = create_proc_entry("smp_affinity", 0600, irq_dir[irq]);
 
+	if (!entry) {
+		printk(KERN_ERR "register_irq_proc: create_proc_entry failed.\n");
+		return;
+	}
 	entry->nlink = 1;
 	entry->data = (void *)(long)irq;
 	entry->read_proc = irq_affinity_read_proc;
@@ -953,10 +963,16 @@ void init_irq_proc (void)
 
 	/* create /proc/irq */
 	root_irq_dir = proc_mkdir("irq", 0);
+	if (root_irq_dir == NULL)
+		printk(KERN_ERR "init_irq_proc: proc_mkdir failed.\n");
 
 	/* create /proc/irq/prof_cpu_mask */
 	entry = create_proc_entry("prof_cpu_mask", 0600, root_irq_dir);
 
+	if (!entry) {
+		printk(KERN_ERR "init_irq_proc: create_proc_entry failed.\n");
+		return;
+	}
 	entry->nlink = 1;
 	entry->data = (void *)&prof_cpu_mask;
 	entry->read_proc = prof_cpu_mask_read_proc;
@@ -966,3 +982,104 @@ void init_irq_proc (void)
 void no_action(int irq, void *dev, struct pt_regs *regs)
 {
 }
+
+/*
+ * Virtual IRQ mapping code, used on systems with XICS interrupt controllers.
+ */
+
+#define UNDEFINED_IRQ 0xffffffffU
+unsigned int virt_irq_to_real_map[NR_IRQS];
+
+/*
+ * Don't use virtual irqs 0, 1, 2 for devices.
+ * The pcnet32 driver considers interrupt numbers < 2 to be invalid,
+ * and 2 is the XICS IPI interrupt.
+ * We limit virtual irqs to 17 less than NR_IRQS so that when we
+ * offset them by 16 (to reserve the first 16 for ISA interrupts)
+ * we don't end up with an interrupt number >= NR_IRQS.
+ */
+#define MIN_VIRT_IRQ	3
+#define MAX_VIRT_IRQ	(NR_IRQS - NUM_ISA_INTERRUPTS - 1)
+#define NR_VIRT_IRQS	(MAX_VIRT_IRQ - MIN_VIRT_IRQ + 1)
+
+void
+virt_irq_init(void)
+{
+	int i;
+	for (i = 0; i < NR_IRQS; i++)
+		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
+}
+
+/* Create a mapping for a real_irq if it doesn't already exist.
+ * Return the virtual irq as a convenience.
+ */
+int virt_irq_create_mapping(unsigned int real_irq)
+{
+	unsigned int virq, first_virq;
+	static int warned;
+
+	if (naca->interrupt_controller == IC_OPEN_PIC)
+		return real_irq;	/* no mapping for openpic (for now) */
+
+	/* don't map interrupts < MIN_VIRT_IRQ */
+	if (real_irq < MIN_VIRT_IRQ) {
+		virt_irq_to_real_map[real_irq] = real_irq;
+		return real_irq;
+	}
+
+	/* map to a number between MIN_VIRT_IRQ and MAX_VIRT_IRQ */
+	virq = real_irq;
+	if (virq > MAX_VIRT_IRQ)
+		virq = (virq % NR_VIRT_IRQS) + MIN_VIRT_IRQ;
+
+	/* search for this number or a free slot */
+	first_virq = virq;
+	while (virt_irq_to_real_map[virq] != UNDEFINED_IRQ) {
+		if (virt_irq_to_real_map[virq] == real_irq)
+			return virq;
+		if (++virq > MAX_VIRT_IRQ)
+			virq = MIN_VIRT_IRQ;
+		if (virq == first_virq)
+			goto nospace;	/* oops, no free slots */
+	}
+
+	virt_irq_to_real_map[virq] = real_irq;
+	return virq;
+
+ nospace:
+	if (!warned) {
+		printk(KERN_CRIT "Interrupt table is full\n");
+		printk(KERN_CRIT "Increase NR_IRQS (currently %d) "
+		       "in your kernel sources and rebuild.\n", NR_IRQS);
+		warned = 1;
+	}
+	return NO_IRQ;
+}
+
+/*
+ * In most cases we will get a hit on the very first slot checked in
+ * the virt_irq_to_real_map.  Only when there are a large number of
+ * IRQs will this be expensive.
+ */
+int real_irq_to_virt_slow(unsigned int real_irq)
+{
+	unsigned int virq;
+	unsigned int first_virq;
+
+	virq = real_irq;
+
+	if (virq > MAX_VIRT_IRQ)
+		virq = (virq % NR_VIRT_IRQS) + MIN_VIRT_IRQ;
+
+	first_virq = virq;
+	do {
+		if (virt_irq_to_real_map[virq] == real_irq)
+			return virq;
+		virq++;
+		if (virq >= MAX_VIRT_IRQ)
+			virq = 0;
+	} while (first_virq != virq);
+
+	return NO_IRQ;
+}
+
diff -urNp linux-371/arch/ppc64/kernel/local_irq.h linux-372/arch/ppc64/kernel/local_irq.h
--- linux-371/arch/ppc64/kernel/local_irq.h
+++ linux-372/arch/ppc64/kernel/local_irq.h
@@ -20,7 +20,5 @@ void ppc_irq_dispatch_handler(struct pt_
 #define NR_MASK_WORDS	((NR_IRQS + 63) / 64)
 
 extern int ppc_spurious_interrupts;
-extern int ppc_second_irq;
-extern struct irqaction *ppc_irq_action[NR_IRQS];
 
 #endif /* _PPC_KERNEL_LOCAL_IRQ_H */
diff -urNp linux-371/arch/ppc64/kernel/open_pic.c linux-372/arch/ppc64/kernel/open_pic.c
--- linux-371/arch/ppc64/kernel/open_pic.c
+++ linux-372/arch/ppc64/kernel/open_pic.c
@@ -137,7 +137,7 @@ void __init openpic_init_IRQ(void)
         int i;
         unsigned int *addrp;
         unsigned char* chrp_int_ack_special = 0;
-        unsigned char init_senses[NR_IRQS - NUM_8259_INTERRUPTS];
+        unsigned char init_senses[NR_IRQS - NUM_ISA_INTERRUPTS];
         int nmi_irq = -1;
 #if defined(CONFIG_VT) && defined(CONFIG_ADB_KEYBOARD) && defined(XMON)
         struct device_node *kbd;
@@ -152,13 +152,23 @@ void __init openpic_init_IRQ(void)
 			__ioremap(addrp[prom_n_addr_cells(np)-1], 1, _PAGE_NO_CACHE);
         /* hydra still sets OpenPIC_InitSenses to a static set of values */
         if (OpenPIC_InitSenses == NULL) {
-                prom_get_irq_senses(init_senses, NUM_8259_INTERRUPTS, NR_IRQS);
+                prom_get_irq_senses(init_senses, NUM_ISA_INTERRUPTS, NR_IRQS);
                 OpenPIC_InitSenses = init_senses;
-                OpenPIC_NumInitSenses = NR_IRQS - NUM_8259_INTERRUPTS;
+                OpenPIC_NumInitSenses = NR_IRQS - NUM_ISA_INTERRUPTS;
         }
-        openpic_init(1, NUM_8259_INTERRUPTS, chrp_int_ack_special, nmi_irq);
-        for ( i = 0 ; i < NUM_8259_INTERRUPTS  ; i++ )
+        openpic_init(1, NUM_ISA_INTERRUPTS, chrp_int_ack_special, nmi_irq);
+        for ( i = 0 ; i < NUM_ISA_INTERRUPTS  ; i++ )
                 irq_desc[i].handler = &i8259_pic;
+}
+
+void openpic_isa_init(void)
+{
+
+	/* Initialize the cascade */
+	if (request_irq(open_pic_irq_offset, no_action, SA_INTERRUPT,
+			"82c59 cascade", NULL))
+		printk(KERN_CRIT "Unable to get OpenPIC IRQ 0 for cascade\n");
+
         i8259_init();
 }
 
@@ -385,12 +395,6 @@ void __init openpic_init(int main_pic, i
 	ppc64_boot_msg(0x24, "OpenPic Spurious");
 	openpic_set_spurious(openpic_vec_spurious);
 
-	/* Initialize the cascade */
-	if (offset) {
-		if (request_irq(offset, no_action, SA_INTERRUPT,
-				"82c59 cascade", NULL))
-			printk(KERN_ERR "Unable to get OpenPIC IRQ 0 for cascade\n");
-	}
 	openpic_set_priority(0);
 	openpic_disable_8259_pass_through();
 
diff -urNp linux-371/arch/ppc64/kernel/open_pic.h linux-372/arch/ppc64/kernel/open_pic.h
--- linux-371/arch/ppc64/kernel/open_pic.h
+++ linux-372/arch/ppc64/kernel/open_pic.h
@@ -29,6 +29,7 @@ extern u_char *OpenPIC_InitSenses;
 extern void* OpenPIC_Addr;
 
 /* Exported functions */
+extern void openpic_isa_init(void);
 extern void openpic_init(int, int, unsigned char *, int);
 extern void openpic_request_IPIs(void);
 extern void do_openpic_setup_cpu(void);
@@ -37,9 +38,4 @@ extern void openpic_init_processor(u_int
 extern void openpic_setup_ISU(int isu_num, unsigned long addr);
 extern void openpic_cause_IPI(u_int ipi, u_int cpumask);
 
-extern inline int openpic_to_irq(int irq)
-{
-	return irq += NUM_8259_INTERRUPTS;
-}
-/*extern int open_pic_irq_offset;*/
 #endif /* _PPC64_KERNEL_OPEN_PIC_H */
diff -urNp linux-371/arch/ppc64/kernel/pSeries_pci.c linux-372/arch/ppc64/kernel/pSeries_pci.c
--- linux-371/arch/ppc64/kernel/pSeries_pci.c
+++ linux-372/arch/ppc64/kernel/pSeries_pci.c
@@ -718,6 +718,8 @@ pSeries_pcibios_fixup(void)
 
 	if (naca->interrupt_controller == IC_PPC_XIC) {
 		xics_isa_init(); 
+	} else {
+		openpic_isa_init();
 	}
 }
 
diff -urNp linux-371/arch/ppc64/kernel/prom.c linux-372/arch/ppc64/kernel/prom.c
--- linux-371/arch/ppc64/kernel/prom.c
+++ linux-372/arch/ppc64/kernel/prom.c
@@ -203,11 +203,6 @@ unsigned long ramdisk_start = 0;
 
 struct device_node *allnodes = 0;
 
-#define UNDEFINED_IRQ 0xffff
-unsigned short real_irq_to_virt_map[NR_HW_IRQS];
-unsigned short virt_irq_to_real_map[NR_IRQS];
-int last_virt_irq = 2;	/* index of last virt_irq.  Skip through IPI */
-
 static unsigned long call_prom(const char *service, int nargs, int nret, ...);
 static void prom_exit(void);
 static unsigned long copy_device_tree(unsigned long);
@@ -1892,46 +1887,6 @@ check_display(unsigned long mem)
 	return DOUBLEWORD_ALIGN(mem);
 }
 
-void
-virt_irq_init(void)
-{
-	int i;
-	for (i = 0; i < NR_IRQS; i++)
-		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
-	for (i = 0; i < NR_HW_IRQS; i++)
-		real_irq_to_virt_map[i] = UNDEFINED_IRQ;
-}
-
-/* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
- */
-unsigned long
-virt_irq_create_mapping(unsigned long real_irq)
-{
-	unsigned long virq;
-	if (naca->interrupt_controller == IC_OPEN_PIC)
-		return real_irq;	/* no mapping for openpic (for now) */
-	virq = real_irq_to_virt(real_irq);
-	if (virq == UNDEFINED_IRQ) {
-		/* Assign a virtual IRQ number */
-		if (real_irq < NR_IRQS && virt_irq_to_real(real_irq) == UNDEFINED_IRQ) {
-			/* A 1-1 mapping will work. */
-			virq = real_irq;
-		} else {
-			while (last_virt_irq < NR_IRQS &&
-			       virt_irq_to_real(++last_virt_irq) != UNDEFINED_IRQ)
-				/* skip irq's in use */;
-			if (last_virt_irq >= NR_IRQS)
-				panic("Too many IRQs are required on this system.  NR_IRQS=%d\n", NR_IRQS);
-			virq = last_virt_irq;
-		}
-		virt_irq_to_real_map[virq] = real_irq;
-		real_irq_to_virt_map[real_irq] = virq;
-	}
-	return virq;
-}
-
-
 static int __init
 prom_next_node(phandle *nodep)
 {
@@ -2166,137 +2121,195 @@ finish_node(struct device_node *np, unsi
 	return mem_start;
 }
 
-/* This routine walks the interrupt tree for a given device node and gather 
- * all necessary informations according to the draft interrupt mapping
- * for CHRP. The current version was only tested on Apple "Core99" machines
- * and may not handle cascaded controllers correctly.
+/*
+ * Find the interrupt parent of a node.
  */
-__init
-static unsigned long
-finish_node_interrupts(struct device_node *np, unsigned long mem_start)
+static struct device_node * __devinit
+intr_parent(struct device_node *p)
 {
-	/* Finish this node */
-	unsigned int *isizep, *asizep, *interrupts, *map, *map_mask, *reg;
-	phandle *parent, map_parent;
-	struct device_node *node, *parent_node;
-	int l, isize, ipsize, asize, map_size, regpsize;
+	phandle *parp;
 
-	/* Currently, we don't look at all nodes with no "interrupts" property */
+	parp = (phandle *) get_property(p, "interrupt-parent", NULL);
+	if (parp == NULL)
+		return p->parent;
+	return find_phandle(*parp);
+}
 
-	interrupts = (unsigned int *)get_property(np, "interrupts", &l);
-	if (interrupts == NULL)
-		return mem_start;
-	ipsize = l>>2;
+/*
+ * Find out the size of each entry of the interrupts property
+ * for a node.
+ */
+static int __devinit
+prom_n_intr_cells(struct device_node *np)
+{
+	struct device_node *p;
+	unsigned int *icp;
 
-	reg = (unsigned int *)get_property(np, "reg", &l);
-	regpsize = l>>2;
+	for (p = np; (p = intr_parent(p)) != NULL; ) {
+		icp = (unsigned int *)
+			get_property(p, "#interrupt-cells", NULL);
+		if (icp != NULL)
+			return *icp;
+		if (get_property(p, "interrupt-controller", NULL) != NULL
+		    || get_property(p, "interrupt-map", NULL) != NULL) {
+			printk("oops, node %s doesn't have #interrupt-cells\n",
+			       p->full_name);
+		return 1;
+		}
+	}
+#ifdef DEBUG_IRQ
+	printk("prom_n_intr_cells failed for %s\n", np->full_name);
+#endif
+	return 1;
+}
 
-	/* We assume default interrupt cell size is 1 (bugus ?) */
-	isize = 1;
-	node = np;
-	
-	do {
-	    /* We adjust the cell size if the current parent contains an #interrupt-cells
-	     * property */
-	    isizep = (unsigned int *)get_property(node, "#interrupt-cells", &l);
-	    if (isizep)
-	    	isize = *isizep;
-
-	    /* We don't do interrupt cascade (ISA) for now, we stop on the first 
-	     * controller found
-	     */
-	    if (get_property(node, "interrupt-controller", &l)) {
-	    	int i,j;
-
-	    	np->intrs = (struct interrupt_info *) mem_start;
-		np->n_intrs = ipsize / isize;
-		mem_start += np->n_intrs * sizeof(struct interrupt_info);
-		for (i = 0; i < np->n_intrs; ++i) {
-		    np->intrs[i].line = openpic_to_irq(virt_irq_create_mapping(*interrupts++));
-		    np->intrs[i].sense = 1;
-		    if (isize > 1)
-		        np->intrs[i].sense = *interrupts++;
-		    for (j=2; j<isize; j++)
-		    	interrupts++;
+/*
+ * Map an interrupt from a device up to the platform interrupt
+ * descriptor.
+ */
+static int __devinit
+map_interrupt(unsigned int **irq, struct device_node **ictrler,
+	      struct device_node *np, unsigned int *ints, int nintrc)
+{
+	struct device_node *p, *ipar;
+	unsigned int *imap, *imask, *ip;
+	int i, imaplen, match;
+	int newintrc, newaddrc;
+	unsigned int *reg;
+	int naddrc;
+
+	reg = (unsigned int *) get_property(np, "reg", NULL);
+	naddrc = prom_n_addr_cells(np);
+	p = intr_parent(np);
+	while (p != NULL) {
+		if (get_property(p, "interrupt-controller", NULL) != NULL)
+			/* this node is an interrupt controller, stop here */
+			break;
+		imap = (unsigned int *)
+			get_property(p, "interrupt-map", &imaplen);
+		if (imap == NULL) {
+			p = intr_parent(p);
+			continue;
+		}
+		imask = (unsigned int *)
+			get_property(p, "interrupt-map-mask", NULL);
+		if (imask == NULL) {
+			printk("oops, %s has interrupt-map but no mask\n",
+			       p->full_name);
+			return 0;
+		}
+		imaplen /= sizeof(unsigned int);
+		match = 0;
+		ipar = NULL;
+		while (imaplen > 0 && !match) {
+			/* check the child-interrupt field */
+			match = 1;
+			for (i = 0; i < naddrc && match; ++i)
+				match = ((reg[i] ^ imap[i]) & imask[i]) == 0;
+			for (; i < naddrc + nintrc && match; ++i)
+				match = ((ints[i-naddrc] ^ imap[i]) & imask[i]) == 0;
+			imap += naddrc + nintrc;
+			imaplen -= naddrc + nintrc;
+			/* grab the interrupt parent */
+			ipar = find_phandle((phandle) *imap++);
+			--imaplen;
+			if (ipar == NULL) {
+				printk("oops, no int parent %x in map of %s\n",
+				       imap[-1], p->full_name);
+				return 0;
+			}
+			/* find the parent's # addr and intr cells */
+			ip = (unsigned int *)
+				get_property(ipar, "#interrupt-cells", NULL);
+			if (ip == NULL) {
+				printk("oops, no #interrupt-cells on %s\n",
+				       ipar->full_name);
+				return 0;
+			}
+			newintrc = *ip;
+			ip = (unsigned int *)
+				get_property(ipar, "#address-cells", NULL);
+			newaddrc = (ip == NULL)? 0: *ip;
+			imap += newaddrc + newintrc;
+			imaplen -= newaddrc + newintrc;
+		}
+		if (imaplen < 0) {
+			printk("oops, error decoding int-map on %s, len=%d\n",
+			       p->full_name, imaplen);
+			return 0;
+		}
+		if (!match) {
+#ifdef DEBUG_IRQ
+			printk("oops, no match in %s int-map for %s\n",
+			       p->full_name, np->full_name);
+#endif
+			return 0;
 		}
+		p = ipar;
+		naddrc = newaddrc;
+		nintrc = newintrc;
+		ints = imap - nintrc;
+		reg = ints - naddrc;
+	}
+	if (p == NULL) {
+#ifdef DEBUG_IRQ
+		printk("hmmm, int tree for %s doesn't have ctrler\n",
+		       np->full_name);
+#endif
+		return 0;
+	}
+	*irq = ints;
+	*ictrler = p;
+	return nintrc;
+}
+
+/*
+ * New version of finish_node_interrupts.
+ */
+static unsigned long __init
+finish_node_interrupts(struct device_node *np, unsigned long mem_start)
+{
+	unsigned int *ints;
+	int intlen, intrcells, intrcount;
+	int i, j, n;
+	unsigned int *irq, virq;
+	struct device_node *ic;
+
+	ints = (unsigned int *) get_property(np, "interrupts", &intlen);
+	if (ints == NULL)
 		return mem_start;
-	    }
-	    /* We lookup for an interrupt-map. This code can only handle one interrupt
-	     * per device in the map. We also don't handle #address-cells in the parent
-	     * I skip the pci node itself here, may not be necessary but I don't like it's
-	     * reg property.
-	     */
-	    if (np != node)
-	        map = (unsigned int *)get_property(node, "interrupt-map", &l);
-	     else
-	     	map = NULL;
-	    if (map && l) {
-	    	int i, found, temp_isize, temp_asize;
-	        map_size = l>>2;
-	        map_mask = (unsigned int *)get_property(node, "interrupt-map-mask", &l);
-	        asizep = (unsigned int *)get_property(node, "#address-cells", &l);
-	        if (asizep && l == sizeof(unsigned int))
-	            asize = *asizep;
-	        else
-	            asize = 0;
-	        found = 0;
-	        while (map_size>0 && !found) {
-	            found = 1;
-	            for (i=0; i<asize; i++) {
-	            	unsigned int mask = map_mask ? map_mask[i] : 0xffffffff;
-	            	if (!reg || (i>=regpsize) || ((mask & *map) != (mask & reg[i])))
-	           	    found = 0;
-	           	map++;
-	           	map_size--;
-	            }
-	            for (i=0; i<isize; i++) {
-	            	unsigned int mask = map_mask ? map_mask[i+asize] : 0xffffffff;
-	            	if ((mask & *map) != (mask & interrupts[i]))
-	            	    found = 0;
-	            	map++;
-	            	map_size--;
-	            }
-	            map_parent = *((phandle *)map);
-	            map+=1; map_size-=1;
-	            parent_node = find_phandle(map_parent);
-	            temp_isize = isize;
-		    temp_asize = 0;
-	            if (parent_node) {
-			isizep = (unsigned int *)get_property(parent_node, "#interrupt-cells", &l);
-	    		if (isizep)
-	    		    temp_isize = *isizep;
-			asizep = (unsigned int *)get_property(parent_node, "#address-cells", &l);
-			if (asizep && l == sizeof(unsigned int))
-				temp_asize = *asizep;
-	            }
-	            if (!found) {
-			map += temp_isize + temp_asize;
-			map_size -= temp_isize + temp_asize;
-	            }
-	        }
-	        if (found) {
-		    /* Mapped to a new parent.  Use the reg and interrupts specified in
-		     * the map as the new search parameters.  Then search from the parent.
-		     */
-	            node = parent_node;
-		    reg = map;
-		    regpsize = temp_asize;
-		    interrupts = map + temp_asize;
-		    ipsize = temp_isize;
-		    continue;
-	        }
-	    }
-	    /* We look for an explicit interrupt-parent.
-	     */
-	    parent = (phandle *)get_property(node, "interrupt-parent", &l);
-	    if (parent && (l == sizeof(phandle)) &&
-	    	(parent_node = find_phandle(*parent))) {
-	    	node = parent_node;
-	    	continue;
-	    }
-	    /* Default, get real parent */
-	    node = node->parent;
-	} while (node);
+	intrcells = prom_n_intr_cells(np);
+	intlen /= intrcells * sizeof(unsigned int);
+	np->intrs = (struct interrupt_info *) mem_start;
+	mem_start += intlen * sizeof(struct interrupt_info);
+
+	intrcount = 0;
+	for (i = 0; i < intlen; ++i, ints += intrcells) {
+		n = map_interrupt(&irq, &ic, np, ints, intrcells);
+		if (n <= 0)
+			continue;
+
+		/* don't map IRQ numbers under a cascaded 8259 controller */
+		if (ic && device_is_compatible(ic, "chrp,iic")) {
+			np->intrs[intrcount].line = irq[0];
+		} else {
+			virq = virt_irq_create_mapping(irq[0]);
+			np->intrs[intrcount].line = irq_offset_up(virq);
+		}
+
+		np->intrs[intrcount].sense = 1;
+		if (n > 1)
+			np->intrs[intrcount].sense = irq[1];
+		if (n > 2) {
+			printk("hmmm, got %d intr cells for %s:", n,
+			       np->full_name);
+			for (j = 0; j < n; ++j)
+				printk(" %d", irq[j]);
+			printk("\n");
+		}
+		++intrcount;
+	}
+	np->n_intrs = intrcount;
 
 	return mem_start;
 }
diff -urNp linux-371/arch/ppc64/kernel/ras.c linux-372/arch/ppc64/kernel/ras.c
--- linux-371/arch/ppc64/kernel/ras.c
+++ linux-372/arch/ppc64/kernel/ras.c
@@ -59,35 +59,79 @@ static void ras_epow_interrupt(int irq, 
 static void ras_error_interrupt(int irq, void *dev_id, struct pt_regs * regs);
 void init_ras_IRQ(void);
 
+static unsigned char log_buf[RTAS_ERROR_LOG_MAX];
+static spinlock_t log_lock = SPIN_LOCK_UNLOCKED;
+
+static int ras_get_sensor_state_token;
+static int ras_check_exception_token;
+static int ras_error_log_max;
+
+#define EPOW_SENSOR_TOKEN   9
+#define EPOW_SENSOR_INDEX   0
+#define RAS_VECTOR_OFFSET   0x500
+
 /* #define DEBUG */
 
 /*
  * Initialize handlers for the set of interrupts caused by hardware errors
  * and power system events.
  */
-void init_ras_IRQ(void) {
+void init_ras_IRQ(void)
+{
+	char *props[] = {"open-pic-interrupt", "interrupts"};
+	int num_props = 2;
 	struct device_node *np;
-	unsigned int *ireg, len, i;
+	unsigned int *ireg, len, i, j;
+	int virq;
 
-	if((np = find_path_device("/event-sources/internal-errors")) &&
-	   (ireg = (unsigned int *)get_property(np, "open-pic-interrupt", 
-						&len))) {
-		for(i=0; i<(len / sizeof(*ireg)); i++) {
-			request_irq(virt_irq_create_mapping(*(ireg)) + NUM_8259_INTERRUPTS, 
-				    &ras_error_interrupt, 0, 
-				    "RAS_ERROR", NULL);
-			ireg++;
+	ras_get_sensor_state_token = rtas_token("get-sensor-state");
+	ras_check_exception_token = rtas_token("check-exception");
+	ras_error_log_max = rtas_get_error_log_max();
+			  
+	/* Internal Errors */
+	if ((np = find_path_device("/event-sources/internal-errors")) != NULL) {
+		for (i = 0; i < num_props; i++) {
+			ireg = (unsigned int *)get_property(np, props[i], &len);
+			if (ireg == NULL)
+				continue;
+
+			for (j = 0; j < (len / sizeof(*ireg)); j++) {
+				virq = virt_irq_create_mapping(*(ireg));
+				if (virq == NO_IRQ) {
+					printk(KERN_ERR "Unable to allocate interrupt "
+						"number for %s\n", np->full_name);
+					break;
+				}
+				
+				request_irq(irq_offset_up(virq),
+					    ras_error_interrupt, 0,
+					    "RAS_ERROR", NULL);
+				ireg++;
+			}
 		}
 	}
 
-	if((np = find_path_device("/event-sources/epow-events")) &&
-	   (ireg = (unsigned int *)get_property(np, "open-pic-interrupt", 
-						&len))) {
-		for(i=0; i<(len / sizeof(*ireg)); i++) {
-			request_irq(virt_irq_create_mapping(*(ireg)) + NUM_8259_INTERRUPTS, 
-				    &ras_epow_interrupt, 0, 
-				    "RAS_EPOW", NULL);
-			ireg++;
+	/* EPOW Events */
+	if ((np = find_path_device("/event-sources/epow-events")) != NULL) {
+		for (i = 0; i < num_props; i++) {
+			ireg = (unsigned int *)get_property(np, props[i], &len);
+			if (ireg == NULL)
+				continue;
+
+			for (j = 0; j < (len / sizeof(*ireg)); j++) {
+				virq = virt_irq_create_mapping(*(ireg));
+				if (virq == NO_IRQ) {
+					printk(KERN_ERR "Unable to allocate interrupt "
+						" number for %s\n", np->full_name);
+					break;
+				}
+				
+				printk(KERN_EMERG "################Requesting IRQ for EPOW %d\n", irq_offset_up(virq));
+				request_irq(irq_offset_up(virq),
+					    ras_epow_interrupt, 0,
+					    "RAS_EPOW", NULL);
+				ireg++;
+			}
 		}
 	}
 }
@@ -95,30 +139,42 @@ void init_ras_IRQ(void) {
 /*
  * Handle power subsystem events (EPOW).
  *
- * Presently we just log the event has occured.  This should be fixed
+ * Presently we just log the event has occurred.  This should be fixed
  * to examine the type of power failure and take appropriate action where
  * the time horizon permits something useful to be done.
  */
 static void
 ras_epow_interrupt(int irq, void *dev_id, struct pt_regs * regs)
 {
-	struct rtas_error_log log_entry;
-	unsigned int size = sizeof(log_entry);
 	long status = 0xdeadbeef;
+	unsigned long state = 0;
+	int virq = irq_offset_down(irq);
+	int critical;
+
+	spin_lock(&log_lock);
+
+	status = rtas_call(ras_get_sensor_state_token, 2, 2, &state,
+			   EPOW_SENSOR_TOKEN, EPOW_SENSOR_INDEX);
 
-	status = rtas_call(rtas_token("check-exception"), 6, 1, NULL, 
-			   0x500, irq, 
+	if (state > 3)
+		critical = 1;  /* Time critical event */
+	else
+		critical = 0;
+	
+	status = rtas_call(ras_check_exception_token, 6, 1, NULL, 
+			   RAS_VECTOR_OFFSET, virt_irq_to_real(virq), 
 			   EPOW_WARNING | POWERMGM_EVENTS, 
-			   1,  /* Time Critical */
-			   __pa(&log_entry), size);
+			   critical, __pa(&log_buf), ras_error_log_max);
 
-	udbg_printf("EPOW <0x%lx 0x%lx>\n", 
-		    *((unsigned long *)&log_entry), status); 
-	printk(KERN_WARNING 
-	       "EPOW <0x%lx 0x%lx>\n",*((unsigned long *)&log_entry), status);
+	udbg_printf("EPOW <0x%lx 0x%lx 0x%lx>\n", 
+		    *((unsigned long *)&log_buf), status, state); 
+	printk(KERN_WARNING "EPOW <0x%lx 0x%lx 0x%lx>\n",
+	       *((unsigned long *)&log_buf), status, state);
 
 	/* format and print the extended information */
-	log_error((char *)&log_entry, ERR_TYPE_RTAS_LOG, 0);
+	log_error(log_buf, ERR_TYPE_RTAS_LOG, 0);
+
+	spin_unlock(&log_lock);
 }
 
 /*
@@ -132,32 +188,30 @@ ras_epow_interrupt(int irq, void *dev_id
 static void
 ras_error_interrupt(int irq, void *dev_id, struct pt_regs * regs)
 {
-	struct rtas_error_log log_entry;
-	unsigned int size = sizeof(log_entry);
+	struct rtas_error_log rtas_errlog;
 	long status = 0xdeadbeef;
 	int fatal;
 
-	status = rtas_call(rtas_token("check-exception"), 6, 1, NULL, 
-			   0x500, irq, 
-			   INTERNAL_ERROR, 
-			   1, /* Time Critical */
-			   __pa(&log_entry), size);
+	spin_lock(&log_lock);
+
+	status = rtas_call(ras_check_exception_token, 6, 1, NULL, 
+			   RAS_VECTOR_OFFSET, irq, INTERNAL_ERROR, 
+			   1 /* Time Critical */, __pa(&log_buf), 
+			   ras_error_log_max);
 
-	if((status == 0) && 
-	   (log_entry.severity >= SEVERITY_ERROR_SYNC)) 
+	if ((status == 0) && (rtas_errlog.severity >= SEVERITY_ERROR_SYNC)) 
 		fatal = 1;
 	else
 		fatal = 0;
 
 	/* format and print the extended information */
-	log_error((char *)&log_entry, ERR_TYPE_RTAS_LOG, fatal); 
+	log_error(log_buf, ERR_TYPE_RTAS_LOG, fatal); 
 
 	if (fatal) {
 		udbg_printf("HW Error <0x%lx 0x%lx>\n",
-			    *((unsigned long *)&log_entry), status);
-		printk(KERN_EMERG 
-		       "Error: Fatal hardware error <0x%lx 0x%lx>\n",
-		       *((unsigned long *)&log_entry), status);
+			    *((unsigned long *)&log_buf), status);
+		printk(KERN_EMERG "Error: Fatal hardware error <0x%lx 0x%lx>\n",
+		       *((unsigned long *)&log_buf), status);
 
 #ifndef DEBUG
 		/* Don't actually power off when debugging so we can test
@@ -168,11 +222,11 @@ ras_error_interrupt(int irq, void *dev_i
 #endif
 	} else {
 		udbg_printf("Recoverable HW Error <0x%lx 0x%lx>\n",
-			    *((unsigned long *)&log_entry), status); 
+			    *((unsigned long *)&log_buf), status); 
 		printk(KERN_WARNING 
 		       "Warning: Recoverable hardware error <0x%lx 0x%lx>\n",
-		       *((unsigned long *)&log_entry), status);
-
-		return;
+		       *((unsigned long *)&log_buf), status);
 	}
+
+	spin_unlock(&log_lock);
 }
diff -urNp linux-371/arch/ppc64/kernel/setup.c linux-372/arch/ppc64/kernel/setup.c
--- linux-371/arch/ppc64/kernel/setup.c
+++ linux-372/arch/ppc64/kernel/setup.c
@@ -498,6 +498,9 @@ void __init ppc_init(void)
 	if (ppc_md.init != NULL) {
 		ppc_md.init();
 	}
+
+	if (ppc_md.init_ras_IRQ)
+		ppc_md.init_ras_IRQ();
 }
 
 void __init ppc64_calibrate_delay(void)
diff -urNp linux-371/arch/ppc64/kernel/smp.c linux-372/arch/ppc64/kernel/smp.c
--- linux-371/arch/ppc64/kernel/smp.c
+++ linux-372/arch/ppc64/kernel/smp.c
@@ -352,8 +352,7 @@ smp_chrp_setup_cpu(int cpu_nr)
 	if (OpenPIC_Addr) {
 		do_openpic_setup_cpu();
 	} else {
-	  if (cpu_nr > 0)
-	    xics_setup_cpu();
+		xics_setup_cpu();
 	}
 }
 
@@ -376,6 +375,7 @@ smp_xics_message_pass(int target, int ms
 static int
 smp_xics_probe(void)
 {
+	xics_request_IPI();
 	return systemcfg->processorCount;
 }
 
diff -urNp linux-371/arch/ppc64/kernel/xics.c linux-372/arch/ppc64/kernel/xics.c
--- linux-371/arch/ppc64/kernel/xics.c
+++ linux-372/arch/ppc64/kernel/xics.c
@@ -1,5 +1,5 @@
 /* 
- * arch/ppc/kernel/xics.c
+ * arch/ppc64/kernel/xics.c
  *
  * Copyright 2000 IBM Corporation.
  *
@@ -13,6 +13,7 @@
 #include <linux/threads.h>
 #include <linux/kernel.h>
 #include <linux/sched.h>
+#include <linux/slab.h>
 #include <asm/prom.h>
 #include <asm/io.h>
 #include <asm/pgtable.h>
@@ -23,35 +24,29 @@
 #include "xics.h"
 #include <asm/ppcdebug.h>
 
-void xics_enable_irq(u_int irq);
-void xics_disable_irq(u_int irq);
-void xics_mask_and_ack_irq(u_int irq);
-void xics_end_irq(u_int irq);
-void xics_set_affinity(unsigned int irq_nr, unsigned long cpumask);
+static unsigned int xics_startup(unsigned int irq);
+static void xics_enable_irq(unsigned int irq);
+static void xics_disable_irq(unsigned int irq);
+static void xics_mask_and_ack_irq(unsigned int irq);
+static void xics_end_irq(unsigned int irq);
+static void xics_set_affinity(unsigned int irq_nr, unsigned long cpumask);
 
 struct hw_interrupt_type xics_pic = {
-	" XICS     ",
-	NULL,
-	NULL,
-	xics_enable_irq,
-	xics_disable_irq,
-	xics_mask_and_ack_irq,
-	xics_end_irq,
-	xics_set_affinity
+	.typename = " XICS     ",
+	.startup = xics_startup,
+	.enable = xics_enable_irq,
+	.disable = xics_disable_irq,
+	.ack = xics_mask_and_ack_irq,
+	.end = xics_end_irq,
+	.set_affinity = xics_set_affinity
 };
 
 struct hw_interrupt_type xics_8259_pic = {
-	" XICS/8259",
-	NULL,
-	NULL,
-	NULL,
-	NULL,
-	xics_mask_and_ack_irq,
-	NULL
+	.typename = " XICS/8259",
+	.ack = xics_mask_and_ack_irq,
 };
 
 #define XICS_IPI		2
-#define XICS_IRQ_OFFSET		0x10
 #define XICS_IRQ_SPURIOUS	0
 
 /* Want a priority other than 0.  Various HW issues require this. */
@@ -73,16 +68,11 @@ struct xics_ipl {
 	} qirr;
 };
 
-struct xics_info {
-	volatile struct xics_ipl *	per_cpu[NR_CPUS];
-};
-
-struct xics_info	xics_info;
+static struct xics_ipl *xics_per_cpu[NR_CPUS];
 
-unsigned long long intr_base = 0;
-int xics_irq_8259_cascade = 0;
-int xics_irq_8259_cascade_real = 0;
-unsigned int default_server = 0xFF;
+static int xics_irq_8259_cascade = 0;
+static int xics_irq_8259_cascade_real = 0;
+static unsigned int default_server = 0xFF;
 unsigned int default_distrib_server = 0;
 
 static inline u32 physmask(u32);
@@ -94,11 +84,6 @@ int ibm_set_xive;
 int ibm_int_on;
 int ibm_int_off;
 
-struct xics_interrupt_node {
-	unsigned long long addr;
-	unsigned long long size;
-} inodes[NR_CPUS*2];	 
-
 typedef struct {
 	int (*xirr_info_get)(int cpu);
 	void (*xirr_info_set)(int cpu, int val);
@@ -109,22 +94,22 @@ typedef struct {
 
 static int pSeries_xirr_info_get(int n_cpu)
 {
-	return (xics_info.per_cpu[n_cpu]->xirr.word);
+	return xics_per_cpu[n_cpu]->xirr.word;
 }
 
 static void pSeries_xirr_info_set(int n_cpu, int value)
 {
-	xics_info.per_cpu[n_cpu]->xirr.word = value;
+	xics_per_cpu[n_cpu]->xirr.word = value;
 }
 
 static void pSeries_cppr_info(int n_cpu, u8 value)
 {
-	xics_info.per_cpu[n_cpu]->xirr.bytes[0] = value;
+	xics_per_cpu[n_cpu]->xirr.bytes[0] = value;
 }
 
-static void pSeries_qirr_info(int n_cpu , u8 value)
+static void pSeries_qirr_info(int n_cpu, u8 value)
 {
-	xics_info.per_cpu[n_cpu]->qirr.bytes[0] = value;
+	xics_per_cpu[n_cpu]->qirr.bytes[0] = value;
 }
 
 static xics_ops pSeries_ops = {
@@ -137,121 +122,244 @@ static xics_ops pSeries_ops = {
 static xics_ops *ops = &pSeries_ops;
 extern xics_ops pSeriesLP_ops;
 
+/*
+ * Stuff for mapping real irq numbers to virtual relatively quickly.
+ * We use a radix tree of degree 64.
+ */
+#define RADIX_BITS	6
+#define RADIX_DEGREE	(1U << RADIX_BITS)
+#define RADIX_MASK	(RADIX_DEGREE - 1)
+
+struct radix_node {
+	void *ptrs[RADIX_DEGREE];
+};
 
-void
-xics_enable_irq(
-	u_int	virq
-	)
+static struct radix_node *radix_root;
+static unsigned int radix_depth;
+static unsigned int radix_max = 1;
+
+static int radix_tree_insert(unsigned int key, void *ptr)
+{
+	struct radix_node *p, *q;
+	unsigned int i, l;
+
+	while (key >= radix_max || radix_depth == 0) {
+		/* add another level... */
+		p = kmalloc(sizeof(struct radix_node), GFP_ATOMIC);
+		if (p == NULL)
+			return -ENOMEM;
+		memset(p, 0, sizeof(struct radix_node));
+		p->ptrs[0] = radix_root;
+		radix_root = p;
+		++radix_depth;
+		radix_max <<= RADIX_BITS;
+	}
+
+	p = radix_root;
+	/* note radix_depth > 0 */
+	for (l = radix_depth; l > 1; --l) {
+		i = (key >> ((l - 1) * RADIX_BITS)) & RADIX_MASK;
+		q = p;
+		p = p->ptrs[i];
+		if (p != NULL)
+			continue;
+		p = kmalloc(sizeof(struct radix_node), GFP_ATOMIC);
+		if (p == NULL)
+			return -ENOMEM;
+		memset(p, 0, sizeof(struct radix_node));
+		q->ptrs[i] = p;
+	}
+
+	p->ptrs[key & RADIX_MASK] = ptr;
+	return 0;
+}
+
+static void *radix_tree_lookup(unsigned int key)
+{
+	struct radix_node *p;
+	unsigned int i, l;
+
+	p = radix_root;
+	for (l = radix_depth; l > 0 && p != NULL; --l) {
+		i = (key >> ((l - 1) * RADIX_BITS)) & RADIX_MASK;
+		p = p->ptrs[i];
+	}
+	return (void *) p;
+}
+
+static unsigned int xics_startup(unsigned int virq)
+{
+	virq = irq_offset_down(virq);
+	if (radix_tree_insert(virt_irq_to_real(virq),
+			      &virt_irq_to_real_map[virq]) == -ENOMEM)
+		printk(KERN_CRIT "Out of memory creating real -> virtual"
+		       " IRQ mapping for irq %u (real 0x%x)\n",
+		       virq, virt_irq_to_real(virq));
+	return 0;	/* return value is ignored */
+}
+
+static unsigned int real_irq_to_virt(unsigned int real_irq)
+{
+	unsigned int *ptr;
+	unsigned int virq;
+
+	ptr = radix_tree_lookup(real_irq);
+	if (ptr == NULL)
+		return NO_IRQ;
+	virq = ptr - virt_irq_to_real_map;
+	if (virq >= NR_IRQS)
+		return NO_IRQ;		/* something has gone badly wrong */
+	return virq;
+}
+
+/*
+ * Find first logical cpu and return its physical cpu number
+ */
+static inline u32 physmask(u32 cpumask)
 {
-	u_int		irq;
-	unsigned long	status;
-	long	        call_status;
-	unsigned int    interrupt_server = default_server;
+	int i;
 
-	irq = virt_irq_to_real(virq - XICS_IRQ_OFFSET);
-	if (irq == XICS_IPI)
-		return;
+	for (i = 0; i < smp_num_cpus; ++i, cpumask >>= 1) {
+		if (cpumask & 1)
+			return get_hard_smp_processor_id(i);
+	}
+
+	printk(KERN_ERR "xics_set_affinity: invalid irq mask\n");
 
+	return default_distrib_server;
+}
+
+static unsigned int get_irq_server(unsigned int irq)
+{
+	unsigned int server;
+	
 #ifdef CONFIG_IRQ_ALL_CPUS
-	if((smp_num_cpus == systemcfg->processorCount) &&
-	   (smp_threads_ready)) {
+	if ((smp_num_cpus == systemcfg->processorCount) &&
+	    (smp_threads_ready)) {
 		/* Retain the affinity setting specified */
-		if (irq_affinity[virq] == 0xffffffff)
-			interrupt_server = default_distrib_server;
+		if (irq_affinity[irq] == 0xffffffff)
+			server = default_distrib_server;
 		else
-			interrupt_server = physmask(irq_affinity[virq]);
-	}
+			server = physmask(irq_affinity[irq]);
+	} else
 #endif
-	call_status = rtas_call(ibm_set_xive, 3, 1, (unsigned long*)&status,
+		server = default_server;
+	return server;
+
+}
+
+static void xics_enable_irq(unsigned int virq)
+{
+	u_int		irq;
+	long	        call_status;
+	unsigned int    interrupt_server;
+
+	irq = virt_irq_to_real(irq_offset_down(virq));
+	if (irq == XICS_IPI)
+		return;
+
+	interrupt_server = get_irq_server(virq);
+	call_status = rtas_call(ibm_set_xive, 3, 1, NULL,
 				irq, interrupt_server, DEFAULT_PRIORITY);
 
-	if( call_status != 0 ) {
-		printk("xics_enable_irq: irq=%x: rtas_call failed; retn=%lx, status=%lx\n",
-		       irq, call_status, status);
+	if (call_status != 0) {
+		printk(KERN_ERR "xics_enable_irq: irq=0x%x: "
+		       "ibm_set_xive returned %lx\n", irq, call_status);
 		return;
 	}
+
 	/* Now unmask the interrupt (often a no-op) */
-	call_status = rtas_call(ibm_int_on, 1, 1, (unsigned long*)&status, 
-				irq);
+	call_status = rtas_call(ibm_int_on, 1, 1, NULL, irq);
 	if( call_status != 0 ) {
-		printk("xics_disable_irq on: irq=%x: rtas_call failed, retn=%lx\n",
-		       irq, call_status);
+		printk(KERN_ERR "xics_enable_irq: irq=%x: ibm_int_on "
+		       "returned %lx\n", irq, call_status);
 		return;
 	}
 }
 
-void
-xics_disable_irq(
-	u_int	virq
-	)
+static void xics_disable_real_irq(unsigned int irq)
 {
-	u_int		irq;
-	unsigned long 	status;
-	long 	        call_status;
+	long call_status;
+	unsigned int server;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
-	call_status = rtas_call(ibm_int_off, 1, 1, (unsigned long*)&status, 
-				irq);
-	if( call_status != 0 ) {
-		printk("xics_disable_irq: irq=%x: rtas_call failed, retn=%lx\n",
-		       irq, call_status);
+	call_status = rtas_call(ibm_int_off, 1, 1, NULL, irq);
+	if (call_status != 0) {
+		printk(KERN_ERR "xics_disable_real_irq: irq=%x: "
+		       "ibm_int_off returned %lx\n", irq, call_status);
 		return;
 	}
+
+	/* Have to set XIVE to 0xff to be able to remove a slot */
+	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq,
+				default_server, 0xff);
+	if (call_status != 0) {
+		printk(KERN_ERR "xics_disable_irq: irq=%x: ibm_set_xive(0xff)"
+		       " returned %lx\n", irq, call_status);
+	}
 }
 
-void
-xics_end_irq(
-	u_int	irq
-	)
+static void xics_disable_irq(unsigned int virq)
+{
+	unsigned int irq;
+
+	irq = virt_irq_to_real(irq_offset_down(virq));
+	xics_disable_real_irq(irq);
+}
+
+static void xics_end_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
 	ops->cppr_info(cpu, 0); /* actually the value overwritten by ack */
 	iosync();
-	ops->xirr_info_set(cpu, ((0xff<<24) | (virt_irq_to_real(irq-XICS_IRQ_OFFSET))));
+	ops->xirr_info_set(cpu, ((0xff<<24) |
+				 (virt_irq_to_real(irq_offset_down(irq)))));
 	iosync();
 }
 
-void
-xics_mask_and_ack_irq(u_int	irq)
+static void xics_mask_and_ack_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
-	if( irq < XICS_IRQ_OFFSET ) {
+	if (irq < NUM_ISA_INTERRUPTS) {
 		i8259_pic.ack(irq);
 		iosync();
-		ops->xirr_info_set(cpu, ((0xff<<24) | xics_irq_8259_cascade_real));
-		iosync();
-	}
-	else {
-		ops->cppr_info(cpu, 0xff);
+		ops->xirr_info_set(cpu, ((0xff<<24) |
+					 xics_irq_8259_cascade_real));
 		iosync();
 	}
 }
 
-int
-xics_get_irq(struct pt_regs *regs)
+int xics_get_irq(struct pt_regs *regs)
 {
-	u_int	cpu = smp_processor_id();
-	u_int	vec;
+	unsigned int cpu = smp_processor_id();
+	unsigned int vec;
 	int irq;
 
 	vec = ops->xirr_info_get(cpu);
 	/*  (vec >> 24) == old priority */
 	vec &= 0x00ffffff;
 	/* for sanity, this had better be < NR_IRQS - 16 */
-	if( vec == xics_irq_8259_cascade_real ) {
+	if (vec == xics_irq_8259_cascade_real) {
 		irq = i8259_irq(cpu);
-		if(irq == -1) {
+		if (irq == -1) {
 			/* Spurious cascaded interrupt.  Still must ack xics */
-                        xics_end_irq(XICS_IRQ_OFFSET + xics_irq_8259_cascade);
+			xics_end_irq(irq_offset_up(xics_irq_8259_cascade));
+
 			irq = -1;
 		}
-	} else if( vec == XICS_IRQ_SPURIOUS ) {
+	} else if (vec == XICS_IRQ_SPURIOUS) {
 		irq = -1;
 	} else {
-		irq = real_irq_to_virt(vec) + XICS_IRQ_OFFSET;
+		irq = real_irq_to_virt(vec);
+		if (irq == NO_IRQ)
+			irq = real_irq_to_virt_slow(vec);
+		if (irq == NO_IRQ) {
+			printk(KERN_ERR "Interrupt 0x%x (real) is invalid,"
+			       " disabling it.\n", vec);
+			xics_disable_real_irq(vec);
+		} else
+			irq = irq_offset_up(irq);
 	}
 	return irq;
 }
@@ -294,15 +402,25 @@ void xics_setup_cpu(void)
 	ops->cppr_info(cpu, 0xff);
 	iosync();
 }
+
+void xics_request_IPI(void)
+{
+	if (request_irq(irq_offset_up(XICS_IPI), xics_ipi_action, 0, "IPI", 0))
+		printk(KERN_CRIT "Unable to get XICS irq 2 for IPI\n");
+}
 #endif /* CONFIG_SMP */
 
-void
-xics_init_IRQ( void )
+void xics_init_IRQ(void)
 {
 	int i;
 	unsigned long intr_size = 0;
 	struct device_node *np;
-	uint *ireg, ilen, indx=0;
+	uint *ireg, ilen, indx = 0;
+	unsigned long intr_base = 0;
+	struct xics_interrupt_node {
+		unsigned long addr;
+		unsigned long size;
+	} inodes[NR_CPUS]; 
 
 	ppc64_boot_msg(0x20, "XICS Init");
 
@@ -379,18 +497,19 @@ nextnode:
 			while (1);
 		}
 		xics_irq_8259_cascade_real = *ireg;
-		xics_irq_8259_cascade = virt_irq_create_mapping(xics_irq_8259_cascade_real);
+		xics_irq_8259_cascade
+			= virt_irq_create_mapping(xics_irq_8259_cascade_real);
 	}
 
 	if (systemcfg->platform == PLATFORM_PSERIES) {
 #ifdef CONFIG_SMP
 		for (i = 0; i < systemcfg->processorCount; ++i) {
-			xics_info.per_cpu[i] =
+			xics_per_cpu[i] =
 			  __ioremap((ulong)inodes[get_hard_smp_processor_id(i)].addr, 
 				  (ulong)inodes[get_hard_smp_processor_id(i)].size, _PAGE_NO_CACHE);
 		}
 #else
-		xics_info.per_cpu[0] = __ioremap((ulong)intr_base, intr_size, _PAGE_NO_CACHE);
+		xics_per_cpu[0] = __ioremap((ulong)intr_base, intr_size, _PAGE_NO_CACHE);
 #endif /* CONFIG_SMP */
 #ifdef CONFIG_PPC_PSERIES
 	/* actually iSeries does not use any of xics...but it has link dependencies
@@ -410,48 +529,23 @@ nextnode:
 
 	ops->cppr_info(0, 0xff);
 	iosync();
-	if (xics_irq_8259_cascade != -1) {
-		if (request_irq(xics_irq_8259_cascade + XICS_IRQ_OFFSET, no_action,
-				0, "8259 cascade", 0))
-			printk(KERN_ERR "xics_init_IRQ: couldn't get 8259 cascade\n");
-		i8259_init();
-	}
 
 #ifdef CONFIG_SMP
-	real_irq_to_virt_map[XICS_IPI] = virt_irq_to_real_map[XICS_IPI] = XICS_IPI;
-	request_irq(XICS_IPI + XICS_IRQ_OFFSET, xics_ipi_action, 0, "IPI", 0);
-	irq_desc[XICS_IPI+XICS_IRQ_OFFSET].status |= IRQ_PER_CPU;
+	virt_irq_to_real_map[XICS_IPI] = XICS_IPI;
+	irq_desc[irq_offset_up(XICS_IPI)].status |= IRQ_PER_CPU;
 #endif
 	ppc64_boot_msg(0x21, "XICS Done");
 }
 
 void xics_isa_init(void)
 {
-	return;
-	if (request_irq(xics_irq_8259_cascade + XICS_IRQ_OFFSET, no_action,
+	if (request_irq(irq_offset_up(xics_irq_8259_cascade), no_action,
 			0, "8259 cascade", 0))
 		printk(KERN_ERR "xics_init_IRQ: couldn't get 8259 cascade\n");
 	i8259_init();
 }
 
-/*
- * Find first logical cpu and return its physical cpu number
- */
-static inline u32 physmask(u32 cpumask)
-{
-	int i;
-
-	for (i = 0; i < smp_num_cpus; ++i, cpumask >>= 1) {
-		if (cpumask & 1)
-			return get_hard_smp_processor_id(i);
-	}
-
-	printk(KERN_ERR "xics_set_affinity: invalid irq mask\n");
-
-	return default_distrib_server;
-}
-
-void xics_set_affinity(unsigned int virq, unsigned long cpumask)
+static void xics_set_affinity(unsigned int virq, unsigned long cpumask)
 {
         irq_desc_t *desc = irq_desc + virq;
 	unsigned int irq;
@@ -460,8 +554,7 @@ void xics_set_affinity(unsigned int virq
 	unsigned long xics_status[2];
 	u32 newmask;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(irq_offset_down(virq));
 	if (irq == XICS_IPI)
 		return;
 
diff -urNp linux-371/arch/ppc64/kernel/xics.h linux-372/arch/ppc64/kernel/xics.h
--- linux-371/arch/ppc64/kernel/xics.h
+++ linux-372/arch/ppc64/kernel/xics.h
@@ -20,5 +20,6 @@ extern struct hw_interrupt_type xics_825
 void xics_init_IRQ(void);
 int xics_get_irq(struct pt_regs *);
 void xics_isa_init(void);
+void xics_request_IPI(void);
 
 #endif /* _PPC_KERNEL_XICS_H */
diff -urNp linux-371/include/asm-ppc64/irq.h linux-372/include/asm-ppc64/irq.h
--- linux-371/include/asm-ppc64/irq.h
+++ linux-372/include/asm-ppc64/irq.h
@@ -20,27 +20,28 @@ extern void enable_irq(unsigned int);
  */
 #define NR_IRQS			512
 
-#define NUM_8259_INTERRUPTS	16
+/* Token to indicate an unassigned or invalid IRQ number */
+#define NO_IRQ			(-1)
 
 /* Interrupt numbers are virtual in case they are sparsely
  * distributed by the hardware.
  */
-#define NR_HW_IRQS		8192
-extern unsigned short real_irq_to_virt_map[NR_HW_IRQS];
-extern unsigned short virt_irq_to_real_map[NR_IRQS];
+extern unsigned int virt_irq_to_real_map[NR_IRQS];
+
 /* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
+ * Returns the virtual irq.
  */
-unsigned long virt_irq_create_mapping(unsigned long real_irq);
+int virt_irq_create_mapping(unsigned int real_irq);
 
-/* These funcs map irqs between real and virtual */
-static inline unsigned long real_irq_to_virt(unsigned long real_irq) {
-	return real_irq_to_virt_map[real_irq];
-}
-static inline unsigned long virt_irq_to_real(unsigned long virt_irq) {
+/* This maps virtual irqs to real */
+static inline unsigned int virt_irq_to_real(int virt_irq)
+{
 	return virt_irq_to_real_map[virt_irq];
 }
 
+/* This maps real irqs to virtual by looking in the virt_irq_to_real_map. */
+extern int real_irq_to_virt_slow(unsigned int real_irq);
+
 /*
  * This gets called from serial.c, which is now used on
  * powermacs as well as prep/chrp boxes.
@@ -51,5 +52,34 @@ static __inline__ int irq_cannonicalize(
 	return irq;
 }
 
+/*
+ * Because many systems have two overlapping names spaces for
+ * interrupts (ISA and XICS for example), and the ISA interrupts
+ * have historically not been easy to renumber, we allow ISA
+ * interrupts to take values 0 - 15, and shift up the remaining
+ * interrupts by 0x10.
+ *
+ * This would be nice to remove at some point as it adds confusion
+ * and adds a nasty end case if any platform native interrupts have
+ * values within 0x10 of the end of that namespace.
+ */
+
+#define NUM_ISA_INTERRUPTS	0x10
+
+extern inline int irq_offset_up(int irq)
+{
+	return(irq + NUM_ISA_INTERRUPTS);
+}
+
+extern inline int irq_offset_down(int irq)
+{
+	return(irq - NUM_ISA_INTERRUPTS);
+}
+
+extern inline int irq_offset_value(void)
+{
+	return NUM_ISA_INTERRUPTS;
+}
+
 #endif /* _ASM_IRQ_H */
 #endif /* __KERNEL__ */
