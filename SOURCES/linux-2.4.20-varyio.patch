--- linux-2.4.20/fs/buffer.c.varyio	2003-04-23 17:39:33.000000000 -0400
+++ linux-2.4.20/fs/buffer.c	2003-04-23 17:43:05.000000000 -0400
@@ -2185,8 +2185,8 @@ static int wait_kio(int rw, int nr, stru
 	err = 0;
 
 	for (i = nr; --i >= 0; ) {
-		iosize += size;
 		tmp = bh[i];
+		iosize += tmp->b_size;
 		if (buffer_locked(tmp)) {
 			wait_on_buffer(tmp);
 		}
@@ -2231,6 +2231,7 @@ int brw_kiovec(int rw, int nr, struct ki
 	struct kiobuf *	iobuf = NULL;
 	struct page *	map;
 	struct buffer_head *tmp, **bhs = NULL;
+	int iosize = size;
 
 	if (!nr)
 		return 0;
@@ -2267,7 +2268,7 @@ int brw_kiovec(int rw, int nr, struct ki
 			}
 			
 			while (length > 0) {
-				blocknr = b[bufind++];
+				blocknr = b[bufind];
 				if (blocknr == -1UL) {
 					if (rw == READ) {
 						/* there was an hole in the filesystem */
@@ -2275,14 +2276,28 @@ int brw_kiovec(int rw, int nr, struct ki
 						flush_dcache_page(map);
 						kunmap(map);
 
+						iosize = size;
 						transferred += size;
 						goto skip_block;
 					} else
 						BUG();
 				}
+				if (iobuf->varyio &&
+				    (!(offset & RAWIO_BLOCKMASK))) {
+					int block_iter;
+					iosize = RAWIO_BLOCKSIZE; 
+					if (iosize > length)
+						iosize = length;
+					for (block_iter = 1; block_iter < iosize / size; block_iter++) {
+						if (blocknr + block_iter != b[bufind + block_iter]) {
+							iosize = size;
+							break;
+						}
+					}
+				}
 				tmp = bhs[bhind++];
 
-				tmp->b_size = size;
+				tmp->b_size = iosize;
 				set_bh_page(tmp, map, offset);
 				tmp->b_this_page = tmp;
 
@@ -2298,7 +2313,11 @@ int brw_kiovec(int rw, int nr, struct ki
 					set_bit(BH_Uptodate, &tmp->b_state);
 
 				atomic_inc(&iobuf->io_count);
-				submit_bh(rw, tmp);
+				if (iobuf->varyio) {
+					tmp->b_blocknr *= size >> 9;
+					submit_bh_blknr(rw, tmp);
+				} else 
+					submit_bh(rw, tmp);
 				/* 
 				 * Wait for IO if we have got too much 
 				 */
@@ -2313,8 +2332,9 @@ int brw_kiovec(int rw, int nr, struct ki
 				}
 
 			skip_block:
-				length -= size;
-				offset += size;
+				bufind += iosize / size;
+				length -= iosize;
+				offset += iosize;
 
 				if (offset >= PAGE_SIZE) {
 					offset = 0;
@@ -3101,6 +3121,7 @@ int brw_kvec_async(int rw, kvec_cb_t cb,
 	int		i;
 
 	struct brw_cb	*brw_cb;
+	int		can_do_varyio = get_blkdev_varyio(dev);
 
 	if (!vec->nr)
 		BUG();
@@ -3150,19 +3171,31 @@ int brw_kvec_async(int rw, kvec_cb_t cb,
 
 		while (length > 0) {
 			struct buffer_head *tmp;
+			int iosize;
+
+			if (can_do_varyio && ((offset & RAWIO_BLOCKMASK) == 0)) {
+				iosize = RAWIO_BLOCKSIZE;
+				if (iosize > length)
+					iosize = length;
+				if (offset+iosize > PAGE_SIZE)
+					iosize = PAGE_SIZE - offset;
+			} else
+				iosize = sector_size;
+			
 			tmp = kmem_cache_alloc(bh_cachep, GFP_NOIO);
 			err = -ENOMEM;
 			if (!tmp)
 				goto error;
 
 			tmp->b_dev = B_FREE;
-			tmp->b_size = sector_size;
+			tmp->b_size = iosize;
 			set_bh_page(tmp, page, offset);
 			tmp->b_this_page = tmp;
 
 			init_buffer(tmp, end_buffer_io_kiobuf_async, NULL);
 			tmp->b_dev = dev;
-			tmp->b_blocknr = blknr++;
+			tmp->b_blocknr = blknr;
+			blknr += (iosize / sector_size);
 			tmp->b_state = (1 << BH_Mapped) | (1 << BH_Lock)
 					| (1 << BH_Req);
 			tmp->b_private = brw_cb;
@@ -3173,8 +3206,8 @@ int brw_kvec_async(int rw, kvec_cb_t cb,
 			}
 
 			brw_cb->bh[brw_cb->nr++] = tmp;
-			length -= sector_size;
-			offset += sector_size;
+			length -= iosize;
+			offset += iosize;
 
 			if (offset >= PAGE_SIZE) {
 				offset = 0;
@@ -3189,8 +3222,12 @@ int brw_kvec_async(int rw, kvec_cb_t cb,
 submit:
 	atomic_set(&brw_cb->io_count, brw_cb->nr+1);
 	/* okay, we've setup all our io requests, now fire them off! */
-	for (i=0; i<brw_cb->nr; i++) 
-		submit_bh(rw, brw_cb->bh[i]);
+	if (can_do_varyio)
+		for (i=0; i<brw_cb->nr; i++) 
+			submit_bh_blknr(rw, brw_cb->bh[i]);
+	else
+		for (i=0; i<brw_cb->nr; i++) 
+			submit_bh(rw, brw_cb->bh[i]);
 	brw_cb_put(brw_cb);
 	run_task_queue(&tq_disk);
 	return 0;
--- linux-2.4.20/fs/iobuf.c.varyio	2003-04-23 17:39:25.000000000 -0400
+++ linux-2.4.20/fs/iobuf.c	2003-04-23 17:43:05.000000000 -0400
@@ -31,6 +31,7 @@ static int kiobuf_init(struct kiobuf *io
 	iobuf->array_len = 0;
 	iobuf->nr_pages = 0;
 	iobuf->locked = 0;
+	iobuf->varyio = 0;
 	iobuf->bh = NULL;
 	iobuf->blocks = NULL;
 	atomic_set(&iobuf->io_count, 0);
--- linux-2.4.20/kernel/ksyms.c.varyio	2003-04-23 17:39:33.000000000 -0400
+++ linux-2.4.20/kernel/ksyms.c	2003-04-23 17:43:05.000000000 -0400
@@ -220,7 +220,7 @@ EXPORT_SYMBOL(bread);
 EXPORT_SYMBOL(__brelse);
 EXPORT_SYMBOL(__bforget);
 EXPORT_SYMBOL(ll_rw_block);
-EXPORT_SYMBOL(submit_bh);
+EXPORT_SYMBOL(__submit_bh);
 EXPORT_SYMBOL(unlock_buffer);
 EXPORT_SYMBOL(__wait_on_buffer);
 EXPORT_SYMBOL(___wait_on_page);
@@ -341,6 +341,7 @@ EXPORT_SYMBOL(init_buffer);
 EXPORT_SYMBOL(refile_buffer);
 EXPORT_SYMBOL(max_sectors);
 EXPORT_SYMBOL(max_readahead);
+EXPORT_SYMBOL(blkdev_varyio);
 
 /* tty routines */
 EXPORT_SYMBOL(tty_hangup);
--- linux-2.4.20/include/linux/blkdev.h.varyio	2003-04-23 17:39:25.000000000 -0400
+++ linux-2.4.20/include/linux/blkdev.h	2003-04-23 17:43:05.000000000 -0400
@@ -243,6 +243,8 @@ extern int * max_sectors[MAX_BLKDEV];
 
 extern int * max_segments[MAX_BLKDEV];
 
+extern char * blkdev_varyio[MAX_BLKDEV];
+
 #define MAX_SEGMENTS 128
 #define MAX_SECTORS 255
 
@@ -296,4 +298,12 @@ static inline unsigned int block_size(kd
 	return retval;
 }
 
+static inline int get_blkdev_varyio(kdev_t dev)
+{
+	int major = MAJOR(dev), minor = MINOR(dev);
+
+	if (blkdev_varyio[major])
+		return blkdev_varyio[major][minor];
+	return 0;
+}
 #endif
--- linux-2.4.20/include/linux/fs.h.varyio	2003-04-23 17:39:34.000000000 -0400
+++ linux-2.4.20/include/linux/fs.h	2003-04-23 17:43:05.000000000 -0400
@@ -1423,7 +1423,15 @@ extern void file_move(struct file *f, st
 extern struct buffer_head * get_hash_table(kdev_t, int, int);
 extern struct buffer_head * getblk(kdev_t, int, int);
 extern void ll_rw_block(int, int, struct buffer_head * bh[]);
-extern void submit_bh(int, struct buffer_head *);
+extern void __submit_bh(int, struct buffer_head *, unsigned long);
+static inline void submit_bh(int rw, struct buffer_head * bh)
+{
+	__submit_bh(rw, bh, bh->b_blocknr * (bh->b_size >> 9));
+}
+static inline void submit_bh_blknr(int rw, struct buffer_head * bh)
+{
+	__submit_bh(rw, bh, bh->b_blocknr);
+}
 extern int is_read_only(kdev_t);
 extern void __brelse(struct buffer_head *);
 static inline void brelse(struct buffer_head *buf)
--- linux-2.4.20/include/linux/iobuf.h.varyio	2003-04-23 17:39:34.000000000 -0400
+++ linux-2.4.20/include/linux/iobuf.h	2003-04-23 17:43:05.000000000 -0400
@@ -28,6 +28,9 @@
 #define KIO_STATIC_PAGES	(KIO_MAX_ATOMIC_IO / (PAGE_SIZE >> 10) + 1)
 #define KIO_MAX_SECTORS		(KIO_MAX_ATOMIC_IO * 2)
 
+#define RAWIO_BLOCKSIZE		4096
+#define RAWIO_BLOCKMASK		(RAWIO_BLOCKSIZE-1)
+
 /* The main kiobuf struct used for all our IO! */
 
 struct kiobuf 
@@ -38,7 +41,8 @@ struct kiobuf 
 	int		length;		/* Number of valid bytes of data */
 
 	unsigned int	locked : 1,	/* If set, pages has been locked */
-			initialized:1;  /* If set, done initialize */
+			initialized:1,  /* If set, done initialize */
+			varyio : 1;	/* If set, do variable size IO */
 
 	struct page **  maplist;
 	struct buffer_head ** bh;
--- linux-2.4.20/drivers/block/cciss.c.varyio	2003-04-23 17:39:26.000000000 -0400
+++ linux-2.4.20/drivers/block/cciss.c	2003-04-23 17:43:05.000000000 -0400
@@ -2935,10 +2935,13 @@ static int __init cciss_init_one(struct 
 	blk_queue_bounce_limit(q, hba[i]->pdev->dma_mask);
 	blk_queue_headactive(q, 0);		
 
+	memset(hba[i]->varyios, 1, sizeof(hba[i]->varyios));
+
 	/* fill in the other Kernel structs */
 	blksize_size[MAJOR_NR+i] = hba[i]->blocksizes;
         hardsect_size[MAJOR_NR+i] = hba[i]->hardsizes;
         read_ahead[MAJOR_NR+i] = READ_AHEAD;
+	blkdev_varyio[MAJOR_NR+i] = hba[i]->varyios;
 
 	/* Set the pointers to queue functions */ 
 	q->back_merge_fn = cpq_back_merge_fn;
--- linux-2.4.20/drivers/block/cciss.h.varyio	2003-04-23 17:39:06.000000000 -0400
+++ linux-2.4.20/drivers/block/cciss.h	2003-04-23 17:43:05.000000000 -0400
@@ -87,6 +87,7 @@ struct ctlr_info 
 	int              sizes[256];
 	int              blocksizes[256];
 	int              hardsizes[256];
+	char		varyios[256];
 	int busy_configuring;
 #ifdef CONFIG_CISS_SCSI_TAPE
 	void *scsi_ctlr; /* ptr to structure containing scsi related stuff */
--- linux-2.4.20/drivers/block/cciss_scsi.h.varyio	2003-04-23 17:39:06.000000000 -0400
+++ linux-2.4.20/drivers/block/cciss_scsi.h	2003-04-23 17:43:05.000000000 -0400
@@ -55,6 +55,7 @@
 	cmd_per_lun:		1,				\
 	use_new_eh_code:	1,				\
 	use_clustering:		DISABLE_CLUSTERING,\
+	vary_io:		1,				\
 }
 
 /*
--- linux-2.4.20/drivers/block/ll_rw_blk.c.varyio	2003-04-23 17:39:32.000000000 -0400
+++ linux-2.4.20/drivers/block/ll_rw_blk.c	2003-04-23 17:43:05.000000000 -0400
@@ -118,6 +118,13 @@ int * max_readahead[MAX_BLKDEV];
  */
 int * max_sectors[MAX_BLKDEV];
 
+/*
+ * blkdev_varyio indicates if variable size IO can be done on a device.
+ *
+ * Currently used for doing variable size IO on RAW devices.
+ */
+char * blkdev_varyio[MAX_BLKDEV];
+
 unsigned long blk_max_low_pfn, blk_max_pfn;
 int blk_nohighio = 0;
 
@@ -1190,11 +1197,11 @@ void generic_make_request (int rw, struc
  * This is is appropriate for IO requests that come from the buffer
  * cache and page cache which (currently) always use aligned blocks.
  */
-void submit_bh(int rw, struct buffer_head * bh)
+void __submit_bh(int rw, struct buffer_head * bh, unsigned long blocknr)
 {
 	int count = bh->b_size >> 9;
 
-	if (!test_bit(BH_Lock, &bh->b_state))
+	if (unlikely(!test_bit(BH_Lock, &bh->b_state)))
 		BUG();
 
 	set_bit(BH_Req, &bh->b_state);
@@ -1205,7 +1212,7 @@ void submit_bh(int rw, struct buffer_hea
 	 * further remap this.
 	 */
 	bh->b_rdev = bh->b_dev;
-	bh->b_rsector = bh->b_blocknr * count;
+	bh->b_rsector = blocknr;
 
 	generic_make_request(rw, bh);
 
--- linux-2.4.20/drivers/char/raw.c.varyio	2003-04-23 17:39:34.000000000 -0400
+++ linux-2.4.20/drivers/char/raw.c	2003-04-23 17:43:05.000000000 -0400
@@ -25,6 +25,7 @@ typedef struct raw_device_data_s {
 	struct block_device *binding;
 	int inuse, sector_size, sector_bits;
 	struct semaphore mutex;
+	unsigned varyio;
 } raw_device_data_t;
 
 static raw_device_data_t raw_devices[256];
@@ -120,6 +121,7 @@ int raw_open(struct inode *inode, struct
 	if (raw_devices[minor].inuse++)
 		goto out;
 
+	raw_devices[minor].varyio = get_blkdev_varyio(rdev);
 	/* 
 	 * Don't interfere with mounted devices: we cannot safely set
 	 * the blocksize on a device which is already mounted.  
@@ -129,6 +131,7 @@ int raw_open(struct inode *inode, struct
 	if (is_mounted(rdev)) {
 		if (blksize_size[MAJOR(rdev)])
 			sector_size = blksize_size[MAJOR(rdev)][MINOR(rdev)];
+		 raw_devices[minor].varyio = 0;
 	} else {
 		if (hardsect_size[MAJOR(rdev)])
 			sector_size = hardsect_size[MAJOR(rdev)][MINOR(rdev)];
@@ -313,8 +316,8 @@ ssize_t	rw_raw_dev(int rw, struct file *
 	err = alloc_kiovec(1, &iobuf);
 	if (err)
 		return err;
+	iobuf->varyio = raw_devices[minor].varyio;
 	
-
 	dev = to_kdev_t(raw_devices[minor].binding->bd_dev);
 	sector_size = raw_devices[minor].sector_size;
 	sector_bits = raw_devices[minor].sector_bits;
--- linux-2.4.20/drivers/scsi/aacraid/linit.c.varyio	2003-04-23 17:39:13.000000000 -0400
+++ linux-2.4.20/drivers/scsi/aacraid/linit.c	2003-04-23 17:43:05.000000000 -0400
@@ -705,6 +705,7 @@ static Scsi_Host_Template driver_templat
 	use_new_eh_code:	1, 
 
 	use_clustering:		ENABLE_CLUSTERING,
+	vary_io:		1,
 };
 
 #include "scsi_module.c"
--- linux-2.4.20/drivers/scsi/hosts.h.varyio	2003-04-23 17:39:14.000000000 -0400
+++ linux-2.4.20/drivers/scsi/hosts.h	2003-04-23 17:43:05.000000000 -0400
@@ -297,6 +297,11 @@ typedef struct	SHT
     unsigned highmem_io:1;
 
     /*
+     * True for drivers which can handle variable length IO
+     */
+    unsigned vary_io:1;
+
+    /*
      * Name of proc directory
      */
     char *proc_name;
--- linux-2.4.20/drivers/scsi/megaraid.h.varyio	2003-04-23 17:39:14.000000000 -0400
+++ linux-2.4.20/drivers/scsi/megaraid.h	2003-04-23 17:43:05.000000000 -0400
@@ -239,7 +239,8 @@
     present:	  	0,		       	/* Present			*/\
     unchecked_isa_dma:	0,		       	/* Default Unchecked ISA DMA	*/\
     use_clustering:   	ENABLE_CLUSTERING, 	/* Enable Clustering		*/\
-	highmem_io:		1, /* enable HIGHMEM I/O */ \
+    highmem_io:		1, /* enable HIGHMEM I/O */ \
+    vary_io: 	1,	\
   }
 #endif
 
--- linux-2.4.20/drivers/scsi/qlogicisp.h.varyio	1999-11-12 07:40:46.000000000 -0500
+++ linux-2.4.20/drivers/scsi/qlogicisp.h	2003-04-23 17:43:05.000000000 -0400
@@ -84,7 +84,8 @@ int isp1020_biosparam(Disk *, kdev_t, in
 	cmd_per_lun:		1,					   \
 	present:		0,					   \
 	unchecked_isa_dma:	0,					   \
-	use_clustering:		DISABLE_CLUSTERING			   \
+	use_clustering:		DISABLE_CLUSTERING,			   \
+	vary_io:		1,					   \
 }
 
 #endif /* _QLOGICISP_H */
--- linux-2.4.20/drivers/scsi/sd.c.varyio	2003-04-23 17:39:28.000000000 -0400
+++ linux-2.4.20/drivers/scsi/sd.c	2003-04-23 17:43:53.000000000 -0400
@@ -95,6 +95,7 @@ static int *sd_sizes;
 static int *sd_blocksizes;
 static int *sd_hardsizes;	/* Hardware sector size */
 static int *sd_max_sectors;
+static char *sd_varyio;
 
 static int check_scsidisk_media_change(kdev_t);
 static int fop_revalidate_scsidisk(kdev_t);
@@ -1147,6 +1148,12 @@ static int sd_init()
 	if (!sd_max_sectors)
 		goto cleanup_max_sectors;
 
+	sd_varyio = kmalloc((sd_template.dev_max << 4), GFP_ATOMIC);
+	if (!sd_varyio)
+		goto cleanup_varyio;
+
+	memset(sd_varyio, 0, (sd_template.dev_max << 4)); 
+
 	for (i = 0; i < sd_template.dev_max << 4; i++) {
 		sd_blocksizes[i] = 1024;
 		sd_hardsizes[i] = 512;
@@ -1211,6 +1218,8 @@ cleanup_gendisks_de_arr:
 	kfree(sd_gendisks);
 	sd_gendisks = NULL;
 cleanup_sd_gendisks:
+	kfree(sd_varyio);
+cleanup_varyio:
 	kfree(sd_max_sectors);
 cleanup_max_sectors:
 	kfree(sd_hardsizes);
@@ -1275,6 +1284,8 @@ static int sd_detect(Scsi_Device * SDp)
 	return 1;
 }
 
+#define SD_DISK_MAJOR(i)	SD_MAJOR((i) >> 4)
+
 static int sd_attach(Scsi_Device * SDp)
 {
         unsigned int devnum;
@@ -1313,6 +1324,14 @@ static int sd_attach(Scsi_Device * SDp)
 	printk("Attached scsi %sdisk %s at scsi%d, channel %d, id %d, lun %d\n",
 	       SDp->removable ? "removable " : "",
 	       nbuff, SDp->host->host_no, SDp->channel, SDp->id, SDp->lun);
+
+	if (SDp->host->hostt->vary_io) {
+		if (blkdev_varyio[SD_DISK_MAJOR(i)] == NULL) {
+			blkdev_varyio[SD_DISK_MAJOR(i)] = 
+				sd_varyio + ((i / SCSI_DISKS_PER_MAJOR) << 8);
+		}
+		memset(blkdev_varyio[SD_DISK_MAJOR(i)] + (devnum << 4), 1, 16);
+	}
 	return 0;
 }
 
@@ -1445,6 +1464,7 @@ static void __exit exit_sd(void)
 		kfree(sd_sizes);
 		kfree(sd_blocksizes);
 		kfree(sd_hardsizes);
+		kfree(sd_varyio);
 		for (i = 0; i < N_USED_SD_MAJORS; i++) {
 			kfree(sd_gendisks[i].de_arr);
 			kfree(sd_gendisks[i].flags);
@@ -1456,6 +1476,7 @@ static void __exit exit_sd(void)
 		blksize_size[SD_MAJOR(i)] = NULL;
 		hardsect_size[SD_MAJOR(i)] = NULL;
 		read_ahead[SD_MAJOR(i)] = 0;
+		blkdev_varyio[SD_MAJOR(i)] = NULL;
 	}
 	sd_template.dev_max = 0;
 	if (sd_gendisks != NULL)    /* kfree tests for 0, but leave explicit */
