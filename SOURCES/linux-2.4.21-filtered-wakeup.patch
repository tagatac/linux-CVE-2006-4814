diff -urNp linux-7060/include/linux/sched.h linux-7065/include/linux/sched.h
--- linux-7060/include/linux/sched.h
+++ linux-7065/include/linux/sched.h
@@ -777,6 +777,7 @@ extern void do_timer(struct pt_regs *);
 #define time_before_eq(a,b)	time_after_eq(b,a)
 
 extern int FASTCALL(wake_up_state(struct task_struct * tsk, unsigned int state));
+extern void FASTCALL(wake_up_filtered(wait_queue_head_t *, void *));
 extern void FASTCALL(__wake_up(wait_queue_head_t *q, unsigned int mode, int nr));
 extern void FASTCALL(__wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr));
 extern void FASTCALL(sleep_on(wait_queue_head_t *q));
diff -urNp linux-7060/include/linux/wait.h linux-7065/include/linux/wait.h
--- linux-7060/include/linux/wait.h
+++ linux-7065/include/linux/wait.h
@@ -43,6 +43,11 @@ struct __wait_queue {
 #endif
 };
 
+struct filtered_wait_queue {
+	void *key;
+	wait_queue_t wait;
+};
+
 /*
  * 'dual' spinlock architecture. Can be switched between spinlock_t and
  * rwlock_t locks via changing this define. Since waitqueues are quite
@@ -157,6 +162,12 @@ typedef struct __wait_queue_head wait_qu
 	task_list:	{ &(name).task_list, &(name).task_list },	\
 			__WAITQUEUE_HEAD_DEBUG_INIT(name)}
 
+#define DEFINE_FILTERED_WAIT(name, p)					\
+	struct filtered_wait_queue name = {				\
+		.key	= p,						\
+		.wait	= __WAITQUEUE_INITIALIZER(name.wait, current),	\
+	}
+
 #define DECLARE_WAIT_QUEUE_HEAD(name) \
 	wait_queue_head_t name = __WAIT_QUEUE_HEAD_INITIALIZER(name)
 
diff -urNp linux-7060/kernel/sched.c linux-7065/kernel/sched.c
--- linux-7060/kernel/sched.c
+++ linux-7065/kernel/sched.c
@@ -1463,6 +1463,23 @@ static inline void __wake_up_common(wait
 	}
 }
 
+void wake_up_filtered(wait_queue_head_t *q, void *key)
+{
+	unsigned long flags;
+	unsigned int mode = TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE;
+	struct filtered_wait_queue *wait, *save;
+	spin_lock_irqsave(&q->lock, flags);
+	list_for_each_entry_safe(wait, save, &q->task_list, wait.task_list) {
+		if (wait->wait.func)
+			wait->wait.func(&wait->wait);
+		else if (wait->key != key)
+			continue;
+		else if (wait->wait.task->state & mode)
+			try_to_wake_up(wait->wait.task, mode, 0, 0);
+	}
+	spin_unlock_irqrestore(&q->lock, flags);
+}
+
 /**
  * __wake_up - wake up threads blocked on a waitqueue.
  * @q: the waitqueue
diff -urNp linux-7060/mm/filemap.c linux-7065/mm/filemap.c
--- linux-7060/mm/filemap.c
+++ linux-7065/mm/filemap.c
@@ -854,7 +854,7 @@ void wakeup_page_waiters(struct page * p
 
 	head = page_waitqueue(page);
 	if (waitqueue_active(head))
-		wake_up(head);
+		wake_up_filtered(head, page);
 }
   
 
@@ -884,9 +884,9 @@ void ___wait_on_page(struct page *page)
 {
 	wait_queue_head_t *waitqueue = page_waitqueue(page);
 	struct task_struct *tsk = current;
-	DECLARE_WAITQUEUE(wait, tsk);
+	DEFINE_FILTERED_WAIT(wait, page);
 
-	add_wait_queue(waitqueue, &wait);
+	add_wait_queue(waitqueue, &wait.wait);
 	do {
 		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 		if (!PageLocked(page))
@@ -895,7 +895,7 @@ void ___wait_on_page(struct page *page)
 		io_schedule();
 	} while (PageLocked(page));
 	__set_task_state(tsk, TASK_RUNNING);
-	remove_wait_queue(waitqueue, &wait);
+	remove_wait_queue(waitqueue, &wait.wait);
 }
 
 /*
@@ -921,7 +921,7 @@ void unlock_page(struct page *page)
 	 * pages are being waited on here.
 	 */
 	if (waitqueue_active(waitqueue))
-		wake_up_all(waitqueue);
+		wake_up_filtered(waitqueue, page);
 }
 
 
@@ -932,12 +932,12 @@ int wait_on_page_timeout(struct page *pa
 {
 	wait_queue_head_t *waitqueue = page_waitqueue(page);
 	struct task_struct *tsk = current;
-	DECLARE_WAITQUEUE(wait, tsk);
+	DEFINE_FILTERED_WAIT(wait, page);
 	
 	if (!PageLocked(page))
 		return 0;
 
-	add_wait_queue(waitqueue, &wait);
+	add_wait_queue(waitqueue, &wait.wait);
 	do {
 		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 		if (!PageLocked(page))
@@ -946,7 +946,7 @@ int wait_on_page_timeout(struct page *pa
 		timeout = schedule_timeout(timeout);
 	} while (PageLocked(page) && timeout);
 	__set_task_state(tsk, TASK_RUNNING);
-	remove_wait_queue(waitqueue, &wait);
+	remove_wait_queue(waitqueue, &wait.wait);
 	return PageLocked(page);
 }
 
@@ -958,9 +958,9 @@ static void __lock_page(struct page *pag
 {
 	wait_queue_head_t *waitqueue = page_waitqueue(page);
 	struct task_struct *tsk = current;
-	DECLARE_WAITQUEUE(wait, tsk);
+	DEFINE_FILTERED_WAIT(wait, page);
 
-	add_wait_queue_exclusive(waitqueue, &wait);
+	add_wait_queue_exclusive(waitqueue, &wait.wait);
 	for (;;) {
 		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 		if (PageLocked(page)) {
@@ -971,7 +971,7 @@ static void __lock_page(struct page *pag
 			break;
 	}
 	__set_task_state(tsk, TASK_RUNNING);
-	remove_wait_queue(waitqueue, &wait);
+	remove_wait_queue(waitqueue, &wait.wait);
 }
 
 /*
