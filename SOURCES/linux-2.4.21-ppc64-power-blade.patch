diff -urNp linux-361/arch/ppc64/boot/ppc32-types.h linux-362/arch/ppc64/boot/ppc32-types.h
--- linux-361/arch/ppc64/boot/ppc32-types.h
+++ linux-362/arch/ppc64/boot/ppc32-types.h
@@ -30,4 +30,10 @@ typedef unsigned int size_t;
 
 #define BITS_PER_LONG 32
 
+typedef struct {
+	__u32 u[4];
+} __attribute((aligned(16))) __vector128;
+
+typedef __vector128 vector128;
+
 #endif /* _PPC64_TYPES_H */
diff -urNp linux-361/arch/ppc64/config.in linux-362/arch/ppc64/config.in
--- linux-361/arch/ppc64/config.in
+++ linux-362/arch/ppc64/config.in
@@ -26,7 +26,7 @@ define_bool CONFIG_SERIAL_CONSOLE y
 choice 'Machine Type'	\
 	"pSeries       		CONFIG_PPC_PSERIES \
 	 iSeries                CONFIG_PPC_ISERIES" CONFIG_PPC_PSERIES
-
+bool 'VMX ( AltiVec ) Support' CONFIG_ALTIVEC
 bool 'Symmetric multi-processing support' CONFIG_SMP
 if [ "$CONFIG_SMP" = "y" ]; then
   bool '  Distribute interrupts on all CPUs by default' CONFIG_IRQ_ALL_CPUS
@@ -46,6 +46,10 @@ bool 'Support for RTAS (RunTime Abstract
      fi
 fi
 
+if [ "$CONFIG_PPC_PSERIES" = "y" ]; then
+   bool 'JS20' CONFIG_JS20
+fi
+
 bool 'Shared kernel/user space addressing' CONFIG_SHARED_MEMORY_ADDRESSING
 
 if [ "$CONFIG_PPC_ISERIES" = "y" -a "$CONFIG_SMP" = "y" ]; then
diff -urNp linux-361/arch/ppc64/kernel/cputable.c linux-362/arch/ppc64/kernel/cputable.c
--- linux-361/arch/ppc64/kernel/cputable.c
+++ linux-362/arch/ppc64/kernel/cputable.c
@@ -30,8 +30,10 @@ extern void __setup_cpu_power4(unsigned 
  */
 #ifdef CONFIG_ALTIVEC
 #define CPU_FTR_ALTIVEC_COMP	CPU_FTR_ALTIVEC
+#define PPC_FEATURE_HAS_ALTIVEC_COMP PPC_FEATURE_HAS_ALTIVEC
 #else
 #define CPU_FTR_ALTIVEC_COMP	0
+#define PPC_FEATURE_HAS_ALTIVEC_COMP    0
 #endif
 
 struct cpu_spec	cpu_specs[] = {
@@ -101,6 +103,24 @@ struct cpu_spec	cpu_specs[] = {
 	    __setup_cpu_power4,
 	    COMMON_PPC64_FW
     },
+    {	/* PPC970 */
+	    0xffff0000, 0x00390000, "PPC970",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP,
+	    COMMON_USER_PPC64 | PPC_FEATURE_HAS_ALTIVEC_COMP,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    },
+    {	 /* PPC970+ */
+	     0xffff0000, 0x003c0000, "PPC970+",
+	     CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	     CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP,
+	     COMMON_USER_PPC64 | PPC_FEATURE_HAS_ALTIVEC_COMP,
+	     128, 128,
+	     __setup_cpu_power4,
+	     COMMON_PPC64_FW
+    },
     {	/* default match */
 	    0x00000000, 0x00000000, "(Power4-Compatible)",
   	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
diff -urNp linux-361/arch/ppc64/kernel/entry.S linux-362/arch/ppc64/kernel/entry.S
--- linux-361/arch/ppc64/kernel/entry.S
+++ linux-362/arch/ppc64/kernel/entry.S
@@ -27,7 +27,8 @@
 #include <linux/errno.h>
 #include <linux/sys.h>
 #include <linux/config.h>
-
+#include <asm/cputable.h>
+	
 #ifdef CONFIG_PPC_ISERIES
 #define DO_SOFT_DISABLE
 #endif
@@ -256,6 +257,11 @@ _GLOBAL(_switch)
 	mflr	r20		/* Return to switch caller */
 	mfmsr	r22
 	li	r6,MSR_FP	/* Disable floating-point */
+#ifdef CONFIG_ALTIVEC
+BEGIN_FTR_SECTION
+	oris	r6,r6,MSR_VEC@h	/* Disable altivec */
+END_FTR_SECTION_IFSET(CPU_FTR_ALTIVEC)
+#endif /* CONFIG_ALTIVEC */
 	andc	r22,r22,r6
 	mtmsrd	r22
 	isync
@@ -383,6 +389,17 @@ restore:	
 	ld	r0,_MSR(r1)
 	andi.	r0,r0,MSR_PR
 	beq+	1f
+#ifdef CONFIG_ALTIVEC
+BEGIN_FTR_SECTION
+	ld	r3,THREAD+VMX_REGS(r13)
+	cmpi	0,r3,0
+	beq	2f
+	ld	r0,_VRSAVE(r3)	
+	mtspr	SPRN_VRSAVE,r0		/* if GPUL, restore VRSAVE reg */
+2:	
+END_FTR_SECTION_IFSET(CPU_FTR_ALTIVEC)
+#endif /* CONFIG_ALTIVEC */	
+	
 	addi	r0,r1,INT_FRAME_SIZE	/* size of frame */
 	std	r0,THREAD+KSP(r13)	/* save kernel stack pointer */
 	std	r1,PACAKSAVE(r4)	/* save exception stack pointer */
diff -urNp linux-361/arch/ppc64/kernel/head.S linux-362/arch/ppc64/kernel/head.S
--- linux-361/arch/ppc64/kernel/head.S
+++ linux-362/arch/ppc64/kernel/head.S
@@ -14,6 +14,10 @@
  *  Adapted for 64bit PowerPC by Dave Engebretsen, Peter Bergner, and
  *    Mike Corrigan {engebret|bergner|mikejc}@us.ibm.com
  *
+ *  VMX/Altivec port from ppc32 (c) IBM 2003
+ *   Denis Joseph Barrow (dj@de.ibm.com,barrow_dj@yahoo.com)
+ *   additional debugging & 2.4-2.5 VMX port 
+ *   Ben Herrenschmidt 	(benh@kernel.crashing.org)
  *  This file contains the low-level support and setup for the
  *  PowerPC-64 platform, including trap and interrupt dispatch.
  *
@@ -38,6 +42,15 @@
 #define DO_SOFT_DISABLE
 #endif
 
+/* copy saved SOFTE bit or EE bit from saved MSR depending
+ * if we are doing soft-disable or not
+ */
+#ifdef DO_SOFT_DISABLE
+#define DO_COPY_EE()	ld	r20,SOFTE(r1)
+#else
+#define DO_COPY_EE()	rldicl	r20,r23,49,63
+#endif
+
 /*
  * hcall interface to pSeries LPAR
  */
@@ -363,9 +376,18 @@ __start_interupts:
 	STD_EXCEPTION_PSERIES( 0xc00, SystemCall )
 	STD_EXCEPTION_PSERIES( 0xd00, SingleStep )
 	STD_EXCEPTION_PSERIES( 0xe00, Trap_0e )
-	STD_EXCEPTION_PSERIES( 0xf00, PerformanceMonitor )
+	. = 0xf00
+	b   PerformanceMonitor_Pseries
+	STD_EXCEPTION_PSERIES( 0xf20, AltiVecUnavailable )
+	. = 0xf90
+	.globl PerformanceMonitor_Pseries
+PerformanceMonitor_Pseries:
+	EXCEPTION_PROLOG_PSERIES( 0xf00, PerformanceMonitor_common )
 	STD_EXCEPTION_PSERIES( 0x1300, InstructionBreakpoint )
+	STD_EXCEPTION_PSERIES( 0x1700, AltiVecAssist )
+	STD_EXCEPTION_PSERIES( 0x1800, ThermalInterrupt)
 
+		
 	/* Space for the naca.  Architected to be located at real address
 	 * 0x4000.  Various tools rely on this location being fixed.
 	 * The first dword of the naca is required by iSeries LPAR to
@@ -551,8 +573,48 @@ __end_stab:
 	STD_EXCEPTION_COMMON( 0xb00, Trap_0b, .UnknownException )
 	STD_EXCEPTION_COMMON( 0xd00, SingleStep, .SingleStepException )
 	STD_EXCEPTION_COMMON( 0xe00, Trap_0e, .UnknownException )
-	STD_EXCEPTION_COMMON(0x1300, InstructionBreakpoint, .InstructionBreakpointException )
 
+	.globl AltiVecUnavailable_common
+AltiVecUnavailable_common:				
+	EXCEPTION_PROLOG_COMMON
+#ifdef CONFIG_ALTIVEC		
+	bne	.load_up_altivec	/* if from user, just load it up */
+#endif	
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	DO_COPY_EE()	
+	li	r6,0xf20
+	bl      .save_remaining_regs
+#ifndef CONFIG_ALTIVEC
+	beq    1f	
+	bl     .IllegalAltiVecInstruction
+	b      .ret_from_except
+1:		
+#endif	
+	bl      .KernelAltiVecUnavailableException
+	BUG_OPCODE
+	
+	.global AltiVecAssist_common
+AltiVecAssist_common:
+	EXCEPTION_PROLOG_COMMON
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	DO_COPY_EE()
+	li	r6,0x1700
+	bl	.save_remaining_regs
+	bl	.AltiVecAssistException
+	b	.ret_from_except
+
+	.global ThermalInterrupt_common
+ThermalInterrupt_common:
+	EXCEPTION_PROLOG_COMMON
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	DO_COPY_EE()	
+	li	r6,0x1800
+	bl      .save_remaining_regs
+	bl	.ThermalInterrupt
+	BUG_OPCODE
+
+		
+	STD_EXCEPTION_COMMON(0x1300, InstructionBreakpoint, .InstructionBreakpointException )
 /*
  * Return from an exception which is handled without calling
  * save_remaining_regs.  The caller is assumed to have done
@@ -613,11 +675,7 @@ DataAccess_common:
 	ld      r4,_DAR(r1)
 	ld      r5,_DSISR(r1)
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)		/* Copy saved SOFTE bit */
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x300
 	bl      .save_remaining_regs
 	bl      .do_page_fault
@@ -639,11 +697,7 @@ DataAccessSLB_common:
 	or.	r3,r3,r3		/* Check return code */
 	beq     fast_exception_return   /* Return if we succeeded */
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x380
 	li	r5,0
 	bl      .save_remaining_regs
@@ -669,11 +723,7 @@ InstructionAccess_common:
 	mr	r4,r22
 	rlwinm	r5,r23,0,4,4		/* We only care about PR in error_code */
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x400
 	bl      .save_remaining_regs
 	bl      .do_page_fault
@@ -689,11 +739,7 @@ InstructionAccessSLB_common:
 	beq     fast_exception_return   /* Return if we succeeded */
 
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x480
 	li	r5,0
 	bl      .save_remaining_regs
@@ -759,11 +805,7 @@ HardwareInterrupt_entry:
 Alignment_common:
 	EXCEPTION_PROLOG_COMMON
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x600
 	bl      .save_remaining_regs
 	bl      .AlignmentException
@@ -773,11 +815,7 @@ Alignment_common:
 ProgramCheck_common:
 	EXCEPTION_PROLOG_COMMON
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x700
 	bl      .save_remaining_regs
 	bl      .ProgramCheckException
@@ -788,11 +826,7 @@ FPUnavailable_common:
 	EXCEPTION_PROLOG_COMMON
 	bne	.load_up_fpu		/* if from user, just load it up */
 	addi	r3,r1,STACK_FRAME_OVERHEAD
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0x800
 	bl      .save_remaining_regs
 	bl      .KernelFPUnavailableException
@@ -809,11 +843,7 @@ SystemCall_common:
 1:
 #endif
 	std	r3,ORIG_GPR3(r1)
-#ifdef DO_SOFT_DISABLE
-	ld	r20,SOFTE(r1)
-#else
-	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
-#endif
+	DO_COPY_EE()
 	li	r6,0xC00
 	bl      .save_remaining_regs
 	bl      .DoSyscall
@@ -1318,6 +1348,16 @@ _GLOBAL(save_remaining_regs)
 	beq	2f			/* Modify THREAD.regs if from user */
 	addi	r24,r1,STACK_FRAME_OVERHEAD
 	std	r24,THREAD+PT_REGS(r13)
+#ifdef CONFIG_ALTIVEC
+BEGIN_FTR_SECTION
+	mfspr	r24,SPRN_VRSAVE		/* if save vrsave register value */
+	addi	r22,r13,THREAD
+	ld	r22,VMX_REGS(r22)
+	cmpi	0,r22,0
+	beq	2f
+	std	r24,_VRSAVE(r22)
+END_FTR_SECTION_IFSET(CPU_FTR_ALTIVEC)
+#endif /* CONFIG_ALTIVEC */	
 2:
 	SET_REG_TO_CONST(r22, MSR_KERNEL)
 
@@ -1648,8 +1688,7 @@ _GLOBAL(disable_kernel_fp)
 	mtmsrd  r3			/* disable use of fpu now */
 	isync
 	blr
-
-
+	
 /*
  * giveup_fpu(tsk)
  * Disable FP for the task given as the argument,
@@ -1686,6 +1725,126 @@ _GLOBAL(giveup_fpu)
 	std	r5,last_task_used_math@l(r4)
 #endif /* CONFIG_SMP */
 	blr
+	
+#ifdef CONFIG_ALTIVEC 
+/*
+ * load_up_altivec(unused, unused, tsk)
+ * Disable Altivec for the task which used altivec previously,
+ * and save its altivec registers in its thread_struct.
+ * Enables Altivec for use in the kernel on return.
+ * On SMP we know the fpu is free, since we give it up every
+ * switch (ie, no lazy save of the altivec registers).
+ * On entry: r13 == 'current' && last_task_used_altivec != 'current'
+ */	
+_STATIC(load_up_altivec)
+	mfmsr	r5
+	mr	r21,r5		/* save old value in case of error */
+	oris	r5,r5,MSR_VEC@h
+	mtmsrd	r5		/* enable use of AltiVec now */
+	isync
+/*
+ * For SMP, we don't do lazy AltiVec switching because it just gets too
+ * horrendously complex, especially when a task switches from one CPU
+ * to another.  Instead we call giveup_altivec in switch_to.
+ */
+#ifndef CONFIG_SMP
+	LOADBASE(r3,last_task_used_altivec)
+	ld	r4,last_task_used_altivec@l(r3)
+	cmpi	0,r4,0
+	beq	1f		
+	addi	r4,r4,THREAD	/* want THREAD of last_task_used_altivec */
+	ld	r5,VMX_REGS(r4)
+	SAVE_32VR(0,r20,r5)
+	MFVSCR(vr0)
+	li	r20,_VSCR
+	STVX(vr0,r20,r5)
+	ld	r5,PT_REGS(r4)
+	ld	r4,_MSR-STACK_FRAME_OVERHEAD(r5)	
+	lis	r20,MSR_VEC@h
+	andc	r4,r4,r20	/* disable altivec for previous task */
+	std	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+1:
+#endif /* CONFIG_SMP */
+	/* enable use of AltiVec after return */
+	addi	r5,r13,THREAD
+	ld	r5,VMX_REGS(r5)
+	cmpi	0,r5,0		/* check for reg save area */
+	bne	3f		/* save area already exists so branch */
+	mr	r20,r3		/* need to save for later */
+	bl	.init_altivec_regs
+	cmpi	0,r3,0		/* check for failure */
+	bne	2f
+
+	/* init_altivec_regs failed */
+	mtmsrd	r21		/* restore original MSR value */
+	isync
+	/* complete the register save before killing the user proc */
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	DO_COPY_EE()
+	li	r6,0xf20	/* trap # is AltiVec Unavailable */
+	bl	.save_remaining_regs
+	bl	.AltiVecMemShortage
+	b	.ret_from_except
+
+	/* init_altivec_regs succeeded */
+2:
+	addi	r5,r13,THREAD
+	std	r3,VMX_REGS(r5)
+	mr	r5,r3
+	
+	mr	r3,r20		
+3:	
+	oris	r23,r23,MSR_VEC@h
+	li	r20,_VSCR
+	LVX(vr0,r20,r5)
+	MTVSCR(vr0)
+	REST_32VR(0,r20,r5)
+#ifndef CONFIG_SMP
+	/* Update last_task_used_altivec to 'current' */
+	std	r13,last_task_used_altivec@l(r3)
+#endif /* CONFIG_SMP */
+	/* restore registers and return */
+	b	fast_exception_return
+/*
+ * giveup_altivec(tsk)
+ * Disable AltiVec for the task given as the argument,
+ * and save the AltiVec registers in its thread_struct.
+ * Enables AltiVec for use in the kernel on return.
+ */		
+_GLOBAL(giveup_altivec)
+	mfmsr	r5
+	oris	r5,r5,MSR_VEC@h
+	mtmsrd	r5			/* enable use of AltiVec now */
+	isync
+	cmpi	0,r3,0
+	beqlr-				/* if no previous owner, done */
+	addi	r3,r3,THREAD		/* want THREAD of task */
+	ld	r6,VMX_REGS(r3)
+	cmpi	0,r6,0
+	beqlr
+	
+	ld	r5,PT_REGS(r3)
+	cmpi	0,r5,0
+	
+	SAVE_32VR(0, r4, r6)
+	MFVSCR(vr0)
+	li	r4,_VSCR
+	STVX(vr0, r4, r6)
+	beq	1f
+	ld	r4,_MSR-STACK_FRAME_OVERHEAD(r5)	
+	lis	r3,MSR_VEC@h
+	andc	r4,r4,r3		/* disable AltiVec for previous task */
+	std	r4,_MSR-STACK_FRAME_OVERHEAD(r5)
+1:
+#ifndef CONFIG_SMP
+	li	r5,0
+	LOADBASE(r4,last_task_used_altivec)
+	std	r5,last_task_used_altivec@l(r4)
+#endif /* CONFIG_SMP */
+	blr
+#endif /* CONFIG_ALTIVEC */
+
+	
 
 #ifdef CONFIG_SMP
 /*
@@ -1771,17 +1930,16 @@ _GLOBAL(__secondary_start)
 	mtspr	SRR0,r3
 	mtspr	SRR1,r4
 	rfid
-#endif /* CONFIG_SMP */
 
 /* 
  * Running with relocation on at this point.  All we want to do is
  * zero the stack back-chain pointer before going into C code.
- */
+ */	
 _GLOBAL(start_secondary_prolog)
 	li	r3,0
 	std	r3,0(r1)                /* Zero the stack frame pointer     */
 	bl	.start_secondary
-
+#endif /* CONFIG_SMP */
 /*
  * This subroutine clobbers r11, r12 and the LR
  */
@@ -1856,8 +2014,8 @@ _STATIC(start_here_pSeries)
 	 * get out of the common spinloop.
 	 */
 	li	r3,1
-	LOADADDR(r5,__secondary_hold_spinloop)
-	tophys(r4,r5)
+	LOADADDR(r4,__secondary_hold_spinloop)
+	sub     r4,r4,r26
 	std     r3,0(r4)
 #endif
 
diff -urNp linux-361/arch/ppc64/kernel/misc.S linux-362/arch/ppc64/kernel/misc.S
--- linux-361/arch/ppc64/kernel/misc.S
+++ linux-362/arch/ppc64/kernel/misc.S
@@ -507,6 +507,9 @@ _GLOBAL(identify_cpu)
  * r3 = data offset (not changed)
  */
 _GLOBAL(do_cpu_ftr_fixups)
+/* Dummy feature section to make sure section exists */	
+BEGIN_FTR_SECTION
+END_FTR_SECTION(0,0)
 	/* Get CPU 0 features */
 	LOADADDR(r6,cur_cpu_spec)
 	sub	r6,r6,r3
diff -urNp linux-361/arch/ppc64/kernel/mk_defs.c linux-362/arch/ppc64/kernel/mk_defs.c
--- linux-361/arch/ppc64/kernel/mk_defs.c
+++ linux-362/arch/ppc64/kernel/mk_defs.c
@@ -181,6 +181,13 @@ main(void)
 	DEFINE(TRAP, STACK_FRAME_OVERHEAD+offsetof(struct pt_regs, trap));
 	DEFINE(SOFTE, STACK_FRAME_OVERHEAD+offsetof(struct pt_regs, softe));
 
+#ifdef CONFIG_ALTIVEC
+	DEFINE(VMX_REGS, offsetof(struct thread_struct, vmx_regs));
+	DEFINE(_VR0, offsetof(struct altivec_regs, vr[0]));
+	DEFINE(_VRSAVE, offsetof(struct altivec_regs, vrsave));
+	DEFINE(_VSCR, offsetof(struct altivec_regs, vscr));
+#endif /* CONFIG_ALTIVEC */
+
 	/*
 	 * These _only_ to be used with {PROM,RTAS}_FRAME_SIZE!!!
 	 */
@@ -196,5 +203,12 @@ main(void)
 	DEFINE(CPU_SPEC_FEATURES, offsetof(struct cpu_spec, cpu_features));
 	DEFINE(CPU_SPEC_SETUP, offsetof(struct cpu_spec, cpu_setup));
 
+	/* About the CPU features table */
+	DEFINE(CPU_SPEC_ENTRY_SIZE, sizeof(struct cpu_spec));
+	DEFINE(CPU_SPEC_PVR_MASK, offsetof(struct cpu_spec, pvr_mask));
+	DEFINE(CPU_SPEC_PVR_VALUE, offsetof(struct cpu_spec, pvr_value));
+	DEFINE(CPU_SPEC_FEATURES, offsetof(struct cpu_spec, cpu_features));
+	DEFINE(CPU_SPEC_SETUP, offsetof(struct cpu_spec, cpu_setup));
+
 	return 0;
 }
diff -urNp linux-361/arch/ppc64/kernel/pSeries_pci.c linux-362/arch/ppc64/kernel/pSeries_pci.c
--- linux-361/arch/ppc64/kernel/pSeries_pci.c
+++ linux-362/arch/ppc64/kernel/pSeries_pci.c
@@ -529,8 +529,20 @@ alloc_phb(struct device_node *dev, char 
 	***************************************************************/
 	} else { 
 		PPCDBG(PPCDBG_PHBINIT, "\tUnknown PHB Type!\n");
-		printk("PCI: Unknown Phb Type!\n");
-		return NULL;
+		if (systemcfg->platform == PLATFORM_PSERIES_LPAR) {
+
+			phb=pci_alloc_pci_controller("PHB UK",phb_type_unknown);
+			if (phb == NULL) return NULL;
+
+			phb->cfg_addr = NULL;
+			phb->cfg_data = NULL; 
+			phb->phb_regs = NULL;
+			phb->chip_regs = NULL;
+		} else {
+			printk("PCI: Unknown Phb Type!\n");
+			return NULL;
+		}
+ 
 	}
 
 	/* Add a linux,phbnum property to the device tree so user code
diff -urNp linux-361/arch/ppc64/kernel/ppc_asm.h linux-362/arch/ppc64/kernel/ppc_asm.h
--- linux-361/arch/ppc64/kernel/ppc_asm.h
+++ linux-362/arch/ppc64/kernel/ppc_asm.h
@@ -44,6 +44,33 @@
 #define REST_16FPRS(n, base)	REST_8FPRS(n, base); REST_8FPRS(n+8, base)
 #define REST_32FPRS(n, base)	REST_16FPRS(n, base); REST_16FPRS(n+16, base)
 
+/*
+ * Once a version of gas that understands the AltiVec instructions
+ * is freely available, we can do this the normal way...  - paulus
+ */
+#define LVX(r,a,b)	.long	(31<<26)+((r)<<21)+((a)<<16)+((b)<<11)+(103<<1)
+#define STVX(r,a,b)	.long	(31<<26)+((r)<<21)+((a)<<16)+((b)<<11)+(231<<1)
+#define MFVSCR(r)	.long	(4<<26)+((r)<<21)+(770<<1)
+#define MTVSCR(r)	.long	(4<<26)+((r)<<11)+(802<<1)
+#define DSSALL		.long	(0x1f<<26)+(0x10<<21)+(0x336<<1)
+
+
+#define SAVE_VR(n,b,base)	li b,_VR0+(16*(n)); STVX(n,b,base)
+#define SAVE_2VR(n,b,base)	SAVE_VR(n,b,base); SAVE_VR(n+1,b,base) 
+#define SAVE_4VR(n,b,base)	SAVE_2VR(n,b,base); SAVE_2VR(n+2,b,base) 
+#define SAVE_8VR(n,b,base)	SAVE_4VR(n,b,base); SAVE_4VR(n+4,b,base) 
+#define SAVE_16VR(n,b,base)	SAVE_8VR(n,b,base); SAVE_8VR(n+8,b,base)
+#define SAVE_32VR(n,b,base)	SAVE_16VR(n,b,base); SAVE_16VR(n+16,b,base)
+#define REST_VR(n,b,base)	li b,_VR0+(16*(n)); LVX(n,b,base)
+#define REST_2VR(n,b,base)	REST_VR(n,b,base); REST_VR(n+1,b,base) 
+#define REST_4VR(n,b,base)	REST_2VR(n,b,base); REST_2VR(n+2,b,base) 
+#define REST_8VR(n,b,base)	REST_4VR(n,b,base); REST_4VR(n+4,b,base) 
+#define REST_16VR(n,b,base)	REST_8VR(n,b,base); REST_8VR(n+8,b,base) 
+#define REST_32VR(n,b,base)	REST_16VR(n,b,base); REST_16VR(n+16,b,base)
+
+
+
+
 #define CHECKANYINT(ra,rb)			\
 	mfspr	rb,SPRG3;		/* Get Paca address */\
 	ld	ra,PACALPPACA+LPPACAANYINT(rb); /* Get pending interrupt flags */\
diff -urNp linux-361/arch/ppc64/kernel/ppc_ksyms.c linux-362/arch/ppc64/kernel/ppc_ksyms.c
--- linux-361/arch/ppc64/kernel/ppc_ksyms.c
+++ linux-362/arch/ppc64/kernel/ppc_ksyms.c
@@ -257,6 +257,9 @@ EXPORT_SYMBOL(device_is_compatible);
 EXPORT_SYMBOL(machine_is_compatible);
 EXPORT_SYMBOL(find_all_nodes);
 EXPORT_SYMBOL(get_property);
+#ifdef CONFIG_JS20
+EXPORT_SYMBOL(is_js20);
+#endif
 
 #ifdef CONFIG_PPC_PSERIES
 EXPORT_SYMBOL(rtas_proc_dir);
diff -urNp linux-361/arch/ppc64/kernel/process.c linux-362/arch/ppc64/kernel/process.c
--- linux-361/arch/ppc64/kernel/process.c
+++ linux-362/arch/ppc64/kernel/process.c
@@ -10,6 +10,9 @@
  *  PowerPC version 
  *    Copyright (C) 1995-1996 Gary Thomas (gdt@linuxppc.org)
  *
+ *  VMX/Altivec port from ppc32 (c) IBM 2003
+ *   Denis Joseph Barrow (dj@de.ibm.com,barrow_dj@yahoo.com)
+ *
  *  This program is free software; you can redistribute it and/or
  *  modify it under the terms of the GNU General Public License
  *  as published by the Free Software Foundation; either version
@@ -46,7 +49,10 @@
 
 int dump_fpu(struct pt_regs *regs, elf_fpregset_t *fpregs);
 
+#ifndef CONFIG_SMP
 struct task_struct *last_task_used_math = NULL;
+struct task_struct *last_task_used_altivec = NULL;
+#endif /* CONFIG_SMP */
 static struct fs_struct init_fs = INIT_FS;
 static struct files_struct init_files = INIT_FILES;
 static struct signal_struct init_signals = INIT_SIGNALS(init_signals);
@@ -72,6 +78,50 @@ extern char __toc_start;
 
 #undef SHOW_TASK_SWITCHES
 
+#ifdef CONFIG_ALTIVEC
+int
+dump_altivec(struct pt_regs *regs, elf_vrregset_t *vrregs)
+{
+	if (regs->msr & MSR_VEC)
+		giveup_altivec(current);
+	memcpy(vrregs, &current->thread.vmx_regs->vr[0], sizeof(*vrregs));
+	return 1;
+}
+
+
+void 
+enable_kernel_altivec(void)
+{
+#ifdef CONFIG_SMP
+	if (current->thread.regs && (current->thread.regs->msr & MSR_VEC))
+		giveup_altivec(current);
+	else
+		giveup_altivec(NULL);	/* just enable AltiVec for kernel - force */
+#else
+	giveup_altivec(last_task_used_altivec);
+#endif /* __SMP __ */
+}
+
+
+struct altivec_regs *
+init_altivec_regs(void)
+{
+	struct altivec_regs * regs;
+
+	regs = (struct altivec_regs *)kmalloc(sizeof(struct altivec_regs), GFP_KERNEL);
+	if (!regs) {
+		printk(KERN_WARNING "init_altivec_regs: insufficient memory\n");
+		return 0;	
+	}
+
+	memset(regs, 0, sizeof(struct altivec_regs));
+	regs->vscr.u[3] = 0x00010000; /* Java mode disabled */
+	
+	return regs;
+}
+#endif /* CONFIG_ALTIVEC */
+
+
 void
 enable_kernel_fp(void)
 {
@@ -121,7 +171,21 @@ struct task_struct *__switch_to(struct t
 	 */
 	if ( prev->thread.regs && (prev->thread.regs->msr & MSR_FP) )
 		giveup_fpu(prev);
-
+#ifdef CONFIG_ALTIVEC	
+	/*
+	 * If the previous thread used altivec in the last quantum
+	 * (thus changing altivec regs) then save them.
+	 * We used to check the VRSAVE register but not all apps
+	 * set it, so we don't rely on it now (and in fact we need
+	 * to save & restore VSCR even if VRSAVE == 0).  -- paulus
+	 *
+	 * On SMP we always save/restore altivec regs just to avoid the
+	 * complexity of changing processors.
+	 *  -- Cort
+	 */
+	if ((prev->thread.regs && (prev->thread.regs->msr & MSR_VEC)))
+		giveup_altivec(prev);
+#endif /* CONFIG_ALTIVEC */	
 	/* prev->last_processor = prev->processor; */
 	current_set[smp_processor_id()].task = new;
 #endif /* CONFIG_SMP */
@@ -145,9 +209,12 @@ void show_regs(struct pt_regs * regs)
 	       regs->msr&MSR_DR ? 1 : 0);
 	printk("TASK = %p[%d] '%s' ",
 	       current, current->pid, current->comm);
-	printk("Last syscall: %ld ", current->thread.last_syscall);
-	printk("\nlast math %p ", last_task_used_math);
-	
+	printk("Last syscall: %ld\n", current->thread.last_syscall);
+#ifndef CONFIG_SMP
+	printk("last math %p last altivec %p", last_task_used_math,
+		last_task_used_altivec);
+#endif
+
 #ifdef CONFIG_SMP
 	/* printk(" CPU: %d last CPU: %d", current->processor,current->last_processor); */
 #endif /* CONFIG_SMP */
@@ -174,16 +241,31 @@ void show_regs(struct pt_regs * regs)
 
 void exit_thread(void)
 {
+#ifndef CONFIG_SMP
 	if (last_task_used_math == current)
 		last_task_used_math = NULL;
+	if (last_task_used_altivec == current)
+		last_task_used_altivec = NULL;
+#endif
+#ifdef CONFIG_ALTIVEC	
+	if (current->thread.vmx_regs) {
+		kfree(current->thread.vmx_regs);
+		current->thread.vmx_regs = 0;
+	}
+#endif
 }
 
 void flush_thread(void)
 {
+#ifndef CONFIG_SMP
 	if (last_task_used_math == current)
 		last_task_used_math = NULL;
+	if (last_task_used_altivec == current)
+		last_task_used_altivec = NULL;
+#endif
 }
 
+
 void
 release_thread(struct task_struct *t)
 {
@@ -263,6 +345,24 @@ copy_thread(int nr, unsigned long clone_
 	p->thread.fpscr = current->thread.fpscr;
 	p->thread.fpexc_mode = current->thread.fpexc_mode;
 
+#ifdef CONFIG_ALTIVEC
+        /*
+         * copy altiVec info - assume lazy altiVec switch
+         * - kumar
+         */
+	if (!current->thread.vmx_regs)
+		return 0;
+        if (regs->msr & MSR_VEC)
+                giveup_altivec(current);
+	p->thread.vmx_regs = init_altivec_regs();
+	if (!p->thread.vmx_regs) {
+		return -ENOMEM;
+	}
+        memcpy(&p->thread.vmx_regs->vr, &current->thread.vmx_regs->vr, sizeof(p->thread.vmx_regs->vr));
+        p->thread.vmx_regs->vscr = current->thread.vmx_regs->vscr;
+        childregs->msr &= ~MSR_VEC;
+#endif /* CONFIG_ALTIVEC */
+ 
 	return 0;
 }
 
@@ -294,8 +394,13 @@ void start_thread(struct pt_regs *regs, 
 	regs->gpr[1] = sp;
 	regs->gpr[2] = toc;
 	regs->msr = MSR_USER64;
+#ifndef CONFIG_SMP
 	if (last_task_used_math == current)
 		last_task_used_math = 0;
+	if (last_task_used_altivec == current)
+		last_task_used_altivec = 0;
+#endif /* CONFIG_SMP */
+        memset(current->thread.fpr, 0, sizeof(current->thread.fpr));
 	current->thread.fpscr = 0;
 }
 
@@ -377,7 +482,10 @@ int sys_execve(unsigned long a0, unsigne
 		goto out;
 	if (regs->msr & MSR_FP)
 		giveup_fpu(current);
-  
+#ifdef CONFIG_ALTIVEC
+        if (regs->msr & MSR_VEC)
+                giveup_altivec(current);
+#endif /* CONFIG_ALTIVEC */
 	error = do_execve(filename, (char **) a1, (char **) a2, regs);
   
 	if (error == 0)
diff -urNp linux-361/arch/ppc64/kernel/prom.c linux-362/arch/ppc64/kernel/prom.c
--- linux-361/arch/ppc64/kernel/prom.c
+++ linux-362/arch/ppc64/kernel/prom.c
@@ -33,6 +33,10 @@
 #include <linux/spinlock.h>
 #include <linux/blk.h>
 
+#ifdef CONFIG_JS20
+int is_js20 = 0;
+#endif
+
 #ifdef DEBUG_YABOOT
 #define call_yaboot(FUNC,...) \
 	do { \
@@ -1367,6 +1371,9 @@ prom_init(unsigned long r3, unsigned lon
 	struct paca_struct *_xPaca = PTRRELOC(&paca[0]);
 	struct prom_t *_prom = PTRRELOC(&prom);
 	char *_cmd_line = PTRRELOC(&cmd_line[0]);
+#ifdef CONFIG_JS20
+	ihandle pci_node;
+#endif	
 
 	/* Default machine type. */
 	_systemcfg->platform = PLATFORM_PSERIES;
@@ -1434,7 +1441,23 @@ prom_init(unsigned long r3, unsigned lon
 #ifdef DEBUG_YABOOT
 	call_yaboot(yaboot->printf, RELOC("Location: 0x11b\n"));
 #endif
-
+	
+#ifdef CONFIG_JS20
+	pci_node = (ihandle)call_prom(RELOC("finddevice"), 1, 1, RELOC("/pci"));
+	if (pci_node != (ihandle)-1) {
+		char model[64];
+		sz = (long)call_prom(RELOC("getprop"), 4, 1, pci_node,
+				    RELOC("compatible"), model, 64);
+		if (sz > 0) {
+			char *c;
+			if (strstr(model, RELOC("U3"))) {
+				RELOC(is_js20) = 1;
+			} else {
+				RELOC(is_js20) = 0;
+			}
+		} 
+	} 
+#endif	
 	/* Get the full OF pathname of the stdout device */
 	p = (char *) mem;
 	memset(p, 0, 256);
diff -urNp linux-361/arch/ppc64/kernel/ptrace.c linux-362/arch/ppc64/kernel/ptrace.c
--- linux-361/arch/ppc64/kernel/ptrace.c
+++ linux-362/arch/ppc64/kernel/ptrace.c
@@ -67,6 +67,32 @@ static inline int put_reg(struct task_st
 	return -EIO;
 }
 
+#ifdef CONFIG_ALTIVEC
+/*
+ * Get contents of AltiVec register state in task TASK
+ */
+static inline int get_vrregs(unsigned long data, struct task_struct *task)
+{
+	if (!task->thread.vmx_regs)
+		return -EIO;
+
+	return (copy_to_user((void *)data, task->thread.vmx_regs,
+			sizeof(struct altivec_regs)) ? -EFAULT : 0 );
+}
+
+/*
+ * Write contents of AltiVec register state into task TASK.
+ */
+static inline int set_vrregs(struct task_struct *task, unsigned long data)
+{
+	if (!task->thread.vmx_regs)
+		return -EIO;
+
+	return (copy_from_user(task->thread.vmx_regs,(void *)data,
+			sizeof(struct altivec_regs)) ? -EFAULT : 0 );
+}
+#endif
+
 static inline void
 set_single_step(struct task_struct *task)
 {
@@ -316,6 +342,23 @@ int sys_ptrace(long request, long pid, l
 		}
 		break;
 	}
+#ifdef CONFIG_ALTIVEC
+	case PPC_PTRACE_GETVRREGS:
+		/* Get the child altivec register state. */
+		if (child->thread.regs->msr & MSR_VEC)
+			giveup_altivec(child);
+		ret = get_vrregs(data, child);
+		break;
+
+	case PPC_PTRACE_SETVRREGS:
+		/* Set the child altivec register state. */
+		/* this is to clear the MSR_VEC bit to force a reload
+		 * of register state from memory */
+		if (child->thread.regs->msr & MSR_VEC)
+			giveup_altivec(child);
+		ret = set_vrregs(child,data);
+		break;
+#endif
 
 	default:
 		ret = -EIO;
diff -urNp linux-361/arch/ppc64/kernel/ptrace32.c linux-362/arch/ppc64/kernel/ptrace32.c
--- linux-361/arch/ppc64/kernel/ptrace32.c
+++ linux-362/arch/ppc64/kernel/ptrace32.c
@@ -31,6 +31,46 @@
 #include <asm/pgtable.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_ALTIVEC
+/*
+ * Get contents of AltiVec register state in task TASK
+ */
+static inline int get_vrregs32(unsigned long data, struct task_struct *task)
+{
+	if (!task->thread.vmx_regs) 
+		return -EIO;
+
+	if(copy_to_user((void *)data,&task->thread.vmx_regs->vr[0],
+			offsetof(struct altivec_regs,vrsave)-
+			offsetof(struct altivec_regs,vr[0])))
+		return -EFAULT;
+	data+=offsetof(struct altivec_regs,vrsave[1])-
+		offsetof(struct altivec_regs,vr[0]);
+	if (put_user(task->thread.vmx_regs->vrsave[1],((u32 *)data)))
+		return -EFAULT;
+	return 0;
+}
+
+/*
+ * Write contents of AltiVec register state into task TASK.
+ */
+static inline int set_vrregs32(struct task_struct *task, unsigned long data)
+{
+	if (!task->thread.vmx_regs) 
+		return -EIO;
+
+	if(copy_from_user(&task->thread.vmx_regs->vr[0],(void *)data,
+			offsetof(struct altivec_regs,vrsave)-
+			  offsetof(struct altivec_regs,vr[0])))
+		return -EFAULT;
+	data+=offsetof(struct altivec_regs,vrsave[1])-
+		offsetof(struct altivec_regs,vr[0]);
+	if (get_user(task->thread.vmx_regs->vrsave[1],((u32 *)data)))
+		return -EFAULT;
+	return 0;
+}
+#endif
+
 /*
  * Set of msr bits that gdb can change on behalf of a process.
  */
@@ -463,6 +503,23 @@ int sys32_ptrace(long request, long pid,
 
 
 
+#ifdef CONFIG_ALTIVEC
+	case PPC_PTRACE_GETVRREGS:
+		/* Get the child altivec register state. */
+		if (child->thread.regs->msr & MSR_VEC)
+			giveup_altivec(child);
+		ret = get_vrregs32((unsigned long)data, child);
+		break;
+
+	case PPC_PTRACE_SETVRREGS:
+		/* Set the child altivec register state. */
+		/* this is to clear the MSR_VEC bit to force a reload
+		 * of register state from memory */
+		if (child->thread.regs->msr & MSR_VEC)
+			giveup_altivec(child);
+		ret = set_vrregs32(child,(unsigned long)data);
+		break;
+#endif
 	default:
 		ret = -EIO;
 		break;
diff -urNp linux-361/arch/ppc64/kernel/setup.c linux-362/arch/ppc64/kernel/setup.c
--- linux-361/arch/ppc64/kernel/setup.c
+++ linux-362/arch/ppc64/kernel/setup.c
@@ -270,8 +270,14 @@ static int show_cpuinfo(struct seq_file 
 	case PV_POWER4p:
 		seq_printf(m, "POWER4+ (gq)\n");
 		break;
+	case PV_POWER4ul:
+		seq_printf(m, "POWER4+ (gpul)\n");
+		break;
 	default:
-		seq_printf(m, "Unknown (%08x)\n", pvr);
+		if (cur_cpu_spec->pvr_mask)
+			seq_printf(m, "%s\n", cur_cpu_spec->cpu_name);
+		else
+			seq_printf(m, "Unknown (%08x)\n", pvr);
 		break;
 	}
 
@@ -281,14 +287,14 @@ static int show_cpuinfo(struct seq_file 
 	 */
 	if (systemcfg->platform != PLATFORM_ISERIES_LPAR) {
 		struct device_node *cpu_node;
-		int *fp;
+		unsigned int *fp;
 
 		cpu_node = find_type_devices("cpu");
 		if (cpu_node) {
-			fp = (int *) get_property(cpu_node, "clock-frequency",
-						  NULL);
+			fp = (unsigned int *) get_property(cpu_node, 	
+					      "clock-frequency", NULL);
 			if (fp)
-				seq_printf(m, "clock\t\t: %dMHz\n",
+				seq_printf(m, "clock\t\t: %uMHz\n",
 					   *fp / 1000000);
 		}
 	}
diff -urNp linux-361/arch/ppc64/kernel/signal.c linux-362/arch/ppc64/kernel/signal.c
--- linux-361/arch/ppc64/kernel/signal.c
+++ linux-362/arch/ppc64/kernel/signal.c
@@ -241,7 +241,9 @@ setup_sigcontext(struct sigcontext *sc, 
 
 	current->thread.saved_msr = regs->msr & ~(MSR_FP | MSR_FE0 | MSR_FE1);
 	regs->msr = current->thread.saved_msr | current->thread.fpexc_mode;
+#ifdef CONFIG_PPC_ISERIES
 	current->thread.saved_softe = regs->softe;
+#endif
 
 	err |= __put_user(&sc->gp_regs, &sc->regs);
 	err |= __copy_to_user(&sc->gp_regs, regs, GP_REGS_SIZE);
@@ -277,7 +279,9 @@ restore_sigcontext(struct pt_regs *regs,
 
 	/* Don't allow the signal handler to change these modulo FE{0,1} */
 	regs->msr = current->thread.saved_msr & ~(MSR_FP | MSR_FE0 | MSR_FE1);
+#ifdef CONFIG_PPC_ISERIES
 	regs->softe = current->thread.saved_softe;
+#endif
 
 	return err;
 }
diff -urNp linux-361/arch/ppc64/kernel/sys_ppc32.c linux-362/arch/ppc64/kernel/sys_ppc32.c
--- linux-361/arch/ppc64/kernel/sys_ppc32.c
+++ linux-362/arch/ppc64/kernel/sys_ppc32.c
@@ -3958,6 +3958,10 @@ asmlinkage long sys32_execve(unsigned lo
 		goto out;
 	if (regs->msr & MSR_FP)
 		giveup_fpu(current);
+#ifdef CONFIG_ALTIVEC
+        if (regs->msr & MSR_VEC)
+                giveup_altivec(current);
+#endif /* CONFIG_ALTIVEC */
 
 	error = do_execve32(filename, (u32*) a1, (u32*) a2, regs);
 
@@ -3978,8 +3982,13 @@ void start_thread32(struct pt_regs* regs
 	regs->nip = nip;
 	regs->gpr[1] = sp;
 	regs->msr = MSR_USER32;
+#ifndef CONFIG_SMP
 	if (last_task_used_math == current)
 		last_task_used_math = 0;
+	if (last_task_used_altivec == current)
+		last_task_used_altivec = 0;
+#endif
+	memset(current->thread.fpr, 0, sizeof(current->thread.fpr));
 	current->thread.fpscr = 0;
 }
 
diff -urNp linux-361/arch/ppc64/kernel/traps.c linux-362/arch/ppc64/kernel/traps.c
--- linux-361/arch/ppc64/kernel/traps.c
+++ linux-362/arch/ppc64/kernel/traps.c
@@ -399,6 +399,36 @@ parse_fpe(siginfo_t *info, struct pt_reg
 	_exception(SIGFPE, info, regs);
 }
 
+#ifndef CONFIG_ALTIVEC
+void IllegalAltiVecInstruction(struct pt_regs *regs)
+{
+	siginfo_t info;
+
+	info.si_signo = SIGILL;
+	info.si_errno = 0;
+	info.si_code = ILL_ILLTRP;
+	info.si_addr = (void *)regs->nip;
+	_exception(SIGILL, &info, regs);
+}
+#endif
+
+#ifdef CONFIG_ALTIVEC
+/* 
+ * Couldn't allocate space for the AltiVec register set for the
+ * current thread.
+ */
+void AltiVecMemShortage(struct pt_regs *regs)
+{
+	siginfo_t info;
+
+	info.si_signo = SIGILL;
+	info.si_errno = 0;
+	info.si_code = ILL_BADSTK;
+	info.si_addr = (void *)regs->nip;
+	_exception(SIGILL, &info, regs);
+}
+#endif
+
 void
 ProgramCheckException(struct pt_regs *regs)
 {
@@ -443,14 +473,55 @@ ProgramCheckException(struct pt_regs *re
 	}
 }
 
- void
+void
 KernelFPUnavailableException(struct pt_regs *regs)
 {
 	printk("Illegal floating point used in kernel (task=0x%016lx, pc=0x%016lx, trap=0x%08x)\n",
-		current, regs->nip, regs->trap);
+		(unsigned long)current, regs->nip, (unsigned int)regs->trap);
 	panic("Unrecoverable FP Unavailable Exception in Kernel");
 }
 
+
+void
+KernelAltiVecUnavailableException(struct pt_regs *regs)
+{
+	printk("Illegal Altivec used in kernel (task=0x%016lx, pc=0x%016lx, trap=0x%08x)\n",
+		(unsigned long)current, regs->nip, (unsigned int)regs->trap);
+	panic("Unrecoverable Altivec Unavailable Exception in Kernel");
+}
+
+void
+AltiVecAssistException(struct pt_regs *regs)
+{
+#ifdef CONFIG_ALTIVEC
+	printk(KERN_INFO "Altivec assist called by %s, switching java mode off\n",
+		current->comm);
+	/* We do this the "hard" way, but that's ok for now, maybe one
+	 * day, we'll have a proper implementation...
+	 */
+	if (regs->msr & MSR_VEC)
+		giveup_altivec(current);
+	current->thread.vmx_regs->vscr.u[3] |= 0x00010000;
+#else
+        siginfo_t info;
+                                                                                                                  
+	printk(KERN_NOTICE "Altivec assist called by %s, no altivec support\n",
+		current->comm);
+                                                                                                                  
+        info.si_signo = SIGTRAP;
+        info.si_errno = 0;
+        info.si_code = 0;
+        info.si_addr = 0;
+        _exception(SIGTRAP, &info, regs);
+#endif /* CONFIG_ALTIVEC */
+}
+
+void
+ThermalInterrupt(struct pt_regs *regs)
+{
+	panic("Thermal interrupt exception not handled !");
+}
+
 void
 SingleStepException(struct pt_regs *regs)
 {
diff -urNp linux-361/arch/ppc64/mm/fault.c linux-362/arch/ppc64/mm/fault.c
--- linux-361/arch/ppc64/mm/fault.c
+++ linux-362/arch/ppc64/mm/fault.c
@@ -59,8 +59,10 @@ extern unsigned long get_srr1(void);
 #endif
 
 /*
- * For 600- and 800-family processors, the error_code parameter is DSISR
- * for a data fault, SRR1 for an instruction fault.
+ * The error_code parameter is
+ *  - DSISR for a non-SLB data access fault,
+ *  - SRR1 & 0x08000000 for a non-SLB instruction access fault
+ *  - 0 any SLB fault.
  */
 void do_page_fault(struct pt_regs *regs, unsigned long address,
 		   unsigned long error_code)
@@ -72,15 +74,6 @@ void do_page_fault(struct pt_regs *regs,
 	unsigned long is_write = error_code & 0x02000000;
 	unsigned long mm_fault_return;
 
-	PPCDBG(PPCDBG_MM, "Entering do_page_fault: addr = 0x%16.16lx, error_code = %lx\n\tregs_trap = %lx, srr0 = %lx, srr1 = %lx\n", address, error_code, regs->trap, get_srr0(), get_srr1());
-	/*
-	 * Fortunately the bit assignments in SRR1 for an instruction
-	 * fault and DSISR for a data fault are mostly the same for the
-	 * bits we are interested in.  But there are some bits which
-	 * indicate errors in DSISR but can validly be set in SRR1.
-	 */
-	if (regs->trap == 0x400)
-		error_code &= 0x48200000;
 
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 	if (debugger_fault_handler && (regs->trap == 0x300 ||
diff -urNp linux-361/arch/ppc64/vmlinux.lds linux-362/arch/ppc64/vmlinux.lds
--- linux-361/arch/ppc64/vmlinux.lds
+++ linux-362/arch/ppc64/vmlinux.lds
@@ -73,6 +73,7 @@ SECTIONS
   __kallsyms : { *(__kallsyms) }
   __stop___kallsyms = .;
 
+  . = ALIGN(16);
   __start___ftr_fixup = .;
   __ftr_fixup : { *(__ftr_fixup) }
   __stop___ftr_fixup = .;
diff -urNp linux-361/include/asm-ppc64/cputable.h linux-362/include/asm-ppc64/cputable.h
--- linux-361/include/asm-ppc64/cputable.h
+++ linux-362/include/asm-ppc64/cputable.h
@@ -142,11 +142,25 @@ extern firmware_feature_t firmware_featu
 	.llong 99b;	 		        \
 	.previous
 
-#define END_FTR_SECTION_IFSET(msk)	END_FTR_SECTION((msk), (msk))
-#define END_FTR_SECTION_IFCLR(msk)	END_FTR_SECTION((msk), 0)
+#else
+
+#define BEGIN_FTR_SECTION		"98:\n"
+#define END_FTR_SECTION(msk, val)		\
+"99:\n"						\
+"	.section __ftr_fixup,\"a\";\n"		\
+"	.align 3;\n"				\
+"	.llong "#msk";\n"			\
+"	.llong "#val";\n"			\
+"	.llong 98b;\n"			        \
+"	.llong 99b;\n"	 		        \
+"	.previous\n"
 
 #endif /* __ASSEMBLY__ */
 
+
+#define END_FTR_SECTION_IFSET(msk)	END_FTR_SECTION((msk), (msk))
+#define END_FTR_SECTION_IFCLR(msk)	END_FTR_SECTION((msk), 0)
+
 #endif /* __ASM_PPC_CPUTABLE_H */
 #endif /* __KERNEL__ */
 
diff -urNp linux-361/include/asm-ppc64/eeh.h linux-362/include/asm-ppc64/eeh.h
--- linux-361/include/asm-ppc64/eeh.h
+++ linux-362/include/asm-ppc64/eeh.h
@@ -25,6 +25,10 @@
 #ifndef _EEH_H
 #define _EEH_H
 
+#ifdef CONFIG_JS20
+#include <asm/system.h>
+#endif
+
 struct pci_dev;
 
 /* I/O addresses are converted to EEH "tokens" such that a driver will cause
@@ -147,11 +151,27 @@ static inline void eeh_memcpy_toio(void 
 	memcpy(vdest, src, n);
 }
 
-/* The I/O macros must handle ISA ports as well as PCI I/O bars.
+/* 
+ * The I/O macros must handle ISA ports as well as PCI I/O bars.
  * ISA does not implement EEH and ISA may not exist in the system.
- * For PCI we check for EEH failures.
+ * If ISA does not exist in the system and an ISA port is specified,
+ * the macros below will not do the I/O.
+ * 
+ * The only exception to this is for the JS20 which must use the
+ * legacy I/O ports for some devices (IDE in particular). However,
+ * JS20 systems do not think they have an ISA bus and thus the
+ * macros below would not permit the I/O without some adjustment. 
+ * Hence the ISA check is relaxed for the JS20 to treat as ISA 
+ * only those devices at addresses below the IDE controller port 
+ * address (0x6c00).
+ *
+ * For PCI devices, EEH failures are checked.
  */
+#ifdef CONFIG_JS20
+#define _IO_IS_ISA(port) ((is_js20) ? ((port) < 0x6c00) : ((port) < 0x10000))
+#else
 #define _IO_IS_ISA(port) ((port) < 0x10000)
+#endif
 #define _IO_HAS_ISA_BUS	(isa_io_base != 0)
 
 static inline u8 eeh_inb(unsigned long port) {
diff -urNp linux-361/include/asm-ppc64/elf.h linux-362/include/asm-ppc64/elf.h
--- linux-361/include/asm-ppc64/elf.h
+++ linux-362/include/asm-ppc64/elf.h
@@ -9,7 +9,9 @@
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
  */
+#include <asm/types.h>
 #include <asm/ptrace.h>
+#include <asm/cputable.h>
 
 #define ELF_NGREG	48	/* includes nip, msr, lr, etc. */
 #define ELF_NFPREG	33	/* includes fpscr */
@@ -40,9 +42,15 @@ typedef elf_greg_t32 elf_gregset_t32[ELF
 # define elf_caddr_t u32
 #endif
 
+/* Floating point registers */
 typedef double elf_fpreg_t;
 typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 
+/* Altivec registers */
+typedef __vector128 elf_vrreg_t;
+typedef elf_vrreg_t elf_vrregset_t[ELF_NVRREG];
+
+
 #ifdef __KERNEL__
 
 /*
@@ -77,7 +85,7 @@ ppc64_elf_core_copy_regs(elf_gregset_t d
    instruction set this cpu supports.  This could be done in userspace,
    but it's not easy, and we've already done it here.  */
 
-#define ELF_HWCAP	(0)
+#define ELF_HWCAP	(cur_cpu_spec->cpu_user_features)
 
 /* This yields a string that ld.so will use to load implementation
    specific libraries for optimization.  This is more specific in
diff -urNp linux-361/include/asm-ppc64/mmu.h linux-362/include/asm-ppc64/mmu.h
--- linux-361/include/asm-ppc64/mmu.h
+++ linux-362/include/asm-ppc64/mmu.h
@@ -180,7 +180,7 @@ typedef struct {
 extern HTAB htab_data;
 
 #include <linux/cache.h>
-#include <asm/spinlock.h>
+#include <linux/spinlock.h>
 typedef struct {
 	spinlock_t lock;
 } ____cacheline_aligned hash_table_lock_t;
diff -urNp linux-361/include/asm-ppc64/mmu_context.h linux-362/include/asm-ppc64/mmu_context.h
--- linux-361/include/asm-ppc64/mmu_context.h
+++ linux-362/include/asm-ppc64/mmu_context.h
@@ -6,7 +6,9 @@
 #include <linux/mm.h>	
 #include <asm/mmu.h>	
 #include <asm/ppcdebug.h>	
-
+#ifdef CONFIG_ALTIVEC
+#include <asm/cputable.h>
+#endif
 /*
  * Copyright (C) 2001 PPC 64 Team, IBM Corp
  *
@@ -146,6 +148,14 @@ static inline void
 switch_mm(struct mm_struct *prev, struct mm_struct *next,
 	  struct task_struct *tsk, int cpu)
 {
+#ifdef CONFIG_ALTIVEC
+	 __asm__ __volatile__(
+		 BEGIN_FTR_SECTION
+		 "\tdssall\n"
+		  "\tsync\n"
+		 END_FTR_SECTION_IFSET(CPU_FTR_ALTIVEC)
+		 ::);
+#endif
 	flush_stab();
 }
 
diff -urNp linux-361/include/asm-ppc64/processor.h linux-362/include/asm-ppc64/processor.h
--- linux-361/include/asm-ppc64/processor.h
+++ linux-362/include/asm-ppc64/processor.h
@@ -317,6 +317,7 @@
 #define	    WRS_SYSTEM		3		/* WDT forced system reset */
 #define	  TSR_PIS		0x08000000	/* PIT Interrupt Status */
 #define	  TSR_FIS		0x04000000	/* FIT Interrupt Status */
+#define SPRN_VRSAVE	0x100	/* Vector Register Save Register */
 #define	SPRN_XER	0x001	/* Fixed Point Exception Register */
 #define	SPRN_ZPR	0x3B0	/* Zone Protection Register */
 
@@ -485,6 +486,7 @@
 #define	PV_ICESTAR	0x0036
 #define	PV_SSTAR	0x0037
 #define	PV_POWER4p	0x0038
+#define PV_POWER4ul	0x0039
 #define	PV_630        	0x0040
 #define	PV_630p	        0x0041
 
@@ -612,8 +614,11 @@ extern long arch_kernel_thread(int (*fn)
 #define MCA_bus 0
 #define MCA_bus__is_a_macro /* for versions in ksyms.c */
 
+#ifndef CONFIG_SMP
 /* Lazy FPU handling on uni-processor */
 extern struct task_struct *last_task_used_math;
+extern struct task_struct *last_task_used_altivec;
+#endif /* CONFIG_SMP */
 
 
 #ifdef __KERNEL__
@@ -656,8 +661,21 @@ struct thread_struct {
 	unsigned long	fpscr;		/* Floating point status (plus pad) */
 	unsigned long	fpexc_mode;	/* Floating-point exception mode */
 	unsigned long	saved_msr;	/* Save MSR across signal handlers */
+#if defined(CONFIG_ALTIVEC) && !defined(__GENKSYMS__)
+	struct altivec_regs *vmx_regs;  /* Pointer to saved vmx_regs */
+#else
 	unsigned long	saved_softe;	/* Ditto for Soft Enable/Disable */
+#endif
+};
+
+#ifdef CONFIG_ALTIVEC
+struct altivec_regs {
+	vector128	vr[32];		/* Complete AltiVec set */
+	vector128	vscr;		/* AltiVec status */
+	u32             vrsave[2];      /* 32 bit vrsave is in vrsave[1] */     
 };
+#endif /* CONFIG_ALTIVEC */
+
 
 #define PPC_FLAG_32BIT		0x01
 #define PPC_FLAG_RUN_LIGHT	RUN_FLAG
diff -urNp linux-361/include/asm-ppc64/ptrace.h linux-362/include/asm-ppc64/ptrace.h
--- linux-361/include/asm-ppc64/ptrace.h
+++ linux-362/include/asm-ppc64/ptrace.h
@@ -141,5 +141,8 @@ struct pt_regs32 {
 #define PPC_PTRACE_PEEKUSR_3264   0x91  /* Read a register (specified by ADDR) out of the "user area" on a 64-bit process from a 32-bit process. */
 #define PPC_PTRACE_POKEUSR_3264   0x90  /* Write DATA into location ADDR within the "user area" on a 64-bit process from a 32-bit process. */
 
+/* Get/set all the altivec registers vr0..vr31, vscr, vrsave, in one go */
+#define PPC_PTRACE_GETVRREGS	18
+#define PPC_PTRACE_SETVRREGS	19
 
 #endif /* _PPC64_PTRACE_H */
diff -urNp linux-361/include/asm-ppc64/smp.h linux-362/include/asm-ppc64/smp.h
--- linux-361/include/asm-ppc64/smp.h
+++ linux-362/include/asm-ppc64/smp.h
@@ -21,9 +21,9 @@
 #include <linux/kernel.h>
 #include <linux/threads.h>	/* for NR_CPUS */
 
-#ifdef CONFIG_SMP
 
 #ifndef __ASSEMBLY__
+#ifdef CONFIG_SMP
 
 #include <asm/paca.h>
 
@@ -59,7 +59,6 @@ extern volatile unsigned long cpu_callin
 
 #define smp_processor_id() (get_paca()->xPacaIndex)
 #define hard_smp_processor_id() (get_paca()->xHwProcNum)
-#define get_hard_smp_processor_id(CPU) (paca[(CPU)].xHwProcNum)
 
 
 
@@ -75,7 +74,8 @@ extern volatile unsigned long cpu_callin
 void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 
-#endif /* __ASSEMBLY__ */
 #endif /* !(CONFIG_SMP) */
+#endif /* __ASSEMBLY__ */
+#define get_hard_smp_processor_id(CPU) (paca[(CPU)].xHwProcNum)
 #endif /* !(_PPC64_SMP_H) */
 #endif /* __KERNEL__ */
diff -urNp linux-361/include/asm-ppc64/system.h linux-362/include/asm-ppc64/system.h
--- linux-361/include/asm-ppc64/system.h
+++ linux-362/include/asm-ppc64/system.h
@@ -63,11 +63,17 @@ extern long _get_L2CR(void);
 extern void _set_L2CR(unsigned long);
 extern void giveup_fpu(struct task_struct *);
 extern void enable_kernel_fp(void);
+extern void giveup_altivec(struct task_struct *);
+extern void load_up_altivec(struct task_struct *);
 extern void cvt_fd(float *from, double *to, unsigned long *fpscr);
 extern void cvt_df(double *from, float *to, unsigned long *fpscr);
 extern int abs(int);
 extern void cacheable_memzero(void *p, unsigned int nb);
 
+#ifdef CONFIG_JS20
+extern int is_js20;
+#endif
+
 struct device_node;
 
 struct task_struct;
diff -urNp linux-361/include/asm-ppc64/systemcfg.h linux-362/include/asm-ppc64/systemcfg.h
--- linux-361/include/asm-ppc64/systemcfg.h
+++ linux-362/include/asm-ppc64/systemcfg.h
@@ -70,6 +70,7 @@ extern struct systemcfg *systemcfg;
 #define PV_ICESTAR      0x0036
 #define PV_SSTAR        0x0037
 #define PV_POWER4p      0x0038
+#define PV_POWER4ul     0x0039
 #define PV_630          0x0040
 #define PV_630p         0x0041
 
diff -urNp linux-361/include/asm-ppc64/user_exports.h linux-362/include/asm-ppc64/user_exports.h
--- linux-361/include/asm-ppc64/user_exports.h
+++ linux-362/include/asm-ppc64/user_exports.h
@@ -72,10 +72,13 @@ struct user_exports {
 #define PLATFORM_ISERIES_LPAR 0x0201
 
 /* Processor types */
+#define PV_NORTHSTAR    0x0033
 #define PV_PULSAR       0x0034
 #define PV_POWER4       0x0035
 #define PV_ICESTAR      0x0036
 #define PV_SSTAR        0x0037
+#define PV_POWER4p      0x0038
+#define PV_POWER4ul     0x0039
 #define PV_630          0x0040
 #define PV_630p         0x0041
 
