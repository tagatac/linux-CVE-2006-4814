diff -urNp linux-1130/Documentation/cachetlb.txt linux-1140/Documentation/cachetlb.txt
--- linux-1130/Documentation/cachetlb.txt
+++ linux-1140/Documentation/cachetlb.txt
@@ -49,17 +49,18 @@ changes occur:
 	page table operations such as what happens during
 	fork, and exec.
 
-3) void flush_tlb_range(struct mm_struct *mm,
+3) void flush_tlb_range(struct vm_area_struct *vma,
 			unsigned long start, unsigned long end)
 
 	Here we are flushing a specific range of (user) virtual
 	address translations from the TLB.  After running, this
 	interface must make sure that any previous page table
-	modifications for the address space 'mm' in the range 'start'
-	to 'end' will be visible to the cpu.  That is, after running,
-	there will be no entries in the TLB for 'mm' for virtual
-	addresses in the range 'start' to 'end'.
+	modifications for the address space 'vma->vm_mm' in the range
+	'start' to 'end' will be visible to the cpu.  That is, after
+	running, here will be no entries in the TLB for 'mm' for
+	virtual addresses in the range 'start' to 'end'.
 
+	The "vma" is the backing store being used for the region.
 	Primarily, this is used for munmap() type operations.
 
 	The interface is provided in hopes that the port can find
@@ -130,9 +131,9 @@ the sequence will be in one of the follo
 	   change_all_page_tables_of(mm);
 	   flush_tlb_mm(mm);
 
-	2) flush_cache_range(mm, start, end);
+	2) flush_cache_range(vma, start, end);
 	   change_range_of_page_tables(mm, start, end);
-	   flush_tlb_range(mm, start, end);
+	   flush_tlb_range(vma, start, end);
 
 	3) flush_cache_page(vma, page);
 	   set_pte(pte_pointer, new_pte_val);
@@ -173,14 +174,15 @@ Here are the routines, one by one:
 	page table operations such as what happens during
 	fork, exit, and exec.
 
-3) void flush_cache_range(struct mm_struct *mm,
+3) void flush_cache_range(struct vm_area_struct *vma,
 			  unsigned long start, unsigned long end)
 
 	Here we are flushing a specific range of (user) virtual
 	addresses from the cache.  After running, there will be no
-	entries in the cache for 'mm' for virtual addresses in the
-	range 'start' to 'end'.
+	entries in the cache for 'vma->vm_mm' for virtual addresses in
+	the range 'start' to 'end'.
 
+	The "vma" is the backing store being used for the region.
 	Primarily, this is used for munmap() type operations.
 
 	The interface is provided in hopes that the port can find
diff -urNp linux-1130/arch/alpha/kernel/smp.c linux-1140/arch/alpha/kernel/smp.c
--- linux-1130/arch/alpha/kernel/smp.c
+++ linux-1140/arch/alpha/kernel/smp.c
@@ -1033,10 +1033,10 @@ flush_tlb_page(struct vm_area_struct *vm
 }
 
 void
-flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
 	/* On the Alpha we always flush the whole user tlb.  */
-	flush_tlb_mm(mm);
+	flush_tlb_mm(vma->vm_mm);
 }
 
 static void
diff -urNp linux-1130/arch/arm/kernel/ecard.c linux-1140/arch/arm/kernel/ecard.c
--- linux-1130/arch/arm/kernel/ecard.c
+++ linux-1140/arch/arm/kernel/ecard.c
@@ -243,6 +243,8 @@ static DECLARE_COMPLETION(ecard_completi
  */
 static void ecard_init_pgtables(struct mm_struct *mm)
 {
+	struct vm_area_struct vma;
+
 	/* We want to set up the page tables for the following mapping:
 	 *  Virtual	Physical
 	 *  0x03000000	0x03000000
@@ -274,8 +276,10 @@ static void ecard_init_pgtables(struct m
 		dst_addr += PGDIR_SIZE;
 	}
 
-	flush_tlb_range(mm, IO_START, IO_START + IO_SIZE);
-	flush_tlb_range(mm, EASI_START, EASI_START + EASI_SIZE);
+	vma.vm_mm = mm;
+
+	flush_tlb_range(&vma, IO_START, IO_START + IO_SIZE);
+	flush_tlb_range(&vma, EASI_START, EASI_START + EASI_SIZE);
 }
 
 static int ecard_init_mm(void)
diff -urNp linux-1130/arch/cris/mm/tlb.c linux-1140/arch/cris/mm/tlb.c
--- linux-1130/arch/cris/mm/tlb.c
+++ linux-1140/arch/cris/mm/tlb.c
@@ -159,10 +159,11 @@ flush_tlb_page(struct vm_area_struct *vm
 /* invalidate a page range */
 
 void
-flush_tlb_range(struct mm_struct *mm, 
+flush_tlb_range(struct vm_area_struct *vma,
 		unsigned long start,
 		unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	int page_id = mm->context;
 	int i;
 	unsigned long flags;
diff -urNp linux-1130/arch/i386/kernel/pci-i386.c linux-1140/arch/i386/kernel/pci-i386.c
--- linux-1130/arch/i386/kernel/pci-i386.c
+++ linux-1140/arch/i386/kernel/pci-i386.c
@@ -380,7 +380,7 @@ int pci_mmap_page_range(struct pci_dev *
 	/* Write-combine setting is ignored, it is changed via the mtrr
 	 * interfaces on this platform.
 	 */
-	if (remap_page_range(vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
+	if (remap_page_range(vma, vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
 			     vma->vm_end - vma->vm_start,
 			     vma->vm_page_prot))
 		return -EAGAIN;
diff -urNp linux-1130/arch/i386/kernel/vm86.c linux-1140/arch/i386/kernel/vm86.c
--- linux-1130/arch/i386/kernel/vm86.c
+++ linux-1140/arch/i386/kernel/vm86.c
@@ -148,7 +148,7 @@ static void mark_screen_rdonly(struct ta
 	mapped = pte = pte_offset_map(pmd, 0xA0000);
 	for (i = 0; i < 32; i++) {
 		if (pte_present(*pte))
-			ptep_set_wrprotect(pte);
+			vm_ptep_set_wrprotect(tsk->mm, pte);
 		pte++;
 	}
 	pte_unmap(mapped);
diff -urNp linux-1130/arch/ia64/ia32/binfmt_elf32.c linux-1140/arch/ia64/ia32/binfmt_elf32.c
--- linux-1130/arch/ia64/ia32/binfmt_elf32.c
+++ linux-1140/arch/ia64/ia32/binfmt_elf32.c
@@ -42,7 +42,7 @@
 #define CLOCKS_PER_SEC	IA32_CLOCKS_PER_SEC
 
 extern void ia64_elf32_init (struct pt_regs *regs);
-extern void put_dirty_page (struct task_struct * tsk, struct page *page, unsigned long address);
+extern void new_put_dirty_page (struct task_struct * tsk, struct vm_area_struct *vma, struct page *page, unsigned long address);
 
 static void elf32_set_personality (void);
 
@@ -199,7 +199,7 @@ ia32_setup_arg_pages (struct linux_binpr
 		struct page *page = bprm->page[i];
 		if (page) {
 			bprm->page[i] = NULL;
-			put_dirty_page(current, page, stack_base);
+			new_put_dirty_page(current, mpnt, page, stack_base);
 		}
 		stack_base += PAGE_SIZE;
 	}
diff -urNp linux-1130/arch/ia64/kernel/pci.c linux-1140/arch/ia64/kernel/pci.c
--- linux-1130/arch/ia64/kernel/pci.c
+++ linux-1140/arch/ia64/kernel/pci.c
@@ -553,7 +553,7 @@ pci_mmap_page_range (struct pci_dev *dev
 	else
 		vma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);
 
-	if (remap_page_range(vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
+	if (remap_page_range(vma, vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
 			     vma->vm_end - vma->vm_start,
 			     vma->vm_page_prot))
 		return -EAGAIN;
diff -urNp linux-1130/arch/ia64/mm/tlb.c linux-1140/arch/ia64/mm/tlb.c
--- linux-1130/arch/ia64/mm/tlb.c
+++ linux-1140/arch/ia64/mm/tlb.c
@@ -133,8 +133,9 @@ local_flush_tlb_all (void)
 }
 
 void
-flush_tlb_range (struct mm_struct *mm, unsigned long start, unsigned long end)
+flush_tlb_range (struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	unsigned long size = end - start;
 	unsigned long nbits;
 
diff -urNp linux-1130/arch/mips/kernel/smp.c linux-1140/arch/mips/kernel/smp.c
--- linux-1130/arch/mips/kernel/smp.c
+++ linux-1140/arch/mips/kernel/smp.c
@@ -301,8 +301,10 @@ static void flush_tlb_range_ipi(void *in
 	local_flush_tlb_range(fd->mm, fd->addr1, fd->addr2);
 }
 
-void flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+void flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	if ((atomic_read(&mm->mm_users) != 1) || (current->mm != mm)) {
 		struct flush_tlb_data fd;
 
diff -urNp linux-1130/arch/mips/mm/loadmmu.c linux-1140/arch/mips/mm/loadmmu.c
--- linux-1130/arch/mips/mm/loadmmu.c
+++ linux-1140/arch/mips/mm/loadmmu.c
@@ -26,7 +26,7 @@ void (*_copy_page)(void * to, void * fro
 void (*_flush_cache_all)(void);
 void (*___flush_cache_all)(void);
 void (*_flush_cache_mm)(struct mm_struct *mm);
-void (*_flush_cache_range)(struct mm_struct *mm, unsigned long start,
+void (*_flush_cache_range)(struct vm_area_struct *vma, unsigned long start,
 			  unsigned long end);
 void (*_flush_cache_page)(struct vm_area_struct *vma, unsigned long page);
 void (*_flush_cache_sigtramp)(unsigned long addr);
diff -urNp linux-1130/arch/mips/mm/umap.c linux-1140/arch/mips/mm/umap.c
--- linux-1130/arch/mips/mm/umap.c
+++ linux-1140/arch/mips/mm/umap.c
@@ -95,7 +95,7 @@ remove_mapping (struct task_struct *task
 
 	down_write (&task->mm->mmap_sem);
 	dir = pgd_offset (task->mm, start);
-	flush_cache_range (task->mm, beg, end);
+	flush_cache_range (task->mm->mmap, beg, end);
 	while (start < end){
 		remove_mapping_pmd_range (dir, start, end - start);
 		start = (start + PGDIR_SIZE) & PGDIR_MASK;
@@ -192,7 +192,7 @@ vmap_pmd_range (pmd_t *pmd, unsigned lon
 }
 
 int
-vmap_page_range (unsigned long from, unsigned long size, unsigned long vaddr)
+vmap_page_range (struct vm_area_struct *vma, unsigned long from, unsigned long size, unsigned long vaddr)
 {
 	int error = 0;
 	pgd_t * dir;
@@ -201,7 +201,7 @@ vmap_page_range (unsigned long from, uns
 
 	vaddr -= from;
 	dir = pgd_offset(current->mm, from);
-	flush_cache_range(current->mm, beg, end);
+	flush_cache_range(vma, beg, end);
 	while (from < end) {
 		pmd_t *pmd = pmd_alloc(current->mm, dir, from);
 		error = -ENOMEM;
diff -urNp linux-1130/arch/mips64/kernel/smp.c linux-1140/arch/mips64/kernel/smp.c
--- linux-1130/arch/mips64/kernel/smp.c
+++ linux-1140/arch/mips64/kernel/smp.c
@@ -301,8 +301,10 @@ static void flush_tlb_range_ipi(void *in
 	local_flush_tlb_range(fd->mm, fd->addr1, fd->addr2);
 }
 
-void flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+void flush_tlb_range(struct vma_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	if ((atomic_read(&mm->mm_users) != 1) || (current->mm != mm)) {
 		struct flush_tlb_data fd;
 
diff -urNp linux-1130/arch/mips64/mm/loadmmu.c linux-1140/arch/mips64/mm/loadmmu.c
--- linux-1130/arch/mips64/mm/loadmmu.c
+++ linux-1140/arch/mips64/mm/loadmmu.c
@@ -27,7 +27,7 @@ void (*_copy_page)(void * to, void * fro
 void (*_flush_cache_all)(void);
 void (*___flush_cache_all)(void);
 void (*_flush_cache_mm)(struct mm_struct *mm);
-void (*_flush_cache_range)(struct mm_struct *mm, unsigned long start,
+void (*_flush_cache_range)(struct vm_area_struct *vma, unsigned long start,
                            unsigned long end);
 void (*_flush_cache_page)(struct vm_area_struct *vma, unsigned long page);
 void (*_flush_cache_sigtramp)(unsigned long addr);
diff -urNp linux-1130/arch/mips64/mm/r4xx0.c linux-1140/arch/mips64/mm/r4xx0.c
--- linux-1130/arch/mips64/mm/r4xx0.c
+++ linux-1140/arch/mips64/mm/r4xx0.c
@@ -749,8 +749,7 @@ static void r4k_flush_cache_range_s16d16
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s16d16i16();
@@ -785,8 +784,7 @@ static void r4k_flush_cache_range_s32d16
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s32d16i16();
@@ -821,8 +819,7 @@ static void r4k_flush_cache_range_s64d16
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s64d16i16();
@@ -857,8 +854,7 @@ static void r4k_flush_cache_range_s128d1
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s128d16i16();
@@ -893,8 +889,7 @@ static void r4k_flush_cache_range_s32d32
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s32d32i32();
@@ -929,8 +924,7 @@ static void r4k_flush_cache_range_s64d32
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s64d32i32();
@@ -965,8 +959,7 @@ static void r4k_flush_cache_range_s128d3
 #ifdef DEBUG_CACHE
 	printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
 #endif
-	vma = find_vma(mm, start);
-	if(vma) {
+	if (vma) {
 		if (CPU_CONTEXT(smp_processor_id(), mm) !=
 				CPU_CONTEXT(smp_processor_id(), current->mm)) {
 			r4k_flush_cache_all_s128d32i32();
@@ -988,10 +981,12 @@ static void r4k_flush_cache_range_s128d3
 	}
 }
 
-static void r4k_flush_cache_range_d16i16(struct mm_struct *mm,
+static void r4k_flush_cache_range_d16i16(struct vm_area_struct *vma,
 					 unsigned long start,
 					 unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	if (CPU_CONTEXT(smp_processor_id(), mm) != 0) {
 #ifdef DEBUG_CACHE
 		printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
@@ -1000,10 +995,12 @@ static void r4k_flush_cache_range_d16i16
 	}
 }
 
-static void r4k_flush_cache_range_d32i32(struct mm_struct *mm,
+static void r4k_flush_cache_range_d32i32(struct vm_area_struct *vma,
 					 unsigned long start,
 					 unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	if (CPU_CONTEXT(smp_processor_id(), mm) != 0) {
 #ifdef DEBUG_CACHE
 		printk("crange[%d,%08lx,%08lx]", (int)mm->context, start, end);
diff -urNp linux-1130/arch/mips64/mm/umap.c linux-1140/arch/mips64/mm/umap.c
--- linux-1130/arch/mips64/mm/umap.c
+++ linux-1140/arch/mips64/mm/umap.c
@@ -86,7 +86,7 @@ static inline void remove_mapping_pmd_ra
  * This routine is called from the page fault handler to remove a
  * range of active mappings at this point
  */
-void remove_mapping (struct task_struct *task, unsigned long start,
+void remove_mapping (struct vm_area_struct *vma, struct task_struct *task, unsigned long start,
 		     unsigned long end)
 {
 	unsigned long beg = start;
@@ -94,13 +94,13 @@ void remove_mapping (struct task_struct 
 
 	down_write (&task->mm->mmap_sem);
 	dir = pgd_offset (task->mm, start);
-	flush_cache_range (task->mm, beg, end);
+	flush_cache_range (vma, beg, end);
 	while (start < end){
 		remove_mapping_pmd_range (dir, start, end - start);
 		start = (start + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	}
-	flush_tlb_range (task->mm, beg, end);
+	flush_tlb_range (vma, beg, end);
 	up_write (&task->mm->mmap_sem);
 }
 
@@ -190,7 +190,7 @@ static inline int vmap_pmd_range (pmd_t 
 	return 0;
 }
 
-int vmap_page_range (unsigned long from, unsigned long size,
+int vmap_page_range (struct vm_area_struct *vma, unsigned long from, unsigned long size,
 		     unsigned long vaddr)
 {
 	int error = 0;
@@ -200,7 +200,7 @@ int vmap_page_range (unsigned long from,
 
 	vaddr -= from;
 	dir = pgd_offset(current->mm, from);
-	flush_cache_range(current->mm, beg, end);
+	flush_cache_range(vma, beg, end);
 	while (from < end) {
 		pmd_t *pmd = pmd_alloc(current->mm, dir, from);
 		error = -ENOMEM;
@@ -212,6 +212,6 @@ int vmap_page_range (unsigned long from,
 		from = (from + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	}
-	flush_tlb_range(current->mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 	return error;
 }
diff -urNp linux-1130/arch/ppc/kernel/pci.c linux-1140/arch/ppc/kernel/pci.c
--- linux-1130/arch/ppc/kernel/pci.c
+++ linux-1140/arch/ppc/kernel/pci.c
@@ -1642,7 +1642,7 @@ int pci_mmap_page_range(struct pci_dev *
 	__pci_mmap_set_flags(dev, vma, mmap_state);
 	__pci_mmap_set_pgprot(dev, vma, mmap_state, write_combine);
 
-	ret = remap_page_range(vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
+	ret = remap_page_range(vma, vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
 			       vma->vm_end - vma->vm_start, vma->vm_page_prot);
 
 	return ret;
diff -urNp linux-1130/arch/ppc/mm/tlb.c linux-1140/arch/ppc/mm/tlb.c
--- linux-1130/arch/ppc/mm/tlb.c
+++ linux-1140/arch/ppc/mm/tlb.c
@@ -36,7 +36,7 @@
  *  - flush_tlb_all() flushes all processes TLBs
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *
  * since the hardware hash table functions as an extension of the
  * tlb as far as the linux tables are concerned, flush it too.
@@ -50,6 +50,8 @@
 void
 local_flush_tlb_all(void)
 {
+	struct vm_area_struct vma;
+
 	/* aargh!!! */
 	/*
 	 * Just flush the kernel part of the address space, that's
@@ -58,7 +60,8 @@ local_flush_tlb_all(void)
 	 * we can and should dispense with flush_tlb_all().
 	 *  -- paulus.
 	 */
-	local_flush_tlb_range(&init_mm, TASK_SIZE, ~0UL);
+	vma.vm_mm = &init_mm;
+	local_flush_tlb_range(&vma, TASK_SIZE, ~0UL);
 
 #ifdef CONFIG_SMP
 	smp_send_tlb_invalidate(0);
@@ -81,9 +84,12 @@ local_flush_tlb_mm(struct mm_struct *mm)
 	if (mm->map_count) {
 		struct vm_area_struct *mp;
 		for (mp = mm->mmap; mp != NULL; mp = mp->vm_next)
-			local_flush_tlb_range(mm, mp->vm_start, mp->vm_end);
-	} else
-		local_flush_tlb_range(mm, 0, TASK_SIZE);
+			local_flush_tlb_range(mp, mp->vm_start, mp->vm_end);
+	} else {
+		struct vm_area_struct vma;
+		vma.vm_mm = mm;
+		local_flush_tlb_range(&vma, 0, TASK_SIZE);
+	}
 
 #ifdef CONFIG_SMP
 	smp_send_tlb_invalidate(0);
@@ -120,8 +126,9 @@ local_flush_tlb_page(struct vm_area_stru
  * the corresponding HPTE.
  */
 void
-local_flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	pmd_t *pmd;
 	pte_t *pte;
 	unsigned long pmd_end;
diff -urNp linux-1130/arch/ppc64/kernel/pci.c linux-1140/arch/ppc64/kernel/pci.c
--- linux-1130/arch/ppc64/kernel/pci.c
+++ linux-1140/arch/ppc64/kernel/pci.c
@@ -818,7 +818,7 @@ int pci_mmap_page_range(struct pci_dev *
 	__pci_mmap_set_flags(dev, vma, mmap_state);
 	__pci_mmap_set_pgprot(dev, vma, mmap_state, write_combine);
 
-	ret = remap_page_range(vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
+	ret = remap_page_range(vma, vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
 			       vma->vm_end - vma->vm_start, vma->vm_page_prot);
 
 	return ret;
diff -urNp linux-1130/arch/ppc64/kernel/proc_pmc.c linux-1140/arch/ppc64/kernel/proc_pmc.c
--- linux-1130/arch/ppc64/kernel/proc_pmc.c
+++ linux-1140/arch/ppc64/kernel/proc_pmc.c
@@ -1073,7 +1073,7 @@ static int nacamap_mmap( struct file *fi
 	if ((vma->vm_end - vma->vm_start) > dp->size)
 		return -EINVAL;
 
-	remap_page_range( vma->vm_start, __pa(dp->data), dp->size, vma->vm_page_prot );
+	remap_page_range(vma, vma->vm_start, __pa(dp->data), dp->size, vma->vm_page_prot );
 	return 0;
 }
 
diff -urNp linux-1130/arch/ppc64/mm/init.c linux-1140/arch/ppc64/mm/init.c
--- linux-1130/arch/ppc64/mm/init.c
+++ linux-1140/arch/ppc64/mm/init.c
@@ -270,9 +270,9 @@ static void map_io_page(unsigned long ea
 
 #ifndef CONFIG_PPC_ISERIES
 int
-io_remap_page_range(unsigned long from, unsigned long to, unsigned long size, pgprot_t prot)
+io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long to, unsigned long size, pgprot_t prot)
 {
-	return remap_page_range(from, eeh_token_to_phys(to), size, prot);
+	return remap_page_range(vma, from, eeh_token_to_phys(to), size, prot);
 }
 #endif
 
diff -urNp linux-1130/arch/s390x/kernel/exec32.c linux-1140/arch/s390x/kernel/exec32.c
--- linux-1130/arch/s390x/kernel/exec32.c
+++ linux-1140/arch/s390x/kernel/exec32.c
@@ -32,7 +32,7 @@
 #endif
 
 
-extern void put_dirty_page(struct task_struct * tsk, struct page *page, unsigned long address);
+extern void new_put_dirty_page(struct task_struct * tsk, struct vm_area_struct *vma, struct page *page, unsigned long address);
 
 #undef STACK_TOP
 #define STACK_TOP TASK31_SIZE
@@ -73,7 +73,7 @@ int setup_arg_pages32(struct linux_binpr
 		struct page *page = bprm->page[i];
 		if (page) {
 			bprm->page[i] = NULL;
-			put_dirty_page(current,page,stack_base);
+			new_put_dirty_page(current,mpnt,page,stack_base);
 		}
 		stack_base += PAGE_SIZE;
 	}
diff -urNp linux-1130/arch/sh/mm/cache-sh4.c linux-1140/arch/sh/mm/cache-sh4.c
--- linux-1130/arch/sh/mm/cache-sh4.c
+++ linux-1140/arch/sh/mm/cache-sh4.c
@@ -295,7 +295,7 @@ void flush_cache_mm(struct mm_struct *mm
  * Flushing the cache lines for U0 only isn't enough.
  * We need to flush for P1 too, which may contain aliases.
  */
-void flush_cache_range(struct mm_struct *mm, unsigned long start,
+void flush_cache_range(struct vm_area_struct *vma, unsigned long start,
 		       unsigned long end)
 {
 	/*
diff -urNp linux-1130/arch/sh/mm/fault.c linux-1140/arch/sh/mm/fault.c
--- linux-1130/arch/sh/mm/fault.c
+++ linux-1140/arch/sh/mm/fault.c
@@ -370,9 +370,11 @@ void flush_tlb_page(struct vm_area_struc
 	}
 }
 
-void flush_tlb_range(struct mm_struct *mm, unsigned long start,
+void flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 		     unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	if (mm->context != NO_CONTEXT) {
 		unsigned long flags;
 		int size;
diff -urNp linux-1130/arch/sparc/kernel/smp.c linux-1140/arch/sparc/kernel/smp.c
--- linux-1130/arch/sparc/kernel/smp.c
+++ linux-1140/arch/sparc/kernel/smp.c
@@ -170,23 +170,27 @@ void smp_flush_tlb_mm(struct mm_struct *
 	}
 }
 
-void smp_flush_cache_range(struct mm_struct *mm, unsigned long start,
+void smp_flush_cache_range(struct vm_area_struct *vma, unsigned long start,
 			   unsigned long end)
 {
-	if(mm->context != NO_CONTEXT) {
+	struct mm_struct *mm = vma->vm_mm;
+
+	if (mm->context != NO_CONTEXT) {
 		if(mm->cpu_vm_mask != (1 << smp_processor_id()))
-			xc3((smpfunc_t) BTFIXUP_CALL(local_flush_cache_range), (unsigned long) mm, start, end);
-		local_flush_cache_range(mm, start, end);
+			xc3((smpfunc_t) BTFIXUP_CALL(local_flush_cache_range), (unsigned long) vma, start, end);
+		local_flush_cache_range(vma, start, end);
 	}
 }
 
-void smp_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+void smp_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			 unsigned long end)
 {
-	if(mm->context != NO_CONTEXT) {
+	struct mm_struct *mm = vma->vm_mm;
+
+	if (mm->context != NO_CONTEXT) {
 		if(mm->cpu_vm_mask != (1 << smp_processor_id()))
-			xc3((smpfunc_t) BTFIXUP_CALL(local_flush_tlb_range), (unsigned long) mm, start, end);
-		local_flush_tlb_range(mm, start, end);
+			xc3((smpfunc_t) BTFIXUP_CALL(local_flush_tlb_range), (unsigned long) vma, start, end);
+		local_flush_tlb_range(vma, start, end);
 	}
 }
 
diff -urNp linux-1130/arch/sparc/mm/generic.c linux-1140/arch/sparc/mm/generic.c
--- linux-1130/arch/sparc/mm/generic.c
+++ linux-1140/arch/sparc/mm/generic.c
@@ -1,4 +1,4 @@
-/* $Id: generic.c,v 1.13 2001/07/17 16:17:33 anton Exp $
+/* $Id: generic.c,v 1.13.2.1 2001/12/21 04:58:23 davem Exp $
  * generic.c: Generic Sparc mm routines that are not dependent upon
  *            MMU type but are Sparc specific.
  *
@@ -75,18 +75,18 @@ static inline int io_remap_pmd_range(pmd
 	return 0;
 }
 
-int io_remap_page_range(unsigned long from, unsigned long offset, unsigned long size, pgprot_t prot, int space)
+int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long offset, unsigned long size, pgprot_t prot, int space)
 {
 	int error = 0;
 	pgd_t * dir;
 	unsigned long beg = from;
 	unsigned long end = from + size;
-	struct mm_struct *mm = current->mm;
+	struct mm_struct *mm = vma->vm_mm;
 
 	prot = __pgprot(pg_iobits);
 	offset -= from;
 	dir = pgd_offset(mm, from);
-	flush_cache_range(mm, beg, end);
+	flush_cache_range(vma, beg, end);
 
 	spin_lock(&mm->page_table_lock);
 	while (from < end) {
@@ -102,6 +102,6 @@ int io_remap_page_range(unsigned long fr
 	}
 	spin_unlock(&mm->page_table_lock);
 
-	flush_tlb_range(current->mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 	return error;
 }
diff -urNp linux-1130/arch/sparc/mm/hypersparc.S linux-1140/arch/sparc/mm/hypersparc.S
--- linux-1130/arch/sparc/mm/hypersparc.S
+++ linux-1140/arch/sparc/mm/hypersparc.S
@@ -1,4 +1,4 @@
-/* $Id: hypersparc.S,v 1.17 2000/07/16 21:48:52 anton Exp $
+/* $Id: hypersparc.S,v 1.17.2.1 2001/12/21 04:58:23 davem Exp $
  * hypersparc.S: High speed Hypersparc mmu/cache operations.
  *
  * Copyright (C) 1997 David S. Miller (davem@caip.rutgers.edu)
@@ -74,6 +74,7 @@ hypersparc_flush_cache_mm_out:
 
 	/* The things we do for performance... */
 hypersparc_flush_cache_range:
+	ld	[%o0 + 0x0], %o0		/* XXX vma->vm_mm, GROSS XXX */
 #ifndef CONFIG_SMP
 	ld	[%o0 + AOFF_mm_context], %g1
 	cmp	%g1, -1
@@ -283,6 +284,7 @@ hypersparc_flush_tlb_mm_out:
 	 sta	%g5, [%g1] ASI_M_MMUREGS
 
 hypersparc_flush_tlb_range:
+	ld	[%o0 + 0x00], %o0	/* XXX vma->vm_mm GROSS XXX */
 	mov	SRMMU_CTX_REG, %g1
 	ld	[%o0 + AOFF_mm_context], %o3
 	lda	[%g1] ASI_M_MMUREGS, %g5
diff -urNp linux-1130/arch/sparc/mm/srmmu.c linux-1140/arch/sparc/mm/srmmu.c
--- linux-1130/arch/sparc/mm/srmmu.c
+++ linux-1140/arch/sparc/mm/srmmu.c
@@ -572,14 +572,14 @@ static void srmmu_get_task_struct(struct
 /* tsunami.S */
 extern void tsunami_flush_cache_all(void);
 extern void tsunami_flush_cache_mm(struct mm_struct *mm);
-extern void tsunami_flush_cache_range(struct mm_struct *mm, unsigned long start, unsigned long end);
+extern void tsunami_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end);
 extern void tsunami_flush_cache_page(struct vm_area_struct *vma, unsigned long page);
 extern void tsunami_flush_page_to_ram(unsigned long page);
 extern void tsunami_flush_page_for_dma(unsigned long page);
 extern void tsunami_flush_sig_insns(struct mm_struct *mm, unsigned long insn_addr);
 extern void tsunami_flush_tlb_all(void);
 extern void tsunami_flush_tlb_mm(struct mm_struct *mm);
-extern void tsunami_flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end);
+extern void tsunami_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end);
 extern void tsunami_flush_tlb_page(struct vm_area_struct *vma, unsigned long page);
 extern void tsunami_setup_blockops(void);
 
@@ -618,7 +618,7 @@ static void swift_update_mmu_cache(struc
 /* swift.S */
 extern void swift_flush_cache_all(void);
 extern void swift_flush_cache_mm(struct mm_struct *mm);
-extern void swift_flush_cache_range(struct mm_struct *mm,
+extern void swift_flush_cache_range(struct vm_area_struct *vma,
 				    unsigned long start, unsigned long end);
 extern void swift_flush_cache_page(struct vm_area_struct *vma, unsigned long page);
 extern void swift_flush_page_to_ram(unsigned long page);
@@ -626,7 +626,7 @@ extern void swift_flush_page_for_dma(uns
 extern void swift_flush_sig_insns(struct mm_struct *mm, unsigned long insn_addr);
 extern void swift_flush_tlb_all(void);
 extern void swift_flush_tlb_mm(struct mm_struct *mm);
-extern void swift_flush_tlb_range(struct mm_struct *mm,
+extern void swift_flush_tlb_range(struct vm_area_struct *vma,
 				  unsigned long start, unsigned long end);
 extern void swift_flush_tlb_page(struct vm_area_struct *vma, unsigned long page);
 
@@ -722,8 +722,9 @@ static void cypress_flush_cache_mm(struc
 	FLUSH_END
 }
 
-static void cypress_flush_cache_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+static void cypress_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	register unsigned long a, b, c, d, e, f, g;
 	unsigned long flags, faddr;
 	int octx;
@@ -863,8 +864,9 @@ static void cypress_flush_tlb_mm(struct 
 	FLUSH_END
 }
 
-static void cypress_flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+static void cypress_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	unsigned long size;
 
 	FLUSH_BEGIN(mm)
@@ -906,7 +908,7 @@ static void cypress_flush_tlb_page(struc
 /* viking.S */
 extern void viking_flush_cache_all(void);
 extern void viking_flush_cache_mm(struct mm_struct *mm);
-extern void viking_flush_cache_range(struct mm_struct *mm, unsigned long start,
+extern void viking_flush_cache_range(struct vm_area_struct *vma, unsigned long start,
 				     unsigned long end);
 extern void viking_flush_cache_page(struct vm_area_struct *vma,
 				    unsigned long page);
@@ -917,13 +919,13 @@ extern void viking_flush_page(unsigned l
 extern void viking_mxcc_flush_page(unsigned long page);
 extern void viking_flush_tlb_all(void);
 extern void viking_flush_tlb_mm(struct mm_struct *mm);
-extern void viking_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+extern void viking_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				   unsigned long end);
 extern void viking_flush_tlb_page(struct vm_area_struct *vma,
 				  unsigned long page);
 extern void sun4dsmp_flush_tlb_all(void);
 extern void sun4dsmp_flush_tlb_mm(struct mm_struct *mm);
-extern void sun4dsmp_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+extern void sun4dsmp_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				   unsigned long end);
 extern void sun4dsmp_flush_tlb_page(struct vm_area_struct *vma,
 				  unsigned long page);
@@ -931,14 +933,14 @@ extern void sun4dsmp_flush_tlb_page(stru
 /* hypersparc.S */
 extern void hypersparc_flush_cache_all(void);
 extern void hypersparc_flush_cache_mm(struct mm_struct *mm);
-extern void hypersparc_flush_cache_range(struct mm_struct *mm, unsigned long start, unsigned long end);
+extern void hypersparc_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end);
 extern void hypersparc_flush_cache_page(struct vm_area_struct *vma, unsigned long page);
 extern void hypersparc_flush_page_to_ram(unsigned long page);
 extern void hypersparc_flush_page_for_dma(unsigned long page);
 extern void hypersparc_flush_sig_insns(struct mm_struct *mm, unsigned long insn_addr);
 extern void hypersparc_flush_tlb_all(void);
 extern void hypersparc_flush_tlb_mm(struct mm_struct *mm);
-extern void hypersparc_flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end);
+extern void hypersparc_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end);
 extern void hypersparc_flush_tlb_page(struct vm_area_struct *vma, unsigned long page);
 extern void hypersparc_setup_blockops(void);
 
@@ -1596,8 +1598,10 @@ static void turbosparc_flush_cache_mm(st
 	FLUSH_END
 }
 
-static void turbosparc_flush_cache_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+static void turbosparc_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	FLUSH_BEGIN(mm)
 	flush_user_windows();
 	turbosparc_idflash_clear();
@@ -1647,8 +1651,10 @@ static void turbosparc_flush_tlb_mm(stru
 	FLUSH_END
 }
 
-static void turbosparc_flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+static void turbosparc_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	FLUSH_BEGIN(mm)
 	srmmu_flush_whole_tlb();
 	FLUSH_END
@@ -1994,7 +2000,7 @@ extern unsigned long srmmu_fault;
 		iaddr = &(insn); \
 		daddr = &(dest); \
 		*iaddr = SPARC_BRANCH((unsigned long) daddr, (unsigned long) iaddr); \
-	} while(0);
+	} while (0)
 
 static void __init patch_window_trap_handlers(void)
 {
diff -urNp linux-1130/arch/sparc/mm/swift.S linux-1140/arch/sparc/mm/swift.S
--- linux-1130/arch/sparc/mm/swift.S
+++ linux-1140/arch/sparc/mm/swift.S
@@ -1,4 +1,4 @@
-/* $Id: swift.S,v 1.7 2000/07/16 21:48:52 anton Exp $
+/* $Id: swift.S,v 1.7.2.2 2002/01/08 11:10:29 davem Exp $
  * swift.S: MicroSparc-II mmu/cache operations.
  *
  * Copyright (C) 1999 David S. Miller (davem@redhat.com)
@@ -106,6 +106,7 @@ swift_flush_cache_mm_out:
 
 	.globl	swift_flush_cache_range
 swift_flush_cache_range:
+	ld	[%o0 + 0x0], %o0		/* XXX vma->vm_mm, GROSS XXX */
 	sub	%o2, %o1, %o2
 	sethi	%hi(4096), %o3
 	cmp	%o2, %o3
diff -urNp linux-1130/arch/sparc/mm/tsunami.S linux-1140/arch/sparc/mm/tsunami.S
--- linux-1130/arch/sparc/mm/tsunami.S
+++ linux-1140/arch/sparc/mm/tsunami.S
@@ -1,4 +1,4 @@
-/* $Id: tsunami.S,v 1.6 2000/07/16 21:48:52 anton Exp $
+/* $Id: tsunami.S,v 1.6.2.1 2001/12/21 04:58:23 davem Exp $
  * tsunami.S: High speed MicroSparc-I mmu/cache operations.
  *
  * Copyright (C) 1997 David S. Miller (davem@caip.rutgers.edu)
@@ -23,9 +23,9 @@
 
 	/* Sliiick... */
 tsunami_flush_cache_page:
+tsunami_flush_cache_range:
 	ld	[%o0 + 0x0], %o0	/* XXX vma->vm_mm, GROSS XXX */
 tsunami_flush_cache_mm:
-tsunami_flush_cache_range:
 	ld	[%o0 + AOFF_mm_context], %g2
 	cmp	%g2, -1
 	be	tsunami_flush_cache_out
diff -urNp linux-1130/arch/sparc/mm/viking.S linux-1140/arch/sparc/mm/viking.S
--- linux-1130/arch/sparc/mm/viking.S
+++ linux-1140/arch/sparc/mm/viking.S
@@ -1,4 +1,4 @@
-/* $Id: viking.S,v 1.18 2000/07/16 21:48:52 anton Exp $
+/* $Id: viking.S,v 1.18.2.1 2001/12/21 04:58:23 davem Exp $
  * viking.S: High speed Viking cache/mmu operations
  *
  * Copyright (C) 1997  Eddie C. Dost  (ecd@skynet.be)
@@ -108,11 +108,11 @@ viking_mxcc_flush_page:
 	 nop
 
 viking_flush_cache_page:
+viking_flush_cache_range:
 #ifndef CONFIG_SMP
 	ld	[%o0 + 0x0], %o0		/* XXX vma->vm_mm, GROSS XXX */
 #endif
 viking_flush_cache_mm:
-viking_flush_cache_range:
 #ifndef CONFIG_SMP
 	ld	[%o0 + AOFF_mm_context], %g1
 	cmp	%g1, -1
@@ -150,6 +150,7 @@ viking_flush_tlb_mm:
 #endif
 
 viking_flush_tlb_range:
+	ld	[%o0 + 0x00], %o0	/* XXX vma->vm_mm GROSS XXX */
 	mov	SRMMU_CTX_REG, %g1
 	ld	[%o0 + AOFF_mm_context], %o3
 	lda	[%g1] ASI_M_MMUREGS, %g5
@@ -240,6 +241,7 @@ sun4dsmp_flush_tlb_range:
 	tst	%g5
 	bne	3f
 	 mov	SRMMU_CTX_REG, %g1
+	ld	[%o0 + 0x00], %o0	/* XXX vma->vm_mm GROSS XXX */
 	ld	[%o0 + AOFF_mm_context], %o3
 	lda	[%g1] ASI_M_MMUREGS, %g5
 	sethi	%hi(~((1 << SRMMU_PGDIR_SHIFT) - 1)), %o4
diff -urNp linux-1130/arch/sparc64/kernel/pci.c linux-1140/arch/sparc64/kernel/pci.c
--- linux-1130/arch/sparc64/kernel/pci.c
+++ linux-1140/arch/sparc64/kernel/pci.c
@@ -518,7 +518,7 @@ static void __pci_mmap_set_pgprot(struct
 	/* Our io_remap_page_range takes care of this, do nothing. */
 }
 
-extern int io_remap_page_range(unsigned long from, unsigned long offset,
+extern int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long offset,
 			       unsigned long size, pgprot_t prot, int space);
 
 /* Perform the actual remap of the pages for a PCI device mapping, as appropriate
@@ -542,7 +542,7 @@ int pci_mmap_page_range(struct pci_dev *
 	__pci_mmap_set_flags(dev, vma, mmap_state);
 	__pci_mmap_set_pgprot(dev, vma, mmap_state);
 
-	ret = io_remap_page_range(vma->vm_start,
+	ret = io_remap_page_range(vma, vma->vm_start,
 				  (vma->vm_pgoff << PAGE_SHIFT |
 				   (write_combine ? 0x1UL : 0x0UL)),
 				  vma->vm_end - vma->vm_start, vma->vm_page_prot, 0);
diff -urNp linux-1130/arch/sparc64/kernel/smp.c linux-1140/arch/sparc64/kernel/smp.c
--- linux-1130/arch/sparc64/kernel/smp.c
+++ linux-1140/arch/sparc64/kernel/smp.c
@@ -951,9 +951,11 @@ void smp_flush_tlb_mm(struct mm_struct *
 	}
 }
 
-void smp_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+void smp_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			 unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
+
 	{
 		u32 ctx = CTX_HWBITS(mm->context);
 		int cpu = smp_processor_id();
diff -urNp linux-1130/arch/sparc64/kernel/sparc64_ksyms.c linux-1140/arch/sparc64/kernel/sparc64_ksyms.c
--- linux-1130/arch/sparc64/kernel/sparc64_ksyms.c
+++ linux-1140/arch/sparc64/kernel/sparc64_ksyms.c
@@ -88,7 +88,7 @@ extern int (*handle_mathemu)(struct pt_r
 extern long sparc32_open(const char * filename, int flags, int mode);
 extern int register_ioctl32_conversion(unsigned int cmd, int (*handler)(unsigned int, unsigned int, unsigned long, struct file *));
 extern int unregister_ioctl32_conversion(unsigned int cmd);
-extern int io_remap_page_range(unsigned long from, unsigned long offset, unsigned long size, pgprot_t prot, int space);
+extern int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long offset, unsigned long size, pgprot_t prot, int space);
                 
 extern int __ashrdi3(int, int);
 
diff -urNp linux-1130/arch/sparc64/mm/generic.c linux-1140/arch/sparc64/mm/generic.c
--- linux-1130/arch/sparc64/mm/generic.c
+++ linux-1140/arch/sparc64/mm/generic.c
@@ -1,4 +1,4 @@
-/* $Id: generic.c,v 1.17 2001/04/09 04:08:06 davem Exp $
+/* $Id: generic.c,v 1.17.2.1 2001/12/21 04:58:23 davem Exp $
  * generic.c: Generic Sparc mm routines that are not dependent upon
  *            MMU type but are Sparc specific.
  *
@@ -111,18 +111,18 @@ static inline int io_remap_pmd_range(pmd
 	return 0;
 }
 
-int io_remap_page_range(unsigned long from, unsigned long offset, unsigned long size, pgprot_t prot, int space)
+int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long offset, unsigned long size, pgprot_t prot, int space)
 {
 	int error = 0;
 	pgd_t * dir;
 	unsigned long beg = from;
 	unsigned long end = from + size;
-	struct mm_struct *mm = current->mm;
+	struct mm_struct *mm = vma->vm_mm;
 
 	prot = __pgprot(pg_iobits);
 	offset -= from;
 	dir = pgd_offset(mm, from);
-	flush_cache_range(mm, beg, end);
+	flush_cache_range(vma, beg, end);
 
 	spin_lock(&mm->page_table_lock);
 	while (from < end) {
@@ -138,6 +138,6 @@ int io_remap_page_range(unsigned long fr
 	}
 	spin_unlock(&mm->page_table_lock);
 
-	flush_tlb_range(current->mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 	return error;
 }
diff -urNp linux-1130/arch/sparc64/mm/init.c linux-1140/arch/sparc64/mm/init.c
--- linux-1130/arch/sparc64/mm/init.c
+++ linux-1140/arch/sparc64/mm/init.c
@@ -298,6 +298,82 @@ void __init early_pgtable_allocfail(char
 #define BASE_PAGE_SIZE 8192
 static pmd_t *prompmd;
 
+/* When shared+writable mmaps of files go away, we lose all dirty
+ * page state, so we have to deal with D-cache aliasing here.
+ *
+ * This code relies on the fact that flush_cache_range() is always
+ * called for an area composed by a single VMA.  It also assumes that
+ * the MM's page_table_lock is held.
+ */
+static inline void flush_cache_pte_range(struct mm_struct *mm, pmd_t *pmd, unsigned long address, unsigned long size)
+{
+	unsigned long offset;
+	pte_t *ptep;
+
+	if (pmd_none(*pmd))
+		return;
+	ptep = pte_offset(pmd, address);
+	offset = address & ~PMD_MASK;
+	if (offset + size > PMD_SIZE)
+		size = PMD_SIZE - offset;
+	size &= PAGE_MASK;
+	for (offset = 0; offset < size; ptep++, offset += PAGE_SIZE) {
+		pte_t pte = *ptep;
+
+		if (pte_none(pte))
+			continue;
+
+		if (pte_present(pte) && pte_dirty(pte)) {
+			struct page *page = pte_page(pte);
+			unsigned long pgaddr, uaddr;
+
+			if (!VALID_PAGE(page) || PageReserved(page) || !page->mapping)
+				continue;
+			pgaddr = (unsigned long) page_address(page);
+			uaddr = address + offset;
+			if ((pgaddr ^ uaddr) & (1 << 13))
+				flush_dcache_page_all(mm, page);
+		}
+	}
+}
+
+static inline void flush_cache_pmd_range(struct mm_struct *mm, pgd_t *dir, unsigned long address, unsigned long size)
+{
+	pmd_t *pmd;
+	unsigned long end;
+
+	if (pgd_none(*dir))
+		return;
+	pmd = pmd_offset(dir, address);
+	end = address + size;
+	if (end > ((address + PGDIR_SIZE) & PGDIR_MASK))
+		end = ((address + PGDIR_SIZE) & PGDIR_MASK);
+	do {
+		flush_cache_pte_range(mm, pmd, address, end - address);
+		address = (address + PMD_SIZE) & PMD_MASK;
+		pmd++;
+	} while (address < end);
+}
+
+void flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	pgd_t *dir = pgd_offset(mm, start);
+
+	if (mm == current->mm)
+		flushw_user();
+
+	if (vma->vm_file == NULL ||
+	    ((vma->vm_flags & (VM_SHARED|VM_WRITE)) != (VM_SHARED|VM_WRITE)))
+		return;
+
+	do {
+		flush_cache_pmd_range(mm, dir, start, end - start);
+		start = (start + PGDIR_SIZE) & PGDIR_MASK;
+		dir++;
+	} while (start && (start < end));
+}
+
 /*
  * Translate PROM's mapping we capture at boot time into physical address.
  * The second parameter is only set from prom_callback() invocations.
diff -urNp linux-1130/arch/x86_64/ia32/ia32_binfmt.c linux-1140/arch/x86_64/ia32/ia32_binfmt.c
--- linux-1130/arch/x86_64/ia32/ia32_binfmt.c
+++ linux-1140/arch/x86_64/ia32/ia32_binfmt.c
@@ -276,7 +276,7 @@ static void elf32_init(struct pt_regs *r
 	me->thread.flags |= THREAD_IA32;
 }
 
-extern void put_dirty_page(struct task_struct * tsk, struct page *page, unsigned long address);
+extern void new_put_dirty_page(struct task_struct * tsk, struct vm_area_struct *vma, struct page *page, unsigned long address);
  
 
 int ia32_setup_arg_pages(struct linux_binprm *bprm, int executable_stack)
@@ -320,7 +320,7 @@ int ia32_setup_arg_pages(struct linux_bi
 		if (page) {
 			bprm->page[i] = NULL;
 			current->mm->rss++;
-			put_dirty_page(current,page,stack_base);
+			new_put_dirty_page(current,mpnt,page,stack_base);
 		}
 		stack_base += PAGE_SIZE;
 	}
diff -urNp linux-1130/arch/x86_64/kernel/pci-x86_64.c linux-1140/arch/x86_64/kernel/pci-x86_64.c
--- linux-1130/arch/x86_64/kernel/pci-x86_64.c
+++ linux-1140/arch/x86_64/kernel/pci-x86_64.c
@@ -377,7 +377,7 @@ int pci_mmap_page_range(struct pci_dev *
 	/* Write-combine setting is ignored, it is changed via the mtrr
 	 * interfaces on this platform.
 	 */
-	if (remap_page_range(vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
+	if (remap_page_range(vma, vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,
 			     vma->vm_end - vma->vm_start,
 			     vma->vm_page_prot))
 		return -EAGAIN;
diff -urNp linux-1130/drivers/char/agp/agpgart_fe.c linux-1140/drivers/char/agp/agpgart_fe.c
--- linux-1130/drivers/char/agp/agpgart_fe.c
+++ linux-1140/drivers/char/agp/agpgart_fe.c
@@ -644,7 +644,7 @@ static int agp_mmap(struct file *file, s
 			unlock_kernel();
 			return -EINVAL;
 		}
-		if (remap_page_range(vma->vm_start,
+		if (remap_page_range(vma, vma->vm_start,
 				     (kerninfo.aper_base + offset),
 				     size, vma->vm_page_prot)) {
 			AGP_UNLOCK();
@@ -661,7 +661,7 @@ static int agp_mmap(struct file *file, s
 			unlock_kernel();
 			return -EINVAL;
 		}
-		if (remap_page_range(vma->vm_start, kerninfo.aper_base,
+		if (remap_page_range(vma, vma->vm_start, kerninfo.aper_base,
 				     size, vma->vm_page_prot)) {
 			AGP_UNLOCK();
 			unlock_kernel();
diff -urNp linux-1130/drivers/char/drm/drmP.h linux-1140/drivers/char/drm/drmP.h
--- linux-1130/drivers/char/drm/drmP.h
+++ linux-1140/drivers/char/drm/drmP.h
@@ -288,11 +288,7 @@ static inline struct page * vmalloc_to_p
 }
 #endif
 
-#if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)
-#define DRM_RPR_ARG(vma)
-#else
 #define DRM_RPR_ARG(vma) vma,
-#endif
 
 
 #define VM_OFFSET(vma) ((vma)->vm_pgoff << PAGE_SHIFT)
diff -urNp linux-1130/drivers/char/drm-4.0/ffb_drv.c linux-1140/drivers/char/drm-4.0/ffb_drv.c
--- linux-1130/drivers/char/drm-4.0/ffb_drv.c
+++ linux-1140/drivers/char/drm-4.0/ffb_drv.c
@@ -852,7 +852,7 @@ static int ffb_mmap(struct file *filp, s
 		 * address, and we just add in the base here.
 		 */
 		vma->vm_flags |= VM_IO;
-		if (io_remap_page_range(vma->vm_start,
+		if (io_remap_page_range(vma, vma->vm_start,
 					ffb_priv->card_phys_base + VM_OFFSET(vma),
 					vma->vm_end - vma->vm_start,
 					vma->vm_page_prot, 0))
diff -urNp linux-1130/drivers/char/drm-4.0/i810_dma.c linux-1140/drivers/char/drm-4.0/i810_dma.c
--- linux-1130/drivers/char/drm-4.0/i810_dma.c
+++ linux-1140/drivers/char/drm-4.0/i810_dma.c
@@ -174,7 +174,7 @@ int i810_mmap_buffers(struct file *filp,
    	buf_priv->currently_mapped = I810_BUF_MAPPED;
 	unlock_kernel();
 
-	if (remap_page_range(vma->vm_start,
+	if (remap_page_range(vma, vma->vm_start,
 			     VM_OFFSET(vma),
 			     vma->vm_end - vma->vm_start,
 			     vma->vm_page_prot)) return -EAGAIN;
diff -urNp linux-1130/drivers/char/drm-4.0/vm.c linux-1140/drivers/char/drm-4.0/vm.c
--- linux-1130/drivers/char/drm-4.0/vm.c
+++ linux-1140/drivers/char/drm-4.0/vm.c
@@ -327,7 +327,7 @@ int drm_mmap(struct file *filp, struct v
 #endif
 			vma->vm_flags |= VM_IO;	/* not in core dump */
 		}
-		if (remap_page_range(vma->vm_start,
+		if (remap_page_range(vma, vma->vm_start,
 				     VM_OFFSET(vma),
 				     vma->vm_end - vma->vm_start,
 				     vma->vm_page_prot))
diff -urNp linux-1130/drivers/char/ftape/lowlevel/ftape-ctl.c linux-1140/drivers/char/ftape/lowlevel/ftape-ctl.c
--- linux-1130/drivers/char/ftape/lowlevel/ftape-ctl.c
+++ linux-1140/drivers/char/ftape/lowlevel/ftape-ctl.c
@@ -731,7 +731,7 @@ int ftape_mmap(struct vm_area_struct *vm
 		ftape_reset_buffer();
 	}
 	for (i = 0; i < num_buffers; i++) {
-		TRACE_CATCH(remap_page_range(vma->vm_start +
+		TRACE_CATCH(remap_page_range(vma, vma->vm_start +
 					     i * FT_BUFF_SIZE,
 					     virt_to_phys(ft_buffer[i]->address),
 					     FT_BUFF_SIZE,
diff -urNp linux-1130/drivers/char/mem.c linux-1140/drivers/char/mem.c
--- linux-1130/drivers/char/mem.c
+++ linux-1140/drivers/char/mem.c
@@ -212,7 +212,8 @@ static int mmap_mem(struct file * file, 
 	if (offset >= __pa(high_memory) || (file->f_flags & O_SYNC))
 		vma->vm_flags |= VM_IO;
 
-	if (remap_page_range(vma->vm_start, offset, vma->vm_end-vma->vm_start,
+	if (remap_page_range(vma, vma->vm_start, offset,
+			     vma->vm_end-vma->vm_start,
 			     vma->vm_page_prot))
 		return -EAGAIN;
 	return 0;
@@ -409,8 +410,8 @@ static inline size_t read_zero_pagealign
 		if (count > size)
 			count = size;
 
-		zap_page_range(mm, addr, count);
-        	zeromap_page_range(addr, count, PAGE_COPY);
+		zap_page_range(vma, addr, count);
+        	zeromap_page_range(vma, addr, count, PAGE_COPY);
 
 		size -= count;
 		buf += count;
@@ -480,7 +481,7 @@ static int mmap_zero(struct file * file,
 {
 	if (vma->vm_flags & VM_SHARED)
 		return shmem_zero_setup(vma);
-	if (zeromap_page_range(vma->vm_start, vma->vm_end - vma->vm_start, vma->vm_page_prot))
+	if (zeromap_page_range(vma, vma->vm_start, vma->vm_end - vma->vm_start, vma->vm_page_prot))
 		return -EAGAIN;
 	return 0;
 }
diff -urNp linux-1130/drivers/media/video/bttv-driver.c linux-1140/drivers/media/video/bttv-driver.c
--- linux-1130/drivers/media/video/bttv-driver.c
+++ linux-1140/drivers/media/video/bttv-driver.c
@@ -2144,7 +2144,7 @@ static int bttv_ioctl(struct video_devic
  *    But e.g. pte_alloc() does not work in modules ... :-(
  */
 
-static int do_bttv_mmap(struct bttv *btv, const char *adr, unsigned long size)
+static int do_bttv_mmap(struct vm_area_struct *vma, struct bttv *btv, const char *adr, unsigned long size)
 {
         unsigned long start=(unsigned long) adr;
         unsigned long page,pos;
@@ -2158,7 +2158,7 @@ static int do_bttv_mmap(struct bttv *btv
         pos=(unsigned long) btv->fbuffer;
         while (size > 0) {
                 page = kvirt_to_pa(pos);
-                if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED))
+                if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED))
                         return -EAGAIN;
                 start+=PAGE_SIZE;
                 pos+=PAGE_SIZE;
@@ -2167,13 +2167,13 @@ static int do_bttv_mmap(struct bttv *btv
         return 0;
 }
 
-static int bttv_mmap(struct video_device *dev, const char *adr, unsigned long size)
+static int bttv_mmap(struct vm_area_struct *vma, struct video_device *dev, const char *adr, unsigned long size)
 {
         struct bttv *btv=(struct bttv *)dev;
         int r;
 
         down(&btv->lock);
-        r=do_bttv_mmap(btv, adr, size);
+        r=do_bttv_mmap(vma, btv, adr, size);
         up(&btv->lock);
         return r;
 }
diff -urNp linux-1130/drivers/media/video/cpia.c linux-1140/drivers/media/video/cpia.c
--- linux-1130/drivers/media/video/cpia.c
+++ linux-1140/drivers/media/video/cpia.c
@@ -3050,7 +3050,7 @@ static int cpia_mmap(struct file *file, 
 	pos = (unsigned long)(cam->frame_buf);
 	while (size > 0) {
 		page = kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED)) {
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED)) {
 			up(&cam->busy_lock);
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/media/video/meye.c linux-1140/drivers/media/video/meye.c
--- linux-1130/drivers/media/video/meye.c
+++ linux-1140/drivers/media/video/meye.c
@@ -1196,7 +1196,7 @@ static int meye_mmap(struct file *file, 
 
 	while (size > 0) {
 		page = kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED)) {
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED)) {
 			up(&meye.lock);
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/media/video/planb.c linux-1140/drivers/media/video/planb.c
--- linux-1130/drivers/media/video/planb.c
+++ linux-1140/drivers/media/video/planb.c
@@ -2190,7 +2190,7 @@ unimplemented:
 	return 0;
 }
 
-static int planb_mmap(struct video_device *dev, const char *adr, unsigned long size)
+static int planb_mmap(struct vm_area_struct *vma, struct video_device *dev, const char *adr, unsigned long size)
 {
 	struct planb	*pb = (struct planb *)dev->priv;
         unsigned long	start = (unsigned long)adr;
@@ -2204,7 +2204,7 @@ static int planb_mmap(struct video_devic
 			return err;
 	}
 	for (i = 0; i < pb->rawbuf_nchunks; i++) {
-		if (remap_page_range(start, virt_to_phys((void *)pb->rawbuf[i]),
+		if (remap_page_range(vma, start, virt_to_phys((void *)pb->rawbuf[i]),
 						PAGE_SIZE, PAGE_SHARED))
 			return -EAGAIN;
 		start += PAGE_SIZE;
diff -urNp linux-1130/drivers/media/video/videodev.c linux-1140/drivers/media/video/videodev.c
--- linux-1130/drivers/media/video/videodev.c
+++ linux-1140/drivers/media/video/videodev.c
@@ -231,7 +231,7 @@ int video_mmap(struct file *file, struct
 	struct video_device *vfl = video_devdata(file);
 	if(vfl->mmap) {
 		lock_kernel();
-		ret = vfl->mmap(vfl, (char *)vma->vm_start, 
+		ret = vfl->mmap(vma, vfl, (char *)vma->vm_start, 
 				(unsigned long)(vma->vm_end-vma->vm_start));
 		unlock_kernel();
 	}
diff -urNp linux-1130/drivers/media/video/zr36067.c linux-1140/drivers/media/video/zr36067.c
--- linux-1130/drivers/media/video/zr36067.c
+++ linux-1140/drivers/media/video/zr36067.c
@@ -4277,7 +4277,8 @@ static int zoran_ioctl(struct video_devi
  *
  */
 
-static int do_zoran_mmap(struct zoran *zr, const char *adr,
+static int do_zoran_mmap(struct vm_area_struct *vma,
+		      struct zoran *zr, const char *adr,
 		      unsigned long size)
 {
 	unsigned long start = (unsigned long) adr;
@@ -4324,7 +4325,7 @@ static int do_zoran_mmap(struct zoran *z
 				    frag_tab[2 * j];
 				page = virt_to_phys(bus_to_virt(pos));	/* should just be pos on i386 */
 				if (remap_page_range
-				    (start, page, todo, PAGE_SHARED)) {
+				    (vma, start, page, todo, PAGE_SHARED)) {
 					printk(KERN_ERR
 					       "%s: zoran_mmap(V4L): remap_page_range failed\n",
 					       zr->name);
@@ -4365,7 +4366,7 @@ static int do_zoran_mmap(struct zoran *z
 			       ("V4L remap page range %d 0x%lx %ld to 0x%lx\n",
 				i, page, todo, start));
 			if (remap_page_range
-			    (start, page, todo, PAGE_SHARED)) {
+			    (vma, start, page, todo, PAGE_SHARED)) {
 				printk(KERN_ERR
 				       "%s: zoran_mmap(V4L): remap_page_range failed\n",
 				       zr->name);
@@ -4380,14 +4381,15 @@ static int do_zoran_mmap(struct zoran *z
 	return 0;
 }
 
-static int zoran_mmap(struct video_device *dev, const char *adr,
+static int zoran_mmap(struct vm_area_struct *vma,
+		      struct video_device *dev, const char *adr,
 		      unsigned long size)
 {
 	int err;
 	struct zoran *zr = (struct zoran *) dev;
 	
 	down(&zr->sem);
-	err = do_zoran_mmap(zr, adr, size);
+	err = do_zoran_mmap(vma, zr, adr, size);
 	up(&zr->sem);
 		
 	return err;
diff -urNp linux-1130/drivers/media/video/zr36120.c linux-1140/drivers/media/video/zr36120.c
--- linux-1130/drivers/media/video/zr36120.c
+++ linux-1140/drivers/media/video/zr36120.c
@@ -1468,7 +1468,8 @@ int zoran_ioctl(struct video_device* dev
 }
 
 static
-int zoran_mmap(struct video_device* dev, const char* adr, unsigned long size)
+int zoran_mmap(struct vm_area_struct *vma,
+	       struct video_device* dev, const char* adr, unsigned long size)
 {
 	struct zoran* ztv = (struct zoran*)dev;
 	unsigned long start = (unsigned long)adr;
@@ -1484,7 +1485,7 @@ int zoran_mmap(struct video_device* dev,
 	pos = (unsigned long)ztv->fbuffer;
 	while (size>0) {
 		unsigned long page = virt_to_phys((void*)pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED))
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED))
 			return -EAGAIN;
 		start += PAGE_SIZE;
 		pos += PAGE_SIZE;
diff -urNp linux-1130/drivers/pcmcia/hd64465_ss.c linux-1140/drivers/pcmcia/hd64465_ss.c
--- linux-1130/drivers/pcmcia/hd64465_ss.c
+++ linux-1140/drivers/pcmcia/hd64465_ss.c
@@ -673,6 +673,10 @@ static int hs_set_io_map(unsigned int so
 	     */
 	    DPRINTK("remap_page_range(vaddr=0x%08lx, paddr=0x%08lx, size=0x%08lxx)\n",
 	    	vaddrbase + pstart, paddrbase + pstart, psize);
+#error This does not work.  Firstly remap_page_range() uses current->mm for
+#error the address space, which is wrong for kernel mappings.  remap_page_range
+#error also does flush_{cache,tlb}_range() which ONLY works for user mappings.
+#error Next, remap_page_range() now wants to take a vm_area_struct arg.
 	    remap_page_range(vaddrbase + pstart, paddrbase + pstart, psize, prot);
 	    
 	    /*
diff -urNp linux-1130/drivers/sbus/char/flash.c linux-1140/drivers/sbus/char/flash.c
--- linux-1130/drivers/sbus/char/flash.c
+++ linux-1140/drivers/sbus/char/flash.c
@@ -74,7 +74,7 @@ flash_mmap(struct file *file, struct vm_
 	pgprot_val(vma->vm_page_prot) |= _PAGE_E;
 	vma->vm_flags |= (VM_SHM | VM_LOCKED);
 
-	if (remap_page_range(vma->vm_start, addr, size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, addr, size, vma->vm_page_prot))
 		return -EAGAIN;
 		
 	return 0;
diff -urNp linux-1130/drivers/sbus/char/vfc_dev.c linux-1140/drivers/sbus/char/vfc_dev.c
--- linux-1130/drivers/sbus/char/vfc_dev.c
+++ linux-1140/drivers/sbus/char/vfc_dev.c
@@ -632,7 +632,7 @@ static int vfc_mmap(struct inode *inode,
 	vma->vm_flags |=
 		(VM_SHM | VM_LOCKED | VM_IO | VM_MAYREAD | VM_MAYWRITE | VM_MAYSHARE);
 	map_offset = (unsigned int) (long)dev->phys_regs;
-	ret = io_remap_page_range(vma->vm_start, map_offset, map_size, 
+	ret = io_remap_page_range(vma, vma->vm_start, map_offset, map_size, 
 				  vma->vm_page_prot, dev->which_io);
 
 	if(ret)
diff -urNp linux-1130/drivers/sgi/char/graphics.c linux-1140/drivers/sgi/char/graphics.c
--- linux-1130/drivers/sgi/char/graphics.c
+++ linux-1140/drivers/sgi/char/graphics.c
@@ -234,7 +234,7 @@ sgi_graphics_nopage (struct vm_area_stru
 		/* FIXME: save graphics context here, dump it to rendering
 		 * node? */
 
-		remove_mapping(cards[board].g_user, vma->vm_start, vma->vm_end);
+		remove_mapping(vma, cards[board].g_user, vma->vm_start, vma->vm_end);
 	}
 
 	cards [board].g_user = current;
@@ -244,7 +244,7 @@ sgi_graphics_nopage (struct vm_area_stru
 
 	virt_add = address & PAGE_MASK;
 	phys_add = cards[board].g_regs + virt_add - vma->vm_start;
-	remap_page_range(virt_add, phys_add, PAGE_SIZE, vma->vm_page_prot);
+	remap_page_range(vma, virt_add, phys_add, PAGE_SIZE, vma->vm_page_prot);
 
 	pgd = pgd_offset(current->mm, address);
 	pmd = pmd_offset(pgd, address);
diff -urNp linux-1130/drivers/sgi/char/shmiq.c linux-1140/drivers/sgi/char/shmiq.c
--- linux-1130/drivers/sgi/char/shmiq.c
+++ linux-1140/drivers/sgi/char/shmiq.c
@@ -342,7 +342,7 @@ shmiq_qcntl_mmap (struct file *file, str
 	/* Uncache the pages */
 	vma->vm_page_prot = PAGE_USERIO;
 
-	error = vmap_page_range (vma->vm_start, size, mem);
+	error = vmap_page_range (vma, vma->vm_start, size, mem);
 
 	shmiqs [minor].tail = 0;
 	/* Init the shared memory input queue */
diff -urNp linux-1130/drivers/sound/ali5455.c linux-1140/drivers/sound/ali5455.c
--- linux-1130/drivers/sound/ali5455.c
+++ linux-1140/drivers/sound/ali5455.c
@@ -1960,7 +1960,7 @@ static int ali_mmap(struct file *file, s
 	if (size > (PAGE_SIZE << dmabuf->buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(dmabuf->rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(dmabuf->rawbuf), size, vma->vm_page_prot))
 		goto out;
 	dmabuf->mapped = 1;
 	dmabuf->trigger = 0;
diff -urNp linux-1130/drivers/sound/au1000.c linux-1140/drivers/sound/au1000.c
--- linux-1130/drivers/sound/au1000.c
+++ linux-1140/drivers/sound/au1000.c
@@ -1343,7 +1343,7 @@ static int au1000_mmap(struct file *file
 		ret = -EINVAL;
 		goto out;
 	}
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf),
 			     size, vma->vm_page_prot)) {
 		ret = -EAGAIN;
 		goto out;
diff -urNp linux-1130/drivers/sound/cmpci.c linux-1140/drivers/sound/cmpci.c
--- linux-1130/drivers/sound/cmpci.c
+++ linux-1140/drivers/sound/cmpci.c
@@ -1763,7 +1763,7 @@ static int cm_mmap(struct file *file, st
 	if (size > (PAGE_SIZE << db->buforder))
 		goto out;
 	ret = -EINVAL;
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
 		goto out;
 	db->mapped = 1;
 	ret = 0;
diff -urNp linux-1130/drivers/sound/cs4281/cs4281m.c linux-1140/drivers/sound/cs4281/cs4281m.c
--- linux-1130/drivers/sound/cs4281/cs4281m.c
+++ linux-1140/drivers/sound/cs4281/cs4281m.c
@@ -3226,7 +3226,7 @@ static int cs4281_mmap(struct file *file
 	if (size > (PAGE_SIZE << db->buforder))
 		return -EINVAL;
 	if (remap_page_range
-	    (vma->vm_start, virt_to_phys(db->rawbuf), size,
+	    (vma, vma->vm_start, virt_to_phys(db->rawbuf), size,
 	     vma->vm_page_prot)) return -EAGAIN;
 	db->mapped = 1;
 
diff -urNp linux-1130/drivers/sound/cs46xx.c linux-1140/drivers/sound/cs46xx.c
--- linux-1130/drivers/sound/cs46xx.c
+++ linux-1140/drivers/sound/cs46xx.c
@@ -2465,7 +2465,7 @@ static int cs_mmap(struct file *file, st
 		ret = -EINVAL;
 		goto out;
 	}
-	if (remap_page_range(vma->vm_start, virt_to_phys(dmabuf->rawbuf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(dmabuf->rawbuf),
 			     size, vma->vm_page_prot))
 	{
 		ret = -EAGAIN;
diff -urNp linux-1130/drivers/sound/es1370.c linux-1140/drivers/sound/es1370.c
--- linux-1130/drivers/sound/es1370.c
+++ linux-1140/drivers/sound/es1370.c
@@ -1374,7 +1374,7 @@ static int es1370_mmap(struct file *file
 		ret = -EINVAL;
 		goto out;
 	}
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot)) {
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot)) {
 		ret = -EAGAIN;
 		goto out;
 	}
@@ -1946,7 +1946,7 @@ static int es1370_mmap_dac(struct file *
 	if (size > (PAGE_SIZE << s->dma_dac1.buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(s->dma_dac1.rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(s->dma_dac1.rawbuf), size, vma->vm_page_prot))
 		goto out;
 	s->dma_dac1.mapped = 1;
 	ret = 0;
diff -urNp linux-1130/drivers/sound/es1371.c linux-1140/drivers/sound/es1371.c
--- linux-1130/drivers/sound/es1371.c
+++ linux-1140/drivers/sound/es1371.c
@@ -1564,7 +1564,7 @@ static int es1371_mmap(struct file *file
 		ret = -EINVAL;
 		goto out;
 	}
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot)) {
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot)) {
 		ret = -EAGAIN;
 		goto out;
 	}
@@ -2133,7 +2133,7 @@ static int es1371_mmap_dac(struct file *
 	if (size > (PAGE_SIZE << s->dma_dac1.buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(s->dma_dac1.rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(s->dma_dac1.rawbuf), size, vma->vm_page_prot))
 		goto out;
 	s->dma_dac1.mapped = 1;
 	ret = 0;
diff -urNp linux-1130/drivers/sound/esssolo1.c linux-1140/drivers/sound/esssolo1.c
--- linux-1130/drivers/sound/esssolo1.c
+++ linux-1140/drivers/sound/esssolo1.c
@@ -1246,7 +1246,7 @@ static int solo1_mmap(struct file *file,
 	if (size > (PAGE_SIZE << db->buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
 		goto out;
 	db->mapped = 1;
 	ret = 0;
diff -urNp linux-1130/drivers/sound/forte.c linux-1140/drivers/sound/forte.c
--- linux-1130/drivers/sound/forte.c
+++ linux-1140/drivers/sound/forte.c
@@ -1414,7 +1414,7 @@ forte_dsp_mmap (struct file *file, struc
                 goto out;
 	}
 
-        if (remap_page_range (vma->vm_start, virt_to_phys (channel->buf),
+        if (remap_page_range (vma, vma->vm_start, virt_to_phys (channel->buf),
 			      size, vma->vm_page_prot)) {
 		DPRINTK ("%s: remap el a no worko\n", __FUNCTION__);
 		ret = -EAGAIN;
diff -urNp linux-1130/drivers/sound/i810_audio.c linux-1140/drivers/sound/i810_audio.c
--- linux-1130/drivers/sound/i810_audio.c
+++ linux-1140/drivers/sound/i810_audio.c
@@ -1747,7 +1747,7 @@ static int i810_mmap(struct file *file, 
 	if (size > (PAGE_SIZE << dmabuf->buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(dmabuf->rawbuf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(dmabuf->rawbuf),
 			     size, vma->vm_page_prot))
 		goto out;
 	dmabuf->mapped = 1;
diff -urNp linux-1130/drivers/sound/ite8172.c linux-1140/drivers/sound/ite8172.c
--- linux-1130/drivers/sound/ite8172.c
+++ linux-1140/drivers/sound/ite8172.c
@@ -1314,7 +1314,7 @@ static int it8172_mmap(struct file *file
 		unlock_kernel();
 		return -EINVAL;
 	}
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf),
 			     size, vma->vm_page_prot)) {
 		unlock_kernel();
 		return -EAGAIN;
diff -urNp linux-1130/drivers/sound/maestro.c linux-1140/drivers/sound/maestro.c
--- linux-1130/drivers/sound/maestro.c
+++ linux-1140/drivers/sound/maestro.c
@@ -2510,7 +2510,7 @@ static int ess_mmap(struct file *file, s
 	if (size > (PAGE_SIZE << db->buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
 		goto out;
 	db->mapped = 1;
 	ret = 0;
diff -urNp linux-1130/drivers/sound/maestro3.c linux-1140/drivers/sound/maestro3.c
--- linux-1130/drivers/sound/maestro3.c
+++ linux-1140/drivers/sound/maestro3.c
@@ -1559,7 +1559,7 @@ static int m3_mmap(struct file *file, st
      * ask Jeff what the hell I'm doing wrong.
      */
     ret = -EAGAIN;
-    if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
+    if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
         goto out;
 
     db->mapped = 1;
diff -urNp linux-1130/drivers/sound/rme96xx.c linux-1140/drivers/sound/rme96xx.c
--- linux-1130/drivers/sound/rme96xx.c
+++ linux-1140/drivers/sound/rme96xx.c
@@ -1672,14 +1672,14 @@ static int rm96xx_mmap(struct file *file
 	if (vma->vm_flags & VM_WRITE) {
 		if (!s->started) rme96xx_startcard(s,1);
 
-		if (remap_page_range(vma->vm_start, virt_to_phys(s->playbuf + dma->outoffset*RME96xx_DMA_MAX_SIZE), size, vma->vm_page_prot)) {
+		if (remap_page_range(vma, vma->vm_start, virt_to_phys(s->playbuf + dma->outoffset*RME96xx_DMA_MAX_SIZE), size, vma->vm_page_prot)) {
 			unlock_kernel();
 			return -EAGAIN;
 		}
 	} 
 	else if (vma->vm_flags & VM_READ) {
 		if (!s->started) rme96xx_startcard(s,1);
-		if (remap_page_range(vma->vm_start, virt_to_phys(s->playbuf + dma->inoffset*RME96xx_DMA_MAX_SIZE), size, vma->vm_page_prot)) {
+		if (remap_page_range(vma, vma->vm_start, virt_to_phys(s->playbuf + dma->inoffset*RME96xx_DMA_MAX_SIZE), size, vma->vm_page_prot)) {
 			unlock_kernel();
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/sound/sonicvibes.c linux-1140/drivers/sound/sonicvibes.c
--- linux-1130/drivers/sound/sonicvibes.c
+++ linux-1140/drivers/sound/sonicvibes.c
@@ -1550,7 +1550,7 @@ static int sv_mmap(struct file *file, st
 	if (size > (PAGE_SIZE << db->buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(db->rawbuf), size, vma->vm_page_prot))
 		goto out;
 	db->mapped = 1;
 	ret = 0;
diff -urNp linux-1130/drivers/sound/soundcard.c linux-1140/drivers/sound/soundcard.c
--- linux-1130/drivers/sound/soundcard.c
+++ linux-1140/drivers/sound/soundcard.c
@@ -474,7 +474,7 @@ static int sound_mmap(struct file *file,
 	if (size != dmap->bytes_in_use) {
 		printk(KERN_WARNING "Sound: mmap() size = %ld. Should be %d\n", size, dmap->bytes_in_use);
 	}
-	if (remap_page_range(vma->vm_start, virt_to_phys(dmap->raw_buf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(dmap->raw_buf),
 		vma->vm_end - vma->vm_start,
 		vma->vm_page_prot)) {
 		unlock_kernel();
diff -urNp linux-1130/drivers/sound/trident.c linux-1140/drivers/sound/trident.c
--- linux-1130/drivers/sound/trident.c
+++ linux-1140/drivers/sound/trident.c
@@ -2116,7 +2116,7 @@ static int trident_mmap(struct file *fil
 	if (size > (PAGE_SIZE << dmabuf->buforder))
 		goto out;
 	ret = -EAGAIN;
-	if (remap_page_range(vma->vm_start, virt_to_phys(dmabuf->rawbuf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(dmabuf->rawbuf),
 			     size, vma->vm_page_prot))
 		goto out;
 	dmabuf->mapped = 1;
diff -urNp linux-1130/drivers/sound/ymfpci.c linux-1140/drivers/sound/ymfpci.c
--- linux-1130/drivers/sound/ymfpci.c
+++ linux-1140/drivers/sound/ymfpci.c
@@ -1546,7 +1546,7 @@ static int ymf_mmap(struct file *file, s
 	size = vma->vm_end - vma->vm_start;
 	if (size > (PAGE_SIZE << dmabuf->buforder))
 		return -EINVAL;
-	if (remap_page_range(vma->vm_start, virt_to_phys(dmabuf->rawbuf),
+	if (remap_page_range(vma, vma->vm_start, virt_to_phys(dmabuf->rawbuf),
 			     size, vma->vm_page_prot))
 		return -EAGAIN;
 	dmabuf->mapped = 1;
diff -urNp linux-1130/drivers/usb/audio.c linux-1140/drivers/usb/audio.c
--- linux-1130/drivers/usb/audio.c
+++ linux-1140/drivers/usb/audio.c
@@ -570,7 +570,7 @@ static int dmabuf_init(struct dmabuf *db
 	return 0;
 }
 
-static int dmabuf_mmap(struct dmabuf *db, unsigned long start, unsigned long size, pgprot_t prot)
+static int dmabuf_mmap(struct vm_area_struct *vma, struct dmabuf *db, unsigned long start, unsigned long size, pgprot_t prot)
 {
 	unsigned int nr;
 
@@ -582,7 +582,7 @@ static int dmabuf_mmap(struct dmabuf *db
 			return -EINVAL;
 	db->mapped = 1;
 	for(nr = 0; nr < size; nr++) {
-		if (remap_page_range(start, virt_to_phys(db->sgbuf[nr]), PAGE_SIZE, prot))
+		if (remap_page_range(vma, start, virt_to_phys(db->sgbuf[nr]), PAGE_SIZE, prot))
 			return -EAGAIN;
 		start += PAGE_SIZE;
 	}
@@ -2479,7 +2479,7 @@ static int usb_audio_mmap(struct file *f
 	if (vma->vm_pgoff != 0)
 		goto out;
 
-	ret = dmabuf_mmap(db,  vma->vm_start, vma->vm_end - vma->vm_start, vma->vm_page_prot);
+	ret = dmabuf_mmap(vma, db,  vma->vm_start, vma->vm_end - vma->vm_start, vma->vm_page_prot);
 out:
 	unlock_kernel();
 	return ret;
diff -urNp linux-1130/drivers/usb/ov511.c linux-1140/drivers/usb/ov511.c
--- linux-1130/drivers/usb/ov511.c
+++ linux-1140/drivers/usb/ov511.c
@@ -5268,7 +5268,7 @@ ov51x_v4l1_mmap(struct file *file, struc
 	pos = (unsigned long)ov->fbuf;
 	while (size > 0) {
 		page = kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED)) {
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED)) {
 			up(&ov->lock);
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/usb/pwc-if.c linux-1140/drivers/usb/pwc-if.c
--- linux-1130/drivers/usb/pwc-if.c
+++ linux-1140/drivers/usb/pwc-if.c
@@ -130,7 +130,7 @@ static long pwc_video_read(struct video_
 static long pwc_video_write(struct video_device *vdev, const char *buf, unsigned long count, int noblock);
 static unsigned int pwc_video_poll(struct video_device *vdev, struct file *file, poll_table *wait);
 static int  pwc_video_ioctl(struct video_device *vdev, unsigned int cmd, void *arg);
-static int  pwc_video_mmap(struct video_device *vdev, const char *adr, unsigned long size);
+static int  pwc_video_mmap(struct vm_area_struct *vma, struct video_device *vdev, const char *adr, unsigned long size);
 
 static struct video_device pwc_template = {
 	owner:		THIS_MODULE,
@@ -1587,7 +1587,7 @@ static int pwc_video_ioctl(struct video_
 	return 0;
 }	
 
-static int pwc_video_mmap(struct video_device *vdev, const char *adr, unsigned long size)
+static int pwc_video_mmap(struct vm_area_struct *vma, struct video_device *vdev, const char *adr, unsigned long size)
 {
 	struct pwc_device *pdev;
 	unsigned long start = (unsigned long)adr;
@@ -1599,7 +1599,7 @@ static int pwc_video_mmap(struct video_d
 	pos = (unsigned long)pdev->image_data;
 	while (size > 0) {
 		page = kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED))
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED))
 			return -EAGAIN;
 
 		start += PAGE_SIZE;
diff -urNp linux-1130/drivers/usb/se401.c linux-1140/drivers/usb/se401.c
--- linux-1130/drivers/usb/se401.c
+++ linux-1140/drivers/usb/se401.c
@@ -1298,7 +1298,7 @@ static long se401_read(struct video_devi
 	return realcount;
 }
 
-static int se401_mmap(struct video_device *dev, const char *adr,
+static int se401_mmap(struct vm_area_struct *vma, struct video_device *dev, const char *adr,
         unsigned long size)
 {
 	struct usb_se401 *se401 = (struct usb_se401 *)dev;
@@ -1318,7 +1318,7 @@ static int se401_mmap(struct video_devic
 	pos = (unsigned long)se401->fbuf;
 	while (size > 0) {
 		page = kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED)) {
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED)) {
 			up(&se401->lock);
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/usb/stv680.c linux-1140/drivers/usb/stv680.c
--- linux-1130/drivers/usb/stv680.c
+++ linux-1140/drivers/usb/stv680.c
@@ -1394,7 +1394,7 @@ static int stv680_ioctl (struct video_de
 	return 0;
 }
 
-static int stv680_mmap (struct video_device *dev, const char *adr, unsigned long size)
+static int stv680_mmap (struct vm_area_struct *vma, struct video_device *dev, const char *adr, unsigned long size)
 {
 	struct usb_stv *stv680 = (struct usb_stv *) dev;
 	unsigned long start = (unsigned long) adr;
@@ -1414,7 +1414,7 @@ static int stv680_mmap (struct video_dev
 	pos = (unsigned long) stv680->fbuf;
 	while (size > 0) {
 		page = kvirt_to_pa (pos);
-		if (remap_page_range (start, page, PAGE_SIZE, PAGE_SHARED)) {
+		if (remap_page_range (vma, start, page, PAGE_SIZE, PAGE_SHARED)) {
 			up (&stv680->lock);
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/usb/usbvideo.c linux-1140/drivers/usb/usbvideo.c
--- linux-1130/drivers/usb/usbvideo.c
+++ linux-1140/drivers/usb/usbvideo.c
@@ -1164,7 +1164,7 @@ long usbvideo_v4l_write(struct video_dev
 	return -EINVAL;
 }
 
-int usbvideo_v4l_mmap(struct video_device *dev, const char *adr, unsigned long size)
+int usbvideo_v4l_mmap(struct vm_area_struct *vma, struct video_device *dev, const char *adr, unsigned long size)
 {
 	struct uvd *uvd = (struct uvd *) dev;
 	unsigned long start = (unsigned long) adr;
@@ -1179,7 +1179,7 @@ int usbvideo_v4l_mmap(struct video_devic
 	pos = (unsigned long) uvd->fbuf;
 	while (size > 0) {
 		page = usbvideo_kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED))
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED))
 			return -EAGAIN;
 
 		start += PAGE_SIZE;
diff -urNp linux-1130/drivers/usb/usbvideo.h linux-1140/drivers/usb/usbvideo.h
--- linux-1130/drivers/usb/usbvideo.h
+++ linux-1140/drivers/usb/usbvideo.h
@@ -357,7 +357,7 @@ void usbvideo_CameraRelease(struct uvd *
 void usbvideo_v4l_close(struct video_device *dev);
 int usbvideo_v4l_initialize(struct video_device *dev);
 int usbvideo_v4l_ioctl(struct video_device *dev, unsigned int cmd, void *arg);
-int usbvideo_v4l_mmap(struct video_device *dev, const char *adr, unsigned long size);
+int usbvideo_v4l_mmap(struct vm_area_struct *vma, struct video_device *dev, const char *adr, unsigned long size);
 int usbvideo_v4l_open(struct video_device *dev, int flags);
 long usbvideo_v4l_read(struct video_device *dev, char *buf,
 			unsigned long count, int noblock);
diff -urNp linux-1130/drivers/usb/vicam.c linux-1140/drivers/usb/vicam.c
--- linux-1130/drivers/usb/vicam.c
+++ linux-1140/drivers/usb/vicam.c
@@ -988,7 +988,7 @@ vicam_read(struct video_device *dev, cha
 }
 
 static int
-vicam_mmap(struct video_device *dev, const char *adr, unsigned long size)
+vicam_mmap(struct vm_area_struct *vma, struct video_device *dev, const char *adr, unsigned long size)
 {
 	// TODO: allocate the raw frame buffer if necessary
 	unsigned long start = (unsigned long) adr;
@@ -1022,7 +1022,7 @@ vicam_mmap(struct video_device *dev, con
 	pos = (unsigned long) (cam->framebuf);
 	while (size > 0) {
 		page = usbvideo_kvirt_to_pa(pos);
-		if (remap_page_range(start, page, PAGE_SIZE, PAGE_SHARED)) {
+		if (remap_page_range(vma, start, page, PAGE_SIZE, PAGE_SHARED)) {
 			up(&cam->busy_lock);
 			return -EAGAIN;
 		}
diff -urNp linux-1130/drivers/video/acornfb.c linux-1140/drivers/video/acornfb.c
--- linux-1130/drivers/video/acornfb.c
+++ linux-1140/drivers/video/acornfb.c
@@ -1149,7 +1149,7 @@ acornfb_mmap(struct fb_info *info, struc
 	 * some updates to the screen occasionally, but process switches
 	 * should cause the caches and buffers to be flushed often enough.
 	 */
-	if (io_remap_page_range(vma->vm_start, off,
+	if (io_remap_page_range(vma, vma->vm_start, off,
 				vma->vm_end - vma->vm_start,
 				vma->vm_page_prot))
 		return -EAGAIN;
diff -urNp linux-1130/drivers/video/aty/atyfb_base.c linux-1140/drivers/video/aty/atyfb_base.c
--- linux-1130/drivers/video/aty/atyfb_base.c
+++ linux-1140/drivers/video/aty/atyfb_base.c
@@ -1417,7 +1417,7 @@ static int atyfb_mmap(struct fb_info *in
 		pgprot_val(vma->vm_page_prot) &= ~(fb->mmap_map[i].prot_mask);
 		pgprot_val(vma->vm_page_prot) |= fb->mmap_map[i].prot_flag;
 
-		if (remap_page_range(vma->vm_start + page, map_offset,
+		if (remap_page_range(vma, vma->vm_start + page, map_offset,
 				     map_size, vma->vm_page_prot))
 			return -EAGAIN;
 
diff -urNp linux-1130/drivers/video/au1100fb.c linux-1140/drivers/video/au1100fb.c
--- linux-1130/drivers/video/au1100fb.c
+++ linux-1140/drivers/video/au1100fb.c
@@ -400,7 +400,7 @@ au1100fb_mmap(struct fb_info *_fb,
 	/* This is an IO map - tell maydump to skip this VMA */
 	vma->vm_flags |= VM_IO;
     
-	if (io_remap_page_range(vma->vm_start, off,
+	if (io_remap_page_range(vma, vma->vm_start, off,
 				vma->vm_end - vma->vm_start,
 				vma->vm_page_prot)) {
 		return -EAGAIN;
diff -urNp linux-1130/drivers/video/controlfb.c linux-1140/drivers/video/controlfb.c
--- linux-1130/drivers/video/controlfb.c
+++ linux-1140/drivers/video/controlfb.c
@@ -444,7 +444,7 @@ static int control_mmap(struct fb_info *
        		return -EINVAL;
        off += start;
        vma->vm_pgoff = off >> PAGE_SHIFT;
-       if (io_remap_page_range(vma->vm_start, off,
+       if (io_remap_page_range(vma, vma->vm_start, off,
            vma->vm_end - vma->vm_start, vma->vm_page_prot))
                return -EAGAIN;
 
diff -urNp linux-1130/drivers/video/epson1356fb.c linux-1140/drivers/video/epson1356fb.c
--- linux-1130/drivers/video/epson1356fb.c
+++ linux-1140/drivers/video/epson1356fb.c
@@ -214,7 +214,7 @@ static struct fb_info_e1356 fb_info;
 static struct e1356fb_fix boot_fix; // boot options
 static struct e1356fb_par boot_par; // boot options
 
-static int e1356_remap_page_range(unsigned long from, phys_t phys_addr, unsigned long size, pgprot_t prot);
+static int e1356_remap_page_range(struct vm_area_struct *vma, unsigned long from, phys_t phys_addr, unsigned long size, pgprot_t prot);
 
 
 /* ------------------------------------------------------------------------- 
@@ -2123,12 +2123,12 @@ e1356fb_mmap(struct fb_info *fb,
 		vma->vm_start += 2;
 	
 #if defined(CONFIG_64BIT_PHYS_ADDR) && defined(CONFIG_CPU_MIPS32)
-	if (e1356_remap_page_range(vma->vm_start, off,
+	if (e1356_remap_page_range(vma, vma->vm_start, off,
 				vma->vm_end - vma->vm_start,
 				vma->vm_page_prot))
 		return -EAGAIN;
 #else
-	if (io_remap_page_range(vma->vm_start, off,
+	if (io_remap_page_range(vma, vma->vm_start, off,
 				vma->vm_end - vma->vm_start,
 				vma->vm_page_prot))
 		return -EAGAIN;
@@ -3023,17 +3023,6 @@ e1356fb_hwcursor_init(struct fb_info_e13
 #if defined(CONFIG_64BIT_PHYS_ADDR) && defined(CONFIG_CPU_MIPS32)
 
 /*
- * Return indicates whether a page was freed so caller can adjust rss
- */
-static inline void forget_pte(pte_t page)
-{
-	if (!pte_none(page)) {
-		printk("forget_pte: old mapping existed!\n");
-		BUG();
-	}
-}
-
-/*
  * maps a range of physical memory into the requested pages. the old
  * mappings are removed. any references to nonexistent pages results
  * in null mappings (currently treated as "copy-on-access")
@@ -3050,11 +3039,12 @@ static inline void e1356_remap_pte_range
 	do {
 		struct page *page;
 		pte_t oldpage;
-		oldpage = ptep_get_and_clear(pte);
+		if (!pte_none(*pte))
+			BUG();
 
 		page = virt_to_page(__va(phys_addr));
 		if ((!VALID_PAGE(page)) || PageReserved(page))
- 			set_pte(pte, mk_pte_phys(phys_addr, prot));
+ 			vm_set_pte(vma, address, pte, mk_pte_phys(phys_addr, prot));
 		forget_pte(oldpage);
 		address += PAGE_SIZE;
 		phys_addr += PAGE_SIZE;
@@ -3062,7 +3052,7 @@ static inline void e1356_remap_pte_range
 	} while (address && (address < end));
 }
 
-static inline int e1356_remap_pmd_range(struct mm_struct *mm, pmd_t * pmd, unsigned long address, unsigned long size,
+static inline int e1356_remap_pmd_range(struct vm_area_struct *vma, struct mm_struct *mm, pmd_t * pmd, unsigned long address, unsigned long size,
 	phys_t phys_addr, pgprot_t prot)
 {
 	unsigned long end;
@@ -3076,7 +3066,7 @@ static inline int e1356_remap_pmd_range(
 		pte_t * pte = pte_alloc(mm, pmd, address);
 		if (!pte)
 			return -ENOMEM;
-		e1356_remap_pte_range(pte, address, end - address, address + phys_addr, prot);
+		e1356_remap_pte_range(vma, pte, address, end - address, address + phys_addr, prot);
 		address = (address + PMD_SIZE) & PMD_MASK;
 		pmd++;
 	} while (address && (address < end));
@@ -3084,7 +3074,8 @@ static inline int e1356_remap_pmd_range(
 }
 
 /*  Note: this is only safe if the mm semaphore is held when called. */
-static int e1356_remap_page_range(unsigned long from, phys_t phys_addr, unsigned long size, pgprot_t prot)
+static int e1356_remap_page_range(struct vm_area_struct *vma,
+	unsigned long from, phys_t phys_addr, unsigned long size, pgprot_t prot)
 {
 	int error = 0;
 	pgd_t * dir;
@@ -3094,7 +3085,7 @@ static int e1356_remap_page_range(unsign
 
 	phys_addr -= from;
 	dir = pgd_offset(mm, from);
-	flush_cache_range(mm, beg, end);
+	flush_cache_range(vma, beg, end);
 	if (from >= end)
 		BUG();
 
@@ -3104,14 +3095,14 @@ static int e1356_remap_page_range(unsign
 		error = -ENOMEM;
 		if (!pmd)
 			break;
-		error = e1356_remap_pmd_range(mm, pmd, from, end - from, phys_addr + from, prot);
+		error = e1356_remap_pmd_range(vma, mm, pmd, from, end - from, phys_addr + from, prot);
 		if (error)
 			break;
 		from = (from + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	} while (from && (from < end));
 	spin_unlock(&mm->page_table_lock);
-	flush_tlb_range(mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 	return error;
 }
 #endif
diff -urNp linux-1130/drivers/video/fbmem.c linux-1140/drivers/video/fbmem.c
--- linux-1130/drivers/video/fbmem.c
+++ linux-1140/drivers/video/fbmem.c
@@ -625,7 +625,7 @@ fb_mmap(struct file *file, struct vm_are
 	vma->vm_flags |= VM_IO;
 #if defined(__sparc_v9__)
 	vma->vm_flags |= (VM_SHM | VM_LOCKED);
-	if (io_remap_page_range(vma->vm_start, off,
+	if (io_remap_page_range(vma, vma->vm_start, off,
 				vma->vm_end - vma->vm_start, vma->vm_page_prot, 0))
 		return -EAGAIN;
 #else
@@ -661,7 +661,7 @@ fb_mmap(struct file *file, struct vm_are
 #else
 #warning What do we have to do here??
 #endif
-	if (io_remap_page_range(vma->vm_start, off,
+	if (io_remap_page_range(vma, vma->vm_start, off,
 			     vma->vm_end - vma->vm_start, vma->vm_page_prot))
 		return -EAGAIN;
 #endif /* !__sparc_v9__ */
diff -urNp linux-1130/drivers/video/igafb.c linux-1140/drivers/video/igafb.c
--- linux-1130/drivers/video/igafb.c
+++ linux-1140/drivers/video/igafb.c
@@ -283,7 +283,7 @@ static int igafb_mmap(struct fb_info *in
 		pgprot_val(vma->vm_page_prot) &= ~(fb->mmap_map[i].prot_mask);
 		pgprot_val(vma->vm_page_prot) |= fb->mmap_map[i].prot_flag;
 
-		if (remap_page_range(vma->vm_start + page, map_offset,
+		if (remap_page_range(vma, vma->vm_start + page, map_offset,
 				     map_size, vma->vm_page_prot))
 			return -EAGAIN;
 
diff -urNp linux-1130/drivers/video/sbusfb.c linux-1140/drivers/video/sbusfb.c
--- linux-1130/drivers/video/sbusfb.c
+++ linux-1140/drivers/video/sbusfb.c
@@ -214,7 +214,7 @@ static int sbusfb_mmap(struct fb_info *i
 		}
 		if (page + map_size > size)
 			map_size = size - page;
-		r = io_remap_page_range (vma->vm_start+page, map_offset, map_size, vma->vm_page_prot, fb->iospace);
+		r = io_remap_page_range(vma, vma->vm_start+page, map_offset, map_size, vma->vm_page_prot, fb->iospace);
 		if (r)
 			return -EAGAIN;
 		page += map_size;
diff -urNp linux-1130/drivers/video/sgivwfb.c linux-1140/drivers/video/sgivwfb.c
--- linux-1130/drivers/video/sgivwfb.c
+++ linux-1140/drivers/video/sgivwfb.c
@@ -846,7 +846,7 @@ static int sgivwfb_mmap(struct fb_info *
     return -EINVAL;
   offset += sgivwfb_mem_phys;
   pgprot_val(vma->vm_page_prot) = pgprot_val(vma->vm_page_prot) | _PAGE_PCD;
-  if (remap_page_range(vma->vm_start, offset, size, vma->vm_page_prot))
+  if (remap_page_range(vma, vma->vm_start, offset, size, vma->vm_page_prot))
     return -EAGAIN;
   vma->vm_file = file;
   printk(KERN_DEBUG "sgivwfb: mmap framebuffer P(%lx)->V(%lx)\n", offset, vma->vm_start);
diff -urNp linux-1130/drivers/video/sis/sis_main.c linux-1140/drivers/video/sis/sis_main.c
--- linux-1130/drivers/video/sis/sis_main.c
+++ linux-1140/drivers/video/sis/sis_main.c
@@ -1364,7 +1364,7 @@ static int sisfb_mmap(struct fb_info *in
 	if (boot_cpu_data.x86 > 3)
 		pgprot_val(vma->vm_page_prot) |= _PAGE_PCD;
 #endif
-	if (io_remap_page_range(vma->vm_start, off, vma->vm_end - vma->vm_start,
+	if (io_remap_page_range(vma, vma->vm_start, off, vma->vm_end - vma->vm_start,
 				vma->vm_page_prot))
 		return -EAGAIN;
 
diff -urNp linux-1130/fs/exec.c linux-1140/fs/exec.c
--- linux-1130/fs/exec.c
+++ linux-1140/fs/exec.c
@@ -285,7 +285,7 @@ int copy_strings_kernel(int argc,char **
  *
  * tsk->mmap_sem is held for writing.
  */
-void put_dirty_page(struct task_struct * tsk, struct page *page, unsigned long address)
+void new_put_dirty_page(struct task_struct *tsk, struct vm_area_struct *vma, struct page *page, unsigned long address)
 {
 	pgd_t * pgd;
 	pmd_t * pmd;
@@ -294,17 +294,17 @@ void put_dirty_page(struct task_struct *
 
 	if (page_count(page) != 1)
 		printk(KERN_ERR "mem_map disagrees with %p at %08lx\n", page, address);
-	pgd = pgd_offset(tsk->mm, address);
+	pgd = pgd_offset(vma->vm_mm, address);
 
 	pte_chain = pte_chain_alloc(GFP_KERNEL);
 	if (!pte_chain)
 		goto out_nounlock;
 
-	spin_lock(&tsk->mm->page_table_lock);
-	pmd = pmd_alloc(tsk->mm, pgd, address);
+	spin_lock(&vma->vm_mm->page_table_lock);
+	pmd = pmd_alloc(vma->vm_mm, pgd, address);
 	if (!pmd)
 		goto out;
-	pte = pte_alloc_map(tsk->mm, pmd, address);
+	pte = pte_alloc_map(vma->vm_mm, pmd, address);
 	if (!pte)
 		goto out;
 	if (!pte_none(*pte)) {
@@ -314,7 +314,7 @@ void put_dirty_page(struct task_struct *
 	lru_cache_add(page);
 	flush_dcache_page(page);
 	flush_page_to_ram(page);
-	set_pte(pte, pte_mkdirty(pte_mkwrite(mk_pte(page, vma->vm_page_prot))));
+	vm_set_pte(vma, address, pte, pte_mkdirty(pte_mkwrite(mk_pte(page, vma->vm_page_prot))));
 	pte_chain = page_add_rmap(page, pte, pte_chain);
 	tsk->mm->rss++;
 	pte_unmap(pte);
@@ -324,7 +324,7 @@ void put_dirty_page(struct task_struct *
 	pte_chain_free(pte_chain);
 	return;
 out:
-	spin_unlock(&tsk->mm->page_table_lock);
+	spin_unlock(&vma->vm_mm->page_table_lock);
 out_nounlock:
 	__free_page(page);
 	force_sig(SIGKILL, tsk);
@@ -385,7 +385,7 @@ int setup_arg_pages(struct linux_binprm 
 		struct page *page = bprm->page[i];
 		if (page) {
 			bprm->page[i] = NULL;
-			put_dirty_page(current,page,stack_base);
+			new_put_dirty_page(current,mpnt,page,stack_base);
 		}
 		stack_base += PAGE_SIZE;
 	}
@@ -455,7 +455,9 @@ static int exec_mmap(void)
 	if (old_mm && atomic_read(&old_mm->mm_users) == 1) {
 		mm_release();
 		exit_aio(old_mm);
+		down_write(&old_mm->mmap_sem);
 		exit_mmap(old_mm);
+		up_write(&old_mm->mmap_sem);
 		return 0;
 	}
 
diff -urNp linux-1130/fs/proc/array.c linux-1140/fs/proc/array.c
--- linux-1130/fs/proc/array.c
+++ linux-1140/fs/proc/array.c
@@ -495,7 +495,7 @@ static void statm_pgd_range(pgd_t * pgd,
 int proc_pid_statm(struct task_struct *task, char * buffer)
 {
 	struct mm_struct *mm;
-	int size=0, resident=0, share=0, trs=0, lrs=0, drs=0, dt=0;
+	unsigned long size=0, resident=0, share=0, trs=0, lrs=0, drs=0, dt=0;
 
 	task_lock(task);
 	mm = task->mm;
@@ -503,6 +503,7 @@ int proc_pid_statm(struct task_struct *t
 		atomic_inc(&mm->mm_users);
 	task_unlock(task);
 	if (mm) {
+#if 0
 		struct vm_area_struct * vma;
 		down_read(&mm->mmap_sem);
 		vma = mm->mmap;
@@ -525,10 +526,31 @@ int proc_pid_statm(struct task_struct *t
 				drs += pages;
 			vma = vma->vm_next;
 		}
+		printk("new: sz%lu p%lu r%lu s%lu w%lu t%lu l%lu d%lu ",
+			mm->mm_stat.notpresent + mm->mm_stat.present,
+			mm->mm_stat.present,
+			mm->mm_stat.rss,
+			mm->mm_stat.sharable,
+			mm->mm_stat.writable,
+			mm->mm_stat.trs,
+			mm->mm_stat.lrs,
+			mm->mm_stat.drs
+			);
+		printk(" old: sz%d r%d s%d t%d l%d d%d dt%d\n",
+		       size, resident, share, trs, lrs, drs, dt);
 		up_read(&mm->mmap_sem);
+#else
+		size = mm->mm_stat.notpresent + mm->mm_stat.present;
+		resident = mm->mm_stat.rss;
+		share = mm->mm_stat.sharable;
+		trs = mm->mm_stat.trs;
+		lrs = mm->mm_stat.lrs;
+		drs = mm->mm_stat.drs;
+		dt = mm->mm_stat.writable;
+#endif
 		mmput(mm);
 	}
-	return sprintf(buffer,"%d %d %d %d %d %d %d\n",
+	return sprintf(buffer,"%lu %lu %lu %lu %lu %lu %lu\n",
 		       size, resident, share, trs, lrs, drs, dt);
 }
 
diff -urNp linux-1130/include/asm-alpha/pgalloc.h linux-1140/include/asm-alpha/pgalloc.h
--- linux-1130/include/asm-alpha/pgalloc.h
+++ linux-1140/include/asm-alpha/pgalloc.h
@@ -14,7 +14,7 @@ extern void __load_new_mm_context(struct
 /* Caches aren't brain-dead on the Alpha. */
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm, start, end)	do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
 #define flush_cache_page(vma, vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 #define flush_dcache_page(page)			do { } while (0)
@@ -210,10 +210,10 @@ static inline void flush_tlb_page(struct
  * Flush a specified range of user mapping:  on the
  * Alpha we flush the whole user tlb.
  */
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 	unsigned long start, unsigned long end)
 {
-	flush_tlb_mm(mm);
+	flush_tlb_mm(vma->vm_mm);
 }
 
 #else /* CONFIG_SMP */
@@ -221,7 +221,7 @@ static inline void flush_tlb_range(struc
 extern void flush_tlb_all(void);
 extern void flush_tlb_mm(struct mm_struct *);
 extern void flush_tlb_page(struct vm_area_struct *, unsigned long);
-extern void flush_tlb_range(struct mm_struct *, unsigned long, unsigned long);
+extern void flush_tlb_range(struct vm_area_struct *, unsigned long, unsigned long);
 
 #endif /* CONFIG_SMP */
 
diff -urNp linux-1130/include/asm-alpha/pgtable.h linux-1140/include/asm-alpha/pgtable.h
--- linux-1130/include/asm-alpha/pgtable.h
+++ linux-1140/include/asm-alpha/pgtable.h
@@ -342,8 +342,8 @@ extern inline pte_t mk_swap_pte(unsigned
 #define kern_addr_valid(addr)	(1)
 #endif
 
-#define io_remap_page_range(start, busaddr, size, prot) \
-    remap_page_range(start, virt_to_phys(__ioremap(busaddr, size)), size, prot)
+#define io_remap_page_range(vma, start, busaddr, size, prot) \
+    remap_page_range(vma, start, virt_to_phys(__ioremap(busaddr, size)), size, prot)
 
 #define pte_ERROR(e) \
 	printk("%s:%d: bad pte %016lx.\n", __FILE__, __LINE__, pte_val(e))
diff -urNp linux-1130/include/asm-arm/io.h linux-1140/include/asm-arm/io.h
--- linux-1130/include/asm-arm/io.h
+++ linux-1140/include/asm-arm/io.h
@@ -223,8 +223,8 @@ out:
  * remap a physical address `phys' of size `size' with page protection `prot'
  * into virtual address `from'
  */
-#define io_remap_page_range(from,phys,size,prot) \
-		remap_page_range(from,phys,size,prot)
+#define io_remap_page_range(vma,from,phys,size,prot) \
+		remap_page_range(vma,from,phys,size,prot)
 
 
 /*
diff -urNp linux-1130/include/asm-arm/proc-armo/cache.h linux-1140/include/asm-arm/proc-armo/cache.h
--- linux-1130/include/asm-arm/proc-armo/cache.h
+++ linux-1140/include/asm-arm/proc-armo/cache.h
@@ -11,7 +11,7 @@
  */
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm,start,end)		do { } while (0)
+#define flush_cache_range(vma,start,end)	do { } while (0)
 #define flush_cache_page(vma,vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 
@@ -34,12 +34,12 @@
  *  - flush_tlb_all() flushes all processes TLBs
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  */
 #define flush_tlb_all()				memc_update_all()
 #define flush_tlb_mm(mm)			memc_update_mm(mm)
-#define flush_tlb_range(mm,start,end)		\
-		do { memc_update_mm(mm); (void)(start); (void)(end); } while (0)
+#define flush_tlb_range(vma,start,end)		\
+		do { memc_update_mm(vma->vm_mm); (void)(start); (void)(end); } while (0)
 #define flush_tlb_page(vma, vmaddr)		do { } while (0)
 
 /*
diff -urNp linux-1130/include/asm-arm/proc-armv/cache.h linux-1140/include/asm-arm/proc-armv/cache.h
--- linux-1130/include/asm-arm/proc-armv/cache.h
+++ linux-1140/include/asm-arm/proc-armv/cache.h
@@ -42,9 +42,9 @@
 			cpu_cache_clean_invalidate_all();		\
 	} while (0)
 
-#define flush_cache_range(_mm,_start,_end)				\
+#define flush_cache_range(_vma,_start,_end)				\
 	do {								\
-		if ((_mm) == current->active_mm)			\
+		if ((_vma)->vm_mm == current->active_mm)			\
 			cpu_cache_clean_invalidate_range((_start) & PAGE_MASK, \
 							 PAGE_ALIGN(_end), 1); \
 	} while (0)
@@ -177,7 +177,7 @@ static inline void flush_dcache_page(str
  *  - flush_tlb_all()			flushes all processes TLBs
  *  - flush_tlb_mm(mm)			flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr)	flushes TLB for specified page
- *  - flush_tlb_range(mm, start, end)	flushes TLB for specified range of pages
+ *  - flush_tlb_range(vma, start, end)	flushes TLB for specified range of pages
  *
  * We drain the write buffer in here to ensure that the page tables in ram
  * are really up to date.  It is more efficient to do this here...
@@ -211,9 +211,9 @@ static inline void flush_dcache_page(str
  *
  * _mm may not be current->active_mm, but may not be NULL.
  */
-#define flush_tlb_range(_mm,_start,_end)				\
+#define flush_tlb_range(_vma,_start,_end)				\
 	do {								\
-		if ((_mm) == current->active_mm)			\
+		if ((_mm)->vm_mm == current->active_mm)			\
 			cpu_tlb_invalidate_range((_start), (_end));	\
 	} while (0)
 
diff -urNp linux-1130/include/asm-cris/pgtable.h linux-1140/include/asm-cris/pgtable.h
--- linux-1130/include/asm-cris/pgtable.h
+++ linux-1140/include/asm-cris/pgtable.h
@@ -128,7 +128,7 @@ extern void paging_init(void);
  */
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm, start, end)	do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
 #define flush_cache_page(vma, vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 #define flush_dcache_page(page)                 do { } while (0)
@@ -143,7 +143,7 @@ extern void paging_init(void);
  *  - flush_tlb_all() flushes all processes TLBs
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *
  */
 
@@ -151,7 +151,7 @@ extern void flush_tlb_all(void);
 extern void flush_tlb_mm(struct mm_struct *mm);
 extern void flush_tlb_page(struct vm_area_struct *vma, 
 			   unsigned long addr);
-extern void flush_tlb_range(struct mm_struct *mm,
+extern void flush_tlb_range(struct vm_area_struct *vma,
 			    unsigned long start,
 			    unsigned long end);
 
diff -urNp linux-1130/include/asm-generic/tlb.h linux-1140/include/asm-generic/tlb.h
--- linux-1130/include/asm-generic/tlb.h
+++ linux-1140/include/asm-generic/tlb.h
@@ -25,25 +25,27 @@
  * shootdown.
  */
 typedef struct free_pte_ctx {
-	struct mm_struct	*mm;
+	struct vm_area_struct	*vma;
 	unsigned long		nr;	/* set to ~0UL means fast mode */
 	unsigned long	start_addr, end_addr;
 	pte_t	ptes[FREE_PTE_NR];
 } mmu_gather_t;
 
+#define tlb_vma(ctx)           ((ctx)->vma)
+
 /* Users of the generic TLB shootdown code must declare this storage space. */
 extern mmu_gather_t	mmu_gathers[NR_CPUS];
 
 /* tlb_gather_mmu
  *	Return a pointer to an initialized mmu_gather_t.
  */
-static inline mmu_gather_t *tlb_gather_mmu(struct mm_struct *mm)
+static inline mmu_gather_t *tlb_gather_mmu(struct vm_area_struct *vma)
 {
 	mmu_gather_t *tlb = &mmu_gathers[smp_processor_id()];
 
-	tlb->mm = mm;
+	tlb->vma = vma;
 	/* Use fast mode if there is only one user of this mm (this process) */
-	tlb->nr = (atomic_read(&(mm)->mm_users) == 1) ? ~0UL : 0UL;
+	tlb->nr = (atomic_read(&vma->vm_mm->mm_users) == 1) ? ~0UL : 0UL;
 	return tlb;
 }
 
@@ -56,13 +58,13 @@ static inline mmu_gather_t *tlb_gather_m
 		/* Handle the common case fast, first. */\
 		if ((ctxp)->nr == ~0UL) {\
 			pte_t __pte = *(pte);\
-			pte_clear(pte);\
+			vm_pte_clear((ctxp)->vma, (addr), (pte));\
 			__free_pte(__pte);\
 			break;\
 		}\
 		if (!(ctxp)->nr) \
 			(ctxp)->start_addr = (addr);\
-		(ctxp)->ptes[(ctxp)->nr++] = ptep_get_and_clear(pte);\
+		(ctxp)->ptes[(ctxp)->nr++] = vm_ptep_get_and_clear((ctxp)->vma, (addr), (pte));\
 		(ctxp)->end_addr = (addr) + PAGE_SIZE;\
 		if ((ctxp)->nr >= FREE_PTE_NR)\
 			tlb_finish_mmu((ctxp), 0, 0);\
@@ -70,7 +72,7 @@ static inline mmu_gather_t *tlb_gather_m
 
 /* tlb_finish_mmu
  *	Called at the end of the shootdown operation to free up any resources
- *	that were required.  The page talbe lock is still held at this point.
+ *	that were required.  The page table lock is still held at this point.
  */
 static inline void tlb_finish_mmu(struct free_pte_ctx *ctx, unsigned long start, unsigned long end)
 {
@@ -78,13 +80,13 @@ static inline void tlb_finish_mmu(struct
 
 	/* Handle the fast case first. */
 	if (ctx->nr == ~0UL) {
-		flush_tlb_range(ctx->mm, start, end);
+		flush_tlb_range(ctx->vma, start, end);
 		return;
 	}
 	nr = ctx->nr;
 	ctx->nr = 0;
 	if (nr)
-		flush_tlb_range(ctx->mm, ctx->start_addr, ctx->end_addr);
+		flush_tlb_range(ctx->vma, ctx->start_addr, ctx->end_addr);
 	for (i=0; i < nr; i++) {
 		pte_t pte = ctx->ptes[i];
 		__free_pte(pte);
@@ -97,13 +99,14 @@ static inline void tlb_finish_mmu(struct
  * attempt to get gcc to generate optimal code since this code is run on each
  * page in a process at exit.
  */
-typedef struct mm_struct mmu_gather_t;
+typedef struct vm_area_struct mmu_gather_t;
 
-#define tlb_gather_mmu(mm)	(mm)
+#define tlb_vma(vma)		(vma)
+#define tlb_gather_mmu(vma)	(vma)
 #define tlb_finish_mmu(tlb, start, end)	flush_tlb_range(tlb, start, end)
 #define tlb_remove_page(tlb, ptep, addr)	do {\
 		pte_t __pte = *(ptep);\
-		pte_clear(ptep);\
+		vm_pte_clear((tlb), (addr), (ptep));\
 		__free_pte(__pte);\
 	} while (0)
 
diff -urNp linux-1130/include/asm-i386/pgalloc.h linux-1140/include/asm-i386/pgalloc.h
--- linux-1130/include/asm-i386/pgalloc.h
+++ linux-1140/include/asm-i386/pgalloc.h
@@ -68,7 +68,7 @@ extern int do_check_pgt_cache(int, int);
  *  - flush_tlb_all() flushes all processes TLBs
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  *
  * ..but the i386 has somewhat limited tlb flushing capabilities,
@@ -98,11 +98,11 @@ static inline void flush_tlb_page(struct
 #endif
 }
 
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 	unsigned long start, unsigned long end)
 {
 #ifndef CONFIG_X86_SWITCH_PAGETABLES
-	if (mm == current->active_mm)
+	if (vma->vm_mm == current->active_mm)
 		__flush_tlb();
 #endif
 }
@@ -120,9 +120,9 @@ extern void flush_tlb_page(struct vm_are
 
 #define flush_tlb()	flush_tlb_all()
 
-static inline void flush_tlb_range(struct mm_struct * mm, unsigned long start, unsigned long end)
+static inline void flush_tlb_range(struct vm_area_struct * vma, unsigned long start, unsigned long end)
 {
-	flush_tlb_mm(mm);
+	flush_tlb_mm(vma->vm_mm);
 }
 
 #define TLBSTATE_OK	1
diff -urNp linux-1130/include/asm-i386/pgtable.h linux-1140/include/asm-i386/pgtable.h
--- linux-1130/include/asm-i386/pgtable.h
+++ linux-1140/include/asm-i386/pgtable.h
@@ -27,7 +27,7 @@ extern void paging_init(void);
 /* Caches aren't brain-dead on the intel. */
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm, start, end)	do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
 #define flush_cache_page(vma, vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 #define flush_dcache_page(page)			do { } while (0)
diff -urNp linux-1130/include/asm-ia64/pgalloc.h linux-1140/include/asm-ia64/pgalloc.h
--- linux-1130/include/asm-ia64/pgalloc.h
+++ linux-1140/include/asm-ia64/pgalloc.h
@@ -227,7 +227,7 @@ flush_tlb_mm (struct mm_struct *mm)
 #endif
 }
 
-extern void flush_tlb_range (struct mm_struct *mm, unsigned long start, unsigned long end);
+extern void flush_tlb_range (struct vm_area_struct *vma, unsigned long start, unsigned long end);
 
 /*
  * Page-granular tlb flush.
@@ -236,7 +236,7 @@ static inline void
 flush_tlb_page (struct vm_area_struct *vma, unsigned long addr)
 {
 #ifdef CONFIG_SMP
-	flush_tlb_range(vma->vm_mm, (addr & PAGE_MASK), (addr & PAGE_MASK) + PAGE_SIZE);
+	flush_tlb_range(vma, (addr & PAGE_MASK), (addr & PAGE_MASK) + PAGE_SIZE);
 #else
 	if (vma->vm_mm == current->active_mm)
 		asm volatile ("ptc.l %0,%1" :: "r"(addr), "r"(PAGE_SHIFT << 2) : "memory");
@@ -260,7 +260,7 @@ flush_tlb_pgtables (struct mm_struct *mm
 		 */
 		flush_tlb_all();
 	else
-		flush_tlb_range(mm, ia64_thash(start), ia64_thash(end));
+		flush_tlb_range(mm->mmap, ia64_thash(start), ia64_thash(end));
 }
 
 /*
@@ -270,7 +270,7 @@ flush_tlb_pgtables (struct mm_struct *mm
 
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm, start, end)	do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
 #define flush_cache_page(vma, vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 #define flush_icache_page(vma,page)		do { } while (0)
diff -urNp linux-1130/include/asm-m68k/motorola_pgalloc.h linux-1140/include/asm-m68k/motorola_pgalloc.h
--- linux-1130/include/asm-m68k/motorola_pgalloc.h
+++ linux-1140/include/asm-m68k/motorola_pgalloc.h
@@ -241,10 +241,10 @@ static inline void flush_tlb_page(struct
 		__flush_tlb_one(addr);
 }
 
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 				   unsigned long start, unsigned long end)
 {
-	if (mm == current->mm)
+	if (vma->vm_mm == current->mm)
 		__flush_tlb();
 }
 
diff -urNp linux-1130/include/asm-m68k/pgalloc.h linux-1140/include/asm-m68k/pgalloc.h
--- linux-1130/include/asm-m68k/pgalloc.h
+++ linux-1140/include/asm-m68k/pgalloc.h
@@ -89,11 +89,11 @@ extern inline void flush_cache_mm(struct
 		__flush_cache_030();
 }
 
-extern inline void flush_cache_range(struct mm_struct *mm,
+extern inline void flush_cache_range(struct vm_area_struct *vma,
 				     unsigned long start,
 				     unsigned long end)
 {
-	if (mm == current->mm)
+	if (vma->vm_mm == current->mm)
 	        __flush_cache_030();
 }
 
diff -urNp linux-1130/include/asm-m68k/sun3_pgalloc.h linux-1140/include/asm-m68k/sun3_pgalloc.h
--- linux-1130/include/asm-m68k/sun3_pgalloc.h
+++ linux-1140/include/asm-m68k/sun3_pgalloc.h
@@ -216,9 +216,10 @@ static inline void flush_tlb_page (struc
 }
 /* Flush a range of pages from TLB. */
 
-static inline void flush_tlb_range (struct mm_struct *mm,
+static inline void flush_tlb_range (struct vm_area_struct *vma,
 		      unsigned long start, unsigned long end)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	unsigned char seg, oldctx;
 	
 	start &= ~SUN3_PMEG_MASK;
diff -urNp linux-1130/include/asm-mips/gfx.h linux-1140/include/asm-mips/gfx.h
--- linux-1130/include/asm-mips/gfx.h
+++ linux-1140/include/asm-mips/gfx.h
@@ -47,9 +47,9 @@ struct gfx_attach_board_args {
 
 #ifdef __KERNEL__
 /* umap.c */
-extern void remove_mapping (struct task_struct *, unsigned long, unsigned long);
+extern void remove_mapping (struct vm_area_struct *vma, struct task_struct *, unsigned long, unsigned long);
 extern void *vmalloc_uncached (unsigned long size);
-extern int vmap_page_range (unsigned long from, unsigned long size, unsigned long vaddr);
+extern int vmap_page_range (struct vm_area_struct *vma, unsigned long from, unsigned long size, unsigned long vaddr);
 #endif
 
 #endif /* _ASM_GFX_H */
diff -urNp linux-1130/include/asm-mips/pgalloc.h linux-1140/include/asm-mips/pgalloc.h
--- linux-1130/include/asm-mips/pgalloc.h
+++ linux-1140/include/asm-mips/pgalloc.h
@@ -18,7 +18,7 @@
  *  - flush_tlb_all() flushes all processes TLB entries
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB entries
  *  - flush_tlb_page(mm, vmaddr) flushes a single page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  */
 extern void local_flush_tlb_all(void);
@@ -32,14 +32,14 @@ extern void local_flush_tlb_page(struct 
 
 extern void flush_tlb_all(void);
 extern void flush_tlb_mm(struct mm_struct *);
-extern void flush_tlb_range(struct mm_struct *, unsigned long, unsigned long);
+extern void flush_tlb_range(struct vm_area_struct *, unsigned long, unsigned long);
 extern void flush_tlb_page(struct vm_area_struct *, unsigned long);
 
 #else /* CONFIG_SMP */
 
 #define flush_tlb_all()			local_flush_tlb_all()
 #define flush_tlb_mm(mm)		local_flush_tlb_mm(mm)
-#define flush_tlb_range(mm,vmaddr,end)	local_flush_tlb_range(mm, vmaddr, end)
+#define flush_tlb_range(vma,vmaddr,end)	local_flush_tlb_range((vma)->vm_mm, vmaddr, end)
 #define flush_tlb_page(vma,page)	local_flush_tlb_page(vma, page)
 
 #endif /* CONFIG_SMP */
diff -urNp linux-1130/include/asm-mips/pgtable.h linux-1140/include/asm-mips/pgtable.h
--- linux-1130/include/asm-mips/pgtable.h
+++ linux-1140/include/asm-mips/pgtable.h
@@ -22,7 +22,7 @@
  *  - flush_cache_all() flushes entire cache
  *  - flush_cache_mm(mm) flushes the specified mm context's cache lines
  *  - flush_cache_page(mm, vmaddr) flushes a single page
- *  - flush_cache_range(mm, start, end) flushes a range of pages
+ *  - flush_cache_range(vma, start, end) flushes a range of pages
  *  - flush_page_to_ram(page) write back kernel page to ram
  *  - flush_icache_range(start, end) flush a range of instructions
  *
@@ -48,7 +48,7 @@ extern void (*_flush_icache_all)(void);
 #define flush_cache_all()		_flush_cache_all()
 #define __flush_cache_all()		___flush_cache_all()
 #define flush_cache_mm(mm)		_flush_cache_mm(mm)
-#define flush_cache_range(mm,start,end)	_flush_cache_range(mm,start,end)
+#define flush_cache_range(vma,start,end) _flush_cache_range((vma)->vm_mm,start,end)
 #define flush_cache_page(vma,page)	_flush_cache_page(vma, page)
 #define flush_page_to_ram(page)		_flush_page_to_ram(page)
 
diff -urNp linux-1130/include/asm-mips/umap.h linux-1140/include/asm-mips/umap.h
--- linux-1130/include/asm-mips/umap.h
+++ linux-1140/include/asm-mips/umap.h
@@ -1,7 +1,7 @@
 #ifndef __MIPS_UMAP_H
 #define __MIPS_UMAP_H
 
-void remove_mapping (struct task_struct *task, unsigned long start,
+void remove_mapping (struct vm_area_struct *vma, struct task_struct *task, unsigned long start,
 unsigned long end);
 
 #endif
diff -urNp linux-1130/include/asm-mips64/gfx.h linux-1140/include/asm-mips64/gfx.h
--- linux-1130/include/asm-mips64/gfx.h
+++ linux-1140/include/asm-mips64/gfx.h
@@ -47,9 +47,9 @@ struct gfx_attach_board_args {
 
 #ifdef __KERNEL__
 /* umap.c */
-extern void remove_mapping (struct task_struct *, unsigned long, unsigned long);
+extern void remove_mapping (struct vm_area_struct *vma, struct task_struct *, unsigned long, unsigned long);
 extern void *vmalloc_uncached (unsigned long size);
-extern int vmap_page_range (unsigned long from, unsigned long size, unsigned long vaddr);
+extern int vmap_page_range (struct vm_area_struct *vma, unsigned long from, unsigned long size, unsigned long vaddr);
 #endif
 
 #endif /* _ASM_GFX_H */
diff -urNp linux-1130/include/asm-mips64/pgalloc.h linux-1140/include/asm-mips64/pgalloc.h
--- linux-1130/include/asm-mips64/pgalloc.h
+++ linux-1140/include/asm-mips64/pgalloc.h
@@ -16,7 +16,7 @@
  *  - flush_tlb_all() flushes all processes TLB entries
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB entries
  *  - flush_tlb_page(mm, vmaddr) flushes a single page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  */
 extern void local_flush_tlb_all(void);
@@ -30,14 +30,14 @@ extern void local_flush_tlb_page(struct 
 
 extern void flush_tlb_all(void);
 extern void flush_tlb_mm(struct mm_struct *);
-extern void flush_tlb_range(struct mm_struct *, unsigned long, unsigned long);
+extern void flush_tlb_range(struct vm_area_struct *, unsigned long, unsigned long);
 extern void flush_tlb_page(struct vm_area_struct *, unsigned long);
 
 #else /* CONFIG_SMP */
 
 #define flush_tlb_all()			local_flush_tlb_all()
 #define flush_tlb_mm(mm)		local_flush_tlb_mm(mm)
-#define flush_tlb_range(mm,vmaddr,end)	local_flush_tlb_range(mm, vmaddr, end)
+#define flush_tlb_range(vma,vmaddr,end)	local_flush_tlb_range((vma)->vm_mm, vmaddr, end)
 #define flush_tlb_page(vma,page)	local_flush_tlb_page(vma, page)
 
 #endif /* CONFIG_SMP */
diff -urNp linux-1130/include/asm-mips64/pgtable.h linux-1140/include/asm-mips64/pgtable.h
--- linux-1130/include/asm-mips64/pgtable.h
+++ linux-1140/include/asm-mips64/pgtable.h
@@ -25,7 +25,7 @@
  *  - flush_cache_all() flushes entire cache
  *  - flush_cache_mm(mm) flushes the specified mm context's cache lines
  *  - flush_cache_page(mm, vmaddr) flushes a single page
- *  - flush_cache_range(mm, start, end) flushes a range of pages
+ *  - flush_cache_range(vma, start, end) flushes a range of pages
  *  - flush_page_to_ram(page) write back kernel page to ram
  */
 extern void (*_flush_cache_all)(void);
@@ -63,7 +63,7 @@ extern void (*_flush_cache_l1)(void);
  */
 extern void andes_flush_icache_page(unsigned long);
 #define flush_cache_mm(mm)		do { } while(0)
-#define flush_cache_range(mm,start,end)	do { } while(0)
+#define flush_cache_range(vma,start,end)	do { } while(0)
 #define flush_cache_page(vma,page)	do { } while(0)
 #define flush_page_to_ram(page)		do { } while(0)
 #define flush_icache_range(start, end)	_flush_cache_l1()
@@ -78,7 +78,7 @@ do {									\
 #else
 
 #define flush_cache_mm(mm)		_flush_cache_mm(mm)
-#define flush_cache_range(mm,start,end)	_flush_cache_range(mm,start,end)
+#define flush_cache_range(vma,start,end) _flush_cache_range((vma)->vm_mm,start,end)
 #define flush_cache_page(vma,page)	_flush_cache_page(vma, page)
 #define flush_page_to_ram(page)		_flush_page_to_ram(page)
 #define flush_icache_range(start, end)	_flush_icache_range(start, end)
diff -urNp linux-1130/include/asm-parisc/pgalloc.h linux-1140/include/asm-parisc/pgalloc.h
--- linux-1130/include/asm-parisc/pgalloc.h
+++ linux-1140/include/asm-parisc/pgalloc.h
@@ -70,9 +70,10 @@ flush_user_icache_range(unsigned long st
 }
 
 static inline void
-flush_cache_range(struct mm_struct *mm, unsigned long start, unsigned long end)
+flush_cache_range(struct vma_area_struct *vma, unsigned long start, unsigned long end)
 {
 	int sr3;
+	struct mm_struct *mm = vma->vm_mm;
 
 	if (!mm->context) {
 		BUG();
@@ -190,10 +191,11 @@ static inline void flush_tlb_page(struct
 	pitlb(addr);
 }
 
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 	unsigned long start, unsigned long end)
 {
 	unsigned long npages;
+	struct mm_struct *mm = vma->vm_mm;
 
 	npages = ((end - (start & PAGE_MASK)) + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 	if (npages >= 512)  /* XXX arbitrary, should be tuned */
diff -urNp linux-1130/include/asm-ppc/pgtable.h linux-1140/include/asm-ppc/pgtable.h
--- linux-1130/include/asm-ppc/pgtable.h
+++ linux-1140/include/asm-ppc/pgtable.h
@@ -15,7 +15,7 @@
 extern void local_flush_tlb_all(void);
 extern void local_flush_tlb_mm(struct mm_struct *mm);
 extern void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long vmaddr);
-extern void local_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+extern void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				  unsigned long end);
 #define update_mmu_cache(vma, addr, pte)	do { } while (0)
 
@@ -29,7 +29,7 @@ static inline void local_flush_tlb_mm(st
 static inline void local_flush_tlb_page(struct vm_area_struct *vma,
 				unsigned long vmaddr)
 	{ __tlbia(); }
-static inline void local_flush_tlb_range(struct mm_struct *mm,
+static inline void local_flush_tlb_range(struct vm_area_struct *vma,
 				unsigned long start, unsigned long end)
 	{ __tlbia(); }
 #define update_mmu_cache(vma, addr, pte)	do { } while (0)
@@ -40,7 +40,7 @@ struct vm_area_struct;
 extern void local_flush_tlb_all(void);
 extern void local_flush_tlb_mm(struct mm_struct *mm);
 extern void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long vmaddr);
-extern void local_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+extern void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			    unsigned long end);
 
 /*
@@ -77,7 +77,7 @@ static inline void flush_tlb_pgtables(st
  */
 #define flush_cache_all()		do { } while (0)
 #define flush_cache_mm(mm)		do { } while (0)
-#define flush_cache_range(mm, a, b)	do { } while (0)
+#define flush_cache_range(vma, a, b)	do { } while (0)
 #define flush_cache_page(vma, p)	do { } while (0)
 #define flush_page_to_ram(page)		do { } while (0)
 
diff -urNp linux-1130/include/asm-ppc64/pgtable.h linux-1140/include/asm-ppc64/pgtable.h
--- linux-1130/include/asm-ppc64/pgtable.h
+++ linux-1140/include/asm-ppc64/pgtable.h
@@ -353,7 +353,7 @@ extern void local_flush_tlb_range(struct
 #define flush_tlb_all local_flush_tlb_all
 #define flush_tlb_mm local_flush_tlb_mm
 #define flush_tlb_page local_flush_tlb_page
-#define flush_tlb_range local_flush_tlb_range
+#define flush_tlb_range(vma, start, end) local_flush_tlb_range((vma)->vm_mm, start, end)
 
 static inline void flush_tlb_pgtables(struct mm_struct *mm,
 				      unsigned long start, unsigned long end)
@@ -368,7 +368,7 @@ static inline void flush_tlb_pgtables(st
  */
 #define flush_cache_all()		do { } while (0)
 #define flush_cache_mm(mm)		do { } while (0)
-#define flush_cache_range(mm, a, b)	do { } while (0)
+#define flush_cache_range(vma, a, b)	do { } while (0)
 #define flush_cache_page(vma, p)	do { } while (0)
 #define flush_page_to_ram(page)		do { } while (0)
 
@@ -437,7 +437,7 @@ typedef pte_t *pte_addr_t;
 #ifdef CONFIG_PPC_ISERIES
 #define io_remap_page_range remap_page_range
 #else
-extern int io_remap_page_range(unsigned long from, unsigned long to, unsigned long size, pgprot_t prot);
+extern int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long to, unsigned long size, pgprot_t prot);
 #endif
 
 /*
diff -urNp linux-1130/include/asm-s390/pgalloc.h linux-1140/include/asm-s390/pgalloc.h
--- linux-1130/include/asm-s390/pgalloc.h
+++ linux-1140/include/asm-s390/pgalloc.h
@@ -144,7 +144,7 @@ extern int do_check_pgt_cache(int, int);
  *    called only from vmalloc/vfree
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  */
 
@@ -184,7 +184,7 @@ static inline void flush_tlb_page(struct
 {
 	local_flush_tlb();
 }
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 				   unsigned long start, unsigned long end)
 {
 	local_flush_tlb();
@@ -253,10 +253,10 @@ static inline void flush_tlb_page(struct
 {
 	__flush_tlb_mm(vma->vm_mm);
 }
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 				   unsigned long start, unsigned long end)
 {
-	__flush_tlb_mm(mm); 
+	__flush_tlb_mm(vma->vm_mm); 
 }
 
 #endif
diff -urNp linux-1130/include/asm-s390/pgtable.h linux-1140/include/asm-s390/pgtable.h
--- linux-1130/include/asm-s390/pgtable.h
+++ linux-1140/include/asm-s390/pgtable.h
@@ -36,7 +36,7 @@ extern void paging_init(void);
 /* Caches aren't brain-dead on S390. */
 #define flush_cache_all()                       do { } while (0)
 #define flush_cache_mm(mm)                      do { } while (0)
-#define flush_cache_range(mm, start, end)       do { } while (0)
+#define flush_cache_range(vma, start, end)      do { } while (0)
 #define flush_cache_page(vma, vmaddr)           do { } while (0)
 #define flush_page_to_ram(page)                 do { } while (0)
 #define flush_dcache_page(page)			do { } while (0)
diff -urNp linux-1130/include/asm-s390x/pgalloc.h linux-1140/include/asm-s390x/pgalloc.h
--- linux-1130/include/asm-s390x/pgalloc.h
+++ linux-1140/include/asm-s390x/pgalloc.h
@@ -145,7 +145,7 @@ extern inline void pte_free(struct page 
  *    called only from vmalloc/vfree
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  */
 
@@ -185,7 +185,7 @@ static inline void flush_tlb_page(struct
 {
 	local_flush_tlb();
 }
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 				   unsigned long start, unsigned long end)
 {
 	local_flush_tlb();
@@ -245,10 +245,10 @@ static inline void flush_tlb_page(struct
 {
 	__flush_tlb_mm(vma->vm_mm);
 }
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 				   unsigned long start, unsigned long end)
 {
-	__flush_tlb_mm(mm); 
+	__flush_tlb_mm(vma->vm_mm);
 }
 
 #endif
diff -urNp linux-1130/include/asm-s390x/pgtable.h linux-1140/include/asm-s390x/pgtable.h
--- linux-1130/include/asm-s390x/pgtable.h
+++ linux-1140/include/asm-s390x/pgtable.h
@@ -32,7 +32,7 @@ extern void paging_init(void);
 /* Caches aren't brain-dead on S390. */
 #define flush_cache_all()                       do { } while (0)
 #define flush_cache_mm(mm)                      do { } while (0)
-#define flush_cache_range(mm, start, end)       do { } while (0)
+#define flush_cache_range(vma, start, end)      do { } while (0)
 #define flush_cache_page(vma, vmaddr)           do { } while (0)
 #define flush_page_to_ram(page)                 do { } while (0)
 #define flush_dcache_page(page)			do { } while (0)
diff -urNp linux-1130/include/asm-sh/pgalloc.h linux-1140/include/asm-sh/pgalloc.h
--- linux-1130/include/asm-sh/pgalloc.h
+++ linux-1140/include/asm-sh/pgalloc.h
@@ -78,14 +78,14 @@ static inline int do_check_pgt_cache(int
  *  - flush_tlb_all() flushes all processes TLBs
  *  - flush_tlb_mm(mm) flushes the specified mm context TLB's
  *  - flush_tlb_page(vma, vmaddr) flushes one page
- *  - flush_tlb_range(mm, start, end) flushes a range of pages
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  */
 
 extern void flush_tlb(void);
 extern void flush_tlb_all(void);
 extern void flush_tlb_mm(struct mm_struct *mm);
-extern void flush_tlb_range(struct mm_struct *mm, unsigned long start,
+extern void flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			    unsigned long end);
 extern void flush_tlb_page(struct vm_area_struct *vma, unsigned long page);
 extern void __flush_tlb_page(unsigned long asid, unsigned long page);
diff -urNp linux-1130/include/asm-sh/pgtable.h linux-1140/include/asm-sh/pgtable.h
--- linux-1130/include/asm-sh/pgtable.h
+++ linux-1140/include/asm-sh/pgtable.h
@@ -23,7 +23,7 @@ extern void paging_init(void);
  *  - flush_cache_all() flushes entire cache
  *  - flush_cache_mm(mm) flushes the specified mm context's cache lines
  *  - flush_cache_page(mm, vmaddr) flushes a single page
- *  - flush_cache_range(mm, start, end) flushes a range of pages
+ *  - flush_cache_range(vma, start, end) flushes a range of pages
  *
  *  - flush_dcache_page(pg) flushes(wback&invalidates) a page for dcache
  *  - flush_page_to_ram(page) write back kernel page to ram
@@ -35,7 +35,7 @@ extern void paging_init(void);
  */
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm, start, end)	do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
 #define flush_cache_page(vma, vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 #define flush_dcache_page(page)			do { } while (0)
@@ -56,7 +56,7 @@ extern void paging_init(void);
 
 extern void flush_cache_all(void);
 extern void flush_cache_mm(struct mm_struct *mm);
-extern void flush_cache_range(struct mm_struct *mm, unsigned long start,
+extern void flush_cache_range(struct vm_area_struct *vma, unsigned long start,
 			      unsigned long end);
 extern void flush_cache_page(struct vm_area_struct *vma, unsigned long addr);
 extern void flush_dcache_page(struct page *pg);
diff -urNp linux-1130/include/asm-sparc/pgalloc.h linux-1140/include/asm-sparc/pgalloc.h
--- linux-1130/include/asm-sparc/pgalloc.h
+++ linux-1140/include/asm-sparc/pgalloc.h
@@ -13,22 +13,22 @@
 #ifdef CONFIG_SMP
 BTFIXUPDEF_CALL(void, local_flush_cache_all, void)
 BTFIXUPDEF_CALL(void, local_flush_cache_mm, struct mm_struct *)
-BTFIXUPDEF_CALL(void, local_flush_cache_range, struct mm_struct *, unsigned long, unsigned long)
+BTFIXUPDEF_CALL(void, local_flush_cache_range, struct vm_area_struct *, unsigned long, unsigned long)
 BTFIXUPDEF_CALL(void, local_flush_cache_page, struct vm_area_struct *, unsigned long)
 
 #define local_flush_cache_all() BTFIXUP_CALL(local_flush_cache_all)()
 #define local_flush_cache_mm(mm) BTFIXUP_CALL(local_flush_cache_mm)(mm)
-#define local_flush_cache_range(mm,start,end) BTFIXUP_CALL(local_flush_cache_range)(mm,start,end)
+#define local_flush_cache_range(vma,start,end) BTFIXUP_CALL(local_flush_cache_range)(vma,start,end)
 #define local_flush_cache_page(vma,addr) BTFIXUP_CALL(local_flush_cache_page)(vma,addr)
 
 BTFIXUPDEF_CALL(void, local_flush_tlb_all, void)
 BTFIXUPDEF_CALL(void, local_flush_tlb_mm, struct mm_struct *)
-BTFIXUPDEF_CALL(void, local_flush_tlb_range, struct mm_struct *, unsigned long, unsigned long)
+BTFIXUPDEF_CALL(void, local_flush_tlb_range, struct vm_area_struct *, unsigned long, unsigned long)
 BTFIXUPDEF_CALL(void, local_flush_tlb_page, struct vm_area_struct *, unsigned long)
 
 #define local_flush_tlb_all() BTFIXUP_CALL(local_flush_tlb_all)()
 #define local_flush_tlb_mm(mm) BTFIXUP_CALL(local_flush_tlb_mm)(mm)
-#define local_flush_tlb_range(mm,start,end) BTFIXUP_CALL(local_flush_tlb_range)(mm,start,end)
+#define local_flush_tlb_range(vma,start,end) BTFIXUP_CALL(local_flush_tlb_range)(vma,start,end)
 #define local_flush_tlb_page(vma,addr) BTFIXUP_CALL(local_flush_tlb_page)(vma,addr)
 
 BTFIXUPDEF_CALL(void, local_flush_page_to_ram, unsigned long)
@@ -39,14 +39,14 @@ BTFIXUPDEF_CALL(void, local_flush_sig_in
 
 extern void smp_flush_cache_all(void);
 extern void smp_flush_cache_mm(struct mm_struct *mm);
-extern void smp_flush_cache_range(struct mm_struct *mm,
+extern void smp_flush_cache_range(struct vm_area_struct *vma,
 				  unsigned long start,
 				  unsigned long end);
 extern void smp_flush_cache_page(struct vm_area_struct *vma, unsigned long page);
 
 extern void smp_flush_tlb_all(void);
 extern void smp_flush_tlb_mm(struct mm_struct *mm);
-extern void smp_flush_tlb_range(struct mm_struct *mm,
+extern void smp_flush_tlb_range(struct vm_area_struct *vma,
 				  unsigned long start,
 				  unsigned long end);
 extern void smp_flush_tlb_page(struct vm_area_struct *mm, unsigned long page);
@@ -56,18 +56,18 @@ extern void smp_flush_sig_insns(struct m
 
 BTFIXUPDEF_CALL(void, flush_cache_all, void)
 BTFIXUPDEF_CALL(void, flush_cache_mm, struct mm_struct *)
-BTFIXUPDEF_CALL(void, flush_cache_range, struct mm_struct *, unsigned long, unsigned long)
+BTFIXUPDEF_CALL(void, flush_cache_range, struct vm_area_struct *, unsigned long, unsigned long)
 BTFIXUPDEF_CALL(void, flush_cache_page, struct vm_area_struct *, unsigned long)
 
 #define flush_cache_all() BTFIXUP_CALL(flush_cache_all)()
 #define flush_cache_mm(mm) BTFIXUP_CALL(flush_cache_mm)(mm)
-#define flush_cache_range(mm,start,end) BTFIXUP_CALL(flush_cache_range)(mm,start,end)
+#define flush_cache_range(vma,start,end) BTFIXUP_CALL(flush_cache_range)(vma,start,end)
 #define flush_cache_page(vma,addr) BTFIXUP_CALL(flush_cache_page)(vma,addr)
 #define flush_icache_range(start, end)		do { } while (0)
 
 BTFIXUPDEF_CALL(void, flush_tlb_all, void)
 BTFIXUPDEF_CALL(void, flush_tlb_mm, struct mm_struct *)
-BTFIXUPDEF_CALL(void, flush_tlb_range, struct mm_struct *, unsigned long, unsigned long)
+BTFIXUPDEF_CALL(void, flush_tlb_range, struct vm_area_struct *, unsigned long, unsigned long)
 BTFIXUPDEF_CALL(void, flush_tlb_page, struct vm_area_struct *, unsigned long)
 
 extern __inline__ void flush_tlb_pgtables(struct mm_struct *mm, unsigned long start, unsigned long end)
@@ -76,7 +76,7 @@ extern __inline__ void flush_tlb_pgtable
 
 #define flush_tlb_all() BTFIXUP_CALL(flush_tlb_all)()
 #define flush_tlb_mm(mm) BTFIXUP_CALL(flush_tlb_mm)(mm)
-#define flush_tlb_range(mm,start,end) BTFIXUP_CALL(flush_tlb_range)(mm,start,end)
+#define flush_tlb_range(vma,start,end) BTFIXUP_CALL(flush_tlb_range)(vma,start,end)
 #define flush_tlb_page(vma,addr) BTFIXUP_CALL(flush_tlb_page)(vma,addr)
 
 BTFIXUPDEF_CALL(void, __flush_page_to_ram, unsigned long)
diff -urNp linux-1130/include/asm-sparc/pgtable.h linux-1140/include/asm-sparc/pgtable.h
--- linux-1130/include/asm-sparc/pgtable.h
+++ linux-1140/include/asm-sparc/pgtable.h
@@ -443,7 +443,7 @@ extern unsigned long *sparc_valid_addr_b
 #define kern_addr_valid(addr) \
 	(test_bit(__pa((unsigned long)(addr))>>20, sparc_valid_addr_bitmap))
 
-extern int io_remap_page_range(unsigned long from, unsigned long to,
+extern int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long to,
 			       unsigned long size, pgprot_t prot, int space);
 
 #include <asm-generic/pgtable.h>
diff -urNp linux-1130/include/asm-sparc64/pgalloc.h linux-1140/include/asm-sparc64/pgalloc.h
--- linux-1130/include/asm-sparc64/pgalloc.h
+++ linux-1140/include/asm-sparc64/pgalloc.h
@@ -15,8 +15,7 @@
 /* These are the same regardless of whether this is an SMP kernel or not. */
 #define flush_cache_mm(__mm) \
 	do { if ((__mm) == current->mm) flushw_user(); } while(0)
-#define flush_cache_range(mm, start, end) \
-	flush_cache_mm(mm)
+extern void flush_cache_range(struct vm_area_struct *, unsigned long, unsigned long);
 #define flush_cache_page(vma, page) \
 	flush_cache_mm((vma)->vm_mm)
 
@@ -64,11 +63,11 @@ do { if(CTX_VALID((__mm)->context)) \
 	__flush_tlb_mm(CTX_HWBITS((__mm)->context), SECONDARY_CONTEXT); \
 } while(0)
 
-#define flush_tlb_range(__mm, start, end) \
-do { if(CTX_VALID((__mm)->context)) { \
+#define flush_tlb_range(__vma, start, end) \
+do { if(CTX_VALID((__vma)->vm_mm->context)) { \
 	unsigned long __start = (start)&PAGE_MASK; \
 	unsigned long __end = PAGE_ALIGN(end); \
-	__flush_tlb_range(CTX_HWBITS((__mm)->context), __start, \
+	__flush_tlb_range(CTX_HWBITS((__vma)->vm_mm->context), __start, \
 			  SECONDARY_CONTEXT, __end, PAGE_SIZE, \
 			  (__end - __start)); \
      } \
@@ -86,15 +85,15 @@ do { struct mm_struct *__mm = (vma)->vm_
 extern void smp_flush_cache_all(void);
 extern void smp_flush_tlb_all(void);
 extern void smp_flush_tlb_mm(struct mm_struct *mm);
-extern void smp_flush_tlb_range(struct mm_struct *mm, unsigned long start,
+extern void smp_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				unsigned long end);
 extern void smp_flush_tlb_page(struct mm_struct *mm, unsigned long page);
 
 #define flush_cache_all()	smp_flush_cache_all()
 #define flush_tlb_all()		smp_flush_tlb_all()
 #define flush_tlb_mm(mm)	smp_flush_tlb_mm(mm)
-#define flush_tlb_range(mm, start, end) \
-	smp_flush_tlb_range(mm, start, end)
+#define flush_tlb_range(vma, start, end) \
+	smp_flush_tlb_range(vma, start, end)
 #define flush_tlb_page(vma, page) \
 	smp_flush_tlb_page((vma)->vm_mm, page)
 
@@ -117,9 +116,13 @@ extern __inline__ void flush_tlb_pgtable
 	vpte_base = (tlb_type == spitfire ?
 		     VPTE_BASE_SPITFIRE :
 		     VPTE_BASE_CHEETAH);
-	flush_tlb_range(mm,
-			vpte_base + (s >> (PAGE_SHIFT - 3)),
-			vpte_base + (e >> (PAGE_SHIFT - 3)));
+	{
+		struct vm_area_struct vma;
+		vma.vm_mm = mm;
+		flush_tlb_range(&vma,
+				vpte_base + (s >> (PAGE_SHIFT - 3)),
+				vpte_base + (e >> (PAGE_SHIFT - 3)));
+	}
 }
 
 /* Page table allocation/freeing. */
diff -urNp linux-1130/include/asm-sparc64/pgtable.h linux-1140/include/asm-sparc64/pgtable.h
--- linux-1130/include/asm-sparc64/pgtable.h
+++ linux-1140/include/asm-sparc64/pgtable.h
@@ -336,7 +336,7 @@ extern unsigned long *sparc64_valid_addr
 #define kern_addr_valid(addr)	\
 	(test_bit(__pa((unsigned long)(addr))>>22, sparc64_valid_addr_bitmap))
 
-extern int io_remap_page_range(unsigned long from, unsigned long offset,
+extern int io_remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long offset,
 			       unsigned long size, pgprot_t prot, int space);
 
 #include <asm-generic/pgtable.h>
diff -urNp linux-1130/include/asm-x86_64/pgalloc.h linux-1140/include/asm-x86_64/pgalloc.h
--- linux-1130/include/asm-x86_64/pgalloc.h
+++ linux-1140/include/asm-x86_64/pgalloc.h
@@ -113,10 +113,10 @@ static inline void flush_tlb_page(struct
 		__flush_tlb_one(addr);
 }
 
-static inline void flush_tlb_range(struct mm_struct *mm,
+static inline void flush_tlb_range(struct vm_area_struct *vma,
 	unsigned long start, unsigned long end)
 {
-	if (mm == current->active_mm)
+	if (vma->vm_mm == current->active_mm)
 		__flush_tlb();
 }
 
@@ -134,9 +134,9 @@ extern void flush_tlb_page(struct vm_are
 
 #define flush_tlb()	flush_tlb_current_task()
 
-static inline void flush_tlb_range(struct mm_struct * mm, unsigned long start, unsigned long end)
+static inline void flush_tlb_range(struct vm_area_struct * vma, unsigned long start, unsigned long end)
 {
-	flush_tlb_mm(mm);
+	flush_tlb_mm(vma->vm_mm);
 }
 
 #define TLBSTATE_OK	1
diff -urNp linux-1130/include/asm-x86_64/pgtable.h linux-1140/include/asm-x86_64/pgtable.h
--- linux-1130/include/asm-x86_64/pgtable.h
+++ linux-1140/include/asm-x86_64/pgtable.h
@@ -34,7 +34,7 @@ extern void paging_init(void);
 /* Caches aren't brain-dead on the intel. */
 #define flush_cache_all()			do { } while (0)
 #define flush_cache_mm(mm)			do { } while (0)
-#define flush_cache_range(mm, start, end)	do { } while (0)
+#define flush_cache_range(vma, start, end)	do { } while (0)
 #define flush_cache_page(vma, vmaddr)		do { } while (0)
 #define flush_page_to_ram(page)			do { } while (0)
 #define flush_dcache_page(page)			do { } while (0)
diff -urNp linux-1130/include/linux/mm.h linux-1140/include/linux/mm.h
--- linux-1130/include/linux/mm.h
+++ linux-1140/include/linux/mm.h
@@ -609,10 +609,10 @@ struct file *shmem_file_setup(char * nam
 extern int shmem_lock(struct file *, int lock, struct mm_struct **, pid_t *);
 extern int shmem_zero_setup(struct vm_area_struct *);
 
-extern void zap_page_range(struct mm_struct *mm, unsigned long address, unsigned long size);
+extern void zap_page_range(struct vm_area_struct *vma, unsigned long address, unsigned long size);
 extern int copy_page_range(struct mm_struct *dst, struct mm_struct *src, struct vm_area_struct *vma);
-extern int remap_page_range(unsigned long from, unsigned long to, unsigned long size, pgprot_t prot);
-extern int zeromap_page_range(unsigned long from, unsigned long size, pgprot_t prot);
+extern int remap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long to, unsigned long size, pgprot_t prot);
+extern int zeromap_page_range(struct vm_area_struct *vma, unsigned long from, unsigned long size, pgprot_t prot);
 
 extern int vmtruncate(struct inode * inode, loff_t offset);
 extern pmd_t *FASTCALL(__pmd_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address));
@@ -663,7 +663,14 @@ static inline int is_page_cache_freeable
 extern int can_share_swap_page(struct page *);
 extern int remove_exclusive_swap_page(struct page *);
 
-extern void __free_pte(pte_t);
+/* vm pte ops for accounting. */
+extern void FASTCALL(vm_ptep_set_wrprotect(struct mm_struct *mm, pte_t *ptep));
+extern void FASTCALL(vm_set_pte(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep, pte_t pte));
+extern pte_t FASTCALL(vm_ptep_get_and_clear(struct vm_area_struct *vma, unsigned long addr, pte_t *ptep));
+extern void vm_pte_clear(struct vm_area_struct *vma, unsigned long address, pte_t *ptep);
+extern void FASTCALL(__free_pte(pte_t pte));
+extern void vm_account(struct vm_area_struct *, pte_t, unsigned long, long);
+
 
 /* mmap.c */
 extern void lock_vma_mappings(struct vm_area_struct *);
diff -urNp linux-1130/include/linux/sched.h linux-1140/include/linux/sched.h
--- linux-1130/include/linux/sched.h
+++ linux-1140/include/linux/sched.h
@@ -298,6 +298,17 @@ struct mm_struct {
 
 	unsigned dumpable:1;
 
+	struct {
+		unsigned long	lrs;
+		unsigned long	drs;
+		unsigned long	trs;
+		unsigned long	rss;
+		unsigned long	notpresent;
+		unsigned long	present;
+		unsigned long	sharable;
+		unsigned long	writable;
+	}		mm_stat;
+
 	/* Architecture-specific MM context */
 	mm_context_t context;
 
diff -urNp linux-1130/include/linux/videodev.h linux-1140/include/linux/videodev.h
--- linux-1130/include/linux/videodev.h
+++ linux-1140/include/linux/videodev.h
@@ -20,6 +20,9 @@
 
 #include <linux/poll.h>
 #include <linux/devfs_fs_kernel.h>
+#include <linux/mm.h>
+
+struct vm_area_struct;
 
 struct video_device
 {
@@ -37,7 +40,7 @@ struct video_device
 	long (*write)(struct video_device *, const char *, unsigned long, int noblock);
 	unsigned int (*poll)(struct video_device *, struct file *, poll_table *);
 	int (*ioctl)(struct video_device *, unsigned int , void *);
-	int (*mmap)(struct video_device *, const char *, unsigned long);
+	int (*mmap)(struct vm_area_struct *vma, struct video_device *, const char *, unsigned long);
 	int (*initialize)(struct video_device *);       
 
  	/* new interface -- we will use file_operations directly
diff -urNp linux-1130/kernel/fork.c linux-1140/kernel/fork.c
--- linux-1130/kernel/fork.c
+++ linux-1140/kernel/fork.c
@@ -288,6 +288,7 @@ static struct mm_struct * mm_init(struct
 	atomic_set(&mm->mm_users, 1);
 	atomic_set(&mm->mm_count, 1);
 	init_rwsem(&mm->mmap_sem);
+	memset(&mm->mm_stat, 0, sizeof(mm->mm_stat));
 	mm->core_waiters = 0;
 	mm->page_table_lock = SPIN_LOCK_UNLOCKED;
 	mm->free_area_cache = TASK_UNMAPPED_BASE;
diff -urNp linux-1130/mm/filemap.c linux-1140/mm/filemap.c
--- linux-1130/mm/filemap.c
+++ linux-1140/mm/filemap.c
@@ -2388,7 +2388,7 @@ int filemap_sync(struct vm_area_struct *
 	spin_lock(&vma->vm_mm->page_table_lock);
 
 	dir = pgd_offset(vma->vm_mm, address);
-	flush_cache_range(vma->vm_mm, end - size, end);
+	flush_cache_range(vma, end - size, end);
 	if (address >= end)
 		BUG();
 	do {
@@ -2396,7 +2396,7 @@ int filemap_sync(struct vm_area_struct *
 		address = (address + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	} while (address && (address < end));
-	flush_tlb_range(vma->vm_mm, end - size, end);
+	flush_tlb_range(vma, end - size, end);
 
 	spin_unlock(&vma->vm_mm->page_table_lock);
 
@@ -2755,7 +2755,7 @@ static long madvise_dontneed(struct vm_a
 	if (vma->vm_flags & VM_LOCKED)
 		return -EINVAL;
 
-	zap_page_range(vma->vm_mm, start, end - start);
+	zap_page_range(vma, start, end - start);
 	return 0;
 }
 
diff -urNp linux-1130/mm/fremap.c linux-1140/mm/fremap.c
--- linux-1130/mm/fremap.c
+++ linux-1140/mm/fremap.c
@@ -12,8 +12,10 @@
 #include <linux/pagemap.h>
 #include <asm/mmu_context.h>
 
-static inline int zap_pte(struct mm_struct *mm, pte_t *ptep)
+static inline int zap_pte(struct vm_area_struct *vma, pte_t *ptep, unsigned long addr)
 {
+
+	struct mm_struct *mm = vma->vm_mm;
 	pte_t pte = *ptep;
 
 	if (pte_none(pte))
@@ -21,7 +23,7 @@ static inline int zap_pte(struct mm_stru
 	if (pte_present(pte)) {
 		unsigned long pfn = pte_pfn(pte);
 
-		pte = ptep_get_and_clear(ptep);
+		pte = vm_ptep_get_and_clear(vma, addr, ptep);
 		if (pfn_valid(pfn)) {
 			struct page *page = pfn_to_page(pfn);
 			if (!PageReserved(page)) {
@@ -41,7 +43,7 @@ static inline int zap_pte(struct mm_stru
 		return 1;
 	} else {
 		free_swap_and_cache(pte_to_swp_entry(pte));
-		pte_clear(ptep);
+		vm_pte_clear(vma, addr, ptep);
 		return 0;
 	}
 }
@@ -69,13 +71,13 @@ int install_page(struct mm_struct *mm, s
 	if (!pte)
 		goto err_unlock;
 
-	flush = zap_pte(mm, pte);
+	flush = zap_pte(vma, pte, addr);
 
 	mm->rss++;
 	flush_page_to_ram(page);
 	flush_icache_page(vma, page);
 	entry = mk_pte(page, prot);
-	set_pte(pte, entry);
+	vm_set_pte(vma, addr, pte, entry);
 	pte_unmap(pte);
 	if (flush)
 		flush_tlb_page(vma, addr);
diff -urNp linux-1130/mm/memory.c linux-1140/mm/memory.c
--- linux-1130/mm/memory.c
+++ linux-1140/mm/memory.c
@@ -60,6 +60,74 @@ unsigned long num_mappedpages;
 void * high_memory;
 struct page *highmem_start_page;
 
+void vm_account(struct vm_area_struct *vma, pte_t pte, unsigned long address, long adj)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	if (pte_present(pte)) {
+		struct page *page = pte_page(pte);
+		if (VALID_PAGE(page) && !PageReserved(page)) {
+			if (vma->vm_flags & VM_EXECUTABLE)
+				mm->mm_stat.trs += adj;
+			else if (vma->vm_flags & VM_GROWSDOWN)
+				mm->mm_stat.drs += adj;
+			else if (address >= 0x60000000)
+				mm->mm_stat.lrs += adj;
+			else
+				mm->mm_stat.drs += adj;
+
+			mm->mm_stat.rss += adj;
+			/* Old shared was based on the current state of the
+			 * page.  We can't do that here, so just guess based
+			 * on potential of the page being in the page cache.
+			 */
+			if (page->mapping && !PageSwapCache(page)) {
+				mm->mm_stat.sharable += adj;
+				if (mm->mm_stat.sharable < 0)
+					mm->mm_stat.sharable = 0;
+			}
+		}
+		mm->mm_stat.present += adj;
+		if (pte_write(pte))
+			mm->mm_stat.writable += adj;
+	} else if (!pte_none(pte))
+		mm->mm_stat.notpresent += adj;
+}
+
+#define vm_account_add(vma, pte, addr)		vm_account(vma, pte, addr, +1)
+#define vm_account_remove(vma, pte, addr)	vm_account(vma, pte, addr, -1)
+
+void vm_ptep_set_wrprotect(struct mm_struct *mm, pte_t *ptep)
+{
+	if (pte_write(*ptep))
+		mm->mm_stat.writable--;
+	ptep_set_wrprotect(ptep);
+}
+
+void vm_set_pte(struct vm_area_struct *vma, unsigned long address, 
+		pte_t *ptep, pte_t pte)
+{
+	if (!pte_none(*ptep))
+		vm_account_remove(vma, *ptep, address);
+	vm_account_add(vma, pte, address);
+	set_pte(ptep, pte);
+}
+
+pte_t vm_ptep_get_and_clear(struct vm_area_struct *vma, unsigned long address,
+			    pte_t *ptep)
+{
+	pte_t pte = ptep_get_and_clear(ptep);
+	vm_account_remove(vma, pte, address);
+	return pte;
+}
+
+void vm_pte_clear(struct vm_area_struct *vma, unsigned long address,
+		  pte_t *ptep)
+{
+	pte_t pte = *ptep;
+	vm_account_remove(vma, pte, address);
+	pte_clear(ptep);
+}
+
 /*
  * We special-case the C-O-W ZERO_PAGE, because it's such
  * a common occurrence (no need to read the page to know
@@ -318,7 +386,7 @@ skip_copy_pte_range:		address = (address
 				/* pte contains position in swap, so copy. */
 				if (!pte_present(pte)) {
 					swap_duplicate(pte_to_swp_entry(pte));
-					set_pte(dst_pte, pte);
+					vm_set_pte(vma, address, dst_pte, pte);
 					goto cont_copy_pte_range_noset;
 				}
 				ptepage = pte_page(pte);
@@ -328,7 +396,7 @@ skip_copy_pte_range:		address = (address
 
 				/* If it's a COW mapping, write protect it both in the parent and the child */
 				if (cow && pte_write(pte)) {
-					ptep_set_wrprotect(src_pte);
+					vm_ptep_set_wrprotect(src, src_pte);
 					pte = *src_pte;
 				}
 
@@ -339,7 +407,7 @@ skip_copy_pte_range:		address = (address
 				get_page(ptepage);
 				dst->rss++;
 
-cont_copy_pte_range:		set_pte(dst_pte, pte);
+cont_copy_pte_range:		vm_set_pte(vma, address, dst_pte, pte);
 				pte_chain = page_add_rmap(ptepage, dst_pte,
 							pte_chain);
 				if (pte_chain)
@@ -433,7 +501,7 @@ static inline int zap_pte_range(mmu_gath
 			tlb_remove_page(tlb, ptep, address + offset);
 		} else {
 			free_swap_and_cache(pte_to_swp_entry(pte));
-			pte_clear(ptep);
+			vm_pte_clear(tlb_vma(tlb), address + offset, ptep);
 		}
 	}
 	pte_unmap(mapping);
@@ -476,8 +544,10 @@ static inline int zap_pmd_range(mmu_gath
  * @address: starting address of pages to zap
  * @size: number of bytes to zap
  */
-void zap_page_range(struct mm_struct *mm, unsigned long address, unsigned long size)
+void zap_page_range(struct vm_area_struct *vma, unsigned long address,
+		    unsigned long size)
 {
+	struct mm_struct *mm = vma->vm_mm;
 	mmu_gather_t *tlb;
 	pgd_t * dir;
 	unsigned long start, end, addr, block;
@@ -504,8 +574,8 @@ void zap_page_range(struct mm_struct *mm
 		BUG_ON(address >= end);
 
 		spin_lock(&mm->page_table_lock);
-		flush_cache_range(mm, start, end);
-		tlb = tlb_gather_mmu(mm);
+		flush_cache_range(vma, start, end);
+		tlb = tlb_gather_mmu(vma);
 
 		do {
 			freed += zap_pmd_range(tlb, dir, addr, end - addr);
@@ -920,26 +990,30 @@ int unlock_kiovec(int nr, struct kiobuf 
 	return 0;
 }
 
-static inline void zeromap_pte_range(pte_t * pte, unsigned long address,
+static inline void zeromap_pte_range(struct vm_area_struct *vma,
+				     pte_t * pte, unsigned long address,
                                      unsigned long size, pgprot_t prot)
 {
-	unsigned long end;
+	unsigned long end, start;
 
+	start = address & PMD_MASK;
 	address &= ~PMD_MASK;
 	end = address + size;
 	if (end > PMD_SIZE)
 		end = PMD_SIZE;
 	do {
-		pte_t zero_pte = pte_wrprotect(mk_pte(ZERO_PAGE(address), prot));
-		pte_t oldpage = ptep_get_and_clear(pte);
-		set_pte(pte, zero_pte);
+		pte_t zero_pte = pte_wrprotect(mk_pte(ZERO_PAGE(address + start), prot));
+		pte_t oldpage = vm_ptep_get_and_clear(vma, address + start, pte);
+		vm_set_pte(vma, address + start, pte, zero_pte);
 		forget_pte(oldpage);
 		address += PAGE_SIZE;
 		pte++;
 	} while (address && (address < end));
 }
 
-static inline int zeromap_pmd_range(struct mm_struct *mm, pmd_t * pmd, unsigned long address,
+static inline int zeromap_pmd_range(struct vm_area_struct *vma,
+				    struct mm_struct *mm, pmd_t * pmd,
+				    unsigned long address,
                                     unsigned long size, pgprot_t prot)
 {
 	unsigned long base, end;
@@ -953,7 +1027,7 @@ static inline int zeromap_pmd_range(stru
 		pte_t * pte = pte_alloc_map(mm, pmd, base + address);
 		if (!pte)
 			return -ENOMEM;
-		zeromap_pte_range(pte, base + address, end - address, prot);
+		zeromap_pte_range(vma, pte, base + address, end - address, prot);
 		pte_unmap(pte);
 		address = (address + PMD_SIZE) & PMD_MASK;
 		pmd++;
@@ -961,7 +1035,8 @@ static inline int zeromap_pmd_range(stru
 	return 0;
 }
 
-int zeromap_page_range(unsigned long address, unsigned long size, pgprot_t prot)
+int zeromap_page_range(struct vm_area_struct *vma, unsigned long address,
+		       unsigned long size, pgprot_t prot)
 {
 	int error = 0;
 	pgd_t * dir;
@@ -970,7 +1045,7 @@ int zeromap_page_range(unsigned long add
 	struct mm_struct *mm = current->mm;
 
 	dir = pgd_offset(mm, address);
-	flush_cache_range(mm, beg, end);
+	flush_cache_range(vma, beg, end);
 	if (address >= end)
 		BUG();
 
@@ -980,14 +1055,14 @@ int zeromap_page_range(unsigned long add
 		error = -ENOMEM;
 		if (!pmd)
 			break;
-		error = zeromap_pmd_range(mm, pmd, address, end - address, prot);
+		error = zeromap_pmd_range(vma, mm, pmd, address, end - address, prot);
 		if (error)
 			break;
 		address = (address + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	} while (address && (address < end));
 	spin_unlock(&mm->page_table_lock);
-	flush_tlb_range(mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 	return error;
 }
 
@@ -996,11 +1071,13 @@ int zeromap_page_range(unsigned long add
  * mappings are removed. any references to nonexistent pages results
  * in null mappings (currently treated as "copy-on-access")
  */
-static inline void remap_pte_range(pte_t * pte, unsigned long address, unsigned long size,
+static inline void remap_pte_range(struct vm_area_struct *vma,
+	pte_t * pte, unsigned long address, unsigned long size,
 	unsigned long phys_addr, pgprot_t prot)
 {
-	unsigned long end;
+	unsigned long end, start;
 
+	start = address & PMD_MASK;
 	address &= ~PMD_MASK;
 	end = address + size;
 	if (end > PMD_SIZE)
@@ -1008,11 +1085,12 @@ static inline void remap_pte_range(pte_t
 	do {
 		struct page *page;
 		pte_t oldpage;
-		oldpage = ptep_get_and_clear(pte);
+		oldpage = vm_ptep_get_and_clear(vma, address + start, pte);
 
 		page = virt_to_page(__va(phys_addr));
 		if ((!VALID_PAGE(page)) || PageReserved(page))
- 			set_pte(pte, mk_pte_phys(phys_addr, prot));
+ 			vm_set_pte(vma, address + start,
+				   pte, mk_pte_phys(phys_addr, prot));
 		forget_pte(oldpage);
 		address += PAGE_SIZE;
 		phys_addr += PAGE_SIZE;
@@ -1020,8 +1098,9 @@ static inline void remap_pte_range(pte_t
 	} while (address && (address < end));
 }
 
-static inline int remap_pmd_range(struct mm_struct *mm, pmd_t * pmd, unsigned long address, unsigned long size,
-	unsigned long phys_addr, pgprot_t prot)
+static inline int remap_pmd_range(struct vm_area_struct *vma, 
+		struct mm_struct *mm, pmd_t * pmd, unsigned long address,
+		unsigned long size, unsigned long phys_addr, pgprot_t prot)
 {
 	unsigned long base, end;
 
@@ -1035,7 +1114,7 @@ static inline int remap_pmd_range(struct
 		pte_t * pte = pte_alloc_map(mm, pmd, address + base);
 		if (!pte)
 			return -ENOMEM;
-		remap_pte_range(pte, base + address, end - address, address + phys_addr, prot);
+		remap_pte_range(vma, pte, base + address, end - address, address + phys_addr, prot);
 		pte_unmap(pte);
 		address = (address + PMD_SIZE) & PMD_MASK;
 		pmd++;
@@ -1044,7 +1123,8 @@ static inline int remap_pmd_range(struct
 }
 
 /*  Note: this is only safe if the mm semaphore is held when called. */
-int remap_page_range(unsigned long from, unsigned long phys_addr, unsigned long size, pgprot_t prot)
+int remap_page_range(struct vm_area_struct *vma, unsigned long from,
+		unsigned long phys_addr, unsigned long size, pgprot_t prot)
 {
 	int error = 0;
 	pgd_t * dir;
@@ -1052,9 +1132,11 @@ int remap_page_range(unsigned long from,
 	unsigned long end = from + size;
 	struct mm_struct *mm = current->mm;
 
+	vma->vm_flags |= VM_IO | VM_RESERVED;
+	
 	phys_addr -= from;
 	dir = pgd_offset(mm, from);
-	flush_cache_range(mm, beg, end);
+	flush_cache_range(vma, beg, end);
 	if (from >= end)
 		BUG();
 
@@ -1064,14 +1146,14 @@ int remap_page_range(unsigned long from,
 		error = -ENOMEM;
 		if (!pmd)
 			break;
-		error = remap_pmd_range(mm, pmd, from, end - from, phys_addr + from, prot);
+		error = remap_pmd_range(vma, mm, pmd, from, end - from, phys_addr + from, prot);
 		if (error)
 			break;
 		from = (from + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	} while (from && (from < end));
 	spin_unlock(&mm->page_table_lock);
-	flush_tlb_range(mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 	return error;
 }
 
@@ -1196,7 +1278,6 @@ no_mem:
 static void vmtruncate_list(struct vm_area_struct *mpnt, unsigned long pgoff)
 {
 	do {
-		struct mm_struct *mm = mpnt->vm_mm;
 		unsigned long start = mpnt->vm_start;
 		unsigned long end = mpnt->vm_end;
 		unsigned long len = end - start;
@@ -1204,7 +1285,7 @@ static void vmtruncate_list(struct vm_ar
 
 		/* mapping wholly truncated? */
 		if (mpnt->vm_pgoff >= pgoff) {
-			zap_page_range(mm, start, len);
+			zap_page_range(mpnt, start, len);
 			continue;
 		}
 
@@ -1217,7 +1298,7 @@ static void vmtruncate_list(struct vm_ar
 		/* Ok, partially affected.. */
 		start += diff << PAGE_SHIFT;
 		len = (len - diff) << PAGE_SHIFT;
-		zap_page_range(mm, start, len);
+		zap_page_range(mpnt, start, len);
 	} while ((mpnt = mpnt->vm_next_share) != NULL);
 }
 
@@ -1379,7 +1460,7 @@ static int do_swap_page(struct mm_struct
 
 	flush_page_to_ram(page);
 	flush_icache_page(vma, page);
-	set_pte(page_table, pte);
+	vm_set_pte(vma, address, page_table, pte);
 	pte_chain = page_add_rmap(page, page_table, pte_chain);
 
 	/* No need to invalidate - it was non-present before */
@@ -1434,7 +1515,7 @@ static int do_anonymous_page(struct mm_s
 		lru_cache_add(page);
 	}
 
-	set_pte(page_table, entry);
+	vm_set_pte(vma, addr, page_table, entry);
 	if (write_access)
 		pte_chain = page_add_rmap(page, page_table, pte_chain);
 
@@ -1525,7 +1606,7 @@ static int do_no_page(struct mm_struct *
 		entry = mk_pte(new_page, vma->vm_page_prot);
 		if (write_access)
 			entry = pte_mkwrite(pte_mkdirty(entry));
-		set_pte(page_table, entry);
+		vm_set_pte(vma, address, page_table, entry);
 		pte_chain = page_add_rmap(new_page, page_table, pte_chain);
 		pte_unmap(page_table);
 	} else {
diff -urNp linux-1130/mm/mmap.c linux-1140/mm/mmap.c
--- linux-1130/mm/mmap.c
+++ linux-1140/mm/mmap.c
@@ -724,7 +724,7 @@ unmap_and_free_vma:
 	fput(file);
 
 	/* Undo any partial mapping done by a device driver. */
-	zap_page_range(mm, vma->vm_start, vma->vm_end - vma->vm_start);
+	zap_page_range(vma, vma->vm_start, vma->vm_end - vma->vm_start);
 free_vma:
 	kmem_cache_free(vm_area_cachep, vma);
 unacct_error:
@@ -1217,7 +1217,7 @@ int do_munmap(struct mm_struct *mm, unsi
 		remove_shared_vm_struct(mpnt);
 		mm->map_count--;
 
-		zap_page_range(mm, st, size);
+		zap_page_range(mpnt, st, size);
 
 		/*
 		 * Fix the mapping, and free the old area if it wasn't reused.
@@ -1396,7 +1396,7 @@ void exit_mmap(struct mm_struct * mm)
 		}
 		mm->map_count--;
 		remove_shared_vm_struct(mpnt);
-		zap_page_range(mm, start, size);
+		zap_page_range(mpnt, start, size);
 		if (mpnt->vm_file)
 			fput(mpnt->vm_file);
 		kmem_cache_free(vm_area_cachep, mpnt);
diff -urNp linux-1130/mm/mprotect.c linux-1140/mm/mprotect.c
--- linux-1130/mm/mprotect.c
+++ linux-1140/mm/mprotect.c
@@ -30,11 +30,12 @@
 #include <asm/pgalloc.h>
 #include <asm/pgtable.h>
 
-static inline void change_pte_range(pmd_t * pmd, unsigned long address,
+static inline void change_pte_range(struct vm_area_struct *vma,
+	pmd_t * pmd, unsigned long address,
 	unsigned long size, pgprot_t newprot)
 {
 	pte_t *pte, *mapping;
-	unsigned long end;
+	unsigned long end, start;
 
 	if (pmd_none(*pmd))
 		return;
@@ -44,6 +45,7 @@ static inline void change_pte_range(pmd_
 		return;
 	}
 	mapping = pte = pte_offset_map(pmd, address);
+	start = address & PMD_MASK;
 	address &= ~PMD_MASK;
 	end = address + size;
 	if (end > PMD_SIZE)
@@ -56,8 +58,9 @@ static inline void change_pte_range(pmd_
 			 * bits by wiping the pte and then setting the new pte
 			 * into place.
 			 */
-			entry = ptep_get_and_clear(pte);
-			set_pte(pte, pte_modify(entry, newprot));
+			entry = vm_ptep_get_and_clear(vma, address + start, pte);
+			vm_set_pte(vma, address + start,
+				   pte, pte_modify(entry, newprot));
 		}
 		address += PAGE_SIZE;
 		pte++;
@@ -65,11 +68,12 @@ static inline void change_pte_range(pmd_
 	pte_unmap(mapping);
 }
 
-static inline void change_pmd_range(pgd_t * pgd, unsigned long address,
+static inline void change_pmd_range(struct vm_area_struct *vma,
+	pgd_t * pgd, unsigned long address,
 	unsigned long size, pgprot_t newprot)
 {
 	pmd_t * pmd;
-	unsigned long end;
+	unsigned long end, start;
 
 	if (pgd_none(*pgd))
 		return;
@@ -79,40 +83,42 @@ static inline void change_pmd_range(pgd_
 		return;
 	}
 	pmd = pmd_offset(pgd, address);
+	start = address & PGDIR_MASK;
 	address &= ~PGDIR_MASK;
 	end = address + size;
 	if (end > PGDIR_SIZE)
 		end = PGDIR_SIZE;
 	do {
-		change_pte_range(pmd, address, end - address, newprot);
+		change_pte_range(vma, pmd, start + address, end - address, newprot);
 		address = (address + PMD_SIZE) & PMD_MASK;
 		pmd++;
 	} while (address && (address < end));
 }
 
-static void change_protection(unsigned long start, unsigned long end, pgprot_t newprot)
+static void change_protection(struct vm_area_struct *vma, unsigned long start, unsigned long end, pgprot_t newprot)
 {
 	pgd_t *dir;
 	unsigned long beg = start;
 
 	dir = pgd_offset(current->mm, start);
-	flush_cache_range(current->mm, beg, end);
+	flush_cache_range(vma, beg, end);
 	if (start >= end)
 		BUG();
 	spin_lock(&current->mm->page_table_lock);
 	do {
-		change_pmd_range(dir, start, end - start, newprot);
+		change_pmd_range(vma, dir, start, end - start, newprot);
 		start = (start + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	} while (start && (start < end));
 	spin_unlock(&current->mm->page_table_lock);
-	flush_tlb_range(current->mm, beg, end);
+	flush_tlb_range(vma, beg, end);
 }
 
-static inline int mprotect_fixup_all(struct vm_area_struct * vma, struct vm_area_struct ** pprev,
+static inline int mprotect_fixup_all(struct vm_area_struct ** pvma, struct vm_area_struct ** pprev,
 	int newflags, pgprot_t prot)
 {
 	struct vm_area_struct * prev = *pprev;
+	struct vm_area_struct * vma = *pvma;
 	struct mm_struct * mm = vma->vm_mm;
 	int oldflags;
 
@@ -125,6 +131,7 @@ static inline int mprotect_fixup_all(str
 
 		kmem_cache_free(vm_area_cachep, vma);
 		mm->map_count--;
+		*pvma = prev;
 
 		return 0;
 	}
@@ -298,7 +305,7 @@ static int mprotect_fixup(struct vm_area
 	newprot = protection_map[newflags & 0xf];
 	if (start == vma->vm_start) {
 		if (end == vma->vm_end)
-			error = mprotect_fixup_all(vma, pprev, newflags, newprot);
+			error = mprotect_fixup_all(&vma, pprev, newflags, newprot);
 		else
 			error = mprotect_fixup_start(vma, pprev, end, newflags, newprot);
 	} else if (end == vma->vm_end)
@@ -309,7 +316,7 @@ static int mprotect_fixup(struct vm_area
 		vm_unacct_memory(charged);
 		return error;
 	}
-	change_protection(start, end, newprot);
+	change_protection(vma, start, end, newprot);
 	return 0;
 }
 
diff -urNp linux-1130/mm/mremap.c linux-1140/mm/mremap.c
--- linux-1130/mm/mremap.c
+++ linux-1140/mm/mremap.c
@@ -91,7 +91,8 @@ static inline pte_t *alloc_one_pte_map(s
 	return pte;
 }
 
-static int copy_one_pte(struct mm_struct *mm, pte_t * src, pte_t * dst,
+static int copy_one_pte(struct vm_area_struct *vma, pte_t * src, pte_t * dst,
+			unsigned long old_addr, unsigned long new_addr,
 			struct pte_chain ** pte_chainp)
 {
 	int error = 0;
@@ -104,13 +105,13 @@ static int copy_one_pte(struct mm_struct
 	if (!pte_none(*src)) {
 		if (page)
 			page_remove_rmap(page, src);
-		pte = ptep_get_and_clear(src);
+		pte = vm_ptep_get_and_clear(vma, old_addr, src);
 		if (!dst) {
 			/* No dest?  We must put it back. */
 			dst = src;
 			error++;
 		}
-		set_pte(dst, pte);
+		vm_set_pte(vma, new_addr, dst, pte);
 		if (page)
 			*pte_chainp = page_add_rmap(page, dst, *pte_chainp);
 	}
@@ -142,7 +143,7 @@ static int move_one_page(struct vm_area_
 		dst = alloc_one_pte_map(mm, new_addr);
 		if (src == NULL)
 			src = get_one_pte_map_nested(mm, old_addr);
-		error = copy_one_pte(mm, src, dst, &pte_chain);
+		error = copy_one_pte(vma, src, dst, old_addr, new_addr, &pte_chain);
 		pte_unmap_nested(src);
 		pte_unmap(dst);
 	}
@@ -182,7 +183,7 @@ oops_we_failed:
 	flush_cache_range(vma, new_addr, new_addr + len);
 	while ((offset += PAGE_SIZE) < len)
 		move_one_page(vma, new_addr + offset, old_addr + offset);
-	zap_page_range(vma->vm_mm, new_addr, len);
+	zap_page_range(vma, new_addr, len);
 	return -1;
 }
 
diff -urNp linux-1130/mm/rmap.c linux-1140/mm/rmap.c
--- linux-1130/mm/rmap.c
+++ linux-1140/mm/rmap.c
@@ -440,7 +440,7 @@ static int try_to_unmap_one(struct page 
 	}
 
 	/* Nuke the page table entry. */
-	pte = ptep_get_and_clear(ptep);
+	pte = vm_ptep_get_and_clear(vma, address, ptep);
 	flush_tlb_page(vma, address);
 	flush_cache_page(vma, address);
 
@@ -448,7 +448,7 @@ static int try_to_unmap_one(struct page 
 	if (PageSwapCache(page)) {
 		swp_entry_t entry = { .val = page->index };
 		swap_duplicate(entry);
-		set_pte(ptep, swp_entry_to_pte(entry));
+		vm_set_pte(vma, address, ptep, swp_entry_to_pte(entry));
 	}
 
 	/* Move the dirty bit to the physical page now the pte is gone. */
diff -urNp linux-1130/mm/swapfile.c linux-1140/mm/swapfile.c
--- linux-1130/mm/swapfile.c
+++ linux-1140/mm/swapfile.c
@@ -373,7 +373,7 @@ unuse_pte(struct vm_area_struct * vma, u
 	if (unlikely(pte_none(pte) || pte_present(pte)))
 		return;
 	get_page(page);
-	set_pte(dir, pte_mkold(mk_pte(page, vma->vm_page_prot)));
+	vm_set_pte(vma, address, dir, pte_mkold(mk_pte(page, vma->vm_page_prot)));
 	*pte_chainp = page_add_rmap(page, dir, *pte_chainp);
 	swap_free(entry);
 	++vma->vm_mm->rss;
diff -urNp linux-1130/net/packet/af_packet.c linux-1140/net/packet/af_packet.c
--- linux-1130/net/packet/af_packet.c
+++ linux-1140/net/packet/af_packet.c
@@ -1765,7 +1765,7 @@ static int packet_mmap(struct file *file
 	start = vma->vm_start;
 	err = -EAGAIN;
 	for (i=0; i<po->pg_vec_len; i++) {
-		if (remap_page_range(start, __pa(po->pg_vec[i]),
+		if (remap_page_range(vma, start, __pa(po->pg_vec[i]),
 				     po->pg_vec_pages*PAGE_SIZE,
 				     vma->vm_page_prot))
 			goto out;
