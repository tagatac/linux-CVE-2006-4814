diff -urNp linux-1225/fs/ramfs/inode.c linux-1226/fs/ramfs/inode.c
--- linux-1225/fs/ramfs/inode.c
+++ linux-1226/fs/ramfs/inode.c
@@ -29,6 +29,7 @@
 #include <linux/init.h>
 #include <linux/string.h>
 #include <linux/locks.h>
+#include <linux/mm_inline.h>
 
 #include <asm/uaccess.h>
 
@@ -313,6 +314,21 @@ repeat:
 	return 0;
 }
 
+static int ramfs_writepage(struct page *page)
+{
+
+	lru_lock(page_zone(page));
+	if (PageLaunder(page) && PageInactiveLaundry(page)) {
+		del_page_from_inactive_laundry_list(page);
+		add_page_to_wired_list(page);
+		 lru_unlock(page_zone(page));
+		 UnlockPage(page);
+		return 0;
+	} else
+		lru_unlock(page_zone(page));
+	return fail_writepage(page);
+}
+
 static struct vm_operations_struct ramfs_vm_ops = {
 	nopage: filemap_nopage,
 	populate: ramfs_populate,
@@ -320,7 +336,7 @@ static struct vm_operations_struct ramfs
 
 static struct address_space_operations ramfs_aops = {
 	readpage:	ramfs_readpage,
-	writepage:	fail_writepage,
+	writepage:	ramfs_writepage,
 	prepare_write:	ramfs_prepare_write,
 	commit_write:	ramfs_commit_write,
 };
diff -urNp linux-1225/include/linux/mm.h linux-1226/include/linux/mm.h
--- linux-1225/include/linux/mm.h
+++ linux-1226/include/linux/mm.h
@@ -330,6 +330,7 @@ typedef struct page {
 #define PG_sync			20
 #define PG_fresh_page		21	/* Page freshly read from disk */
 #define PG_compound		22	/* Part of a compound page */
+#define PG_wired		23	/* wired by ramfs */
 
 /* note: don't make page flags of values 24 or higher! */
 
@@ -361,6 +362,9 @@ typedef struct page {
 #define ClearPageReferenced(page) clear_bit(PG_referenced, &(page)->flags)
 #define ClearPageError(page)    clear_bit(PG_error, &(page)->flags)
 #define ClearPageArch1(page)    clear_bit(PG_arch_1, &(page)->flags)
+#define SetPageWired(page)	set_bit(PG_wired, &(page)->flags)
+#define ClearPageWired(page)	clear_bit(PG_wired, &(page)->flags)
+#define PageWired(page)		test_bit(PG_wired, &(page)->flags)
 
 /*
  * inlines for acquisition and release of PG_chainlock
diff -urNp linux-1225/include/linux/mm_inline.h linux-1226/include/linux/mm_inline.h
--- linux-1225/include/linux/mm_inline.h
+++ linux-1226/include/linux/mm_inline.h
@@ -170,6 +170,16 @@ static inline void add_page_to_inactive_
 	zone->inactive_clean_pages++;
 }
 
+static inline void add_page_to_wired_list(struct page * page)
+{
+        struct zone_struct * zone = page_zone(page);
+        DEBUG_LRU_PAGE(page);
+        SetPageWired(page);
+        BUG_ON(PageCompound(page));
+        list_add(&page->lru, &zone_wired[page->flags>>ZONE_SHIFT].wired_list);
+        zone_wired[page->flags>>ZONE_SHIFT].wired_pages++;
+}
+
 static inline void del_page_from_active_anon_list(struct page * page)
 {
 	struct zone_struct * zone = page_zone(page);
@@ -233,6 +243,17 @@ static inline void del_page_from_inactiv
 	DEBUG_LRU_PAGE(page);
 }
 
+static inline void del_page_from_wired_list(struct page * page)
+{
+        struct zone_struct * zone = page_zone(page);
+
+        BUG_ON(PageCompound(page));
+        list_del(&page->lru);
+        ClearPageWired(page);
+        zone_wired[page->flags>>ZONE_SHIFT].wired_pages--;
+        DEBUG_LRU_PAGE(page);
+}
+
 /*
  * Inline functions to control some balancing in the VM.
  *
diff -urNp linux-1225/include/linux/mmzone.h linux-1226/include/linux/mmzone.h
--- linux-1225/include/linux/mmzone.h
+++ linux-1226/include/linux/mmzone.h
@@ -125,6 +125,13 @@ typedef struct zone_struct {
 #define ZONE_HIGHMEM		2
 #define MAX_NR_ZONES		3
 
+typedef struct zone_wired_struct {
+        struct list_head        wired_list;
+        unsigned long           wired_pages;
+} zone_wired_t;
+
+extern zone_wired_t zone_wired[];
+
 /*
  * One allocation request operates on a zonelist. A zonelist
  * is a list of zones, the first one is the 'goal' of the
diff -urNp linux-1225/mm/page_alloc.c linux-1226/mm/page_alloc.c
--- linux-1225/mm/page_alloc.c
+++ linux-1226/mm/page_alloc.c
@@ -37,6 +37,8 @@ pg_data_t *pgdat_list;
 zone_t *zone_table[MAX_NR_ZONES*MAX_NR_NODES];
 EXPORT_SYMBOL(zone_table);
 
+zone_wired_t zone_wired[MAX_NR_ZONES*MAX_NR_NODES];
+
 static char *zone_names[MAX_NR_ZONES] = { "DMA", "Normal", "HighMem" };
 #if defined(CONFIG_HIGHMEM64G) || defined(CONFIG_X86_64)
 static int zone_balance_ratio[MAX_NR_ZONES] __initdata = { 4097, 128, 128, };
@@ -1181,6 +1183,8 @@ void __init free_area_init_core(int nid,
 		INIT_LIST_HEAD(&zone->inactive_dirty_list);
 		INIT_LIST_HEAD(&zone->inactive_laundry_list);
 		INIT_LIST_HEAD(&zone->inactive_clean_list);
+		INIT_LIST_HEAD(&zone_wired[nid * MAX_NR_ZONES + j].wired_list);
+		zone_wired[nid * MAX_NR_ZONES + j].wired_pages = 0;
 		spin_lock_init(&zone->lru_lock);
 
 		if (!size)
diff -urNp linux-1225/mm/rmap.c linux-1226/mm/rmap.c
--- linux-1225/mm/rmap.c
+++ linux-1226/mm/rmap.c
@@ -240,7 +240,8 @@ page_add_rmap(struct page * page, pte_t 
 		BUG();
 #endif
 
-	if (!VALID_PAGE(page) || PageReserved(page))
+	/* wired pages don't get pte_chains */
+	if (!VALID_PAGE(page) || PageReserved(page) || PageWired(page))
 		return pte_chain;
 
 	pte_chain_lock(page);
diff -urNp linux-1225/mm/swap.c linux-1226/mm/swap.c
--- linux-1225/mm/swap.c
+++ linux-1226/mm/swap.c
@@ -98,7 +98,10 @@ void lru_cache_add(struct page * page)
 {
 	if (!PageLRU(page)) {
 		lru_lock(page_zone(page));
-		if (!TestandSetPageLRU(page))
+		/* pages from a WIRED inode go directly to the wired list */
+		if (page->mapping && (page->mapping->gfp_mask & __GFP_WIRED))
+			add_page_to_wired_list(page);
+		else if (!TestandSetPageLRU(page))
 			add_page_to_active_list(page, INITIAL_AGE);
 		lru_unlock(page_zone(page));
 	}
@@ -123,6 +126,8 @@ void __lru_cache_del(struct page * page)
 		del_page_from_inactive_laundry_list(page);
 	} else if (PageInactiveClean(page)) {
 		del_page_from_inactive_clean_list(page);
+	} else if (PageWired(page)) {
+		del_page_from_wired_list(page);
 	}
 	ClearPageLRU(page);
 }
