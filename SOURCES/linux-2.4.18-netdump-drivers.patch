diff -urNp linux-6010/drivers/net/3c59x.c linux-6020/drivers/net/3c59x.c
--- linux-6010/drivers/net/3c59x.c
+++ linux-6020/drivers/net/3c59x.c
@@ -916,6 +916,7 @@ static int vortex_ioctl(struct net_devic
 #endif
 static void vortex_tx_timeout(struct net_device *dev);
 static void acpi_set_WOL(struct net_device *dev);
+static void vorboom_poll(struct net_device *dev);
 static struct ethtool_ops vortex_ethtool_ops;
 static void set_8021q_mode(struct net_device *dev, int enable);
 
@@ -1427,6 +1428,9 @@ static int __devinit vortex_probe1(struc
 	dev->set_multicast_list = set_rx_mode;
 	dev->tx_timeout = vortex_tx_timeout;
 	dev->watchdog_timeo = (watchdog * HZ) / 1000;
+#ifdef HAVE_POLL_CONTROLLER
+	dev->poll_controller = &vorboom_poll;
+#endif
 	if (pdev && vp->enable_wol) {
 		vp->pm_state_valid = 1;
  		pci_save_state(VORTEX_PCI(vp), vp->power_state);
@@ -2424,6 +2428,29 @@ handler_exit:
 	return IRQ_HANDLED;
 }
 
+#ifdef HAVE_POLL_CONTROLLER
+
+/*
+ * Polling 'interrupt' - used by things like netconsole to send skbs
+ * without having to re-enable interrupts. It's not called while
+ * the interrupt routine is executing.
+ */
+
+static void vorboom_poll (struct net_device *dev)
+{
+	struct vortex_private *vp = netdev_priv(dev);
+
+	if (!netdump_mode) disable_irq(dev->irq);
+	if (vp->full_bus_master_tx)
+		boomerang_interrupt(dev->irq, dev, 0);
+	else
+		vortex_interrupt(dev->irq, dev, 0);
+	if (!netdump_mode) enable_irq(dev->irq);
+}
+
+#endif
+
+
 static int vortex_rx(struct net_device *dev)
 {
 	struct vortex_private *vp = netdev_priv(dev);
diff -urNp linux-6010/drivers/net/8139cp.c linux-6020/drivers/net/8139cp.c
--- linux-6010/drivers/net/8139cp.c
+++ linux-6020/drivers/net/8139cp.c
@@ -47,7 +47,7 @@
  */
 
 #define DRV_NAME		"8139cp"
-#define DRV_VERSION		"0.3.0"
+#define DRV_VERSION		"0.3.0-rh1"
 #define DRV_RELDATE		"Sep 29, 2002"
 
 
@@ -756,17 +756,18 @@ static int cp_start_xmit (struct sk_buff
 {
 	struct cp_private *cp = dev->priv;
 	unsigned entry;
+	unsigned long flags;
 	u32 eor;
 #if CP_VLAN_TAG_USED
 	u32 vlan_tag = 0;
 #endif
 
-	spin_lock_irq(&cp->lock);
+	spin_lock_irqsave(&cp->lock, flags);
 
 	/* This is a hard error, log it. */
 	if (TX_BUFFS_AVAIL(cp) <= (skb_shinfo(skb)->nr_frags + 1)) {
 		netif_stop_queue(dev);
-		spin_unlock_irq(&cp->lock);
+		spin_unlock_irqrestore(&cp->lock, flags);
 		printk(KERN_ERR PFX "%s: BUG! Tx Ring full when queue awake!\n",
 		       dev->name);
 		return 1;
@@ -906,7 +907,7 @@ static int cp_start_xmit (struct sk_buff
 	if (TX_BUFFS_AVAIL(cp) <= (MAX_SKB_FRAGS + 1))
 		netif_stop_queue(dev);
 
-	spin_unlock_irq(&cp->lock);
+	spin_unlock_irqrestore(&cp->lock, flags);
 
 	cpw8(TxPoll, NormalTxPoll);
 	dev->trans_start = jiffies;
@@ -927,8 +928,6 @@ static void __cp_set_rx_mode (struct net
 	/* Note: do not reorder, GCC is clever about common statements. */
 	if (dev->flags & IFF_PROMISC) {
 		/* Unconditionally log net taps. */
-		printk (KERN_NOTICE "%s: Promiscuous mode enabled.\n",
-			dev->name);
 		rx_mode =
 		    AcceptBroadcast | AcceptMulticast | AcceptMyPhys |
 		    AcceptAllPhys;
@@ -1693,6 +1692,17 @@ static void cp_vlan_rx_kill_vid(struct n
 }
 #endif
 
+#ifdef HAVE_POLL_CONTROLLER
+static void
+cp_netpoll(struct net_device *dev)
+{
+	struct cp_private *cp = dev->priv;
+	if (!netdump_mode) disable_irq(cp->pdev->irq);
+	cp_interrupt(cp->pdev->irq, dev, NULL);
+	if (!netdump_mode) enable_irq(cp->pdev->irq);
+}
+#endif
+
 /* Serial EEPROM section. */
 
 /*  EEPROM_Ctrl bits. */
@@ -1889,6 +1899,9 @@ static int __devinit cp_init_one (struct
 	dev->vlan_rx_kill_vid = cp_vlan_rx_kill_vid;
 #endif
 
+#ifdef HAVE_POLL_CONTROLLER
+	dev->poll_controller = cp_netpoll;
+#endif
 	dev->irq = pdev->irq;
 
 	rc = register_netdev(dev);
diff -urNp linux-6010/drivers/net/e100/e100_main.c linux-6020/drivers/net/e100/e100_main.c
--- linux-6010/drivers/net/e100/e100_main.c
+++ linux-6020/drivers/net/e100/e100_main.c
@@ -1750,6 +1750,36 @@ static int e100_poll(struct net_device *
 	return 1;
 }
 
+#ifdef HAVE_POLL_CONTROLLER
+static void e100_netpoll(struct net_device *netdev)
+{
+	struct nic *nic = netdev_priv(netdev);
+
+	if (unlikely(netdump_mode)) {
+		int bogus_budget = 64; /* netdev_max_backlog */
+
+		/*
+		 *  In the case where the poll routine exhausted its
+		 *  quota, it relies on the NAPI infrastructure to reset
+		 *  the value.
+		 */
+		netdev->quota = netdev->weight;
+		e100_intr(nic->pdev->irq, netdev, NULL);
+		/*
+		 *  Check to see if there is work to do.  Only call the
+		 *  clean routine if we put ourselves on the poll list.
+		 */
+		if (netdev->poll_list.prev)
+			e100_poll (netdev, &bogus_budget);
+        } else {
+		e100_disable_irq(nic);
+		e100_intr(nic->pdev->irq, netdev, NULL);
+		e100_tx_clean(nic);
+		e100_enable_irq(nic);
+	}
+}
+#endif
+
 static struct net_device_stats *e100_get_stats(struct net_device *netdev)
 {
 	struct nic *nic = netdev_priv(netdev);
@@ -2307,6 +2337,9 @@ static int __devinit e100_probe(struct p
 	netdev->watchdog_timeo = E100_WATCHDOG_PERIOD;
 	netdev->poll = e100_poll;
 	netdev->weight = E100_NAPI_WEIGHT;
+#ifdef HAVE_POLL_CONTROLLER
+	netdev->poll_controller = e100_netpoll;
+#endif
 	strcpy(netdev->name, pci_name(pdev));
 
 	nic = netdev_priv(netdev);
diff -urNp linux-6010/drivers/net/e1000/e1000_main.c linux-6020/drivers/net/e1000/e1000_main.c
--- linux-6010/drivers/net/e1000/e1000_main.c
+++ linux-6020/drivers/net/e1000/e1000_main.c
@@ -227,6 +227,11 @@ static struct notifier_block e1000_notif
 	.priority       = 0
 };
 
+#ifdef HAVE_POLL_CONTROLLER
+/* for netdump / net console */
+static void e1000_netpoll (struct net_device *netdev);
+#endif
+
 
 static struct pci_driver e1000_driver = {
 	.name     = e1000_driver_name,
@@ -695,6 +700,9 @@ e1000_probe(struct pci_dev *pdev,
 	netdev->vlan_rx_register = e1000_vlan_rx_register;
 	netdev->vlan_rx_add_vid = e1000_vlan_rx_add_vid;
 	netdev->vlan_rx_kill_vid = e1000_vlan_rx_kill_vid;
+#ifdef HAVE_POLL_CONTROLLER
+	netdev->poll_controller = e1000_netpoll;
+#endif
 	strcpy(netdev->name, pci_name(pdev));
 
 	netdev->mem_start = mmio_start;
@@ -4640,4 +4648,48 @@ e1000_resume(struct pci_dev *pdev)
 }
 #endif
 
+#ifdef HAVE_POLL_CONTROLLER
+/*
+ * Polling 'interrupt' - used by things like netconsole to send skbs
+ * without having to re-enable interrupts. It's not called while
+ * the interrupt routine is executing.
+ */
+static void
+e1000_netpoll(struct net_device *netdev)
+{
+	struct e1000_adapter *adapter = netdev_priv(netdev);
+
+	if (unlikely(netdump_mode)) {
+		int bogus_budget = 64; /* netdev_max_backlog */
+		int work_done = 0;
+
+		/*
+		 *  In the case where the poll routine exhausted its
+		 *  quota, it relies on the NAPI infrastructure to reset
+		 *  the value.
+		 */
+		netdev->quota = netdev->weight;
+		e1000_intr(adapter->pdev->irq, netdev, NULL);
+		e1000_clean_tx_irq(adapter, adapter->tx_ring);
+#ifdef CONFIG_E1000_NAPI
+		adapter->clean_rx(adapter, adapter->rx_ring, &work_done, bogus_budget);
+		/*
+		 *  Check to see if there is work to do.  Only call the
+		 *  clean routine if we put ourselves on the poll list.
+		 */
+		if (netdev->poll_list.prev)
+			e1000_clean(netdev, &bogus_budget);
+#endif
+        } else {
+		disable_irq(adapter->pdev->irq);
+		e1000_intr(adapter->pdev->irq, netdev, NULL);
+		e1000_clean_tx_irq(adapter, adapter->tx_ring);
+#ifndef CONFIG_E1000_NAPI
+		adapter->clean_rx(adapter, adapter->rx_ring);
+#endif
+		enable_irq(adapter->pdev->irq);
+	}
+}
+#endif
+
 /* e1000_main.c */
diff -urNp linux-6010/drivers/net/eepro100.c linux-6020/drivers/net/eepro100.c
--- linux-6010/drivers/net/eepro100.c
+++ linux-6020/drivers/net/eepro100.c
@@ -543,6 +543,7 @@ static void speedo_refill_rx_buffers(str
 static int speedo_rx(struct net_device *dev);
 static void speedo_tx_buffer_gc(struct net_device *dev);
 static void speedo_interrupt(int irq, void *dev_instance, struct pt_regs *regs);
+static void poll_speedo (struct net_device *dev);
 static int speedo_close(struct net_device *dev);
 static struct net_device_stats *speedo_get_stats(struct net_device *dev);
 static int speedo_ioctl(struct net_device *dev, struct ifreq *rq, int cmd);
@@ -879,6 +880,9 @@ static int __devinit speedo_found1(struc
 	dev->get_stats = &speedo_get_stats;
 	dev->set_multicast_list = &set_rx_mode;
 	dev->do_ioctl = &speedo_ioctl;
+#ifdef HAVE_POLL_CONTROLLER
+	dev->poll_controller = &poll_speedo;
+#endif
 
 	return 0;
 }
@@ -1176,10 +1180,8 @@ speedo_rx_soft_reset(struct net_device *
 
 
 /* Media monitoring and control. */
-static void speedo_timer(unsigned long data)
+static void speedo_timeout(struct net_device *dev, struct speedo_private *sp)
 {
-	struct net_device *dev = (struct net_device *)data;
-	struct speedo_private *sp = (struct speedo_private *)dev->priv;
 	long ioaddr = dev->base_addr;
 	int phy_num = sp->phy[0] & 0x1f;
 
@@ -1217,6 +1219,15 @@ static void speedo_timer(unsigned long d
 				   dev->name, sp->rx_mode, jiffies, sp->last_rx_time);
 		set_rx_mode(dev);
 	}
+}
+
+static void speedo_timer(unsigned long data)
+{
+	struct net_device *dev = (struct net_device *)data;
+	struct speedo_private *sp = (struct speedo_private *)dev->priv;
+
+	speedo_timeout(dev, sp);
+
 	/* We must continue to monitor the media. */
 	sp->timer.expires = RUN_AT(2*HZ); 			/* 2.0 sec. */
 	add_timer(&sp->timer);
@@ -1661,6 +1672,29 @@ static void speedo_interrupt(int irq, vo
 	return;
 }
 
+#ifdef HAVE_POLL_CONTROLLER
+
+/*
+ * Polling 'interrupt' - used by things like netconsole to send skbs
+ * without having to re-enable interrupts. It's not called while
+ * the interrupt routine is executing.
+ */
+
+static void poll_speedo (struct net_device *dev)
+{
+	struct speedo_private *sp = (struct speedo_private *)dev->priv;
+
+        if (!netdump_mode) disable_irq(dev->irq);
+        if (sp->timer.expires == jiffies) {
+                sp->timer.expires = RUN_AT(2*HZ);
+                speedo_timeout(dev, sp);
+        }
+        speedo_interrupt (dev->irq, dev, NULL);
+        if (!netdump_mode) enable_irq(dev->irq);
+}
+
+#endif
+
 static inline struct RxFD *speedo_rx_alloc(struct net_device *dev, int entry)
 {
 	struct speedo_private *sp = (struct speedo_private *)dev->priv;
diff -urNp linux-6010/drivers/net/pcnet32.c linux-6020/drivers/net/pcnet32.c
--- linux-6010/drivers/net/pcnet32.c
+++ linux-6020/drivers/net/pcnet32.c
@@ -501,6 +501,23 @@ static struct pcnet32_access pcnet32_dwi
     .reset	= pcnet32_dwio_reset
 };
 
+#ifdef HAVE_POLL_CONTROLLER
+
+/*
+ * Polling 'interrupt' - used by things like netconsole to send skbs
+ * without having to re-enable interrupts. It's not called while
+ * the interrupt routine is executing.
+ */
+
+static void pcnet32_poll_controller (struct net_device *dev)
+{
+    if (!netdump_mode) disable_irq(dev->irq);
+    pcnet32_interrupt(0, dev, NULL);
+    if (!netdump_mode) enable_irq(dev->irq);
+}
+
+#endif
+
 
 static int pcnet32_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 {
@@ -1309,6 +1326,10 @@ pcnet32_probe1(unsigned long ioaddr, uns
     dev->tx_timeout = pcnet32_tx_timeout;
     dev->watchdog_timeo = (5*HZ);
 
+#ifdef HAVE_POLL_CONTROLLER
+    dev->poll_controller = pcnet32_poll_controller;
+#endif
+
     /* Fill in the generic fields of the device structure. */
     if (register_netdev(dev))
 	goto err_free_consistent;
diff -urNp linux-6010/drivers/net/tg3.c linux-6020/drivers/net/tg3.c
--- linux-6010/drivers/net/tg3.c
+++ linux-6020/drivers/net/tg3.c
@@ -3528,6 +3528,35 @@ static irqreturn_t tg3_test_isr(int irq,
 static int tg3_init_hw(struct tg3 *);
 static int tg3_halt(struct tg3 *, int, int);
 
+#ifdef HAVE_POLL_CONTROLLER
+static void tg3_poll_controller(struct net_device *dev)
+{
+	struct tg3 *tp = netdev_priv(dev);
+
+	if (unlikely(netdump_mode)) {
+		int  bogus_budget = 64; /* netdump_max_backlog */
+
+		/*
+		 *  In the case where the poll routine exhausted its
+		 *  quota, it relies on the NAPI infrastructure to reset
+		 *  the value.
+		 */
+		dev->quota = dev->weight;
+		tg3_interrupt (tp->pdev->irq, dev, NULL);
+		/*
+		 *  Check to see if there is work to do.  Only call the
+		 *  poll routine if we put ourselves on the poll list.
+		 */
+		if (dev->poll_list.prev)
+			tg3_poll (dev, &bogus_budget);
+	} else {
+		disable_irq(tp->pdev->irq);
+		tg3_interrupt(tp->pdev->irq, dev, NULL);
+		enable_irq(tp->pdev->irq);
+	}
+}
+#endif
+
 static void tg3_reset_task(void *_data)
 {
 	struct tg3 *tp = _data;
@@ -11284,6 +11313,9 @@ static int __devinit tg3_init_one(struct
 	dev->watchdog_timeo = TG3_TX_TIMEOUT;
 	dev->change_mtu = tg3_change_mtu;
 	dev->irq = pdev->irq;
+#ifdef HAVE_POLL_CONTROLLER
+	dev->poll_controller = tg3_poll_controller;
+#endif
 
 	err = tg3_get_invariants(tp);
 	if (err) {
diff -urNp linux-6010/drivers/net/tlan.c linux-6020/drivers/net/tlan.c
--- linux-6010/drivers/net/tlan.c
+++ linux-6020/drivers/net/tlan.c
@@ -345,6 +345,8 @@ static int	TLan_EeSendByte( u16, u8, int
 static void	TLan_EeReceiveByte( u16, u8 *, int );
 static int	TLan_EeReadByte( struct net_device *, u8, u8 * );
 
+static void	TLan_Poll(struct net_device *);
+
 
 static void 
 TLan_StoreSKB( struct tlan_list_tag *tag, struct sk_buff *skb)
@@ -889,6 +891,9 @@ static int TLan_Init( struct net_device 
 	dev->get_stats = &TLan_GetStats;
 	dev->set_multicast_list = &TLan_SetMulticastList;
 	dev->do_ioctl = &TLan_ioctl;
+#ifdef HAVE_POLL_CONTROLLER
+	dev->poll_controller = &TLan_Poll;
+#endif
 	dev->tx_timeout = &TLan_tx_timeout;
 	dev->watchdog_timeo = TX_TIMEOUT;
 
@@ -1174,7 +1179,14 @@ static void TLan_HandleInterrupt(int irq
 
 } /* TLan_HandleInterrupts */
 
-
+#ifdef HAVE_POLL_CONTROLLER
+static void TLan_Poll(struct net_device *dev)
+{
+	if (!netdump_mode) disable_irq(dev->irq);
+	TLan_HandleInterrupt(dev->irq, dev, NULL);
+	if (!netdump_mode) enable_irq(dev->irq);
+}
+#endif
 
 
 	/***************************************************************
diff -urNp linux-6010/drivers/net/tulip/tulip_core.c linux-6020/drivers/net/tulip/tulip_core.c
--- linux-6010/drivers/net/tulip/tulip_core.c
+++ linux-6020/drivers/net/tulip/tulip_core.c
@@ -267,6 +267,7 @@ static void tulip_down(struct net_device
 static struct net_device_stats *tulip_get_stats(struct net_device *dev);
 static int private_ioctl(struct net_device *dev, struct ifreq *rq, int cmd);
 static void set_rx_mode(struct net_device *dev);
+static void poll_tulip(struct net_device *dev);
 
 
 
@@ -1729,6 +1730,9 @@ static int __devinit tulip_init_one (str
 	dev->get_stats = tulip_get_stats;
 	dev->do_ioctl = private_ioctl;
 	dev->set_multicast_list = set_rx_mode;
+#ifdef HAVE_POLL_CONTROLLER
+	dev->poll_controller = &poll_tulip;
+#endif
 
 	if (register_netdev(dev))
 		goto err_out_free_ring;
@@ -1903,6 +1907,24 @@ static void __devexit tulip_remove_one (
 }
 
 
+#ifdef HAVE_POLL_CONTROLLER
+
+/*
+ * Polling 'interrupt' - used by things like netconsole to send skbs
+ * without having to re-enable interrupts. It's not called while
+ * the interrupt routine is executing.
+ */
+
+static void poll_tulip (struct net_device *dev)
+{
+       if (!netdump_mode) disable_irq(dev->irq);
+       tulip_interrupt (dev->irq, dev, NULL);
+       if (!netdump_mode) enable_irq(dev->irq);
+}
+
+#endif
+
+
 static struct pci_driver tulip_driver = {
 	name:		DRV_NAME,
 	id_table:	tulip_pci_tbl,
diff -urNp linux-6010/net/core/dev.c linux-6020/net/core/dev.c
--- linux-6010/net/core/dev.c
+++ linux-6020/net/core/dev.c
@@ -1506,6 +1506,14 @@ int netif_receive_skb(struct sk_buff *sk
 	if (skb->stamp.tv_sec == 0)
 		do_gettimeofday(&skb->stamp);
 
+	if (unlikely(netdump_func != NULL)) {
+		if (netdump_receive_skb &&
+		    netdump_receive_skb(skb) == NET_RX_DROP) { 
+			kfree_skb(skb);
+			return NET_RX_DROP;
+		}
+	}
+
 	skb_bond(skb);
 
 	netdev_rx_stat[smp_processor_id()].total++;
