diff -urNp linux-8230/drivers/addon/ipr/Makefile linux-8240/drivers/addon/ipr/Makefile
--- linux-8230/drivers/addon/ipr/Makefile
+++ linux-8240/drivers/addon/ipr/Makefile
@@ -0,0 +1,27 @@
+# File: drivers/addon/ipr/Makefile
+# Makefile for the IBM Power RAID SCSI driver.
+
+include version.mk
+
+list-multi := ipr.o
+ifeq ($(CONFIG_PPC_PSERIES),y)
+  ipr-objs := iprdd.o lib/iprlib.o arch/ipr_pseries.o
+else
+ifeq ($(CONFIG_PPC_ISERIES),y)
+  ipr-objs := iprdd.o lib/iprlib.o arch/ipr_iseries.o
+else
+  ipr-objs := iprdd.o lib/iprlib.o arch/ipr_generic.o
+endif
+endif
+
+obj-$(CONFIG_SCSI_IPR) := ipr.o
+
+EXTRA_CFLAGS += -I. -I../../scsi -I./arch -I./lib -DIPR_IPRDD $(IPR_DEFINES)
+
+ipr.o: $(ipr-objs)
+	$(LD) -r -o $@ $(ipr-objs)
+
+include $(TOPDIR)/Rules.make
+
+clean:
+	rm -f *.o
diff -urNp linux-8230/drivers/addon/ipr/arch/ipr_generic.c linux-8240/drivers/addon/ipr/arch/ipr_generic.c
--- linux-8230/drivers/addon/ipr/arch/ipr_generic.c
+++ linux-8240/drivers/addon/ipr/arch/ipr_generic.c
@@ -0,0 +1,410 @@
+/*****************************************************************************/
+/* ipr_generic.c -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/******************************************************************/ 
+/* Generic architecture dependent utilties                        */
+/******************************************************************/ 
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/arch/ipr_generic.c,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/blk.h>
+#include <linux/ctype.h>
+#include <asm/uaccess.h>
+#include <scsi.h>
+#include <hosts.h>
+
+#ifndef iprdd_h
+#include "iprdd.h"
+#endif
+
+#ifndef ipr_generic_h
+#include "ipr_generic.h"
+#endif
+
+#ifdef MODULE
+#include <linux/module.h>
+
+MODULE_SUPPORTED_DEVICE("IBM storage adapters");
+MODULE_DESCRIPTION ("IBM SCSI device driver");
+#endif
+
+const char ipr_platform[] = "generic";
+const int ipr_arch = IPR_ARCH_GENERIC;
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: no locks assumed to be held
+ * Returns: Location data structure or NULL on failure
+ *---------------------------------------------------------------------------*/
+struct ipr_location_data *ipr_get_ioa_location_data(struct pci_dev *p_dev)
+{
+    struct ipr_location_data *p_location = NULL;
+
+    p_location = ipr_kcalloc(sizeof(struct ipr_location_data), IPR_ALLOC_CAN_SLEEP);
+
+    if (p_location == NULL)
+        return NULL;
+
+    p_location->pci_bus_number = p_dev->bus->number;
+    p_location->pci_slot = PCI_SLOT(p_dev->devfn);
+    p_location->pci_function = PCI_FUNC(p_dev->devfn);
+
+    return p_location;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Provide Host location data
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing.
+ *---------------------------------------------------------------------------*/
+void ipr_ioa_loc_str(struct ipr_location_data *p_location, char *p_buf)
+{
+    sprintf(p_buf, "PCI Bus: %d device: %d",
+            p_location->pci_bus_number,
+            p_location->pci_slot);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Provide device location data
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed
+ * Returns: Nothing.
+ *---------------------------------------------------------------------------*/
+void ipr_dev_loc_str(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_resource_entry *p_resource, char *p_buf)
+{
+    sprintf(p_buf, "PCI: %d:%d, Channel: %2d Id: %2d Lun: %2d",
+            p_shared_cfg->p_location->pci_bus_number,
+            p_shared_cfg->p_location->pci_slot,
+            p_resource->resource_address.bus,
+            p_resource->resource_address.target,
+            p_resource->resource_address.lun);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_ioa_physical_location(struct ipr_location_data *p_location,
+                                      char *printk_level)
+{
+    ipr_hcam_log("PCI Bus: %d device: %d",
+                    p_location->pci_bus_number,
+                    p_location->pci_slot);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of a device
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_physical_location(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_res_addr resource_address,
+                                      char *printk_level)
+{
+    ipr_hcam_log("IOA Location: PCI Bus: %d device: %d",
+                    p_shared_cfg->p_location->pci_bus_number,
+                    p_shared_cfg->p_location->pci_slot);
+
+    ipr_hcam_log("Device Location: Channel: %2d Id: %2d Lun: %2d",
+                    resource_address.bus,
+                    resource_address.target,
+                    resource_address.lun);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of a device
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_unknown_dev_phys_loc(char *printk_level)
+{
+    ipr_hcam_log("Device Location: unknown");
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Toggle reset on the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          non-zero    - failure
+ *---------------------------------------------------------------------------*/
+int ipr_toggle_reset(ipr_host_config *ipr_cfg)
+{
+    int rc;
+
+    /* Start BIST and wait 2 seconds for completion */
+    rc = pci_write_config_dword(ipr_cfg->pdev, 0x0C, 0x40000000);
+    set_current_state(TASK_UNINTERRUPTIBLE);  
+    schedule_timeout(2*HZ);
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return slot position of a device
+ * Context: Task level or interrupt level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_get_card_pos(struct ipr_shared_config *p_shared_cfg,
+                         struct ipr_res_addr resource_addr, char *p_buffer)
+{
+    *p_buffer = '\0';
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a DSA/UA
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt0(struct ipr_shared_config *p_shared_cfg,
+                             u32 dsa, u32 ua,
+                             struct ipr_res_addr *p_res_addr)
+{
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a Frame ID/Card Position
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt1(struct ipr_shared_config *p_shared_cfg,
+                             u32 frame, char *p_slot,
+                             struct ipr_res_addr *p_res_addr)
+{
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a pSeries location
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt2(struct ipr_shared_config *p_shared_cfg,
+                             char *p_location, struct ipr_res_addr *p_res_addr)
+{
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a device location
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt3(struct ipr_shared_config *p_shared_cfg,
+                             u16 pci_bus, u16 pci_device, u8 bus, u8 target, u8 lun,
+                             struct ipr_res_addr *p_res_addr)
+{
+    if ((pci_bus != p_shared_cfg->p_location->pci_bus_number) ||
+        (pci_device != p_shared_cfg->p_location->pci_slot))
+    {
+        return -ENXIO;
+    }
+
+    p_res_addr->reserved = 0;
+    p_res_addr->bus = bus;
+    p_res_addr->target = target;
+    p_res_addr->lun = lun;
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Update the location information for a resource
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_update_location_data(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_resource_entry *p_resource_entry)
+{
+    p_resource_entry->dsa = 0;
+    p_resource_entry->frame_id[0] = '\0';
+    p_resource_entry->unit_address = 0;
+    p_resource_entry->slot_label[0] = '\0';
+    p_resource_entry->pseries_location[0] = '\0';
+    p_resource_entry->pci_bus_number = p_shared_cfg->p_location->pci_bus_number;
+    p_resource_entry->pci_slot = p_shared_cfg->p_location->pci_slot;
+
+    if ((IPR_IS_DASD_DEVICE(p_resource_entry->std_inq_data)) &&
+        (!p_resource_entry->is_ioa_resource))
+    {
+        ipr_get_card_pos(p_shared_cfg, p_resource_entry->resource_address,
+                            p_resource_entry->slot_label);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a unique host identifier
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: unique id
+ * Note: This is used by scsidev to generate device names so we want to
+ *       generate something that doesn't change.
+ *---------------------------------------------------------------------------*/
+u32 ipr_get_unique_id(struct ipr_location_data *p_location)
+{
+    return (((p_location->pci_bus_number & 0xffff) << 16) |
+            ((p_location->pci_slot & 0xff) << 8) |
+            p_location->pci_function);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for a device
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_vpd(struct ipr_resource_entry *p_resource,
+                        char *printk_level)
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN+1];
+    u8 product_id[IPR_PROD_ID_LEN+1];
+
+    memcpy(vendor_id, p_resource->std_inq_data.vpids.vendor_id,
+           IPR_VENDOR_ID_LEN);
+    vendor_id[IPR_VENDOR_ID_LEN] = '\0';
+    memcpy(product_id, p_resource->std_inq_data.vpids.product_id,
+           IPR_PROD_ID_LEN);
+    product_id[IPR_PROD_ID_LEN] = '\0';
+
+    ipr_hcam_log("Device Vendor ID: %s", vendor_id);
+    ipr_hcam_log("Device Product ID: %s", product_id);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for an array member
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_array_dev_vpd(struct ipr_std_inq_vpids *p_vpids,
+                              char *default_ccin,
+                              char *printk_level)
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN+1];
+    u8 product_id[IPR_PROD_ID_LEN+1];
+
+    memcpy(vendor_id, p_vpids->vendor_id, IPR_VENDOR_ID_LEN);
+    vendor_id[IPR_VENDOR_ID_LEN] = '\0';
+    memcpy(product_id, p_vpids->product_id, IPR_PROD_ID_LEN);
+    product_id[IPR_PROD_ID_LEN] = '\0';
+
+    ipr_hcam_log("        Vendor ID: %s", vendor_id);
+    ipr_hcam_log("       Product ID: %s", product_id);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for an IOA
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_ioa_vpd(struct ipr_std_inq_vpids *p_vpids,
+                          char *printk_level)
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN+1];
+    u8 product_id[IPR_PROD_ID_LEN+1];
+
+    memcpy(vendor_id, p_vpids->vendor_id, IPR_VENDOR_ID_LEN);
+    vendor_id[IPR_VENDOR_ID_LEN] = '\0';
+    memcpy(product_id, p_vpids->product_id, IPR_PROD_ID_LEN);
+    product_id[IPR_PROD_ID_LEN] = '\0';
+
+    ipr_hcam_log("        Vendor ID: %s", vendor_id);
+    ipr_hcam_log("       Product ID: %s", product_id);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the current and expected locations for a device
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_current_expected_locations(ipr_host_config *ipr_cfg,
+                                               struct ipr_res_addr current_res_addr,
+                                               struct ipr_res_addr expected_res_addr,
+                                               char *printk_level)
+{
+    ipr_hcam_log(" PCI/SCSI Address: ");
+
+    if (current_res_addr.bus == 0xff)
+        ipr_hcam_log("         Current: unknown");
+    else
+    {
+        ipr_hcam_log("         Current: %02X:%02X/%02X%02X%02X",
+                        ipr_cfg->shared.p_location->pci_bus_number,
+                        ipr_cfg->shared.p_location->pci_slot,
+                        current_res_addr.bus,
+                        current_res_addr.target,
+                        current_res_addr.lun);
+    }
+
+    if (expected_res_addr.bus == 0xff)
+        ipr_hcam_log("        Expected: unknown");
+    else
+    {
+        ipr_hcam_log("        Expected: %02X:%02X/%02X%02X%02X",
+                        ipr_cfg->shared.p_location->pci_bus_number,
+                        ipr_cfg->shared.p_location->pci_slot,
+                        expected_res_addr.bus,
+                        expected_res_addr.target,
+                        expected_res_addr.lun);
+    }
+};
+
+/*---------------------------------------------------------------------------
+ * Purpose: Determine if this adapter is supported on this arch
+ * Context: Task level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0 if adapter is supported
+ *---------------------------------------------------------------------------*/
+int ipr_invalid_adapter(ipr_host_config *ipr_cfg)
+{
+    return 0;
+}
diff -urNp linux-8230/drivers/addon/ipr/arch/ipr_generic.h linux-8240/drivers/addon/ipr/arch/ipr_generic.h
--- linux-8230/drivers/addon/ipr/arch/ipr_generic.h
+++ linux-8240/drivers/addon/ipr/arch/ipr_generic.h
@@ -0,0 +1,70 @@
+/*****************************************************************************/
+/* ipr_generic.h -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/******************************************************************/ 
+/* Generic architecture dependent header file                     */
+/******************************************************************/ 
+
+#ifndef ipr_generic_h
+#define ipr_generic_h
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/arch/ipr_generic.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+
+/******************************************************************/
+/* Literals                                                       */
+/******************************************************************/
+#define NO_TCE ((dma_addr_t)-1)
+#define IPR_CL_SIZE_LATENCY_MASK 0x000000FF  /* only modify Cache line size */
+
+/******************************************************************/
+/* Function Prototypes                                            */
+/******************************************************************/
+static IPR_INL int register_ioctl32_conversion(unsigned int cmd,
+                                                  int (*handler)(unsigned int,
+                                                                 unsigned int,
+                                                                 unsigned long,
+                                                                 struct file *))
+{
+    return 0;
+}
+static IPR_INL int unregister_ioctl32_conversion(unsigned int cmd)
+{
+    return 0;
+}
+
+
+/******************************************************************/
+/* Structures                                                     */
+/******************************************************************/
+
+struct ipr_location_data
+{
+    unsigned int pci_bus_number;
+    unsigned int pci_slot;
+    unsigned int pci_function;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/arch/ipr_iseries.c linux-8240/drivers/addon/ipr/arch/ipr_iseries.c
--- linux-8230/drivers/addon/ipr/arch/ipr_iseries.c
+++ linux-8240/drivers/addon/ipr/arch/ipr_iseries.c
@@ -0,0 +1,590 @@
+/*****************************************************************************/
+/* ipr_iseries.c -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/******************************************************************/ 
+/* iSeries architecture dependent utilties                        */
+/******************************************************************/ 
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/arch/ipr_iseries.c,v 1.3 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/blk.h>
+#include <linux/ctype.h>
+#include <asm/uaccess.h>
+#include <scsi.h>
+#include <hosts.h>
+
+#ifndef iprdd_h
+#include "iprdd.h"
+#endif
+
+#ifndef ipr_iseries_h
+#include "ipr_iseries.h"
+#endif
+
+#ifdef MODULE
+#include <linux/module.h>
+
+MODULE_SUPPORTED_DEVICE("IBM iSeries 2763, 2748, 2778, 2757, 2780, 2782, 5702, and 5703 storage adapters");
+MODULE_DESCRIPTION ("IBM Power Linux RAID driver");
+#endif
+
+const char ipr_platform[] = "iSeries";
+const int ipr_arch = IPR_ARCH_ISERIES;
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: no locks assumed to be held
+ * Returns: Location data structure or NULL on failure
+ *---------------------------------------------------------------------------*/
+struct ipr_location_data *ipr_get_ioa_location_data(struct pci_dev *p_dev)
+{
+    struct LocationDataStruct *p_location_data = NULL;
+    struct ipr_location_data *p_location = NULL;
+
+    p_location_data = iSeries_GetLocationData(p_dev);
+
+    if (p_location_data == NULL)
+        return NULL;
+
+    p_location = ipr_kcalloc(sizeof(struct ipr_location_data), IPR_ALLOC_CAN_SLEEP);
+
+    if (p_location == NULL)
+    {
+        ipr_kfree(p_location_data, sizeof(struct LocationDataStruct));
+        return NULL;
+    }
+
+    p_location->sys_bus = p_location_data->Bus;
+    p_location->sys_card = p_location_data->Card;
+    p_location->io_adapter = p_location_data->Board;
+    p_location->io_bus = 0xF;
+    p_location->ctl = 0xFF;
+    p_location->dev = 0xFF;
+    p_location->frame_id = p_location_data->FrameId;
+
+    strcpy(p_location->slot, p_location_data->CardLocation);
+
+    p_location->pci_bus_number = p_dev->bus->number;
+    p_location->pci_slot = PCI_SLOT(p_dev->devfn);
+    p_location->pci_function = PCI_FUNC(p_dev->devfn);
+
+    kfree(p_location_data);
+
+    return p_location;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Provide Host location data
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: string containing ioa's host name.
+ *---------------------------------------------------------------------------*/
+void ipr_ioa_loc_str(struct ipr_location_data *p_location, char *p_buf)
+{
+    sprintf(p_buf, "Frame ID: %d, Card Position: %s",
+            p_location->frame_id, p_location->slot);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Provide device location data
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing.
+ *---------------------------------------------------------------------------*/
+void ipr_dev_loc_str(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_resource_entry *p_resource, char *p_buf)
+{
+    sprintf(p_buf, "Frame ID: %s, Card Position: %s",
+            p_resource->frame_id, p_resource->slot_label);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_ioa_physical_location(struct ipr_location_data *p_location,
+                                        char *printk_level)
+{
+    ipr_hcam_log("DSA/UA: %04X%02X%02X/%X%X%02X%02X%02X",
+                    p_location->sys_bus,
+                    p_location->sys_card,
+                    p_location->io_adapter,
+                    0,
+                    p_location->io_bus,
+                    p_location->ctl,
+                    p_location->dev,
+                    0xFF);
+    ipr_hcam_log("Frame ID: %d", p_location->frame_id);
+    ipr_hcam_log("Card Position: %s", p_location->slot);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of a device
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_physical_location(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_res_addr resource_address,
+                                      char *printk_level)
+{
+    char error_buffer[10];
+
+    ipr_hcam_log("DSA/UA: %04X%02X%02X/%X%X%02X%02X%02X",
+                    p_shared_cfg->p_location->sys_bus,
+                    p_shared_cfg->p_location->sys_card,
+                    p_shared_cfg->p_location->io_adapter,
+                    0,
+                    resource_address.bus,
+                    resource_address.target ^ 7,
+                    resource_address.lun,
+                    0xFF);
+
+    ipr_hcam_log("Frame ID: %d", p_shared_cfg->p_location->frame_id);
+
+    ipr_get_card_pos(p_shared_cfg, resource_address, error_buffer);
+
+    ipr_hcam_log("Card Position: %s", error_buffer);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of a device
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_unknown_dev_phys_loc(char *printk_level)
+{
+    ipr_hcam_log("DSA/UA: unknown");
+    ipr_hcam_log("Frame ID: unknown");
+    ipr_hcam_log("Card Position: unknown");
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Toggle reset on the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          non-zero    - failure
+ *---------------------------------------------------------------------------*/
+int ipr_toggle_reset(ipr_host_config *ipr_cfg)
+{
+    /* Hold reset line down for .5 second then wait for 3 seconds after active */
+    return iSeries_Device_ToggleReset(ipr_cfg->pdev, 5, 30);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return slot position of a device
+ * Context: Task level or interrupt level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_get_card_pos(struct ipr_shared_config *p_shared_cfg,
+                         struct ipr_res_addr resource_addr, char *p_buffer)
+{
+    int i, j, bus;
+    struct ipr_drive_element_desc *p_drive_elem_desc;
+    struct ipr_element_desc_page *p_desc_page;
+
+    *p_buffer = '\0';
+
+    bus = resource_addr.bus;
+    if (bus > (IPR_MAX_NUM_BUSES - 1))
+        return;
+
+    p_desc_page = p_shared_cfg->p_ses_data[bus];
+
+    /* check if pageCode is zero, if zero, presume SES does not exist or that it has not
+     shown up yet. */
+    if (p_desc_page->pageCode == 0)
+        return;
+
+    for (i=0; i < IPR_MAX_NUM_ELEM_DESCRIPTORS; i++)
+    {
+        if (sistoh32(p_desc_page->global_desc_hdr.length) == IPR_GLOBAL_DESC_12BYTES)
+        {
+            p_drive_elem_desc = &p_desc_page->desc.drive_elem_desc_c.drive_elem_desc[i];
+        }
+        else if (sistoh32(p_desc_page->global_desc_hdr.length) == IPR_GLOBAL_DESC_13BYTES)
+        {
+            p_drive_elem_desc = &p_desc_page->desc.drive_elem_desc_d.drive_elem_desc[i];
+        }
+        else
+        {
+            ipr_log_err("Unknown backplane. Global descriptor is %d bytes"IPR_EOL,
+                           p_desc_page->global_desc_hdr.length);
+            continue;
+        }
+
+        if (resource_addr.target == p_drive_elem_desc->slot_map.scsi_id)
+        {
+            for (j=0; j < 3; j++)
+                p_buffer[j] = p_drive_elem_desc->slot_map.label[j];
+            p_buffer[3] = '\0';
+            return;
+        }
+    }
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a DSA/UA
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt0(struct ipr_shared_config *p_shared_cfg,
+                             u32 dsa, u32 ua,
+                             struct ipr_res_addr *p_res_addr)
+{
+    int result = 0;
+
+    if (dsa != p_shared_cfg->ioa_resource.dsa)
+        result = -ENXIO;
+    else
+    {
+        p_res_addr->reserved = 0;
+        p_res_addr->bus = IPR_GET_IO_BUS(ua);
+        p_res_addr->target = IPR_GET_CTL(ua) ^ 7;
+        p_res_addr->lun = IPR_GET_DEV(ua);
+    }
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a Frame ID/Card Position
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt1(struct ipr_shared_config *p_shared_cfg,
+                             u32 frame, char *p_slot,
+                             struct ipr_res_addr *p_res_addr)
+{
+    int i, bus;
+    struct ipr_drive_element_desc *p_drive_elem_desc;
+    struct ipr_element_desc_page *p_desc_page;
+
+    if (p_shared_cfg->p_location->frame_id == frame)
+    {
+        for (bus = 0; bus < IPR_MAX_NUM_BUSES; bus++)
+        {
+            p_desc_page = p_shared_cfg->p_ses_data[bus];
+
+            /* check if pageCode is zero, if zero, presume SES does not exist or that it has not
+             shown up yet. */
+            if (p_desc_page->pageCode == 0)
+                continue;
+
+            for (i = 0; i < IPR_MAX_NUM_ELEM_DESCRIPTORS; i++)
+            {
+                if (sistoh32(p_desc_page->global_desc_hdr.length) == IPR_GLOBAL_DESC_12BYTES)
+                    p_drive_elem_desc = &p_desc_page->desc.drive_elem_desc_c.drive_elem_desc[i];
+                else if (sistoh32(p_desc_page->global_desc_hdr.length) == IPR_GLOBAL_DESC_13BYTES)
+                    p_drive_elem_desc = &p_desc_page->desc.drive_elem_desc_d.drive_elem_desc[i];
+                else
+                    continue;
+
+                if ((p_drive_elem_desc->slot_map.label[0] == p_slot[0]) &&
+                    (p_drive_elem_desc->slot_map.label[1] == p_slot[1]) &&
+                    (p_drive_elem_desc->slot_map.label[2] == p_slot[2]))
+                {
+                    p_res_addr->reserved = 0;
+                    p_res_addr->bus = bus;
+                    p_res_addr->target = p_drive_elem_desc->slot_map.scsi_id;
+                    p_res_addr->lun = 0;
+
+                    return 0;
+                }
+            }
+        }
+    }
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a pSeries location
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt2(struct ipr_shared_config *p_shared_cfg,
+                              char *p_location, struct ipr_res_addr *p_res_addr)
+{
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a device location
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt3(struct ipr_shared_config *p_shared_cfg,
+                             u16 pci_bus, u16 pci_device, u8 bus, u8 target, u8 lun,
+                             struct ipr_res_addr *p_res_addr)
+{
+    if ((pci_bus != p_shared_cfg->p_location->pci_bus_number) ||
+        (pci_device != p_shared_cfg->p_location->pci_slot))
+    {
+        return -ENXIO;
+    }
+
+    p_res_addr->reserved = 0;
+    p_res_addr->bus = bus;
+    p_res_addr->target = target;
+    p_res_addr->lun = lun;
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Update the location information for a resource
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_update_location_data(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_resource_entry *p_resource_entry)
+{
+    struct ipr_location_data *p_location = p_shared_cfg->p_location;
+
+    p_resource_entry->dsa = ((p_location->sys_bus << 16) |
+                             (p_location->sys_card << 8) |
+                             (p_location->io_adapter));
+
+    sprintf(p_resource_entry->frame_id, "%d",
+            p_location->frame_id);
+
+    if (p_resource_entry->is_ioa_resource)
+    {
+        p_resource_entry->unit_address = 0x0FFFFFFF;
+        strncpy(p_resource_entry->slot_label,
+                p_location->slot, 3);
+        p_location->slot[3] = '\0';
+    }
+    else
+    {
+        p_resource_entry->unit_address =
+            ((p_resource_entry->resource_address.bus << 24) |
+             ((p_resource_entry->resource_address.target ^ 7) << 16) |
+             (p_resource_entry->resource_address.lun << 8) | 0xFF);
+    }
+
+    p_resource_entry->pseries_location[0] = '\0';
+
+    p_resource_entry->pci_bus_number = p_shared_cfg->p_location->pci_bus_number;
+    p_resource_entry->pci_slot = p_shared_cfg->p_location->pci_slot;
+
+    if ((IPR_IS_DASD_DEVICE(p_resource_entry->std_inq_data)) &&
+        (!p_resource_entry->is_ioa_resource))
+    {
+        ipr_get_card_pos(p_shared_cfg, p_resource_entry->resource_address,
+                            p_resource_entry->slot_label);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a unique host identifier
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: unique id
+ * Note: This is used by scsidev to generate device names so we want to
+ *       generate something that doesn't change.
+ *---------------------------------------------------------------------------*/
+u32 ipr_get_unique_id(struct ipr_location_data *p_location)
+{
+    return (((p_location->sys_bus & 0xffff) << 16) |
+            ((p_location->sys_card & 0xff) << 8) |
+            p_location->io_adapter);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for a device
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_vpd(struct ipr_resource_entry *p_resource,
+                        char *printk_level)
+{
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for an array member
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_array_dev_vpd(struct ipr_std_inq_vpids *p_vpids,
+                              char *default_ccin,
+                              char *printk_level)
+{
+    char device_ccin_str[5];
+
+    ipr_dasd_vpids_to_ccin_str(p_vpids, device_ccin_str, default_ccin);
+    ipr_hcam_log("             Type: %s", device_ccin_str);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for an IOA
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_ioa_vpd(struct ipr_std_inq_vpids *p_vpids,
+                          char *printk_level)
+{
+    char temp_ccin[5];
+
+    temp_ccin[4] = '\0';
+
+    memcpy(temp_ccin, p_vpids->product_id, 4);
+    ipr_hcam_log("             Type: %s", temp_ccin);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the current and expected locations for a device
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_current_expected_locations(ipr_host_config *ipr_cfg,
+                                               struct ipr_res_addr current_res_addr,
+                                               struct ipr_res_addr expected_res_addr,
+                                               char *printk_level)
+{
+    char error_buffer[10];
+
+    ipr_hcam_log(" PCI/SCSI Address: ");
+
+    if (current_res_addr.bus == 0xff)
+        ipr_hcam_log("         Current: unknown");
+    else
+    {
+        ipr_hcam_log("         Current: %02X:%02X/%02X%02X%02X",
+                        ipr_cfg->shared.p_location->pci_bus_number,
+                        ipr_cfg->shared.p_location->pci_slot,
+                        current_res_addr.bus,
+                        current_res_addr.target,
+                        current_res_addr.lun);
+    }
+
+    if (expected_res_addr.bus == 0xff)
+        ipr_hcam_log("        Expected: unknown");
+    else
+    {
+        ipr_hcam_log("        Expected: %02X:%02X/%02X%02X%02X",
+                        ipr_cfg->shared.p_location->pci_bus_number,
+                        ipr_cfg->shared.p_location->pci_slot,
+                        expected_res_addr.bus,
+                        expected_res_addr.target,
+                        expected_res_addr.lun);
+    }
+
+    ipr_hcam_log(" DSA/UA: ");
+
+    if (current_res_addr.bus == 0xff)
+        ipr_hcam_log("         Current: unknown");
+    else
+    {
+        ipr_hcam_log("         Current: %04X%02X%02X/%X%X%02X%02X%02X",
+                        ipr_cfg->shared.p_location->sys_bus,
+                        ipr_cfg->shared.p_location->sys_card,
+                        ipr_cfg->shared.p_location->io_adapter,
+                        0,
+                        current_res_addr.bus,
+                        current_res_addr.target ^ 7,
+                        current_res_addr.lun,
+                        0xFF);
+    }
+
+    if (expected_res_addr.bus == 0xff)
+        ipr_hcam_log("        Expected: unknown");
+    else
+    {
+        ipr_hcam_log("        Expected: %04X%02X%02X/%X%X%02X%02X%02X",
+                        ipr_cfg->shared.p_location->sys_bus,
+                        ipr_cfg->shared.p_location->sys_card,
+                        ipr_cfg->shared.p_location->io_adapter,
+                        0,
+                        expected_res_addr.bus,
+                        expected_res_addr.target ^ 7,
+                        expected_res_addr.lun,
+                        0xFF);
+    }
+
+    ipr_hcam_log(" Frame ID/Card Position: ");
+
+    if (current_res_addr.bus == 0xff)
+        ipr_hcam_log("         Current: unknown");
+    else
+    {
+        ipr_get_card_pos(&ipr_cfg->shared,
+                            current_res_addr, error_buffer);
+        ipr_hcam_log("         Current: %d/%s",
+                        ipr_cfg->shared.p_location->frame_id,
+                        error_buffer);
+    }
+
+    if (expected_res_addr.bus == 0xff)
+        ipr_hcam_log("        Expected: unknown");
+    else
+    {
+        ipr_get_card_pos(&ipr_cfg->shared,
+                            expected_res_addr,
+                            error_buffer);
+        ipr_hcam_log("        Expected: %d/%s",
+                        ipr_cfg->shared.p_location->frame_id,
+                        error_buffer);
+    }
+};
+
+/*---------------------------------------------------------------------------
+ * Purpose: Determine if this adapter is supported on this arch
+ * Context: Task level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0 if adapter is supported
+ *---------------------------------------------------------------------------*/
+int ipr_invalid_adapter(ipr_host_config *ipr_cfg)
+{
+    return 0;
+}
diff -urNp linux-8230/drivers/addon/ipr/arch/ipr_iseries.h linux-8240/drivers/addon/ipr/arch/ipr_iseries.h
--- linux-8230/drivers/addon/ipr/arch/ipr_iseries.h
+++ linux-8240/drivers/addon/ipr/arch/ipr_iseries.h
@@ -0,0 +1,98 @@
+/*****************************************************************************/
+/* ipr_iseries.c -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/******************************************************************/ 
+/* iSeries architecture dependent header file                     */
+/******************************************************************/ 
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/arch/ipr_iseries.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#ifndef ipr_iseries_h
+#define ipr_iseries_h
+
+/******************************************************************/
+/* Includes                                                       */
+/******************************************************************/
+#ifndef CONFIG_PPC64
+#include <asm/iSeries/iSeries_VpdInfo.h>
+#endif
+
+#include <asm/iSeries/iSeries_pci.h>
+#include <asm/iSeries/iSeries_dma.h>
+
+/******************************************************************/
+/* Function Prototypes                                            */
+/******************************************************************/
+#ifdef CONFIG_PPC64
+extern int register_ioctl32_conversion(unsigned int cmd,
+                                       int (*handler)(unsigned int,
+                                                      unsigned int,
+                                                      unsigned long,
+                                                      struct file *));
+extern int unregister_ioctl32_conversion(unsigned int cmd);
+#else
+static IPR_INL int register_ioctl32_conversion(unsigned int cmd,
+                                                  int (*handler)(unsigned int,
+                                                                 unsigned int,
+                                                                 unsigned long,
+                                                                 struct file *))
+{
+    return 0;
+}
+static IPR_INL int unregister_ioctl32_conversion(unsigned int cmd)
+{
+    return 0;
+}
+#endif
+
+
+/******************************************************************/
+/* Literals                                                       */
+/******************************************************************/
+#define IPR_CL_SIZE_LATENCY_MASK 0xFFFFFFFF
+
+
+/******************************************************************/
+/* Structures                                                     */
+/******************************************************************/
+
+struct ipr_location_data
+{
+    u32 frame_id;
+    u8 slot[4];
+    u16 sys_bus;
+    u8 sys_card;
+    u8 io_adapter;
+    u8 ioa_num:4; /* Always 0 */
+    u8 io_bus:4;
+    u8 ctl;
+    u8 dev;
+    u8 reserved;
+    unsigned int pci_bus_number;
+    unsigned int pci_slot;
+    unsigned int pci_function;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/arch/ipr_pseries.c linux-8240/drivers/addon/ipr/arch/ipr_pseries.c
--- linux-8230/drivers/addon/ipr/arch/ipr_pseries.c
+++ linux-8240/drivers/addon/ipr/arch/ipr_pseries.c
@@ -0,0 +1,643 @@
+/*****************************************************************************/
+/* ipr_pseries.c -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/******************************************************************/ 
+/* pSeries architecture dependent utilties                        */
+/******************************************************************/ 
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/arch/ipr_pseries.c,v 1.3 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/blk.h>
+#include <linux/ctype.h>
+#include <asm/uaccess.h>
+#include <asm/processor.h>
+#include <scsi.h>
+#include <hosts.h>
+
+#ifndef iprdd_h
+#include "iprdd.h"
+#endif
+
+#ifndef ipr_pseries_h
+#include "ipr_pseries.h"
+#endif
+
+#ifdef MODULE
+#include <linux/module.h>
+
+MODULE_SUPPORTED_DEVICE("IBM pSeries storage adapters");
+MODULE_DESCRIPTION ("IBM Power Linux RAID driver");
+#endif
+
+const char ipr_platform[] = "pSeries";
+const int ipr_arch = IPR_ARCH_PSERIES;
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get the bus number for use in the pSeries location code
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: bus number
+ *---------------------------------------------------------------------------*/
+static IPR_INL u8 ipr_get_loc_bus(struct ipr_shared_config *p_shared_cfg,
+                                        struct ipr_res_addr resource_address)
+{
+    u8 bus = resource_address.bus;
+
+    if (bus == 0xff)
+        bus = p_shared_cfg->num_physical_buses + 1;
+    else
+        bus++;
+    return bus;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: no locks assumed to be held
+ * Returns: Location data structure or NULL on failure
+ *---------------------------------------------------------------------------*/
+struct ipr_location_data *ipr_get_ioa_location_data(struct pci_dev *p_dev)
+{
+    char *p_buf;
+    struct device_node* p_dev_node;
+    int len;
+    struct ipr_location_data *p_location = NULL;
+
+    p_dev_node = (struct device_node*)p_dev->sysdata;
+
+    p_buf = (char*)get_property(p_dev_node,"ibm,loc-code",&len);
+
+    len = IPR_MIN(len, strlen(p_buf));
+
+    if (p_buf && (len > 3) && ((len+1) < IPR_MAX_PSERIES_LOCATION_LEN))
+    {
+        p_location = ipr_kcalloc(sizeof(struct ipr_location_data),
+                                    IPR_ALLOC_CAN_SLEEP);
+
+        if (p_location != NULL)
+        {
+            strncpy(p_location->of_location, p_buf, len);
+            strncpy(p_location->location, p_buf, len);
+
+            strcpy(&p_location->of_location[len], "/Z");
+            p_location->location[len] = '\0';
+
+            p_location->pci_bus_number = p_dev->bus->number;
+            p_location->pci_slot = PCI_SLOT(p_dev->devfn);
+            p_location->pci_function = PCI_FUNC(p_dev->devfn);
+        }
+    }
+
+    return p_location;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Provide Host location data
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: string containing ioa's host name.
+ *---------------------------------------------------------------------------*/
+void ipr_ioa_loc_str(struct ipr_location_data *p_location, char *p_buf)
+{
+    sprintf(p_buf, "PCI Bus: %d, Device: %3d Location %s",
+            p_location->pci_bus_number,
+            p_location->pci_slot,
+            p_location->location);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Provide device location data
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing.
+ *--------------------------------------------------------------------------*/
+void ipr_dev_loc_str(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_resource_entry *p_resource, char *p_buf)
+{
+    if (p_resource->resource_address.lun == 0)
+    {
+        sprintf(p_buf, "Device Location: %s%d-A%x",
+                p_shared_cfg->p_location->of_location,
+                ipr_get_loc_bus(p_shared_cfg, p_resource->resource_address),
+                p_resource->resource_address.target);
+    }
+    else
+    {
+        sprintf(p_buf, "Device Location: %s%d-A%x.%d",
+                p_shared_cfg->p_location->of_location,
+                ipr_get_loc_bus(p_shared_cfg, p_resource->resource_address),
+                p_resource->resource_address.target,
+                p_resource->resource_address.lun);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_ioa_physical_location(struct ipr_location_data *p_location,
+                                      char *printk_level)
+{
+    ipr_hcam_log("PCI Bus: %d, Device: %3d Location %s",
+                    p_location->pci_bus_number,
+                    p_location->pci_slot,
+                    p_location->location);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_physical_location(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_res_addr resource_address,
+                                      char *printk_level)
+{
+    struct ipr_location_data *p_location;
+
+    p_location = p_shared_cfg->p_location;
+
+    ipr_hcam_log("IOA Location: PCI Bus: %d, Device: %3d Location %s",
+                    p_shared_cfg->p_location->pci_bus_number,
+                    p_shared_cfg->p_location->pci_slot,
+                    p_shared_cfg->p_location->location);
+
+    if (resource_address.lun == 0)
+    {
+        ipr_hcam_log("Device Location: %s%d-A%x",
+                        p_shared_cfg->p_location->of_location,
+                        ipr_get_loc_bus(p_shared_cfg, resource_address),
+                        resource_address.target);
+    }
+    else
+    {
+        ipr_hcam_log("Device Location: %s%d-A%x.%d",
+                        p_shared_cfg->p_location->of_location,
+                        ipr_get_loc_bus(p_shared_cfg, resource_address),
+                        resource_address.target, resource_address.lun);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the physical location of a device
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_unknown_dev_phys_loc(char *printk_level)
+{
+    ipr_hcam_log("Device Location: unknown");
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Toggle reset on the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          non-zero    - failure
+ *---------------------------------------------------------------------------*/
+int ipr_toggle_reset(ipr_host_config *ipr_cfg)
+{
+    int rc;
+
+    /* Start BIST and wait 2 seconds for completion */
+    rc = pci_write_config_dword(ipr_cfg->pdev, 0x0C, 0x40000000);
+    set_current_state(TASK_UNINTERRUPTIBLE);  
+    schedule_timeout(2*HZ);
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return slot position of a device
+ * Context: Task level or interrupt level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_get_card_pos(struct ipr_shared_config *p_shared_cfg,
+                         struct ipr_res_addr resource_addr, char *p_buffer)
+{
+    *p_buffer = '\0';
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a DSA/UA
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt0(struct ipr_shared_config *p_shared_cfg,
+                             u32 dsa, u32 ua,
+                             struct ipr_res_addr *p_res_addr)
+{
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a Frame ID/Card Position
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt1(struct ipr_shared_config *p_shared_cfg,
+                             u32 frame, char *p_slot,
+                             struct ipr_res_addr *p_res_addr)
+{
+    return -ENXIO;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a pSeries location
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt2(struct ipr_shared_config *p_shared_cfg,
+                             char *p_location, struct ipr_res_addr *p_res_addr)
+{
+    char *p_char;
+    char string[3];
+    int ioa_loc_len = strlen(p_shared_cfg->p_location->location);
+
+    string[1] = '\0';
+
+    if (!strncmp(p_location, p_shared_cfg->p_location->location,
+                 strlen(p_shared_cfg->p_location->location)))
+    {
+        /* Look for bus */
+        p_char = strchr(&p_location[ioa_loc_len], 'Z');
+
+        if (!p_char)
+            p_char = strchr(&p_location[ioa_loc_len], 'Q');
+
+        if (!p_char)
+            return -ENXIO;
+
+        string[0] = p_char[1];
+        p_res_addr->bus = simple_strtoul(string, NULL, 10) - 1;
+
+        /* Look for target */
+        p_char = strchr(&p_location[ioa_loc_len], 'A');
+
+        if (!p_char)
+            return -ENXIO;
+
+        string[0] = p_char[1];
+        p_res_addr->target = simple_strtoul(string, NULL, 16);
+
+        /* Look for lun */
+        p_char = strchr(&p_location[ioa_loc_len], '.');
+
+        if (!p_char)
+        {
+            p_res_addr->lun = 0;
+            return 0;
+        }
+
+        string[0] = p_char[1];
+        p_res_addr->lun = simple_strtoul(string, NULL, 10);
+    }
+    else
+        return -ENXIO;
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return resource address of a device location
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: -ENXIO      - Physical location does not exist under this IOA
+ *          0           - Success
+ *---------------------------------------------------------------------------*/
+int ipr_get_res_addr_fmt3(struct ipr_shared_config *p_shared_cfg,
+                             u16 pci_bus, u16 pci_device, u8 bus, u8 target, u8 lun,
+                             struct ipr_res_addr *p_res_addr)
+{
+    if ((pci_bus != p_shared_cfg->p_location->pci_bus_number) ||
+        (pci_device != p_shared_cfg->p_location->pci_slot))
+    {
+        return -ENXIO;
+    }
+
+    p_res_addr->reserved = 0;
+    p_res_addr->bus = bus;
+    p_res_addr->target = target;
+    p_res_addr->lun = lun;
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Update the location information for a resource
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_update_location_data(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_resource_entry *p_resource_entry)
+{
+    struct ipr_location_data *p_location = p_shared_cfg->p_location;
+
+    p_resource_entry->dsa = 0;
+    p_resource_entry->frame_id[0] = '\0';
+    p_resource_entry->unit_address = 0;
+    p_resource_entry->slot_label[0] = '\0';
+
+    if (p_resource_entry->is_ioa_resource)
+    {
+        sprintf(p_resource_entry->pseries_location, "%s",
+                p_location->location);
+    }
+    else
+    {
+        if (p_resource_entry->resource_address.lun == 0)
+        {
+            sprintf(p_resource_entry->pseries_location, "%s%d-A%x",
+                    p_location->of_location,
+                    ipr_get_loc_bus(p_shared_cfg, p_resource_entry->resource_address),
+                    p_resource_entry->resource_address.target);
+        }
+        else
+        {
+            sprintf(p_resource_entry->pseries_location, "%s%d-A%x.%d",
+                    p_location->of_location,
+                    ipr_get_loc_bus(p_shared_cfg, p_resource_entry->resource_address),
+                    p_resource_entry->resource_address.target,
+                    p_resource_entry->resource_address.lun);
+        }
+    }
+
+    p_resource_entry->pci_bus_number = p_shared_cfg->p_location->pci_bus_number;
+    p_resource_entry->pci_slot = p_shared_cfg->p_location->pci_slot;
+
+    if ((IPR_IS_DASD_DEVICE(p_resource_entry->std_inq_data)) &&
+        (!p_resource_entry->is_ioa_resource))
+    {
+        ipr_get_card_pos(p_shared_cfg, p_resource_entry->resource_address,
+                            p_resource_entry->slot_label);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a unique host identifier
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: unique id
+ * Note: This is used by scsidev to generate device names so we want to
+ *       generate something that doesn't change.
+ *---------------------------------------------------------------------------*/
+u32 ipr_get_unique_id(struct ipr_location_data *p_location)
+{
+    return (((p_location->pci_bus_number & 0xffff) << 16) |
+            ((p_location->pci_slot & 0xff) << 8) |
+            p_location->pci_function);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for a device
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: unique id
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_vpd(struct ipr_resource_entry *p_resource,
+                        char *printk_level)
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN+1];
+    u8 product_id[IPR_PROD_ID_LEN+1];
+    u8 *p_char;
+
+    memcpy(vendor_id, p_resource->std_inq_data.vpids.vendor_id,
+           IPR_VENDOR_ID_LEN);
+    vendor_id[IPR_VENDOR_ID_LEN] = '\0';
+    memcpy(product_id, p_resource->std_inq_data.vpids.product_id,
+           IPR_PROD_ID_LEN);
+    product_id[IPR_PROD_ID_LEN] = '\0';
+
+    ipr_hcam_log("Device Manufacturer: %s", vendor_id);
+    ipr_hcam_log("Device Machine Type and Model: %s", product_id);
+
+    if (p_resource->subtype != IPR_SUBTYPE_VOLUME_SET)
+    {
+        ipr_hcam_log("Device FRU Number: %s", p_resource->fru_number);
+        ipr_hcam_log("Device EC Level: %s", p_resource->ec_level);
+        ipr_hcam_log("Device Part Number: %s", p_resource->part_number);
+        /* xxx    ipr_hcam_log("Device Specific (Z0): %02X%02X%02X%02X%02X%02X%02X%02X",
+         p_char[0], p_char[1], p_char[2],
+         p_char[3], p_char[4], p_char[5],
+         p_char[6], p_char[7]);
+         */        ipr_hcam_log("Device Specific (Z1): %s", p_resource->z1_term);
+         ipr_hcam_log("Device Specific (Z2): %s", p_resource->z2_term);
+         ipr_hcam_log("Device Specific (Z3): %s", p_resource->z3_term);
+         ipr_hcam_log("Device Specific (Z4): %s", p_resource->z4_term);
+         ipr_hcam_log("Device Specific (Z5): %s", p_resource->z5_term);
+         ipr_hcam_log("Device Specific (Z6): %s", p_resource->z6_term);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for an array member
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_array_dev_vpd(struct ipr_std_inq_vpids *p_vpids,
+                              char *default_ccin,
+                              char *printk_level)
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN+1];
+    u8 product_id[IPR_PROD_ID_LEN+1];
+
+    memcpy(vendor_id, p_vpids->vendor_id, IPR_VENDOR_ID_LEN);
+    vendor_id[IPR_VENDOR_ID_LEN] = '\0';
+    memcpy(product_id, p_vpids->product_id, IPR_PROD_ID_LEN);
+    product_id[IPR_PROD_ID_LEN] = '\0';
+
+    ipr_hcam_log("        Vendor ID: %s", vendor_id);
+    ipr_hcam_log("       Product ID: %s", product_id);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the VPD for an IOA
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_ioa_vpd(struct ipr_std_inq_vpids *p_vpids,
+                          char *printk_level)
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN+1];
+    u8 product_id[IPR_PROD_ID_LEN+1];
+
+    memcpy(vendor_id, p_vpids->vendor_id, IPR_VENDOR_ID_LEN);
+    vendor_id[IPR_VENDOR_ID_LEN] = '\0';
+    memcpy(product_id, p_vpids->product_id, IPR_PROD_ID_LEN);
+    product_id[IPR_PROD_ID_LEN] = '\0';
+
+    ipr_hcam_log("        Vendor ID: %s", vendor_id);
+    ipr_hcam_log("       Product ID: %s", product_id);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the current and expected locations for a device
+ * Context: Task level or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_log_dev_current_expected_locations(ipr_host_config *ipr_cfg,
+                                               struct ipr_res_addr current_res_addr,
+                                               struct ipr_res_addr expected_res_addr,
+                                               char *printk_level)
+{
+    ipr_hcam_log(" PCI/SCSI Address: ");
+
+    if (current_res_addr.bus == 0xff)
+        ipr_hcam_log("         Current: unknown");
+    else
+    {
+        ipr_hcam_log("         Current: %02X:%02X/%02X%02X%02X",
+                        ipr_cfg->shared.p_location->pci_bus_number,
+                        ipr_cfg->shared.p_location->pci_slot,
+                        current_res_addr.bus,
+                        current_res_addr.target,
+                        current_res_addr.lun);
+    }
+
+    if (expected_res_addr.bus == 0xff)
+        ipr_hcam_log("        Expected: unknown");
+    else
+    {
+        ipr_hcam_log("        Expected: %02X:%02X/%02X%02X%02X",
+                        ipr_cfg->shared.p_location->pci_bus_number,
+                        ipr_cfg->shared.p_location->pci_slot,
+                        expected_res_addr.bus,
+                        expected_res_addr.target,
+                        expected_res_addr.lun);
+    }
+
+    ipr_hcam_log(" Physical Location: ");
+
+    if (current_res_addr.bus == 0xff)
+        ipr_hcam_log("         Current: unknown");
+    else
+    {
+        if (current_res_addr.lun == 0)
+        {
+            ipr_hcam_log("         Current: %s%d-A%x",
+                            ipr_cfg->shared.p_location->of_location,
+                            ipr_get_loc_bus(&ipr_cfg->shared, current_res_addr),
+                            current_res_addr.target);
+        }
+        else
+        {
+            ipr_hcam_log("         Current: %s%d-A%x.%d",
+                            ipr_cfg->shared.p_location->of_location,
+                            ipr_get_loc_bus(&ipr_cfg->shared, current_res_addr),
+                            current_res_addr.target,
+                            current_res_addr.lun);
+        }
+    }
+
+    if (expected_res_addr.bus == 0xff)
+        ipr_hcam_log("        Expected: unknown");
+    else
+    {
+        if (expected_res_addr.lun == 0)
+        {
+            ipr_hcam_log("        Expected: %s%d-A%x",
+                            ipr_cfg->shared.p_location->of_location,
+                            ipr_get_loc_bus(&ipr_cfg->shared, expected_res_addr),
+                            expected_res_addr.target);
+        }
+        else
+        {
+            ipr_hcam_log("        Expected: %s%d-A%x.%d",
+                            ipr_cfg->shared.p_location->of_location,
+                            ipr_get_loc_bus(&ipr_cfg->shared, expected_res_addr),
+                            expected_res_addr.target,
+                            expected_res_addr.lun);
+        }
+    }
+};
+
+static u16 ipr_blocked_processors[] =
+{
+    PV_NORTHSTAR,
+    PV_PULSAR,
+    PV_POWER4,
+    PV_ICESTAR,
+    PV_SSTAR,
+    PV_POWER4p,
+    PV_630,
+    PV_630p
+};
+
+/*---------------------------------------------------------------------------
+ * Purpose: Determine if this adapter is supported on this arch
+ * Context: Task level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0 if adapter is supported
+ *---------------------------------------------------------------------------*/
+int ipr_invalid_adapter(ipr_host_config *ipr_cfg)
+{
+    u8 rev_id;
+    int i, rc = 0;
+
+    if ((ipr_cfg->shared.vendor_id == PCI_VENDOR_ID_MYLEX) &&
+        (ipr_cfg->shared.device_id == PCI_DEVICE_ID_GEMSTONE) &&
+        (ipr_cfg->shared.ccin == 0x5702))
+    {
+        if (pci_read_config_byte(ipr_cfg->pdev,
+                                 PCI_REVISION_ID, &rev_id) == PCIBIOS_SUCCESSFUL)
+        {
+            if (rev_id < 4)
+            {
+                for (i = 0; i < sizeof(ipr_blocked_processors)/sizeof(u16); i++)
+                {
+                    if (__is_processor(ipr_blocked_processors[i]))
+                    {
+                        rc = 1;
+                        break;
+                    }
+                }
+            }
+        }
+    }
+
+    return rc;
+}
diff -urNp linux-8230/drivers/addon/ipr/arch/ipr_pseries.h linux-8240/drivers/addon/ipr/arch/ipr_pseries.h
--- linux-8230/drivers/addon/ipr/arch/ipr_pseries.h
+++ linux-8240/drivers/addon/ipr/arch/ipr_pseries.h
@@ -0,0 +1,69 @@
+/*****************************************************************************/
+/* ipr_pseries.h -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/******************************************************************/ 
+/* pSeries architecture dependent header file                     */
+/******************************************************************/ 
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/arch/ipr_pseries.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#ifndef ipr_pseries_h
+#define ipr_pseries_h
+
+/******************************************************************/
+/* Literals                                                       */
+/******************************************************************/
+
+#ifndef NO_TCE
+#define NO_TCE ((dma_addr_t)-1)
+#endif
+
+#define IPR_CL_SIZE_LATENCY_MASK 0x000000FF  /* only modify Cache line size */
+
+/******************************************************************/
+/* Structures                                                     */
+/******************************************************************/
+
+struct ipr_location_data
+{
+    char location[IPR_MAX_PSERIES_LOCATION_LEN];
+    char of_location[IPR_MAX_PSERIES_LOCATION_LEN];
+    unsigned int pci_bus_number;
+    unsigned int pci_slot;
+    unsigned int pci_function;
+};
+
+/******************************************************************/
+/* Function Prototypes                                            */
+/******************************************************************/
+
+extern int register_ioctl32_conversion(unsigned int cmd,
+                                       int (*handler)(unsigned int,
+                                                      unsigned int,
+                                                      unsigned long,
+                                                      struct file *));
+extern int unregister_ioctl32_conversion(unsigned int cmd);
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/iprdd.c linux-8240/drivers/addon/ipr/iprdd.c
--- linux-8230/drivers/addon/ipr/iprdd.c
+++ linux-8240/drivers/addon/ipr/iprdd.c
@@ -0,0 +1,9386 @@
+/*****************************************************************************/
+/* iprdd.c -- driver for IBM Power Linux RAID adapters                       */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprdd.c,v 1.3.2.2 2003/11/10 19:19:51 bjking1 Exp $
+ */
+
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <linux/pci.h>
+#include <linux/proc_fs.h>
+#include <linux/blk.h>
+#include <linux/wait.h>
+#include <linux/tqueue.h>
+#include <linux/spinlock.h>
+#include <linux/pci_ids.h>
+#include <linux/notifier.h>
+#include <linux/reboot.h>
+#include <linux/ctype.h>
+#include <linux/devfs_fs.h>
+#include <linux/devfs_fs_kernel.h>
+#include <linux/sched.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <linux/tty.h>
+#include <linux/errno.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/uaccess.h>
+#include <asm/processor.h>
+#include <asm/semaphore.h>
+#include <asm/page.h>
+#ifdef CONFIG_KDB
+#include <asm/kdb.h>
+#endif
+
+#include <linux/module.h>
+
+MODULE_AUTHOR ("Brian King <bjking1@us.ibm.com>");
+MODULE_PARM(trace, "b");
+MODULE_PARM_DESC(trace, "IOA command tracing - traces commands issued to IOA");
+MODULE_PARM(verbose, "b");
+MODULE_PARM_DESC(verbose, "Set to 0 - 2 for increasing verbosity of device driver");
+MODULE_PARM(testmode, "b");
+MODULE_PARM_DESC(testmode, "Internal use only");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,10)
+MODULE_LICENSE("GPL");
+#endif
+
+#if !defined(CONFIG_CHR_DEV_SG) && !defined(CONFIG_CHR_DEV_SG_MODULE)
+#error This device driver requires CONFIG_CHR_DEV_SG for proper operation
+#endif
+
+#ifndef CONFIG_PROC_FS
+#error This device driver requires CONFIG_PROC_FS for proper operation
+#endif
+
+#include <sd.h>
+#include <scsi.h>
+#include <hosts.h>
+#include <constants.h>
+
+#ifndef iprdd_h
+#include "iprdd.h"
+#endif
+
+#if defined(CONFIG_PPC_ISERIES)
+#ifndef ipr_iseries_h
+#include "ipr_iseries.h"
+#endif
+#elif defined(CONFIG_PPC_PSERIES) && defined(CONFIG_PPC64)
+#ifndef ipr_pseries_h
+#include "ipr_pseries.h"
+#endif
+#else
+#ifndef ipr_generic_h
+#include "ipr_generic.h"
+#endif
+#endif
+
+#if defined(CONFIG_PPC64)
+#define IPR_GFP_DMA          0
+#elif defined(CONFIG_IA64) || defined(CONFIG_PPC)
+#define IPR_GFP_DMA          GFP_DMA
+#else
+#define IPR_GFP_DMA          0
+#endif
+
+#define IPR_SENSE_BUFFER_COPY_SIZE \
+IPR_MIN(IPR_SENSE_BUFFERSIZE, SCSI_SENSE_BUFFERSIZE)
+
+enum ipr_shutdown_type
+{
+    IPR_SHUTDOWN_NONE,
+    IPR_SHUTDOWN_ABBREV,
+    IPR_SHUTDOWN_NORMAL,
+    IPR_SHUTDOWN_PREPARE_FOR_NORMAL
+};
+
+/**************************************************
+ *   Global Data
+ **************************************************/
+static int ipr_num_ctlrs = 0;
+static ipr_host_config *ipr_cfg_head = NULL;
+static char ipr_buf[2048];
+static int ipr_init_finished = 0;
+static const int ipr_debug = IPR_DEBUG;
+static const int ipr_mem_debug = IPR_MEMORY_DEBUG;
+static u8 trace = IPR_TRACE;
+static u8 verbose = IPR_DEFAULT_DEBUG_LEVEL;
+static u8 testmode = 0;
+static wait_queue_head_t ipr_sdt_wait_q;
+static int ipr_kmalloced_mem = 0;
+static struct ipr_dump_ioa_entry *p_ipr_dump_ioa_entry = NULL;
+static struct ipr_dump_driver_header *p_ipr_dump_driver_header = NULL;
+
+static enum ipr_get_sdt_state
+{
+    INACTIVE,
+    WAIT_FOR_DUMP,
+    NO_DUMP,
+    GET_DUMP,
+    DUMP_OBTAINED
+} ipr_get_sdt_state = INACTIVE;
+
+static const char ipr_version[] = {IPR_NAME" version="IPR_FULL_VERSION};
+extern const char ipr_platform[];
+
+/**************************************************
+ *   Function Prototypes
+ **************************************************/
+static void ipr_add_ioa_to_tail(ipr_host_config *ipr_cfg);
+static void ipr_remove_ioa_from_list(ipr_host_config *ipr_cfg);
+static void ipr_put_ioctl_cmnd_to_free(ipr_host_config *ipr_cfg,
+                                          struct ipr_cmnd* p_sis_cmnd);
+static void ipr_ops_done(ipr_host_config *ipr_cfg);
+static void ipr_find_ioa(Scsi_Host_Template *, u16, u16);
+static int ipr_find_ioa_part2(void);
+static u32 ipr_init_ioa(ipr_host_config *ipr_cfg);
+static u32 ipr_kill_kernel_thread(ipr_host_config *ipr_cfg);
+static u32 ipr_init_ioa_part1(ipr_host_config *ipr_cfg);
+static u32 ipr_init_ioa_part2(ipr_host_config *ipr_cfg);
+void ipr_isr(int irq, void *devp, struct pt_regs *regs);
+static void ipr_fail_all_ops(ipr_host_config *ipr_cfg);
+static void ipr_return_failed_ops(ipr_host_config *ipr_cfg) ;
+static int ipr_notify_sys(struct notifier_block *this, unsigned long code,
+                             void *unused);
+static u32 ipr_shutdown_ioa(ipr_host_config *ipr_cfg,
+                               enum ipr_shutdown_type type);
+static void ipr_ioctl_cmd_done(struct ipr_shared_config *p_shared_cfg,
+                                  struct ipr_ccb *p_sis_ccb);
+static u32 ipr_send_blocking_ioctl(ipr_host_config *ipr_cfg,
+                                      struct ipr_cmnd *p_sis_cmnd,
+                                      u32 timeout,
+                                      u8 retries);
+static void ipr_free_all_resources(ipr_host_config *ipr_cfg,
+                                      int free_reboot_notif, int free_chrdev);
+static void ipr_handle_log_data(ipr_host_config *ipr_cfg,
+                                   struct ipr_hostrcb *p_hostrcb);
+static u32 ipr_get_error(u32 ioasc);
+static int ipr_ioctl(struct inode *inode, struct file *file,
+                        unsigned int cmd_in, unsigned long arg);
+static int ipr_open(struct inode *inode, struct file *filp);
+static int ipr_close(struct inode *inode, struct file *filp);
+static void ipr_mailbox(ipr_host_config *ipr_cfg);
+static int ipr_ioa_reset(ipr_host_config *ipr_cfg, enum ipr_irq_state irq_state);
+static int ipr_reset_reload(ipr_host_config *ipr_cfg,
+                               enum ipr_shutdown_type shutdown_type);
+static u16 ipr_adjust_urc(u32 error_index,
+                             struct ipr_res_addr resource_addr,
+                             u32 ioasc,
+                             u32 dev_urc,
+                             char *p_error_string);
+static void ipr_get_ioa_name(ipr_host_config *ipr_cfg,
+                                char *dev_name);
+static ipr_host_config * ipr_get_host(int dev);
+static void ipr_wake_task(ipr_host_config *ipr_cfg);
+static int ipr_cancelop(ipr_host_config *ipr_cfg,
+                           struct ipr_cmnd *p_sis_cmnd,
+                           Scsi_Cmnd *p_scsi_cmd);
+static void ipr_unit_check_no_data(ipr_host_config *ipr_cfg);
+static ipr_dma_addr ipr_get_hcam_dma_addr(ipr_host_config *ipr_cfg,
+                                                struct ipr_hostrcb *p_hostrcb);
+static void ipr_get_unit_check_buffer(ipr_host_config *ipr_cfg);
+static void ipr_block_all_requests(ipr_host_config *ipr_cfg);
+static void ipr_unblock_all_requests(ipr_host_config *ipr_cfg);
+static void ipr_block_midlayer_requests(ipr_host_config *ipr_cfg);
+static void ipr_unblock_midlayer_requests(ipr_host_config *ipr_cfg);
+static int ipr_cancel_all(Scsi_Cmnd *p_scsi_cmd);
+static int ipr_alloc_ucode_buffer(u32 buf_len,
+                                     struct ipr_dnload_sglist **pp_scatterlist);
+static void ipr_free_ucode_buffer(struct ipr_dnload_sglist *p_dnld);
+static int ipr_copy_ucode_buffer(struct ipr_dnload_sglist *p_scatterlist,
+                                    u8 *p_write_buffer,
+                                    u32 buf_len);
+static struct ipr_resource_entry *ipr_get_ses_resource(ipr_host_config *ipr_cfg,
+                                                             struct ipr_res_addr res_addr);
+static void ipr_sleep_no_lock(signed long delay);
+static struct ipr_drive_elem_status*
+ipr_get_elem_status(struct ipr_encl_status_ctl_pg* p_encl_status_ctl_pg,
+                       u8 scsi_id);
+static int ipr_conc_maint(ipr_host_config *ipr_cfg,
+                             struct ipr_res_addr res_addr, u32 type, u32 delay);
+static int ipr_suspend_device_bus(ipr_host_config *ipr_cfg,
+                                     struct ipr_res_addr res_addr,
+                                     u8 option);
+static int ipr_resume_device_bus(ipr_host_config *ipr_cfg,
+                                    struct ipr_res_addr res_addr);
+static int ipr_ses_receive_diagnostics(ipr_host_config *ipr_cfg,
+                                          u8 page,
+                                          void *p_buffer,
+                                          ipr_dma_addr buffer_dma_addr,
+                                          u16 bufflen,
+                                          struct ipr_resource_entry *p_resource);
+static int ipr_ses_send_diagnostics(ipr_host_config *ipr_cfg,
+                                       void *p_buffer,
+                                       ipr_dma_addr buffer_dma_addr,
+                                       u16 bufflen,
+                                       struct ipr_resource_entry *p_resource);
+static void ipr_print_sense(u8 cmd, unsigned char *p_buf);
+static signed long ipr_sleep_on_timeout(spinlock_t *p_lock,
+                                           wait_queue_head_t *p_wait_head, long timeout);
+static void ipr_interruptible_sleep_on(spinlock_t *p_lock,
+                                          wait_queue_head_t *p_wait_head);
+static void ipr_sleep_on(spinlock_t *p_lock,
+                            wait_queue_head_t *p_wait_head);
+static int ipr_sdt_copy(ipr_host_config *ipr_cfg,
+                           unsigned long pci_address, u32 length, u32 swap,
+                           unsigned long timeout);
+static int ipr_get_ioa_smart_dump(ipr_host_config *ipr_cfg);
+static int ipr_copy_sdt_to_user(u8 *p_dest_buffer, u32 length);
+static void ipr_start_erp(struct ipr_cmnd *p_sis_cmnd);
+static void ipr_end_erp(struct ipr_cmnd *p_sis_cmnd);
+static void *ipr_get_free_pages(u32 flags, u32 order);
+static void *ipr_get_free_page(u32 flags);
+static void ipr_free_pages(void *ptr, u32 order);
+static void ipr_free_page(void *ptr);
+static u32 ipr_xlate_malloc_flags(u32 flags);
+
+/**************************************************
+ *   Internal Data Structures
+ **************************************************/
+static struct notifier_block ipr_notifier =
+{
+    ipr_notify_sys,
+    NULL,
+    0
+};
+
+static struct file_operations ipr_fops =
+{
+    ioctl:      ipr_ioctl,
+    open:       ipr_open,
+    release:    ipr_close,
+};
+
+static const
+struct ipr_error_class_table_t ipr_error_class_table[] =
+{
+    {IPR_NO_ERR_CLASS, KERN_DEBUG, "None"},
+    {IPR_ERR_CLASS_PERM, KERN_ERR, "Permanent"},
+    {IPR_ERR_CLASS_PRED_ANALYSIS, KERN_NOTICE, "Statistical"},
+    {IPR_ERR_CLASS_SERVICE_ACTION_PT, KERN_CRIT, "Threshold"},
+    {IPR_ERR_CLASS_TEMP, KERN_WARNING, "Temporary"},
+    {IPR_ERR_CLASS_RETRYABLE, KERN_WARNING, "Recoverable"},
+    {IPR_ERR_CLASS_INFO, KERN_INFO, "Informational"}
+};
+
+static const struct pci_device_id ipr_pci_table[] =
+{
+    {
+        vendor: PCI_VENDOR_ID_MYLEX,
+        device: PCI_DEVICE_ID_GEMSTONE,
+        subvendor: PCI_VENDOR_ID_IBM,
+        subdevice: IPR_SUBS_DEV_ID_5702,
+    },
+    {
+        vendor: PCI_VENDOR_ID_IBM,
+        device: PCI_DEVICE_ID_IBM_SNIPE,
+        subvendor: PCI_VENDOR_ID_IBM,
+        subdevice: IPR_SUBS_DEV_ID_2780,
+    },
+    {
+        vendor: PCI_VENDOR_ID_MYLEX,
+        device: PCI_DEVICE_ID_GEMSTONE,
+        subvendor: PCI_VENDOR_ID_IBM,
+        subdevice: IPR_SUBS_DEV_ID_5703,
+    },
+    { }
+};
+MODULE_DEVICE_TABLE(pci, ipr_pci_table);
+
+struct ipr_pci_dev_table_t
+{
+    u16 vendor_id;
+    u16 device_id;
+    u16 subsystem_id;
+    u16 ccin;
+    char ccin_str[10];
+    u16 num_physical_buses;
+    u16 max_cmd_len;
+    u8 format_immed:1;
+};
+
+static const 
+struct ipr_pci_dev_table_t ipr_pci_dev_table[] =
+{
+    {PCI_VENDOR_ID_IBM, PCI_DEVICE_ID_IBM_SNIPE , IPR_SUBS_DEV_ID_2780, 0x2780, "2780", 4, 16, 1},
+    {PCI_VENDOR_ID_MYLEX, PCI_DEVICE_ID_GEMSTONE, IPR_SUBS_DEV_ID_5702, 0x5702, "SCSI IOA", 2, 16, 0},
+    {PCI_VENDOR_ID_MYLEX, PCI_DEVICE_ID_GEMSTONE, IPR_SUBS_DEV_ID_5703, 0x5703, "RAID IOA", 2, 16, 1}
+};
+
+/* This table describes the differences between DMA controller chips */
+static const
+struct ipr_ioa_cfg_t ipr_ioa_cfg[] =
+{
+    { /* Gemstone based IOAs */
+        PCI_VENDOR_ID_MYLEX,
+        PCI_DEVICE_ID_GEMSTONE,
+        0,
+        IPR_GEMSTONE_MAILBOX_OFFSET,
+        IPR_FMT2_MBX_BAR_SEL_MASK,
+        IPR_FMT2_MKR_BAR_SEL_SHIFT,
+        IPR_FMT2_MBX_ADDR_MASK,
+        IPR_SDT_REG_SEL_SIZE_1NIBBLE,
+        IPR_CPU_RST_SUPPORT_NONE,
+        IPR_FIXUPS_NONE,
+        0,
+        IPR_SET_MODE_PAGE_20,
+        0,
+        /* Setup the cache line size to 128 bytes and the latency timer to maximum value. */
+        0x0000f820
+    },
+    { /* Snipe based IOAs */
+        PCI_VENDOR_ID_IBM,
+        PCI_DEVICE_ID_IBM_SNIPE,
+        0,
+        IPR_SNIPE_MAILBOX_OFFSET,
+        IPR_FMT2_MBX_BAR_SEL_MASK,
+        IPR_FMT2_MKR_BAR_SEL_SHIFT,
+        IPR_FMT2_MBX_ADDR_MASK,
+        IPR_SDT_REG_SEL_SIZE_1NIBBLE,
+        IPR_CPU_RST_SUPPORT_NONE,
+        IPR_FIXUPS_NONE,
+        0,
+        IPR_SET_MODE_PAGE_20,
+        0,
+        /* Setup the cache line size to 128 bytes and the latency timer to maximum value. */
+      /*  xx 0x0000f820 */
+        0x0000f810
+    },
+};
+
+/*  A constant array of IOASCs/URCs/Error Messages */
+static const
+struct ipr_error_table_t ipr_error_table[] =
+{
+    {0x00000000, 0x0000, 0x0000, IPR_ERR_CLASS_PERM, "An unknown error was received."},
+    {0x01080000, 0xFFFE, 0x8140, IPR_ERR_CLASS_PRED_ANALYSIS, "Temporary disk bus error"},
+    {0x01170600, 0xFFF9, 0x8141, IPR_ERR_CLASS_TEMP, "Temporary disk data error"},
+    {0x01170900, 0xFFF7, 0x8141, IPR_ERR_CLASS_TEMP, "Temporary disk data error"},
+    {0x01180200, 0x7001, 0x8141, IPR_ERR_CLASS_PRED_ANALYSIS, "Temporary disk data error"},
+    {0x01180500, 0xFFF9, 0x8141, IPR_ERR_CLASS_PRED_ANALYSIS, "Temporary disk data error"},
+    {0x01180600, 0xFFF7, 0x8141, IPR_ERR_CLASS_TEMP, "Temporary disk data error"},
+    {0x01418000, 0x0000, 0xFF3D, IPR_ERR_CLASS_PRED_ANALYSIS, "Soft IOA error recovered by the IOA"},
+    {0x01440000, 0xFFF6, 0x8141, IPR_ERR_CLASS_PRED_ANALYSIS, "Disk device detected recoverable error"},
+    {0x01448100, 0xFFF6, 0x8141, IPR_ERR_CLASS_PRED_ANALYSIS, "Disk device detected recoverable error"},
+    {0x01448200, 0x0000, 0xFF3D, IPR_ERR_CLASS_PRED_ANALYSIS, "Soft IOA error recovered by the IOA"},
+    {0x01448300, 0xFFFA, 0x8141, IPR_ERR_CLASS_PRED_ANALYSIS, "Temporary disk bus error"},
+    {0x014A0000, 0xFFF6, 0x8141, IPR_ERR_CLASS_PRED_ANALYSIS, "Temporary disk bus error"},
+    {0x015D0000, 0xFFF6, 0x8145, IPR_ERR_CLASS_SERVICE_ACTION_PT, "Disk device detected recoverable error"},
+    {0x015D9200, 0x0000, 0x8009, IPR_ERR_CLASS_SERVICE_ACTION_PT, "Impending cache battery pack failure"},
+    {0x02040400, 0x0000, 0x34FF, IPR_ERR_CLASS_INFO, "Disk device format in progress"},
+    {0x02670100, 0x3020, 0x3400, IPR_ERR_CLASS_PERM, "Storage subsystem configuration error"},
+    {0x03110B00, 0xFFF5, 0x3400, IPR_ERR_CLASS_PERM, "Disk sector read error"},
+    {0x03110C00, 0x0000, 0x0000, IPR_ERR_CLASS_PERM, "Disk sector read error"}, /* 0x7000, 0x3400 */
+    {0x03310000, 0xFFF3, 0x3400, IPR_ERR_CLASS_PERM, "Disk media format bad"},
+    {0x04050000, 0x3002, 0x3400, IPR_ERR_CLASS_RETRYABLE, "Addressed device failed to respond to selection"},
+    {0x04080000, 0x3100, 0x3100, IPR_ERR_CLASS_PERM, "IOA detected interface error"},
+    {0x04080100, 0x3109, 0x3400, IPR_ERR_CLASS_RETRYABLE, "IOA timed out a disk command"},
+    {0x04088000, 0x0000, 0x3120, IPR_ERR_CLASS_PERM, "SCSI bus is not operational"},
+    {0x04118000, 0x0000, 0x9000, IPR_ERR_CLASS_PERM, "IOA detected device error"},
+    {0x04118100, 0x0000, 0x9001, IPR_ERR_CLASS_PERM, "IOA detected device error"},
+    {0x04118200, 0x0000, 0x9002, IPR_ERR_CLASS_PERM, "IOA detected device error"},
+    {0x04320000, 0x102E, 0x3400, IPR_ERR_CLASS_PERM, "Out of alternate sectors for disk storage"},
+    {0x04330000, 0xFFF4, 0x3400, IPR_ERR_CLASS_PERM, "Disk device problem"},
+    {0x04338000, 0xFFF4, 0x3400, IPR_ERR_CLASS_PERM, "Disk device problem"},
+    {0x043E0100, 0x0000, 0x3400, IPR_ERR_CLASS_PERM, "Permanent IOA failure"},
+    {0x04408500, 0xFFF4, 0x3400, IPR_ERR_CLASS_PERM, "Disk device problem"},
+    {0x04418000, 0x0000, 0x8150, IPR_ERR_CLASS_PERM, "Permanent IOA failure"},
+    {0x04440000, 0xFFF4, 0x3400, IPR_ERR_CLASS_PERM, "Disk device problem"},
+    {0x04448200, 0x0000, 0x8150, IPR_ERR_CLASS_PERM, "Permanent IOA failure"},
+    {0x04448300, 0x3010, 0x3400, IPR_ERR_CLASS_PERM, "Disk device returned wrong response to IOA"},
+    {0x04448400, 0x0000, 0x8151, IPR_ERR_CLASS_PERM, "IOA Licensed Internal Code error"},
+    {0x04448600, 0x0000, 0x8157, IPR_ERR_CLASS_PERM, "Hardware Error, IOA error requiring IOA reset to recover"},
+    {0x04449200, 0x0000, 0x8008, IPR_ERR_CLASS_PERM, "A permanent cache battery pack failure occurred"},
+    {0x0444A000, 0x0000, 0x9090, IPR_ERR_CLASS_PERM, "Disk unit has been modified after the last known status"},
+    {0x0444A200, 0x0000, 0x9081, IPR_ERR_CLASS_PERM, "IOA detected device error"},
+    {0x0444A300, 0x0000, 0x9082, IPR_ERR_CLASS_PERM, "IOA detected device error"},
+    {0x044A0000, 0x3110, 0x3400, IPR_ERR_CLASS_PERM, "Disk bus interface error occurred"},
+    {0x04670400, 0x0000, 0x9091, IPR_ERR_CLASS_PERM, "Incorrect hardware configuration change has been detected"},
+    {0x046E0000, 0xFFF4, 0x3400, IPR_ERR_CLASS_PERM, "Disk device problem"},
+    {0x06040500, 0x0000, 0x9031, IPR_ERR_CLASS_TEMP, "Array protection temporarily suspended"},
+    {0x06040600, 0x0000, 0x9040, IPR_ERR_CLASS_TEMP, "Array protection temporarily suspended"},
+    {0x060A8000, 0x0000, 0x0000, IPR_ERR_CLASS_PERM, "Not applicable"},
+    {0x06288000, 0x0000, 0x3140, IPR_ERR_CLASS_INFO, "SCSI bus is not operational"},
+    {0x06290000, 0xFFFB, 0x3400, IPR_ERR_CLASS_INFO, "Temporary disk bus error"},
+    {0x06290500, 0xFFFE, 0x8140, IPR_ERR_CLASS_INFO, "SCSI bus transition to single ended"},
+    {0x06290600, 0xFFFE, 0x8140, IPR_ERR_CLASS_INFO, "SCSI bus transition to LVD"},
+    {0x06298000, 0xFFFB, 0x3400, IPR_ERR_CLASS_INFO, "Temporary disk bus error"},
+    {0x06308000, 0x0000, 0x9093, IPR_ERR_CLASS_PERM, "Read cache device not in correct format"},
+    {0x063F0300, 0x3029, 0x3400, IPR_ERR_CLASS_INFO, "A device replacement has occurred"},
+    {0x063F8000, 0x0000, 0x9014, IPR_ERR_CLASS_SERVICE_ACTION_PT, "Mode jumper overridden due to cache data in conflicting mode"},
+    {0x063F8100, 0x0000, 0x9015, IPR_ERR_CLASS_SERVICE_ACTION_PT, "Mode jumper missing"},
+    {0x063F8200, 0x0000, 0x0000, IPR_ERR_CLASS_PERM, "TCQing not active - not applicable"}, /* 0x3131 0x3400 */
+    {0x064C8000, 0x0000, 0x9051, IPR_ERR_CLASS_PERM, "IOA cache data exists for a missing or failed device"},
+    {0x06670100, 0x0000, 0x9025, IPR_ERR_CLASS_PERM, "Disk unit is not supported at its physical location"},
+    {0x06670600, 0x0000, 0x3020, IPR_ERR_CLASS_PERM, "IOA detected a SCSI bus configuration error"},
+    {0x06678000, 0x0000, 0x3150, IPR_ERR_CLASS_PERM, "SCSI bus configuration error"},
+    {0x06690200, 0x0000, 0x9041, IPR_ERR_CLASS_TEMP, "Array protection temporarily suspended"},
+    {0x066B0200, 0x0000, 0x9030, IPR_ERR_CLASS_PERM, "Array no longer protected due to missing or failed disk unit"},
+    {0x06808000, 0x0000, 0x8012, IPR_ERR_CLASS_PERM, "Attached read cache devices exceed capacity supported by IOA"},
+    {0x07278000, 0x0000, 0x9008, IPR_ERR_CLASS_PERM, "IOA does not support functions expected by devices"},
+    {0x07278100, 0x0000, 0x9010, IPR_ERR_CLASS_PERM, "Cache data associated with attached devices cannot be found"},
+    {0x07278200, 0x0000, 0x9011, IPR_ERR_CLASS_PERM, "Cache data belongs to devices other than those attached"},
+    {0x07278400, 0x0000, 0x9020, IPR_ERR_CLASS_PERM, "Array not functional due to present hardware configuration"},
+    {0x07278500, 0x0000, 0x9021, IPR_ERR_CLASS_PERM, "Array not functional due to present hardware configuration"},
+    {0x07278600, 0x0000, 0x9022, IPR_ERR_CLASS_PERM, "Array not functional due to present hardware configuration"},
+    {0x07278700, 0x0000, 0x9023, IPR_ERR_CLASS_PERM, "Array member(s) not at required resource address"},
+    {0x07278800, 0x0000, 0x9024, IPR_ERR_CLASS_PERM, "Array not functional due to present hardware configuration"},
+    {0x07278900, 0x0000, 0x9026, IPR_ERR_CLASS_PERM, "Array not functional due to present hardware configuration"},
+    {0x07278A00, 0x0000, 0x9027, IPR_ERR_CLASS_PERM, "Array not functional due to present hardware configuration"},
+    {0x07278B00, 0x0000, 0x9028, IPR_ERR_CLASS_PERM, "Incorrect hardware configuration change has been detected"},
+    {0x07278C00, 0x0000, 0x9050, IPR_ERR_CLASS_PERM, "Required cache data cannot be located for a disk unit"},
+    {0x07278D00, 0x0000, 0x9052, IPR_ERR_CLASS_PERM, "Cache data exists for a device that has been modified"},
+    {0x07278E00, 0x0000, 0x9053, IPR_ERR_CLASS_PERM, "IOA resources not available due to previous problems"},
+    {0x07278F00, 0x0000, 0x9054, IPR_ERR_CLASS_PERM, "IOA resources not available due to previous problems"},
+    {0x07279100, 0x0000, 0x9092, IPR_ERR_CLASS_PERM, "Disk unit requires initialization before use"},
+    {0x07279200, 0x0000, 0x9029, IPR_ERR_CLASS_PERM, "Incorrect hardware configuration change has been detected"},
+    {0x07279500, 0x0000, 0x9009, IPR_ERR_CLASS_PERM, "Data Protect, device configuration sector is not convertible"},
+    {0x07279600, 0x0000, 0x9060, IPR_ERR_CLASS_PERM, "One or more disk pairs are missing from an array"},
+    {0x07279700, 0x0000, 0x9061, IPR_ERR_CLASS_PERM, "One or more disks are missing from an array"},
+    {0x07279800, 0x0000, 0x9062, IPR_ERR_CLASS_PERM, "One or more disks are missing from an array"},
+    {0x07279900, 0x0000, 0x9063, IPR_ERR_CLASS_PERM, "Maximum number of functional arrays has been exceeded"}
+};
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get pointer to a lun given a scsi_cmnd pointer
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL struct ipr_lun
+*ipr_get_lun_scsi(ipr_host_config *ipr_cfg,
+                     Scsi_Cmnd *p_scsi_cmd)
+{
+    u8 bus;
+    struct ipr_lun *p_lun = NULL;
+
+    bus = (u8)(p_scsi_cmd->channel + 1);
+
+    if (bus <= IPR_MAX_NUM_BUSES)
+    {
+        p_lun = &ipr_cfg->shared.bus[bus].
+            target[p_scsi_cmd->target].lun[p_scsi_cmd->lun];
+    }
+
+    return p_lun;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get pointer to a lun given a resource address
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL struct ipr_lun
+*ipr_get_lun_res_addr(ipr_host_config *ipr_cfg,
+                         struct ipr_res_addr res_addr)
+{
+    u8 bus;
+    struct ipr_lun *p_lun = NULL;
+
+    if (IPR_GET_PHYSICAL_LOCATOR(res_addr) != IPR_IOA_RESOURCE_ADDRESS)
+    {
+        bus = (u8)(res_addr.bus + 1);
+
+        if (bus <= IPR_MAX_NUM_BUSES)
+        {
+            p_lun = &ipr_cfg->shared.bus[bus].
+                target[res_addr.target].lun[res_addr.lun];
+        }
+    }
+
+    return p_lun;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Puts IOA in linked list of IOAs
+ * Context: Task level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_add_ioa_to_tail(ipr_host_config *ipr_cfg)
+{
+    int i;
+    ipr_host_config *p_cur_ioa, *p_prev_ioa;
+
+    /* Iterate through the singly linked list to get to the tail */
+    for (i = 0,
+         p_cur_ioa = ipr_cfg_head,
+         p_prev_ioa = NULL;
+         i < ipr_num_ctlrs;
+         p_prev_ioa = p_cur_ioa,
+         p_cur_ioa = p_cur_ioa->p_next,
+         i++)
+    {
+    }
+
+    if (p_prev_ioa)
+        p_prev_ioa->p_next = ipr_cfg;
+    else
+        ipr_cfg_head = ipr_cfg;
+
+    ipr_cfg->p_next = NULL;
+
+    ipr_num_ctlrs++;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Removes IOA from linked list of IOAs
+ * Context: Task level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_remove_ioa_from_list(ipr_host_config *ipr_cfg)
+{
+    int i;
+    ipr_host_config *p_cur_ioa, *p_prev_ioa;
+
+    for (i = 0,
+         p_cur_ioa = ipr_cfg_head,
+         p_prev_ioa = NULL;
+         i < ipr_num_ctlrs;
+         p_prev_ioa = p_cur_ioa,
+         p_cur_ioa = p_cur_ioa->p_next,
+         i++)
+    {
+        /* Is this the IOA we want to delete? */
+        if (p_cur_ioa == ipr_cfg)
+        {
+            if (p_prev_ioa)
+                p_prev_ioa->p_next = p_cur_ioa->p_next;
+            else
+                ipr_cfg_head = ipr_cfg_head->p_next;
+            ipr_num_ctlrs--;
+            return;
+        }
+    }
+
+    panic(IPR_ERR"IOA not found in list: 0x%p"IPR_EOL, ipr_cfg);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Puts a SIS Cmnd on the pending queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_put_sis_cmnd_to_pending(ipr_host_config *ipr_cfg,
+                                                      struct ipr_cmnd* p_sis_cmnd)
+{
+    /* Put SIS Cmnd on the pending list */
+    if (ipr_cfg->qPendingT != NULL)
+    {
+        ipr_cfg->qPendingT->p_next = p_sis_cmnd;
+        p_sis_cmnd->p_prev = ipr_cfg->qPendingT;
+        ipr_cfg->qPendingT = p_sis_cmnd;
+    }
+    else
+    {
+        ipr_cfg->qPendingT = ipr_cfg->qPendingH = p_sis_cmnd;
+        p_sis_cmnd->p_prev = NULL;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Initialize a SIS Cmnd block
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to command block
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_initialize_sis_cmnd(struct ipr_cmnd* p_sis_cmnd)
+{
+    u8 *p_sense_buffer;
+    ipr_dma_addr sense_buffer_dma;
+
+    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+    sense_buffer_dma = p_sis_cmnd->ccb.sense_buffer_dma;
+
+    memset(p_sis_cmnd, 0, sizeof(struct ipr_cmnd));
+    memset(p_sense_buffer, 0, IPR_SENSE_BUFFERSIZE);
+    p_sis_cmnd->ccb.sense_buffer = p_sense_buffer;
+    p_sis_cmnd->ccb.sense_buffer_dma = sense_buffer_dma;
+    p_sis_cmnd->ccb.sglist = p_sis_cmnd->sglist;
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a free SIS Cmnd block.
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to command block
+ * Notes: Cannot run out - will kernel panic if it does.
+ *        Nobody should call this directly - use ipr_get_free_sis_cmnd
+ *        and ipr_get_free_sis_cmnd_for_ioctl instead
+ *---------------------------------------------------------------------------*/
+static IPR_INL struct ipr_cmnd*
+ipr_get_free_sis_cmnd_internal(ipr_host_config *ipr_cfg)
+{
+    struct ipr_cmnd* p_sis_cmnd;
+
+    p_sis_cmnd = ipr_cfg->qFreeH;
+
+    if (p_sis_cmnd == NULL)
+        panic(IPR_ERR": Out of command blocks. ipr_cfg: 0x%p"IPR_EOL, ipr_cfg);
+
+    ipr_cfg->qFreeH = ipr_cfg->qFreeH->p_next;
+
+    if (ipr_cfg->qFreeH == NULL)
+        ipr_cfg->qFreeT = NULL;
+    else
+        ipr_cfg->qFreeH->p_prev = NULL;
+
+    ipr_initialize_sis_cmnd(p_sis_cmnd);
+
+    return p_sis_cmnd;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a free SIS Cmnd block.
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to command block
+ * Notes: Cannot run out - will kernel panic if it does.
+ *---------------------------------------------------------------------------*/
+static IPR_INL struct ipr_cmnd*
+ipr_get_free_sis_cmnd(ipr_host_config *ipr_cfg)
+{
+    struct ipr_cmnd* p_sis_cmnd;
+
+    p_sis_cmnd = ipr_get_free_sis_cmnd_internal(ipr_cfg);
+
+    return p_sis_cmnd;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allocate a SIS Cmnd block for an IOCTL.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O Error
+ *---------------------------------------------------------------------------*/
+static int ipr_get_free_sis_cmnd_for_ioctl(ipr_host_config *ipr_cfg,
+                                              struct ipr_cmnd **pp_sis_cmnd)
+{
+    struct ipr_cmnd *p_sis_cmnd = NULL;
+    int rc = 0;
+
+    /* Are we not accepting new requests? */
+    if ((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0)
+    {
+        ipr_dbg_trace;
+        return -EIO;
+    }
+
+    spin_unlock_irq(&io_request_lock);
+    down(&ipr_cfg->ioctl_semaphore);
+    spin_lock_irq(&io_request_lock);
+
+    /* We can get a command block */
+    if (ipr_cfg->flag & IPR_ALLOW_REQUESTS)
+        p_sis_cmnd = ipr_get_free_sis_cmnd_internal(ipr_cfg);
+    else
+    {
+        /* We should not be servicing external requests now */
+        up(&ipr_cfg->ioctl_semaphore);
+        ipr_dbg_trace;
+        rc = -EIO;
+    }
+
+    *pp_sis_cmnd = p_sis_cmnd;
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allocate a SIS Cmnd block for an internal IOCTL.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O Error
+ *---------------------------------------------------------------------------*/
+static int ipr_get_free_sis_cmnd_for_ioctl_internal(ipr_host_config *ipr_cfg,
+                                                       struct ipr_cmnd **pp_sis_cmnd)
+{
+    struct ipr_cmnd *p_sis_cmnd = NULL;
+    int rc = 0;
+
+    /* Should we be talking to the adapter? */
+    if ((ipr_cfg->shared.ioa_operational) == 0)
+    {
+        ipr_dbg_trace;
+        return -EIO;
+    }
+
+    spin_unlock_irq(&io_request_lock);
+    down(&ipr_cfg->ioctl_semaphore);
+    spin_lock_irq(&io_request_lock);
+
+    /* Should we be talking to the adapter? */
+    if ((ipr_cfg->shared.ioa_operational) == 0)
+    {
+        ipr_dbg_trace;
+        return -EIO;
+    }
+
+    p_sis_cmnd = ipr_get_free_sis_cmnd_internal(ipr_cfg);
+
+    *pp_sis_cmnd = p_sis_cmnd;
+
+    return rc;
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Put SIS Cmnd on the free queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_put_sis_cmnd_to_free(ipr_host_config *ipr_cfg,
+                                                   struct ipr_cmnd* p_sis_cmnd)
+{
+    if (p_sis_cmnd->ccb.flags & IPR_UNMAP_ON_DONE)
+    {
+        if (p_sis_cmnd->ccb.scsi_use_sg > 0)
+        {
+            pci_unmap_sg(ipr_cfg->pdev, p_sis_cmnd->ccb.request_buffer,
+                         p_sis_cmnd->ccb.scsi_use_sg,
+                         scsi_to_pci_dma_dir(p_sis_cmnd->ccb.sc_data_direction));
+        }
+        else if (p_sis_cmnd->ccb.use_sg == 1)
+        {
+            pci_unmap_single(ipr_cfg->pdev, (dma_addr_t)p_sis_cmnd->ccb.buffer_dma,
+                             p_sis_cmnd->ccb.bufflen,
+                             scsi_to_pci_dma_dir(p_sis_cmnd->ccb.sc_data_direction));
+        }
+    }
+
+    /* Put SIS Cmnd back on the free list */
+    if(ipr_cfg->qFreeT != NULL)
+    {
+        ipr_cfg->qFreeT->p_next = p_sis_cmnd;
+        p_sis_cmnd->p_prev = ipr_cfg->qFreeT;
+        ipr_cfg->qFreeT = p_sis_cmnd;
+    }
+    else
+    {
+        ipr_cfg->qFreeH = ipr_cfg->qFreeT = p_sis_cmnd;
+        p_sis_cmnd->p_prev = NULL;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Put SIS IOCTL Cmnd on the free queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_put_ioctl_cmnd_to_free(ipr_host_config *ipr_cfg,
+                                          struct ipr_cmnd* p_sis_cmnd)
+{
+    ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+    up(&ipr_cfg->ioctl_semaphore);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Puts a SIS Cmnd on the error queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_put_sis_cmnd_to_error(ipr_host_config *ipr_cfg,
+                                                    struct ipr_cmnd* p_sis_cmnd)
+{
+    /* Put SIS Cmnd on the error list */
+    if (ipr_cfg->qErrorT != NULL)
+    {
+        ipr_cfg->qErrorT->p_next = p_sis_cmnd;
+        p_sis_cmnd->p_prev = ipr_cfg->qErrorT;
+        ipr_cfg->qErrorT = p_sis_cmnd;
+    }
+    else
+    {
+        ipr_cfg->qErrorT = ipr_cfg->qErrorH = p_sis_cmnd;
+        p_sis_cmnd->p_prev = NULL;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Removes a SIS Cmnd from the completed queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_remove_sis_cmnd_from_completed(ipr_host_config *ipr_cfg,
+                                                             struct ipr_cmnd* p_sis_cmnd)
+{
+    if ((p_sis_cmnd == ipr_cfg->qCompletedH) &&
+        (p_sis_cmnd == ipr_cfg->qCompletedT))
+    {
+        ipr_cfg->qCompletedH = ipr_cfg->qCompletedT = NULL;
+    }
+    else if (p_sis_cmnd == ipr_cfg->qCompletedH)
+    {
+        ipr_cfg->qCompletedH = ipr_cfg->qCompletedH->p_next;
+        ipr_cfg->qCompletedH->p_prev = NULL;
+    }
+    else if (p_sis_cmnd == ipr_cfg->qCompletedT)
+    {
+        ipr_cfg->qCompletedT = ipr_cfg->qCompletedT->p_prev;
+        ipr_cfg->qCompletedT->p_next = NULL;
+    }
+    else
+    {
+        p_sis_cmnd->p_next->p_prev = p_sis_cmnd->p_prev;
+        p_sis_cmnd->p_prev->p_next = p_sis_cmnd->p_next;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+    p_sis_cmnd->p_prev = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Removes a SIS Cmnd from the error queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_remove_sis_cmnd_from_error(ipr_host_config *ipr_cfg,
+                                                         struct ipr_cmnd* p_sis_cmnd)
+{
+    if ((p_sis_cmnd == ipr_cfg->qErrorH) &&
+        (p_sis_cmnd == ipr_cfg->qErrorT))
+    {
+        ipr_cfg->qErrorH = ipr_cfg->qErrorT = NULL;
+    }
+    else if (p_sis_cmnd == ipr_cfg->qErrorH)
+    {
+        ipr_cfg->qErrorH = ipr_cfg->qErrorH->p_next;
+        ipr_cfg->qErrorH->p_prev = NULL;
+    }
+    else if (p_sis_cmnd == ipr_cfg->qErrorT)
+    {
+        ipr_cfg->qErrorT = ipr_cfg->qErrorT->p_prev;
+        ipr_cfg->qErrorT->p_next = NULL;
+    }
+    else
+    {
+        p_sis_cmnd->p_next->p_prev = p_sis_cmnd->p_prev;
+        p_sis_cmnd->p_prev->p_next = p_sis_cmnd->p_next;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+    p_sis_cmnd->p_prev = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Removes a SIS Cmnd from the pending queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_remove_sis_cmnd_from_pending(ipr_host_config *ipr_cfg,
+                                                           struct ipr_cmnd* p_sis_cmnd)
+{
+    if ((p_sis_cmnd == ipr_cfg->qPendingH) &&
+        (p_sis_cmnd == ipr_cfg->qPendingT))
+    {
+        ipr_cfg->qPendingH = ipr_cfg->qPendingT = NULL;
+    }
+    else if (p_sis_cmnd == ipr_cfg->qPendingH)
+    {
+        ipr_cfg->qPendingH = ipr_cfg->qPendingH->p_next;
+        ipr_cfg->qPendingH->p_prev = NULL;
+    }
+    else if (p_sis_cmnd == ipr_cfg->qPendingT)
+    {
+        ipr_cfg->qPendingT = ipr_cfg->qPendingT->p_prev;
+        ipr_cfg->qPendingT->p_next = NULL;
+    }
+    else
+    {
+        p_sis_cmnd->p_next->p_prev = p_sis_cmnd->p_prev;
+        p_sis_cmnd->p_prev->p_next = p_sis_cmnd->p_next;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+    p_sis_cmnd->p_prev = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Removes a SIS Cmnd from the pending queue and puts it on the
+ *          free queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_put_sis_cmnd_from_pending(ipr_host_config *ipr_cfg,
+                                                        struct ipr_cmnd* p_sis_cmnd)
+{
+    ipr_remove_sis_cmnd_from_pending(ipr_cfg, p_sis_cmnd);
+    ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Puts a SIS Cmnd on the completed queue
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_put_sis_cmnd_to_completed(ipr_host_config *ipr_cfg,
+                                                        struct ipr_cmnd* p_sis_cmnd)
+{
+    /* Put SIS Cmnd back on the free list */
+    if (ipr_cfg->qCompletedT != NULL)
+    {
+        ipr_cfg->qCompletedT->p_next = p_sis_cmnd;
+        p_sis_cmnd->p_prev = ipr_cfg->qCompletedT;
+        ipr_cfg->qCompletedT = p_sis_cmnd;
+    }
+    else
+    {
+        ipr_cfg->qCompletedT = ipr_cfg->qCompletedH = p_sis_cmnd;
+        p_sis_cmnd->p_prev = NULL;
+    }
+
+    p_sis_cmnd->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Wake up the kernel thread
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL void ipr_wake_task(ipr_host_config *ipr_cfg)
+{
+    ENTER;
+
+    wake_up_interruptible(&ipr_cfg->wait_q);
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Build a scatter/gather list and map the buffer
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IBSIS_RC_SUCCESS    - Success
+ *          IPR_RC_FAILED    - Failure
+ *---------------------------------------------------------------------------*/
+static int ipr_build_sglist(ipr_host_config *ipr_cfg,
+                               struct ipr_cmnd* p_sis_cmnd)
+{
+    int i;
+    struct ipr_sglist *p_sglist;
+    struct ipr_sglist *p_tmp_sglist;
+    struct scatterlist *p_tmp_scatterlist;
+    u32 length;
+    dma_addr_t dma_handle;
+
+    p_sglist = p_sis_cmnd->ccb.sglist;
+    length = p_sis_cmnd->ccb.bufflen;
+
+    if (p_sis_cmnd->ccb.scsi_use_sg)
+    {
+        if (p_sis_cmnd->ccb.sc_data_direction == SCSI_DATA_READ)
+            p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+        else if (p_sis_cmnd->ccb.sc_data_direction == SCSI_DATA_WRITE)
+            p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+        else
+            panic(IPR_ERR": use_sg was set on a command, but sc_data_direction was not. cmd 0x%02x"IPR_EOL,
+                  p_sis_cmnd->ccb.cdb[0]);
+
+        p_sis_cmnd->ccb.use_sg = pci_map_sg(ipr_cfg->pdev,
+                                            p_sis_cmnd->ccb.request_buffer,
+                                            p_sis_cmnd->ccb.scsi_use_sg,
+                                            scsi_to_pci_dma_dir(p_sis_cmnd->ccb.sc_data_direction));
+
+        for (i = 0, p_tmp_sglist = p_sglist,
+             p_tmp_scatterlist = p_sis_cmnd->ccb.request_buffer;
+             i < p_sis_cmnd->ccb.use_sg;
+             i++, p_tmp_sglist++, p_tmp_scatterlist++)
+        {
+            p_tmp_sglist->address = sg_dma_address(p_tmp_scatterlist);
+            p_tmp_sglist->length = sg_dma_len(p_tmp_scatterlist);
+        }
+
+        if (p_sis_cmnd->ccb.use_sg)
+            p_sis_cmnd->ccb.flags |= IPR_UNMAP_ON_DONE;
+        else
+            ipr_log_err("pci_map_sg failed!"IPR_EOL);
+    }
+    else
+    {
+        if (length == 0)
+        {
+            /* No data to transfer */
+            p_sis_cmnd->ccb.data_direction = IPR_DATA_NONE;
+            return IPR_RC_SUCCESS;
+        }
+
+        /* Does the buffer need to be mapped? */
+        if ((p_sis_cmnd->ccb.flags & IPR_BUFFER_MAPPED) == 0)
+        {
+            if (p_sis_cmnd->ccb.sc_data_direction == SCSI_DATA_READ)
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+            else if (p_sis_cmnd->ccb.sc_data_direction == SCSI_DATA_WRITE)
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+            else
+            {
+                /* No data to transfer */
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_NONE;
+                return IPR_RC_SUCCESS;
+            }
+
+            dma_handle = pci_map_single(ipr_cfg->pdev, p_sis_cmnd->ccb.buffer,
+                                        length, scsi_to_pci_dma_dir(p_sis_cmnd->ccb.sc_data_direction));
+
+            if (dma_handle != NO_TCE)
+            {
+                p_sis_cmnd->ccb.use_sg = 1;
+                p_sglist->address = dma_handle;
+                p_sglist->length = length;
+                p_sis_cmnd->ccb.buffer_dma = dma_handle;
+                p_sis_cmnd->ccb.flags |= IPR_UNMAP_ON_DONE;
+            }
+            else
+                ipr_log_err("pci_map_single failed!"IPR_EOL);
+        }
+        else
+        {
+            /* The buffer has already been mapped by the caller */
+            p_sis_cmnd->ccb.use_sg = 1;
+            p_sglist->address = p_sis_cmnd->ccb.buffer_dma;
+            p_sglist->length = length;
+        }
+    }
+
+    if (p_sis_cmnd->ccb.use_sg)
+        return IPR_RC_SUCCESS;
+
+    return IPR_RC_FAILED;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Build a DASD/Tape/Optical command
+ * Context: Task or interrupt level 
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to command block
+ *          NULL - Command was not built
+ *---------------------------------------------------------------------------*/
+static IPR_INL struct ipr_cmnd* ipr_build_cmd (ipr_host_config * ipr_cfg, 
+                                                        Scsi_Cmnd *p_scsi_cmd,
+                                                        struct ipr_resource_entry *p_resource)
+{
+    struct ipr_cmnd* p_sis_cmnd;
+    int rc = IPR_RC_SUCCESS;
+    void (*timeout_func) (Scsi_Cmnd *);
+    int timeout;
+
+    p_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+
+    ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+
+    memcpy(p_sis_cmnd->ccb.cdb, p_scsi_cmd->cmnd, p_scsi_cmd->cmd_len);
+    p_sis_cmnd->p_scsi_cmd = p_scsi_cmd;
+    p_sis_cmnd->ccb.buffer = p_scsi_cmd->buffer;
+    p_sis_cmnd->ccb.request_buffer = p_scsi_cmd->request_buffer;
+    p_sis_cmnd->ccb.bufflen = p_scsi_cmd->request_bufflen;
+    p_sis_cmnd->ccb.cmd_len = p_scsi_cmd->cmd_len;
+    p_sis_cmnd->ccb.p_resource = p_resource;
+    p_sis_cmnd->ccb.underflow = p_scsi_cmd->underflow;
+    p_sis_cmnd->ccb.scsi_use_sg = p_scsi_cmd->use_sg;
+    p_sis_cmnd->ccb.sc_data_direction = p_scsi_cmd->sc_data_direction;
+
+    /* Double the timeout value to use as we will use the adapter
+     as the primary timing mechanism */
+    timeout_func = (void (*)(Scsi_Cmnd *))p_scsi_cmd->eh_timeout.function;
+    timeout = p_scsi_cmd->timeout_per_command;
+
+    if (1 == IPR_TIMEOUT_MULTIPLIER)
+        p_sis_cmnd->ccb.timeout = IPR_MAX_SIS_TIMEOUT;
+    else
+        p_sis_cmnd->ccb.timeout = timeout/HZ;
+
+    scsi_add_timer(p_scsi_cmd, timeout * IPR_TIMEOUT_MULTIPLIER,
+                   timeout_func);
+
+    if (!p_resource->is_af)
+        p_sis_cmnd->ccb.flags |= IPR_GPDD_CMD;
+
+    if (p_scsi_cmd->cmnd[0] == INQUIRY)
+    {
+        /* Redefine xfer length so IOA doesn't complain of underlength error */
+        p_sis_cmnd->ccb.bufflen = p_scsi_cmd->cmnd[4];
+    }
+
+    rc = ipr_build_sglist(ipr_cfg, p_sis_cmnd);
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        ipr_remove_sis_cmnd_from_pending(ipr_cfg, p_sis_cmnd);
+        ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+        p_sis_cmnd = NULL;
+    }
+
+    return p_sis_cmnd;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Run through completed queue and push op done functions
+ * Context: Interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_ops_done (ipr_host_config *ipr_cfg)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    Scsi_Cmnd *p_scsi_cmd;
+    u32 cc;
+    struct ipr_hostrcb *p_hostrcb, *p_tmp_hostrcb;
+    u8 *p_sense_buffer;
+    int i;
+    int selection_timeout;
+
+    while ((p_sis_cmnd = ipr_cfg->qCompletedH) != NULL)
+    {
+        ipr_remove_sis_cmnd_from_completed(ipr_cfg, p_sis_cmnd);
+        cc = p_sis_cmnd->ccb.completion;
+        p_scsi_cmd = p_sis_cmnd->p_scsi_cmd;
+        p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+        /* Did this command originate from the mid-layer SCSI code? */
+        if (p_scsi_cmd != NULL)
+        {
+            p_scsi_cmd->resid = p_sis_cmnd->ccb.residual;
+
+            if (cc == IPR_RC_FAILED)
+            {
+                if (ipr_sense_valid(p_sense_buffer[0]) &&
+                    (ipr_sense_key(p_sense_buffer) == HARDWARE_ERROR) &&
+                    (ipr_sense_code(p_sense_buffer) == 0x05) &&
+                    (ipr_sense_qual(p_sense_buffer) == 0x00))
+                {
+                    selection_timeout = 1;
+                }
+                else
+                {
+                    selection_timeout = 0;
+                }
+
+                if ((p_scsi_cmd->cmnd[0] == INQUIRY) &&
+                    ((p_scsi_cmd->cmnd[1] & 0x01) == 0) &&
+                    !selection_timeout)
+                {
+                    /* Do we need to do any ERP? */
+                    /* If we got a synchronization required state, and we are
+                     not aborting this command, enter erp thread */
+                    if (ipr_sense_valid(p_sense_buffer[0]) &&
+                        (ipr_sense_key(p_sense_buffer) == NOT_READY) &&
+                        (ipr_sense_code(p_sense_buffer) == IPR_SYNC_REQUIRED) &&
+                        ((p_sis_cmnd->ccb.flags & IPR_ABORTING) == 0))
+                    {
+                        ipr_put_sis_cmnd_to_error(ipr_cfg, p_sis_cmnd);
+
+                        ipr_wake_task(ipr_cfg);
+                        continue;
+                    }
+
+                    /* Return buffered standard inquiry data */
+                    /* This MUST be done since the mid-layer does not
+                     retry inquiries when polling for devices. */
+                    memcpy(p_scsi_cmd->buffer,
+                                       &p_sis_cmnd->ccb.p_resource->std_inq_data,
+                                       sizeof(p_sis_cmnd->ccb.p_resource->std_inq_data));
+                }
+                else
+                {
+                    /* Is this a GPDD op? */
+                    if (p_sis_cmnd->ccb.flags & IPR_GPDD_CMD)
+                    {
+                        /* Do we have a valid sense buffer? */
+                        if (ipr_sense_valid(p_sense_buffer[0]))
+                        {
+                            if ((ipr_sense_key(p_sense_buffer) != ILLEGAL_REQUEST) ||
+                                (ipr_sense_code(p_sense_buffer) != IPR_INVALID_RESH))
+                            {
+                                /* Copy over sense data */
+                                memcpy(p_scsi_cmd->sense_buffer, p_sense_buffer,
+                                                   IPR_SENSE_BUFFER_COPY_SIZE);
+                            }
+
+                            if (ipr_debug)
+                            {
+                                /* Print out the sense data */
+                                print_sense(IPR_NAME, p_scsi_cmd);
+
+                                /* If this is an illegal request, print out the SCSI command for debug */
+                                if (ipr_sense_key(p_sense_buffer) == ILLEGAL_REQUEST)
+                                    print_Scsi_Cmnd(p_scsi_cmd);
+                            }
+                        }
+
+                        if (!((p_scsi_cmd->cmnd[0] == INQUIRY) &&
+                            ((p_scsi_cmd->cmnd[1] & 0x01) == 0)) &&
+                            selection_timeout)
+                        {
+                            p_scsi_cmd->result = (DID_TIME_OUT << 16);
+                        }
+                        /* Do we need to do any ERP? */
+                        /* If we got a check condition or are in a synchronization
+                         required state, and we are not aborting this command,
+                         enter erp thread */
+                        else if (((status_byte(p_sis_cmnd->ccb.status) == CHECK_CONDITION) ||
+                             (ipr_sense_valid(p_sense_buffer[0]) &&
+                              (ipr_sense_key(p_sense_buffer) == NOT_READY) &&
+                              (ipr_sense_code(p_sense_buffer) == IPR_SYNC_REQUIRED))) &&
+                            ((p_sis_cmnd->ccb.flags & IPR_ABORTING) == 0))
+                        {
+                            ipr_put_sis_cmnd_to_error(ipr_cfg, p_sis_cmnd);
+
+                            ipr_wake_task(ipr_cfg);
+                            continue;
+                        }
+                        else if (p_sis_cmnd->ccb.status &&
+                                 (p_sis_cmnd->ccb.flags & IPR_ABORTING) == 0)
+                        {
+                            p_scsi_cmd->result |= p_sis_cmnd->ccb.status;
+                        }
+                        else if (ipr_sense_valid(p_sense_buffer[0]) &&
+                                 (ipr_sense_key(p_sense_buffer) == ILLEGAL_REQUEST) &&
+                                 (ipr_sense_code(p_sense_buffer) == IPR_INVALID_RESH))
+                        {
+                            p_scsi_cmd->result |= (DID_NO_CONNECT << 16);
+                        }
+                        else
+                        {
+                            p_scsi_cmd->result |= (DID_ERROR << 16);
+                        }
+                    }
+                    else /* Not a GPDD op */
+                    {
+                        /* Do we have a valid sense buffer and is this an illegal request,
+                         a not ready or a medium error sense key? */
+                        if (ipr_sense_valid(p_sense_buffer[0]) &&
+                            ((ipr_sense_key(p_sense_buffer) == ILLEGAL_REQUEST) ||
+                             (ipr_sense_key(p_sense_buffer) == NOT_READY) ||
+                             (ipr_sense_key(p_sense_buffer) == MEDIUM_ERROR)))
+                        {
+                            if ((ipr_sense_key(p_sense_buffer) != ILLEGAL_REQUEST) ||
+                                (ipr_sense_code(p_sense_buffer) != IPR_INVALID_RESH))
+                            {
+                                /* Copy over sense data */
+                                memcpy(p_scsi_cmd->sense_buffer, p_sense_buffer,
+                                                   IPR_SENSE_BUFFER_COPY_SIZE);
+                            }
+
+                            if (ipr_debug)
+                            {
+                                /* Print out the sense data */
+                                print_sense(IPR_NAME, p_scsi_cmd);
+
+                                /* If the sense data is valid and this is an illegal request,
+                                 print out the SCSI command for debug */
+                                if (ipr_sense_key(p_sense_buffer) == ILLEGAL_REQUEST)
+                                    print_Scsi_Cmnd(p_scsi_cmd);
+                            }
+                        }
+
+                        if (ipr_sense_valid(p_sense_buffer[0]) &&
+                            ((ipr_sense_key(p_sense_buffer) == MEDIUM_ERROR) ||
+                             (ipr_sense_code(p_sense_buffer) == 0x11) ||
+                             (ipr_sense_qual(p_sense_buffer) == 0x0C)))
+                        {
+                            /* Prevent the midlayer from issuing retries */
+                            p_scsi_cmd->result |= (DID_PASSTHROUGH << 16);
+                        }
+                        else if (ipr_sense_valid(p_sense_buffer[0]) &&
+                                 (ipr_sense_key(p_sense_buffer) == ILLEGAL_REQUEST) &&
+                                 (ipr_sense_code(p_sense_buffer) == IPR_INVALID_RESH))
+                        {
+                            p_scsi_cmd->result |= (DID_NO_CONNECT << 16);
+                        }
+                        else
+                        {
+                            /* Set DID_ERROR to force the mid-layer to do a retry */
+                            p_scsi_cmd->result |= (DID_ERROR << 16);
+                        }
+                    }
+                }
+            }
+
+            /* Are we currently trying to abort this command? */
+            if (p_sis_cmnd->ccb.flags & IPR_ABORTING)
+            {
+                /* Is there another request tied to this op? */
+                if (p_sis_cmnd->p_cancel_op)
+                {
+                    /* Has the cancel request completed? */
+                    if (p_sis_cmnd->p_cancel_op->ccb.flags & IPR_FINISHED)
+                    {
+                        /* Wake the thread sleeping on the cancel */
+                        wake_up(&p_sis_cmnd->p_cancel_op->wait_q);
+                    }
+                    else /* Need to wait for the cancel request to complete */
+                    {
+                        /* NULL out the Cancel request's pointer to us */
+                        p_sis_cmnd->p_cancel_op->p_cancel_op = NULL;
+                    }
+                }
+            }
+
+            ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+            /* If we are failing this op back due to a host reset, we can't push the scsi_done
+             function yet. The caller will queue up the scsi_cmd structures and send them
+             back to the host once we are able to accept new commands */
+            if (cc != IPR_RC_DID_RESET)
+                p_scsi_cmd->scsi_done (p_scsi_cmd);
+        }
+        /* This is a 'blocking command', could be a cancel request */
+        else if (p_sis_cmnd->ccb.flags & IPR_BLOCKING_COMMAND)
+        {
+            /* We don't want to touch the command if it timed out */
+            if ((p_sis_cmnd->ccb.flags & IPR_TIMED_OUT) == 0)
+            {
+                /* Mark the command as finished */
+                p_sis_cmnd->ccb.flags |= IPR_FINISHED;
+
+                /* If this is a cancel request, the p_cancel_op pointer would
+                 have been setup to point to the op being cancelled, otherwise
+                 it would be NULL. If that op had completed, it would have
+                 NULLed out this pointer. In either case, if the pointer is NULL
+                 we don't need to wait for anything and can wake the task
+                 sleeping on our completion */
+                if (p_sis_cmnd->p_cancel_op == NULL)
+                    wake_up(&p_sis_cmnd->wait_q);
+            }
+            else
+            {
+                /* command timed out, free command block resource */
+                ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+            }
+        }
+        /* This is an 'ERP' command for a GPDD device */
+        else if (p_sis_cmnd->ccb.flags & IPR_ERP_CMD)
+        {
+            /* Not aborting this command. Put it back on the error queue
+             and wake up our kernel thread to continue processing it */
+            ipr_put_sis_cmnd_to_error(ipr_cfg, p_sis_cmnd);
+            ipr_wake_task(ipr_cfg);
+        }
+        else if (p_sis_cmnd->ccb.flags & IPR_INTERNAL_REQ)
+        {
+            /* It is the caller's responsibility to free this command block */
+            del_timer(&p_sis_cmnd->timer);
+            p_sis_cmnd->done(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+        }
+        else 
+        {/* HCAM */
+
+            p_hostrcb = p_sis_cmnd->ccb.buffer;
+
+            ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+            if ((cc == IPR_RC_DID_RESET) || ipr_cfg->shared.nr_ioa_microcode)
+            {
+                /* The HCAM failed due to the IOA being braindead, or we are currently
+                 failing back all host ops prior to a reset. In either case we just want
+                 to stop sending HCAMs */
+            }
+            else if (cc != IPR_RC_SUCCESS)
+            {
+                /* The HCAM failed for some other reason, just log an error and resend
+                 the HCAM */
+
+                ipr_log_err("Host RCB failed with SK: 0x%X ASC: 0x%X ASCQ: 0x%X"IPR_EOL,
+                               p_sense_buffer[2] & 0xf, p_sense_buffer[12],
+                               p_sense_buffer[13]);
+
+                if (p_hostrcb->op_code == IPR_HOST_RCB_OP_CODE_CONFIG_CHANGE)
+                {
+                    /* Ship it back to the IOA to be re-used */
+                    ipr_send_hcam(&ipr_cfg->shared,
+                                     IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE, p_hostrcb);
+                }
+                else
+                {
+                    /* Ship it back to the IOA to be re-used */
+                    ipr_send_hcam(&ipr_cfg->shared,
+                                     IPR_HCAM_CDB_OP_CODE_LOG_DATA, p_hostrcb);
+                }
+            }
+            else
+            {
+                /* Put the hostrcb at the end of the done list */
+                for (i = 0, p_tmp_hostrcb = ipr_cfg->done_hostrcb[0];
+                     (p_tmp_hostrcb != NULL) && (i < IPR_NUM_HCAMS);
+                     p_tmp_hostrcb = ipr_cfg->done_hostrcb[++i])
+                {
+                }
+
+                ipr_cfg->done_hostrcb[i] = p_hostrcb;
+
+                /* Process the HCAM and ship it back to the IOA to be re-used */
+                ipr_wake_task(ipr_cfg);
+            }
+        }
+    }
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get information about the card/driver
+ * Context: Task level
+ * Lock State: No lock held upon entry
+ * Returns: pointer to data buffer
+ *---------------------------------------------------------------------------*/
+const char *ipr_info(struct Scsi_Host *p_scsi_host)
+{
+    static char buffer[512];
+    ipr_host_config *ipr_cfg;
+    unsigned long io_flags = 0;
+
+    spin_lock_irqsave(&io_request_lock, io_flags);
+
+    ipr_cfg = (ipr_host_config *) p_scsi_host->hostdata;
+
+    sprintf (buffer, "IBM %X Storage Adapter: %s",
+             ipr_cfg->shared.ccin, ipr_cfg->shared.ioa_host_str);
+
+    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+    return buffer;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Detects all SIS IOAs on this system
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Number of IOAs found
+ *---------------------------------------------------------------------------*/
+int ipr_detect(Scsi_Host_Template *p_host_tmpl)
+{
+    int count = 0;
+    int i;
+
+    p_host_tmpl->proc_name = IPR_NAME;
+
+    ipr_log_info("Driver Version: "IPR_FULL_VERSION ""IPR_EOL);
+
+    init_waitqueue_head(&ipr_sdt_wait_q);
+
+    for (i = 0; i < (sizeof(ipr_ioa_cfg)/sizeof(struct ipr_ioa_cfg_t)); i++)
+    {
+        ipr_find_ioa(p_host_tmpl, ipr_ioa_cfg[i].vendor_id,
+                        ipr_ioa_cfg[i].device_id);
+    }
+
+    count = ipr_find_ioa_part2();
+
+    if (ipr_cfg_head)
+        ipr_log_info(IPR_NAME"_cfg_head: 0x%p"IPR_EOL, ipr_cfg_head);
+
+    ipr_init_finished = 1;
+
+    return count;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Walks the PCI bus looking for a matching IOA
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_find_ioa (Scsi_Host_Template * p_host_tmpl,
+                             u16 pci_vendor, u16 pci_dev)
+{
+    ipr_host_config *ipr_cfg;
+    struct Scsi_Host *host = NULL;
+    unsigned int sis_irq;
+    unsigned long sis_regs, sis_regs_pci;
+    u32 bar0, rc = PCIBIOS_SUCCESSFUL;
+    u16 subsystem_id;
+    int i, j, pcix_command_reg;
+    DECLARE_COMPLETION(completion);
+    struct ipr_location_data *p_location_data = NULL;
+    u8 *p_sense_buffer;
+    ipr_dma_addr dma_addr;
+    struct ipr_hostrcb *p_hostrcb;
+    struct ipr_element_desc_page *p_ses_desc_page;
+    struct pci_dev *pdev = NULL;
+    char ioa_host_str[IPR_MAX_LOCATION_LEN];
+
+    while ((pdev = pci_find_device(pci_vendor, pci_dev, pdev)))
+    {
+        p_location_data = ipr_get_ioa_location_data(pdev);
+
+        /* Lets release the spinlock since we could go to sleep */
+        spin_unlock_irq(&io_request_lock);
+
+        if (p_location_data == NULL)
+        {
+            /* Grab the spinlock again */
+            spin_lock_irq(&io_request_lock);
+
+            ipr_log_err("Call to ipr_get_ioa_location_data failed"IPR_EOL);
+            continue;
+        }
+
+        if (pci_enable_device(pdev))
+        {
+            /* Grab the spinlock again */
+            spin_lock_irq(&io_request_lock);
+
+            ipr_beg_err(KERN_ERR);
+            ipr_log_err("Cannot enable ipr device"IPR_EOL);
+            ipr_log_ioa_physical_location(p_location_data, KERN_ERR);
+            ipr_end_err(KERN_ERR);
+            ipr_kfree(p_location_data, sizeof(struct ipr_location_data));
+            continue;
+        }
+
+        /* Get physical location string */
+        ipr_ioa_loc_str(p_location_data, ioa_host_str);
+
+        /* Get the IRQ */
+        sis_irq  = pdev->irq;
+
+        ipr_log_info("IOA found at %s, IRQ: %d"IPR_EOL,
+                        ioa_host_str, sis_irq);
+
+        /* Initialize SCSI Host structure */
+        host = scsi_register(p_host_tmpl, sizeof (ipr_host_config));
+
+        if (host == NULL)
+        {
+            spin_lock_irq(&io_request_lock);
+            ipr_log_err("call to scsi_register failed! "IPR_EOL);
+            ipr_kfree(p_location_data, sizeof(struct ipr_location_data));
+            continue;
+        }
+
+        /* xx - This is only a temporary hack until the 2.5 work is done */
+        scsi_assign_lock(host, &io_request_lock);
+
+        ipr_cfg = (ipr_host_config *) host->hostdata;
+
+        memset(ipr_cfg, 0, sizeof (ipr_host_config));
+
+        /* Copy resource info into structure */
+        ipr_cfg->p_next = NULL;
+        ipr_cfg->shared.vendor_id = pci_vendor;
+        ipr_cfg->shared.device_id = pci_dev;
+        ipr_cfg->host = host;
+        ipr_cfg->pdev = pdev;
+        ipr_cfg->shared.hdw_bar_addr_pci[0] = pci_resource_start (pdev, 0);
+        ipr_cfg->shared.hdw_bar_addr_pci[1] = pci_resource_start (pdev, 1);
+        ipr_cfg->shared.hdw_bar_addr_pci[2] = pci_resource_start (pdev, 2);
+        ipr_cfg->shared.hdw_bar_addr_pci[3] = pci_resource_start (pdev, 3);
+        ipr_cfg->shared.p_location = p_location_data;
+        ipr_cfg->shared.debug_level = verbose;
+        ipr_cfg->shared.trace = trace;
+        ipr_cfg->shared.host_no = host->host_no;
+        sprintf(ipr_cfg->shared.eye_catcher, IPR_SHARED_LABEL);
+        sprintf(ipr_cfg->shared.resource_table_label, IPR_RES_TABLE_LABEL);
+        sprintf(ipr_cfg->shared.ses_table_start, IPR_DATA_SES_DATA_START);
+        strcpy(ipr_cfg->shared.ioa_host_str, ioa_host_str);
+        sprintf(ipr_cfg->shared.end_eye_catcher, IPR_END_SHARED_LABEL);
+        sprintf(ipr_cfg->ipr_free_label, IPR_FREEQ_LABEL);
+        sprintf(ipr_cfg->ipr_pending_label, IPR_PENDQ_LABEL);
+        sprintf(ipr_cfg->ipr_comp_label, IPR_COMPQ_LABEL);
+        sprintf(ipr_cfg->ipr_err_label, IPR_ERRQ_LABEL);
+        sprintf(ipr_cfg->ipr_hcam_label, IPR_HCAM_LABEL);
+        sprintf(ipr_cfg->ipr_sis_cmd_label, IPR_SIS_CMD_LABEL);
+        ipr_cfg->shared.p_end = ipr_cfg->shared.end_eye_catcher;
+
+        ipr_cfg->host->irq = sis_irq;
+        ipr_cfg->host->io_port = 0;
+        ipr_cfg->host->n_io_port = 0;
+        ipr_cfg->host->max_id = IPR_MAX_NUM_TARGETS_PER_BUS;
+        ipr_cfg->host->max_lun = IPR_MAX_NUM_LUNS_PER_TARGET;
+        ipr_cfg->host->max_channel = IPR_MAX_BUS_TO_SCAN;
+
+        /* Initialize our semaphore for IOCTLs */
+        sema_init(&ipr_cfg->ioctl_semaphore, IPR_NUM_IOCTL_CMD_BLKS);
+
+        /* Verify we should be talking to the adapter - we could have been loaded as a module,
+         unloaded, and on the unload the restore of our PCI config registers failed, in which case
+         we cannot talk to this adapter again */
+        if (pci_read_config_dword(pdev, PCI_BASE_ADDRESS_0, &bar0) != PCIBIOS_SUCCESSFUL)
+        {
+            ipr_ipl_err(ipr_cfg, "Read of config space failed."IPR_EOL);
+            goto cleanup_bar0;
+        }
+
+        if ((bar0 & IPR_BAR0_ADDRESS_BITS) == 0)
+        {
+            ipr_ipl_err(ipr_cfg, "Base address registers lost."IPR_EOL);
+            goto cleanup_bar0;
+        }
+
+        if (pci_read_config_word(pdev, PCI_SUBSYSTEM_ID, &subsystem_id) != PCIBIOS_SUCCESSFUL)
+        {
+            ipr_ipl_err(ipr_cfg, "Read of config space failed."IPR_EOL);
+            goto cleanup_bar0;
+        }
+
+        ipr_cfg->shared.subsystem_id = subsystem_id;
+
+        /* Fill in a 'temporary ccin'. This will be used if the IOA unit checks
+         before we get its inquiry data */
+        for (i = 0; i < (sizeof(ipr_pci_dev_table)/sizeof(struct ipr_pci_dev_table_t)); i++)
+        {
+            if ((ipr_pci_dev_table[i].vendor_id == pci_vendor) &&
+                (ipr_pci_dev_table[i].device_id == pci_dev) &&
+                (ipr_pci_dev_table[i].subsystem_id == subsystem_id))
+            {
+                ipr_cfg->shared.ccin = ipr_pci_dev_table[i].ccin;
+                strcpy(ipr_cfg->shared.ccin_str, ipr_pci_dev_table[i].ccin_str);
+                ipr_cfg->shared.num_physical_buses = ipr_pci_dev_table[i].num_physical_buses;
+                ipr_cfg->host->max_cmd_len = ipr_pci_dev_table[i].max_cmd_len;
+                ipr_cfg->shared.use_immed_format = ipr_pci_dev_table[i].format_immed;
+                break;
+            }
+        }
+
+        if (ipr_cfg->shared.ccin == 0)
+            goto cleanup_bar0;
+
+        ipr_cfg->p_ioa_cfg = NULL;
+
+        for (i = 0; i < (sizeof(ipr_ioa_cfg)/sizeof(struct ipr_ioa_cfg_t)); i++)
+        {
+            if ((ipr_ioa_cfg[i].vendor_id == pci_vendor) &&
+                (ipr_ioa_cfg[i].device_id == pci_dev))
+            {
+                ipr_cfg->p_ioa_cfg = &ipr_ioa_cfg[i];
+                ipr_cfg->shared.set_mode_page_20 = ipr_ioa_cfg[i].set_mode_page_20;
+            }
+        }
+
+        if (ipr_cfg->p_ioa_cfg == NULL)
+        {
+            ipr_ipl_err(ipr_cfg, "Cannot determine IOA config: 0x%04X 0x%04X"IPR_EOL,
+                           pci_vendor, pci_dev);
+            goto cleanup_bar0;
+        }
+
+        /* Save away the start of our hardware regs now that we know where they are */
+        sis_regs_pci = pci_resource_start (pdev, ipr_cfg->p_ioa_cfg->bar_index);
+
+        /* Request and map PCI memory ranges */
+        if (!request_mem_region(sis_regs_pci,
+                                pci_resource_len(pdev, ipr_cfg->p_ioa_cfg->bar_index),
+                                "ipr"))
+        {
+            ipr_ipl_err(ipr_cfg, "Couldn't register memory range of registers!"IPR_EOL);
+            goto cleanup_bar0;
+        }
+
+        sis_regs = (unsigned long)ioremap(sis_regs_pci,
+                                          pci_resource_len(pdev, ipr_cfg->p_ioa_cfg->bar_index));
+
+        ipr_cfg->shared.hdw_dma_regs = sis_regs;
+        ipr_cfg->shared.hdw_dma_regs_pci = sis_regs_pci;
+        ipr_cfg->shared.hdw_bar_addr[ipr_cfg->p_ioa_cfg->bar_index] = sis_regs;
+
+        ipr_cfg->host->unique_id = ipr_get_unique_id(p_location_data);
+
+        ipr_cfg->shared.ioa_mailbox = ipr_cfg->p_ioa_cfg->mailbox + sis_regs;
+
+        if (ipr_cfg->p_ioa_cfg->sdt_reg_sel_size == IPR_SDT_REG_SEL_SIZE_1BYTE)
+        {
+            if (!request_mem_region(ipr_cfg->shared.hdw_bar_addr_pci[2],
+                                    pci_resource_len(pdev, 2), "ipr"))
+            {
+                ipr_ipl_err(ipr_cfg, "Couldn't register BAR2 memory range!"IPR_EOL);
+                goto cleanup_bar2;
+            }
+
+            ipr_cfg->shared.hdw_bar_addr[2] =
+                (unsigned long)ioremap(ipr_cfg->shared.hdw_bar_addr_pci[2],
+                                       pci_resource_len(pdev, 2));
+
+            if (!request_mem_region(ipr_cfg->shared.hdw_bar_addr_pci[3],
+                                    pci_resource_len(pdev, 3), "ipr"))
+            {
+                ipr_ipl_err(ipr_cfg, "Couldn't register BAR3 memory range!"IPR_EOL);
+                goto cleanup_bar3;
+            }
+
+            ipr_cfg->shared.hdw_bar_addr[3] =
+                (unsigned long)ioremap(ipr_cfg->shared.hdw_bar_addr_pci[3],
+                                       pci_resource_len(pdev, 3));
+        }
+
+        /* Set PCI master mode */
+        pci_set_master (pdev);
+
+        /* Save away PCI config space for use following IOA reset */
+        for (i = 0; (i < IPR_CONFIG_SAVE_WORDS) && (rc == PCIBIOS_SUCCESSFUL); i++)
+            rc = pci_read_config_dword(ipr_cfg->pdev, i*4, &ipr_cfg->pci_cfg_buf[i]);
+
+        if (rc != PCIBIOS_SUCCESSFUL)
+        {
+            ipr_ipl_err(ipr_cfg, "Read of config space failed."IPR_EOL);
+            goto cleanup_nolog;
+        }
+
+
+        if (pci_read_config_byte(ipr_cfg->pdev,
+                                 PCI_REVISION_ID,
+                                 &ipr_cfg->shared.chip_rev_id) != PCIBIOS_SUCCESSFUL)
+        {
+            ipr_ipl_err(ipr_cfg, "Read of config space failed."IPR_EOL);
+            goto cleanup_nolog;
+        }
+
+        /* See if we can find the PCI-X command register */
+        pcix_command_reg = pci_find_capability(ipr_cfg->pdev, IPR_PCIX_COMMAND_REG_ID);
+
+        if (pcix_command_reg)
+        {
+            /* Need to save the PCI-X Command register. */
+            if (pci_read_config_word(ipr_cfg->pdev, pcix_command_reg,
+                                     &ipr_cfg->saved_pcix_command_reg) != PCIBIOS_SUCCESSFUL)
+            {
+                ipr_ipl_err(ipr_cfg, "Read of config space failed."IPR_EOL);
+                goto cleanup_nolog;
+            }
+
+            /* Data parity error recovery */
+            ipr_cfg->saved_pcix_command_reg |= IPR_PCIX_CMD_DATA_PARITY_RECOVER;
+
+            /* Enable relaxed ordering */
+            ipr_cfg->saved_pcix_command_reg |= IPR_PCIX_CMD_RELAXED_ORDERING;
+        }
+
+        /* Allocate resource table */
+        ipr_cfg->shared.resource_entry_list = ipr_kcalloc(sizeof(struct ipr_resource_dll) *
+                                                                IPR_MAX_PHYSICAL_DEVS,
+                                                                IPR_ALLOC_CAN_SLEEP);
+
+        if (ipr_cfg->shared.resource_entry_list == NULL)
+        {
+            ipr_trace;
+            goto cleanup;
+        }
+
+        ipr_cfg->shared.p_vpd_cbs = ipr_dma_calloc(&ipr_cfg->shared,
+                                                         sizeof(struct ipr_vpd_cbs),
+                                                         &ipr_cfg->shared.ioa_vpd_dma,
+                                                         IPR_ALLOC_CAN_SLEEP);
+
+        if (ipr_cfg->shared.p_vpd_cbs == NULL)
+        {
+            ipr_trace;
+            goto cleanup;
+        }
+
+        ipr_cfg->shared.p_ioa_vpd = &ipr_cfg->shared.p_vpd_cbs->ioa_vpd;
+        ipr_cfg->shared.p_cfc_vpd = &ipr_cfg->shared.p_vpd_cbs->cfc_vpd;
+        ipr_cfg->shared.p_ucode_vpd = &ipr_cfg->shared.p_vpd_cbs->page3_data;
+        ipr_cfg->shared.p_page0_vpd = &ipr_cfg->shared.p_vpd_cbs->page0_data;
+        ipr_cfg->shared.p_dram_vpd = &ipr_cfg->shared.p_vpd_cbs->dram_vpd;
+
+        ipr_cfg->shared.cfc_vpd_dma = ipr_cfg->shared.ioa_vpd_dma +
+            sizeof(struct ipr_ioa_vpd);
+        ipr_cfg->shared.ucode_vpd_dma = ipr_cfg->shared.cfc_vpd_dma +
+            sizeof(struct ipr_cfc_vpd);
+        ipr_cfg->shared.page0_vpd_dma = ipr_cfg->shared.ucode_vpd_dma +
+            sizeof(struct ipr_inquiry_page3);
+        ipr_cfg->shared.dram_vpd_dma = ipr_cfg->shared.page0_vpd_dma +
+            sizeof(struct ipr_inquiry_page0);
+
+        /* Allocate mode page 28 reserve */
+        ipr_cfg->shared.p_page_28 = ipr_kcalloc(sizeof(struct ipr_page_28_data),
+                                                      IPR_ALLOC_CAN_SLEEP);
+
+        if (ipr_cfg->shared.p_page_28 == NULL)
+        {
+            ipr_trace;
+            goto cleanup;
+        }
+
+        /* Allocate command blocks */
+        for (i = 0; i < IPR_NUM_CMD_BLKS; i++)
+        {
+            ipr_cfg->sis_cmnd_list[i] = ipr_kcalloc(sizeof(struct ipr_cmnd),
+                                                          IPR_ALLOC_CAN_SLEEP);
+            if (ipr_cfg->sis_cmnd_list[i] == NULL)
+            {
+                ipr_trace;
+                goto cleanup;
+            }
+        }
+
+        /* Allocate auto-sense buffers */
+        p_sense_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                           IPR_SENSE_BUFFERSIZE * IPR_NUM_CMD_BLKS,
+                                           &dma_addr, IPR_ALLOC_CAN_SLEEP);
+
+        if (p_sense_buffer == NULL)
+        {
+            ipr_trace;
+            goto cleanup;
+        }
+
+        /* Put the command blocks on the free list */
+        for (i = 0;
+             i < IPR_NUM_CMD_BLKS;
+             i++, dma_addr += IPR_SENSE_BUFFERSIZE, p_sense_buffer += IPR_SENSE_BUFFERSIZE)
+        {
+            ipr_cfg->sis_cmnd_list[i]->ccb.sense_buffer = p_sense_buffer;
+            ipr_cfg->sis_cmnd_list[i]->ccb.sense_buffer_dma = dma_addr;
+            ipr_cfg->sis_cmnd_list[i]->p_scsi_cmd = NULL;
+            ipr_cfg->sis_cmnd_list[i]->ccb.flags = 0;
+            ipr_put_sis_cmnd_to_free(ipr_cfg, ipr_cfg->sis_cmnd_list[i]);
+        }
+
+        /* Allocate our HCAMs */
+        p_hostrcb = ipr_dma_calloc(&ipr_cfg->shared,
+                                      sizeof(struct ipr_hostrcb) * IPR_NUM_HCAMS,
+                                      &dma_addr, IPR_ALLOC_CAN_SLEEP);
+
+        if (p_hostrcb == NULL)
+        {
+            ipr_trace;
+            goto cleanup;
+        }
+
+        for (i = 0;
+             i < IPR_NUM_HCAMS;
+             i++, p_hostrcb++, dma_addr += sizeof(struct ipr_hostrcb))
+        {
+            ipr_cfg->hostrcb[i] = p_hostrcb;
+            ipr_cfg->hostrcb_dma[i] = dma_addr;
+        }
+
+        /* Allocate DMA buffers for SES data */
+        p_ses_desc_page = ipr_dma_calloc(&ipr_cfg->shared,
+                                            sizeof(struct ipr_element_desc_page) *
+                                            IPR_MAX_NUM_BUSES,
+                                            &dma_addr, IPR_ALLOC_CAN_SLEEP);
+
+        if (p_ses_desc_page == NULL)
+        {
+            ipr_trace;
+            goto cleanup;
+        }
+
+        for (i = 0;
+             i < IPR_MAX_NUM_BUSES;
+             i++, p_ses_desc_page++, dma_addr += sizeof(struct ipr_element_desc_page))
+        {
+            ipr_cfg->shared.p_ses_data[i] = p_ses_desc_page;
+            ipr_cfg->shared.ses_data_dma[i] = dma_addr;
+        }
+
+        /* Start a task level ERP thread for ourselves */
+        ipr_cfg->completion = &completion;
+
+        ipr_cfg->task_pid = kernel_thread(ipr_task_thread, ipr_cfg, 0);
+
+        if (ipr_cfg->task_pid < 0)
+        {
+            ipr_log_err("Failed to spawn kernel thread."IPR_EOL);
+            goto cleanup_nolog;
+        }
+
+        /* Wait for the thread to initialize itself */
+        wait_for_completion(&completion);
+
+        ipr_cfg->completion = NULL;
+
+        /* Tell the binary to allocate its memory */
+        rc = ipr_alloc_mem(&ipr_cfg->shared);
+
+        /* Get the spinlock since the functions below expect us to have it */
+        spin_lock_irq(&io_request_lock);
+
+        if (rc)
+        {
+            ipr_kill_kernel_thread(ipr_cfg);
+            spin_unlock_irq(&io_request_lock);
+            if (rc == IPR_RC_NOMEM)
+                goto cleanup;
+            else
+                goto cleanup_nolog;
+        }
+
+        /* Issue a reset to the adapter to make sure it is in a useable state */
+        rc = ipr_ioa_reset(ipr_cfg, IPR_IRQ_DISABLED);
+
+        if (rc)
+        {
+            ipr_ipl_err(ipr_cfg, "Reset of IOA failed."IPR_EOL);
+            ipr_kill_kernel_thread(ipr_cfg);
+            ipr_free_mem(&ipr_cfg->shared);
+            spin_unlock_irq(&io_request_lock);
+            goto cleanup_nolog;
+        }
+
+        /* Request our IRQ */
+        spin_unlock_irq(&io_request_lock);
+        rc = request_irq (sis_irq, ipr_isr, SA_SHIRQ,"ipr", ipr_cfg);
+        spin_lock_irq(&io_request_lock);
+
+        if (rc)
+        {
+            ipr_ipl_err(ipr_cfg, "Couldn't register IRQ %d! rc=%d"IPR_EOL, sis_irq, rc);
+            ipr_kill_kernel_thread(ipr_cfg);
+            ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+            ipr_free_mem(&ipr_cfg->shared);
+            spin_unlock_irq(&io_request_lock);
+            goto cleanup_nolog;
+        }
+
+        /* Fill in default IOA resource entry */
+        ipr_cfg->shared.ioa_resource.is_ioa_resource = 1;
+        ipr_cfg->shared.ioa_resource.nr_ioa_microcode = 1;
+        ipr_cfg->shared.ioa_resource.resource_address.bus = IPR_IOA_RES_ADDR_BUS;
+        ipr_cfg->shared.ioa_resource.resource_address.target = IPR_IOA_RES_ADDR_TARGET;
+        ipr_cfg->shared.ioa_resource.resource_address.lun = IPR_IOA_RES_ADDR_LUN;
+        memset(&ipr_cfg->shared.ioa_resource.std_inq_data.vpids,
+                          ' ', sizeof(ipr_cfg->shared.ioa_resource.std_inq_data.vpids));
+        memcpy(ipr_cfg->shared.ioa_resource.std_inq_data.vpids.vendor_id,
+                           "IBM", 3);
+        snprintf(ipr_cfg->shared.ioa_resource.std_inq_data.vpids.product_id,
+                 8, "%X-%03d", ipr_cfg->shared.ccin, IPR_IOA_DEFAULT_MODEL);
+        
+        ipr_cfg->shared.ioa_resource.type = ipr_cfg->shared.ccin;
+        ipr_cfg->shared.ioa_resource.model = IPR_IOA_DEFAULT_MODEL;
+        ipr_cfg->shared.ioa_resource.host_no = ipr_cfg->shared.host_no;
+        strcpy(ipr_cfg->shared.ioa_resource.serial_num, "00000000");
+        ipr_update_location_data(&ipr_cfg->shared,
+                                    &ipr_cfg->shared.ioa_resource);
+
+        rc = ipr_init_ioa_part1(ipr_cfg);
+
+        if (rc)
+        {
+            /* This is essentially dead code since ipr_init_ioa_part1 can only
+             return success today */
+            ipr_trace;
+            ipr_kill_kernel_thread(ipr_cfg);
+            ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+            ipr_free_all_resources(ipr_cfg, 0, 0);
+            continue;
+        }
+
+        /* Add this controller to the linked list of controllers */
+        ipr_add_ioa_to_tail(ipr_cfg);
+
+        continue;
+
+    cleanup:
+        ipr_log_err("Couldn't allocate enough memory for device driver! "IPR_EOL);
+    cleanup_nolog:
+        ipr_kfree(ipr_cfg->shared.resource_entry_list,
+                     sizeof(struct ipr_resource_dll) * IPR_MAX_PHYSICAL_DEVS);
+
+        ipr_dma_free(&ipr_cfg->shared,
+                        sizeof(struct ipr_element_desc_page) * IPR_MAX_NUM_BUSES,
+                        ipr_cfg->shared.p_ses_data[0], ipr_cfg->shared.ses_data_dma[0]);
+
+        ipr_dma_free(&ipr_cfg->shared, sizeof(struct ipr_vpd_cbs),
+                        ipr_cfg->shared.p_vpd_cbs,
+                        ipr_cfg->shared.ioa_vpd_dma);
+
+        ipr_kfree(ipr_cfg->shared.p_page_28,
+                     sizeof(struct ipr_page_28_data));
+
+        if (ipr_cfg->sis_cmnd_list[0] != NULL)
+        {
+            ipr_dma_free(&ipr_cfg->shared,
+                            IPR_SENSE_BUFFERSIZE * IPR_NUM_CMD_BLKS,
+                            ipr_cfg->sis_cmnd_list[0]->ccb.sense_buffer,
+                            ipr_cfg->sis_cmnd_list[0]->ccb.sense_buffer_dma);
+        }
+
+        for (j=0; j < IPR_NUM_CMD_BLKS; j++)
+            ipr_kfree(ipr_cfg->sis_cmnd_list[j], sizeof(struct ipr_cmnd));
+
+        ipr_dma_free(&ipr_cfg->shared,
+                        sizeof(struct ipr_hostrcb) * IPR_NUM_HCAMS,
+                        ipr_cfg->hostrcb[0], ipr_cfg->hostrcb_dma[0]);
+
+        if (ipr_cfg->p_ioa_cfg->sdt_reg_sel_size == IPR_SDT_REG_SEL_SIZE_1BYTE)
+        {
+            iounmap((void *)ipr_cfg->shared.hdw_bar_addr[3]);
+            release_mem_region(ipr_cfg->shared.hdw_bar_addr_pci[3],
+                               pci_resource_len(pdev, 3));
+        }
+    cleanup_bar3:
+        if (ipr_cfg->p_ioa_cfg->sdt_reg_sel_size == IPR_SDT_REG_SEL_SIZE_1BYTE)
+        {
+            iounmap((void *)ipr_cfg->shared.hdw_bar_addr[2]);
+            release_mem_region(ipr_cfg->shared.hdw_bar_addr_pci[2],
+                               pci_resource_len(pdev, 2));
+        }
+    cleanup_bar2:
+        iounmap((void *)sis_regs);
+        release_mem_region(sis_regs_pci, pci_resource_len(pdev, ipr_cfg->p_ioa_cfg->bar_index));
+    cleanup_bar0:
+        /* Grab the spinlock again */
+        spin_lock_irq(&io_request_lock);
+        ipr_kfree(ipr_cfg->shared.p_location, sizeof(struct ipr_location_data));
+        scsi_unregister(host);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Take the given adapter offline
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_take_ioa_offline(ipr_host_config *ipr_cfg)
+{
+    /* Reset the adapter */
+    ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+
+    ipr_beg_err(KERN_ERR);
+    ipr_log_err("IOA taken offline - error recovery failed."IPR_EOL);
+    ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_ERR);
+    ipr_end_err(KERN_ERR);
+    ipr_cfg->shared.ioa_is_dead = 1;
+    ipr_cfg->shared.ioa_resource.ioa_dead = 1;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Initializes IOAs found in ipr_find_ioa(..)
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Number IOAs of given type found
+ *---------------------------------------------------------------------------*/
+static int ipr_find_ioa_part2 (void)
+{
+    ipr_host_config *ipr_cfg, *temp_ipr_cfg;
+    struct Scsi_Host *host = NULL;
+    int rc = PCIBIOS_SUCCESSFUL;
+    int major_num = 0;
+    int minor_num = 0;
+    u16 num_found = 0;
+
+    ipr_cfg = ipr_cfg_head;
+
+    while(ipr_cfg)
+    {
+        host = ipr_cfg->host;
+
+        ipr_dbg_err("ipr_cfg adx: 0x%p\n", ipr_cfg);
+
+        rc = ipr_init_ioa_part2(ipr_cfg);
+
+        if (rc && (rc != IPR_RC_TIMEOUT))
+        {
+            if (ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NONE) != SUCCESS)
+                rc = IPR_RC_FAILED;
+            else
+                rc = IPR_RC_SUCCESS;
+        }
+        else if (rc == IPR_RC_TIMEOUT)
+            ipr_take_ioa_offline(ipr_cfg);
+
+        if (ipr_invalid_adapter(ipr_cfg))
+        {
+            if (!testmode)
+            {
+                /* Reset the adapter */
+                ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+                ipr_cfg->shared.ioa_is_dead = 1;
+                ipr_cfg->shared.ioa_resource.ioa_dead = 1;
+            }
+
+            ipr_beg_err(KERN_ERR);
+            ipr_log_err("Adapter not supported in this hardware configuration."IPR_EOL);
+            ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_ERR);
+            ipr_end_err(KERN_ERR);
+        }
+
+        /* We only need 1 reboot notifier to shutdown all IOAs */
+        if (num_found == 0)
+        {
+            register_reboot_notifier (&ipr_notifier);
+
+            rc = register_ioctl32_conversion(IPR_IOCTL_SEND_COMMAND, NULL);
+
+            if (rc)
+            {
+                ipr_log_err("Couldn't register ioctl32 conversion! rc=%d"IPR_EOL, rc);
+
+                /* Lets clean ourselves up for this adapter and try the next one. */
+                ipr_kill_kernel_thread(ipr_cfg);
+                temp_ipr_cfg = ipr_cfg;
+                ipr_cfg = ipr_cfg->p_next;
+                ipr_remove_ioa_from_list(temp_ipr_cfg);
+                ipr_free_all_resources(temp_ipr_cfg, 1, 0);
+                continue;
+            }
+        }
+
+        /* Register our controller. Use a dynamic major number */
+        rc = devfs_register_chrdev (major_num, IPR_NAME, &ipr_fops);
+
+        if (rc < 0)
+        {
+            ipr_log_err("Couldn't register "IPR_NAME" char device! rc=%d"IPR_EOL, rc);
+
+            /* Lets clean ourselves up for this adapter and try the next one. */
+            ipr_kill_kernel_thread(ipr_cfg);
+            temp_ipr_cfg = ipr_cfg;
+            ipr_cfg = ipr_cfg->p_next;
+            ipr_remove_ioa_from_list(temp_ipr_cfg);
+            ipr_free_all_resources(temp_ipr_cfg, (num_found == 0), 0);
+            continue;
+        }
+        else
+        {
+            if (rc > 0)
+                major_num = rc;
+
+            ipr_cfg->major_num = major_num;
+            ipr_cfg->minor_num = minor_num++;
+            num_found++;
+        }
+
+        ipr_cfg->block_host_ops = 0;
+
+        ipr_cfg = ipr_cfg->p_next;
+    }
+
+    return num_found;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Kills off the kernel thread
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS
+ *---------------------------------------------------------------------------*/
+static u32 ipr_kill_kernel_thread(ipr_host_config *ipr_cfg)
+{
+    ENTER;
+
+    lock_kernel();
+
+    ipr_cfg->flag |= IPR_KILL_KERNEL_THREAD;
+
+    /* Here we kill our kernel thread */
+    if (ipr_cfg->task_thread)
+    {
+        DECLARE_COMPLETION(completion);
+        ipr_cfg->completion = &completion;
+        send_sig (SIGTERM, ipr_cfg->task_thread, 1);
+        spin_unlock_irq(&io_request_lock);
+        wait_for_completion (&completion);
+        spin_lock_irq(&io_request_lock);
+        ipr_cfg->completion = NULL;
+    }
+
+    unlock_kernel();
+
+    LEAVE;
+
+    return IPR_RC_SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: IPL Part 1 for an IOA
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS - Success
+ *---------------------------------------------------------------------------*/
+static u32 ipr_init_ioa_part1(ipr_host_config *ipr_cfg)
+{
+    struct ipr_ioa_vpd *p_ioa_vpd;
+    struct ipr_cfc_vpd *p_cfc_vpd;
+    struct ipr_inquiry_page3 *p_ucode_vpd;
+    struct ipr_resource_dll *p_resource_dll;
+    u32 rc = 0;
+    int i;
+
+    ENTER;
+
+    p_ioa_vpd = ipr_cfg->shared.p_ioa_vpd;
+    p_cfc_vpd = ipr_cfg->shared.p_cfc_vpd;
+    p_ucode_vpd = ipr_cfg->shared.p_ucode_vpd;
+
+    memset(ipr_cfg->shared.resource_entry_list,
+                      0,
+                      sizeof(struct ipr_resource_dll) * IPR_MAX_PHYSICAL_DEVS);
+
+    memset(ipr_cfg->shared.bus, 0,
+                      sizeof(struct ipr_bus) * (IPR_MAX_NUM_BUSES + 1));
+
+    /* create resource table free dll */
+    ipr_cfg->shared.rsteFreeH = ipr_cfg->shared.resource_entry_list;
+    p_resource_dll = ipr_cfg->shared.rsteFreeH;
+    p_resource_dll->prev = NULL;
+
+    for (i = 0;
+         i < (IPR_MAX_PHYSICAL_DEVS - 1);
+         i++, p_resource_dll = p_resource_dll->next)
+    {
+        p_resource_dll->next = &ipr_cfg->shared.resource_entry_list[i+1];
+        p_resource_dll->next->prev = p_resource_dll;
+    }
+
+    p_resource_dll->next = NULL;
+    ipr_cfg->shared.rsteFreeT = p_resource_dll;
+    ipr_cfg->shared.rsteUsedH = NULL;
+    ipr_cfg->shared.rsteUsedT = NULL;
+
+    /* set microcode status of IOA to be operational */
+    ipr_cfg->shared.nr_ioa_microcode = 0;
+
+    /* Zero out the SES Data table */
+    for (i = 0; i < IPR_MAX_NUM_BUSES; i++)
+        memset(ipr_cfg->shared.p_ses_data[i], 0,
+                          sizeof(struct ipr_element_desc_page));
+
+    /* Zero our HCAMs, put them all on the new list and mark their type */
+    for (i = 0; i < IPR_NUM_LOG_HCAMS; i++)
+    {
+        memset(ipr_cfg->hostrcb[i], 0, sizeof(struct ipr_hostrcb));
+        ipr_cfg->new_hostrcb[i] = ipr_cfg->hostrcb[i];
+        ipr_cfg->new_hostrcb[i]->op_code = IPR_HOST_RCB_OP_CODE_LOG_DATA;
+        ipr_cfg->done_hostrcb[i] = NULL;
+    }
+
+    for (; i < IPR_NUM_HCAMS; i++)
+    {
+        memset(ipr_cfg->hostrcb[i], 0, sizeof(struct ipr_hostrcb));
+        ipr_cfg->new_hostrcb[i] = ipr_cfg->hostrcb[i];
+        ipr_cfg->new_hostrcb[i]->op_code = IPR_HOST_RCB_OP_CODE_CONFIG_CHANGE;
+        ipr_cfg->done_hostrcb[i] = NULL;
+    }
+
+    /* Start the IOA off and running */
+    rc = ipr_init_ioa_internal_part1(&ipr_cfg->shared);
+
+    LEAVE;
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: IPL Part 2 for an IOA
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS       - Success
+ *          IPR_RC_XFER_FAILED   - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ          - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST     - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR       - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED - IOA unit checked
+ *          IPR_RC_FAILED        - Initialization failed
+ *          IPR_RC_TIMEOUT       - IOA timed out
+ *          IPR_RC_NOMEM         - Out of memory
+ *---------------------------------------------------------------------------*/
+static u32 ipr_init_ioa_part2(ipr_host_config *ipr_cfg)
+{
+    u32 rc = 0, rc2 = PCIBIOS_SUCCESSFUL;
+    struct ipr_resource_entry *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll;
+    struct ipr_lun *p_lun;
+    const struct ipr_ioa_cfg_t *p_ioa_cfg = ipr_cfg->p_ioa_cfg;
+
+    ENTER;
+
+    rc = ipr_init_ioa_internal_part2(&ipr_cfg->shared);
+
+    if (!rc)
+    {
+        /* Interrupts are now enabled and IOA is functional */
+
+        /* Create the SCSI-ID -> Resource Address lookup table */
+        for (p_resource_dll = ipr_cfg->shared.rsteUsedH;
+             p_resource_dll != NULL;
+             p_resource_dll = p_resource_dll->next)
+        {
+            p_resource_entry = &p_resource_dll->data;
+
+            if (p_resource_entry->is_ioa_resource)
+            {
+                /* Do nothing - ignore entry */
+            }
+            else if (((p_resource_entry->resource_address.bus >= IPR_MAX_NUM_BUSES) &&
+                      (p_resource_entry->resource_address.bus != 0xff)) ||
+                     (p_resource_entry->resource_address.target >= IPR_MAX_NUM_TARGETS_PER_BUS))
+            {
+                ipr_log_err("Invalid resource address %x\n",
+                               IPR_GET_PHYSICAL_LOCATOR(p_resource_entry->resource_address));
+            }
+            else
+            {
+                p_lun = ipr_get_lun_res_addr(ipr_cfg,
+                                                p_resource_entry->resource_address);
+
+                p_lun->is_valid_entry = 1;
+                p_lun->p_resource_entry = p_resource_entry;
+                p_lun->stop_new_requests = 0;
+            }
+        }
+
+        /* Indicate we have IPLed successfully */ 
+        ipr_cfg->flag |= IPR_ALLOW_REQUESTS | IPR_ALLOW_HCAMS;
+
+        ipr_mailbox(ipr_cfg);
+    }
+
+    switch(rc)
+    {
+        case IPR_RC_SUCCESS:
+            break;
+        case IPR_IOA_UNIT_CHECKED:
+            if (p_ioa_cfg->cpu_rst_support == IPR_CPU_RST_SUPPORT_CFGSPC_403RST_BIT)
+            {
+                /* Hold the 403 in reset so we can get the unit check buffer */
+                rc2 = pci_write_config_dword(ipr_cfg->pdev, IPR_RESET_403_OFFSET, IPR_RESET_403);
+            }
+            if (rc2 != PCIBIOS_SUCCESSFUL)
+            {
+                /* Log an error that the IOA unit checked. Since we couldn't write config
+                 space, we probably shouldn't even try to read memory space */
+                ipr_unit_check_no_data(ipr_cfg);
+            }
+            else
+            {
+                ipr_break_or_die_if_reset_reload_disabled;
+
+                /* Reset the IOA */
+                ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+
+                /* Process the Unit check buffer */
+                ipr_get_unit_check_buffer(ipr_cfg);
+            }
+        case IPR_RC_XFER_FAILED:
+        case IPR_NO_HRRQ:
+        case IPR_IOARRIN_LOST:
+        case IPR_RC_TIMEOUT:
+        case IPR_MMIO_ERROR:
+            ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+            break;
+        case IPR_RC_FAILED:
+            ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+            break;
+    };
+
+    LEAVE;
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Initializes the IOA
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_XFER_FAILED       - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ              - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST         - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR           - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED     - IOA unit checked
+ *          IPR_RC_FAILED            - Initialization failed
+ *          IPR_RC_TIMEOUT           - IOA timed out
+ *          IPR_RC_NOMEM             - Out of memory
+ *---------------------------------------------------------------------------*/
+static u32 ipr_init_ioa(ipr_host_config *ipr_cfg)
+{
+    ipr_init_ioa_part1(ipr_cfg);
+    return ipr_init_ioa_part2(ipr_cfg);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Interrupt service routine
+ * Context: Interrupt level only
+ * Lock State: no locks assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_isr (int irq, void *devp, struct pt_regs *regs)
+{
+    ipr_host_config *ipr_cfg;
+    struct ipr_cmnd *p_cur_sis_cmnd = NULL;
+    unsigned long io_flags = 0;
+    u32 rc, rc2 = PCIBIOS_SUCCESSFUL;
+    const struct ipr_ioa_cfg_t *p_ioa_cfg;
+
+    ipr_cfg = (ipr_host_config *) devp;
+
+    if (ipr_cfg->host->irq != irq)
+        return;
+
+    spin_lock_irqsave(&io_request_lock, io_flags);
+
+    p_ioa_cfg = ipr_cfg->p_ioa_cfg;
+
+    rc = ipr_get_done_ops(&ipr_cfg->shared, (struct ipr_ccb **)&p_cur_sis_cmnd);
+
+    if (rc == IPR_RC_SUCCESS)
+    {
+        while(p_cur_sis_cmnd)
+        {
+            /* Pull off of pending queue */
+            ipr_remove_sis_cmnd_from_pending(ipr_cfg, p_cur_sis_cmnd);
+
+            /* Put onto completed queue */
+            ipr_put_sis_cmnd_to_completed(ipr_cfg, p_cur_sis_cmnd);
+
+            p_cur_sis_cmnd = (struct ipr_cmnd *)p_cur_sis_cmnd->ccb.p_next_done;
+        }
+    }
+    else
+    {
+        /* Process other interrupts */
+        switch(rc)
+        {
+            case IPR_RC_XFER_FAILED:
+            case IPR_NO_HRRQ:
+            case IPR_IOARRIN_LOST:
+            case IPR_MMIO_ERROR:
+
+                /* Any time these interrupts have been seen we have ended up getting a freeze error.
+                 Since we don't have recovery for a freeze error today, we kernel panic and
+                 point to the IOA so it can be replaced. */
+                panic(IPR_ERR": Permanent IOA failure on %s. rc: 0x%08X"IPR_EOL,
+                      ipr_cfg->shared.ioa_host_str, rc);
+                break;
+            case IPR_IOA_UNIT_CHECKED:
+
+                ipr_dbg_err("IOA Unit checked!!"IPR_EOL);
+                IPR_DBG_CMD(ipr_log_ioa_physical_location(ipr_cfg->shared.p_location,
+                                                                  KERN_CRIT));
+
+                /* Prevent ourselves from getting any more requests */
+                ipr_block_all_requests(ipr_cfg);
+
+                if (p_ioa_cfg->cpu_rst_support == IPR_CPU_RST_SUPPORT_CFGSPC_403RST_BIT)
+                {
+                    rc2 = pci_write_config_dword(ipr_cfg->pdev,
+                                                 IPR_RESET_403_OFFSET, IPR_RESET_403);
+                }
+
+                if (rc2 != PCIBIOS_SUCCESSFUL)
+                {
+                    ipr_log_err("Write of 403 reset register failed"IPR_EOL);
+
+                    ipr_cfg->flag |= IPR_IOA_NEEDS_RESET;
+
+                    /* Log an error that the IOA unit checked. Since we couldn't write config
+                     space, we probably shouldn't even try to read memory space */
+                    ipr_unit_check_no_data(ipr_cfg);
+                }
+                else
+                    ipr_cfg->flag |= IPR_UNIT_CHECKED;
+
+
+                /* Wake up task level thread to fetch Unit Check buffer and reset adapter */
+                ipr_wake_task(ipr_cfg);
+                break;
+            case IPR_RESET_ADAPTER:
+                /* Prevent ourselves from getting any more requests */
+                ipr_block_all_requests(ipr_cfg);
+
+                ipr_cfg->flag |= IPR_IOA_NEEDS_RESET;
+
+                /* Wake up task level thread to reset adapter */
+                ipr_wake_task(ipr_cfg);
+                break;
+            default:
+                break;
+        }
+
+        spin_unlock_irqrestore(&io_request_lock,io_flags);
+        return;
+    }
+
+    ipr_ops_done(ipr_cfg);
+
+    spin_unlock_irqrestore(&io_request_lock,io_flags);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Free resources - Used when unloading module
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Returns: 0 - Success
+ *---------------------------------------------------------------------------*/
+int ipr_release(struct Scsi_Host *p_scsi_host)
+{
+    ipr_host_config *ipr_cfg;
+    int rc;
+    unsigned long io_flags = 0;
+    DECLARE_WAIT_QUEUE_HEAD(internal_wait);
+
+    ENTER;
+
+    ipr_cfg = (ipr_host_config *) p_scsi_host->hostdata;
+
+    spin_lock_irqsave(&io_request_lock,io_flags);
+
+    devfs_unregister_chrdev(ipr_cfg->major_num, IPR_NAME);
+
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+    {
+        while(1)
+        {
+            /* Loop forever waiting for IOA to come out of reset/reload, checking once a second */
+            if ((ipr_cfg->flag & IPR_IN_RESET_RELOAD) == 0)
+                break;
+            else 
+                ipr_sleep_on_timeout(&io_request_lock, &internal_wait, HZ);
+        }
+    }
+
+    ipr_init_finished = 0;
+
+    /* Shutdown the IOA */
+    rc = ipr_shutdown_ioa(ipr_cfg, IPR_SHUTDOWN_NORMAL);
+
+    ipr_mask_interrupts(&ipr_cfg->shared);
+
+    /* Here we reset the IOA to get it back in a POR state and
+     so we can free up the memory we allocated for HCAMs */
+    rc = ipr_ioa_reset(ipr_cfg, IPR_IRQ_DISABLED);
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        /* Reset to the adapter failed for some reason. If this happens something is
+         seriously wrong */
+        ipr_log_crit("Reset to adapter failed! %s"IPR_EOL,
+                        ipr_cfg->shared.ioa_host_str);
+    }
+
+    /* The binary could have issued commands to us that may still be outstanding */
+    /* This will return them failed */
+    ipr_fail_all_ops(ipr_cfg);
+
+    /* Kill off our kernel thread */
+    ipr_kill_kernel_thread(ipr_cfg);
+
+    /* Remove the IOA from the linked list */
+    ipr_remove_ioa_from_list(ipr_cfg);
+
+    /* Free all the memory we allocated */
+    ipr_free_all_resources(ipr_cfg, 1, 0);
+
+    if (ipr_mem_debug &&
+        (ipr_num_ctlrs == 0) &&
+        (ipr_kmalloced_mem != 0))
+    {
+        panic("ipr_kmalloced_mem: %d !!"IPR_EOL, ipr_kmalloced_mem);
+    }
+
+    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+    LEAVE;
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Abort a single op
+ * Context: Task level only - mid-layer's ERP thread
+ * Lock State: io_request_lock assumed to be held
+ * Returns: SUCCESS     - Success
+ *          FAILED      - Failure
+ * Notes: We return SUCCESS if we cannot find the op.
+ *---------------------------------------------------------------------------*/
+int ipr_abort(Scsi_Cmnd *p_scsi_cmd)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    ipr_host_config *ipr_cfg;
+    struct ipr_lun *p_lun;
+    struct ipr_resource_entry *p_resource;
+    int rc;
+
+    if (!p_scsi_cmd)
+        return FAILED;
+
+    ENTER;
+
+    ipr_cfg = (ipr_host_config *) p_scsi_cmd->host->hostdata;
+
+    /* If we are currently going through reset/reload, return failed. This will force the
+     mid-layer to call ipr_host_reset, which will then go to sleep and wait for the
+     reset to complete */
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+        return FAILED;
+
+    if (ipr_cfg->shared.ioa_is_dead)
+        return FAILED;
+
+    /* Get a pointer to the LUN structure */
+    p_lun = ipr_get_lun_scsi(ipr_cfg, p_scsi_cmd);
+
+    if (p_lun)
+    {
+        if (p_lun->is_valid_entry)
+            p_resource = p_lun->p_resource_entry;
+        else /* Not a valid resource - cannot abort the op */
+        {
+            ipr_trace;
+            return SUCCESS;
+        }
+    }
+    else
+    {
+        ipr_trace;
+        return SUCCESS;
+    }
+
+    /* If this is a GPDD, lets do a cancel all requests to the device */
+    if (!p_resource->is_af)
+        return ipr_cancel_all(p_scsi_cmd);
+
+    /* Must be an AF DASD or VSET op */
+    p_sis_cmnd = ipr_cfg->qPendingH;
+
+    /* Look for the op on the pending queue */
+    while (p_sis_cmnd != NULL)
+    {
+        if (p_sis_cmnd->p_scsi_cmd == p_scsi_cmd)
+            break;
+
+        p_sis_cmnd = p_sis_cmnd->p_next;
+    }
+
+    /* Couldn't find it - Lets look on the completed queue */
+    if (p_sis_cmnd == NULL)
+    {
+        p_sis_cmnd = ipr_cfg->qCompletedH;
+
+        while (p_sis_cmnd != NULL)
+        {
+            if (p_sis_cmnd->p_scsi_cmd == p_scsi_cmd)
+                break;
+
+            p_sis_cmnd = p_sis_cmnd->p_next;
+        }
+
+        if (p_sis_cmnd != NULL)
+        {
+            /* Found the op on the completed queue. Send response to the host */
+            ipr_ops_done(ipr_cfg);
+            return SUCCESS;
+        }
+        else /* Command not outstanding to the IOA */
+            return SUCCESS;
+    }
+
+    /* Aborts are not supported to volume sets */
+    if (p_resource->subtype == IPR_SUBTYPE_VOLUME_SET)
+        return FAILED;
+
+    rc = ipr_cancelop(ipr_cfg, p_sis_cmnd, p_scsi_cmd);
+
+    LEAVE;
+
+    return rc; 
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Cancel the given op (called for LDD ops only)
+ * Context: Task level only - mid-layer's ERP thread
+ * Lock State: io_request_lock assumed to be held
+ * Returns: SUCCESS  - Success
+ *          FAILED   - Failure
+ * Notes: We return success if we cannot find the op.
+ *---------------------------------------------------------------------------*/
+static int ipr_cancelop(ipr_host_config *ipr_cfg,
+                           struct ipr_cmnd *p_sis_cmnd,
+                           Scsi_Cmnd *p_scsi_cmd)
+{
+    struct ipr_cmnd *p_cancel_sis_cmnd;
+    signed long time_left;
+    u32 timeout = IPR_CANCEL_TIMEOUT;
+    u32 rc;
+    char dev_loc_str[IPR_MAX_LOCATION_LEN];
+
+    ENTER;
+
+    /* Get a SIS Cmd block for the Cancel Request and set it up */
+    p_cancel_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+
+    ipr_put_sis_cmnd_to_pending(ipr_cfg, p_cancel_sis_cmnd);
+
+    ipr_dbg_err("Cancelling 0x%02x ipr_cmd: 0x%p, 0x%p"IPR_EOL, p_scsi_cmd->cmnd[0],
+                   p_sis_cmnd, p_cancel_sis_cmnd);
+
+    /* Tie these two requests together */
+    p_cancel_sis_cmnd->p_cancel_op = p_sis_cmnd;
+    p_sis_cmnd->p_cancel_op = p_cancel_sis_cmnd;
+
+    /* Setup command block */
+    p_cancel_sis_cmnd->ccb.cdb[0] = IPR_CANCEL_REQUEST;
+    *(unsigned long*)&p_cancel_sis_cmnd->ccb.cdb[2] = (unsigned long)p_sis_cmnd;
+
+    p_cancel_sis_cmnd->ccb.p_resource = p_sis_cmnd->ccb.p_resource;
+
+    p_sis_cmnd->ccb.flags |= IPR_ABORTING;
+    p_cancel_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND | IPR_IOA_CMD;
+
+    p_cancel_sis_cmnd->ccb.cmd_len = 10;
+
+    /* Queue the cancel request to the adapter */
+    rc = ipr_queue_internal(&ipr_cfg->shared, &p_cancel_sis_cmnd->ccb);
+
+    if (rc == IPR_RC_OP_NOT_SENT)
+    {
+        /* Cancel was not sent to the adapter. This is the return code we receive if
+         the op was not found on the lower level's queue. This should be dead code... */
+        ipr_trace;
+        ipr_put_sis_cmnd_to_free(ipr_cfg, p_cancel_sis_cmnd);
+        return FAILED;
+    }
+
+    init_waitqueue_head(&p_cancel_sis_cmnd->wait_q);
+
+    /* Sleep on the response and time it */
+    time_left = ipr_sleep_on_timeout(&io_request_lock, &p_cancel_sis_cmnd->wait_q, timeout);
+
+    rc = p_cancel_sis_cmnd->ccb.completion;
+
+    if (time_left <= 0)
+        p_cancel_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+    {
+        /* We are going through reset/reload for some reason and should not
+         be talking to the adapter */
+        return FAILED;
+    }
+    else if (time_left <= 0)
+    {
+        ipr_dev_loc_str(&ipr_cfg->shared, p_sis_cmnd->ccb.p_resource, dev_loc_str);
+
+        /* Cancel timed out - reset the adapter */
+        ipr_log_err("abort to %s timed out."IPR_EOL,
+                       dev_loc_str);
+        return ipr_host_reset(p_scsi_cmd);
+    }
+
+    ipr_put_sis_cmnd_to_free(ipr_cfg, p_cancel_sis_cmnd);
+
+    LEAVE;
+
+    if (rc == IPR_RC_FAILED)
+        return FAILED;
+    else
+        return SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Reset the host adapter
+ * Context: Task level only - mid-layer's ERP thread
+ * Lock State: io_request_lock assumed to be held
+ * Returns: SUCCESS  - Success
+ *          FAILED   - Failure
+ *---------------------------------------------------------------------------*/
+int ipr_host_reset(Scsi_Cmnd *p_scsi_cmd)
+{
+    ipr_host_config *ipr_cfg;
+    int rc;
+
+    ENTER;
+
+    if (!p_scsi_cmd)
+    {
+        ipr_trace;
+        return FAILED;
+    }
+
+    ipr_cfg = (ipr_host_config *) p_scsi_cmd->host->hostdata;
+
+    ipr_beg_err(KERN_ERR);
+    ipr_log_err("Adapter being reset as a result of error recovery."IPR_EOL);
+    ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_ERR);
+    ipr_end_err(KERN_ERR);
+
+    ipr_break_or_die_if_reset_reload_disabled;
+
+    if (WAIT_FOR_DUMP == ipr_get_sdt_state)
+        ipr_get_sdt_state = GET_DUMP;
+
+    rc = ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_ABBREV);
+
+    if (ipr_get_sdt_state == DUMP_OBTAINED)
+        wake_up_interruptible(&ipr_sdt_wait_q);
+
+    if (rc != SUCCESS)
+    {
+        printk(IPR_EOL);
+        ipr_beg_err(KERN_CRIT);
+        ipr_log_crit("Reset of IOA failed."IPR_EOL);
+        ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_CRIT);
+        ipr_end_err(KERN_CRIT);
+    }
+
+    LEAVE;
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Reset/Reload the IOA
+ * Context: Task level only 
+ * Lock State: io_request_lock assumed to be held
+ * Requirements: This function assumes that all new host commands have been
+ *               stopped. 
+ * Returns: SUCCESS     - Success
+ *          FAILED      - Failure
+ *---------------------------------------------------------------------------*/
+static int ipr_reset_reload(ipr_host_config *ipr_cfg,
+                               enum ipr_shutdown_type shutdown_type)
+{
+    int rc, i;
+    DECLARE_WAIT_QUEUE_HEAD(internal_wait);
+
+    if (ipr_cfg->shared.ioa_is_dead)
+        return FAILED;
+
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+    {
+        while(1)
+        {
+            /* Loop forever waiting for IOA to come out of reset/reload, checking once a second */
+            if ((ipr_cfg->flag & IPR_IN_RESET_RELOAD) == 0)
+                break;
+            else 
+                ipr_sleep_on_timeout(&io_request_lock, &internal_wait, HZ);
+        }
+
+        /* If we got hit with a host reset while we were already resetting
+         the adapter for some reason, and the reset failed. */
+        if ((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0)
+        {
+            ipr_trace;
+            return FAILED;
+        }
+    }
+    else
+    {
+        for (i = 0, rc = IPR_RC_FAILED;
+             (i < IPR_NUM_RESET_RELOAD_RETRIES) && (rc != IPR_RC_SUCCESS);
+             i++, shutdown_type = IPR_SHUTDOWN_NONE)
+        {
+            ipr_cfg->flag = (IPR_IN_RESET_RELOAD | IPR_OPERATIONAL);
+
+            ipr_break_if_reset_reload_disabled;
+
+            /* Shutdown the IOA */
+            rc = ipr_shutdown_ioa(ipr_cfg, shutdown_type);
+
+            /* Reset the adapter */
+            rc = ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+
+            if (rc == IPR_RC_SUCCESS)
+            {
+                /* Fail all ops back to the caller - they will be retried later */
+                ipr_fail_all_ops(ipr_cfg);
+            }
+            else
+            {
+                panic(IPR_ERR": IOA reset failed on %s. rc: 0x%08X"IPR_EOL,
+                      ipr_cfg->shared.ioa_host_str, rc);
+            }
+
+            if (GET_DUMP == ipr_get_sdt_state)
+            {
+                ipr_get_ioa_smart_dump(ipr_cfg);
+
+                /* Reset the adapter */
+                rc = ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+
+                if (rc != IPR_RC_SUCCESS)
+                    panic(IPR_ERR": IOA reset failed on %s. rc: 0x%08X"IPR_EOL,
+                          ipr_cfg->shared.ioa_host_str, rc);
+            }
+            else if (NO_DUMP == ipr_get_sdt_state)
+                ipr_get_sdt_state = WAIT_FOR_DUMP;
+
+            if (rc == IPR_RC_SUCCESS)
+                rc = ipr_init_ioa(ipr_cfg);
+
+            ipr_cfg->flag &= ~IPR_IN_RESET_RELOAD;
+        }
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_take_ioa_offline(ipr_cfg);
+            return FAILED;
+        }
+    }
+
+    return SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Reset the IOA.
+ * Context: Task level only 
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *          IPR_RC_FAILED    - Failure
+ *---------------------------------------------------------------------------*/
+static int ipr_ioa_reset(ipr_host_config *ipr_cfg, enum ipr_irq_state irq_state)
+{
+    u16 cmd;
+    u32 cache_line;
+    int rc = IPR_RC_SUCCESS;
+    int timeout, i, pcix_command_reg;
+    const struct ipr_ioa_cfg_t *p_ioa_cfg = ipr_cfg->p_ioa_cfg;
+
+    ENTER;
+
+    /* Turn appropriate flags off */
+    ipr_cfg->flag &= ~(IPR_OPERATIONAL | IPR_ALLOW_HCAMS | IPR_ALLOW_REQUESTS);
+
+    /* Save away PCI command register */
+    if (pci_read_config_word(ipr_cfg->pdev, PCI_COMMAND, &cmd) != PCIBIOS_SUCCESSFUL)
+        goto failure;
+
+    /* Save away cache line size/latency timer register */
+    if (pci_read_config_dword(ipr_cfg->pdev, PCI_CACHE_LINE_SIZE, &cache_line) != PCIBIOS_SUCCESSFUL)
+        goto failure;
+
+    cmd |= (PCI_COMMAND_PARITY | PCI_COMMAND_SERR);
+
+    ipr_cfg->shared.ioa_operational = 0;
+
+    if(irq_state == IPR_IRQ_ENABLED)
+        ipr_mask_interrupts(&ipr_cfg->shared);
+
+    spin_unlock_irq(&io_request_lock);
+
+    /* We will only wait 2 seconds for permission to reset the IOA */
+    timeout = 2000;
+
+    /* Alert the IOA of a pending reset */
+    ipr_reset_alert(&ipr_cfg->shared);
+
+    /* Keep looping while reset to the IOA is not allowed and we
+     haven't timed out yet */
+    while(!ipr_reset_allowed(&ipr_cfg->shared) && timeout)
+    {
+        /* Sleep for 10 milliseconds */
+        ipr_sleep_no_lock(10);
+        timeout -= 10;
+    }
+
+    if (timeout == 0)
+        ipr_log_err("Timed out waiting for permission to reset IOA"IPR_EOL);
+
+    rc = ipr_toggle_reset(ipr_cfg);
+
+    spin_lock_irq(&io_request_lock);
+
+    if (rc)
+    {
+        ipr_trace;
+        goto failure;
+    }
+
+    /* Restore the BARs */
+    for (i = (PCI_BASE_ADDRESS_0 / 4), rc = PCIBIOS_SUCCESSFUL;
+         (i < IPR_CONFIG_SAVE_WORDS) && (rc == PCIBIOS_SUCCESSFUL);
+         i++)
+    {
+        rc = pci_write_config_dword(ipr_cfg->pdev, i*4, ipr_cfg->pci_cfg_buf[i]);
+    }
+
+    if (rc != PCIBIOS_SUCCESSFUL)
+    {
+        ipr_trace;
+        goto failure;
+    }
+
+    /* Restore the cache line size/latency timer */
+    cache_line = (cache_line & ~IPR_CL_SIZE_LATENCY_MASK) |
+        (p_ioa_cfg->cl_size_latency_timer & IPR_CL_SIZE_LATENCY_MASK);
+
+    if (pci_write_config_dword(ipr_cfg->pdev, PCI_CACHE_LINE_SIZE,
+                               cache_line) != PCIBIOS_SUCCESSFUL)
+    {
+        ipr_trace;
+        goto failure;
+    }
+
+    if (pci_write_config_word(ipr_cfg->pdev, PCI_COMMAND, cmd) != PCIBIOS_SUCCESSFUL)
+    {
+        ipr_trace;
+        goto failure;
+    }
+
+    pcix_command_reg = pci_find_capability(ipr_cfg->pdev, IPR_PCIX_COMMAND_REG_ID);
+
+    if (pcix_command_reg)
+    {
+        /* Need to restore the PCI-X Command register. */
+        if (pci_write_config_word(ipr_cfg->pdev, pcix_command_reg,
+                                  ipr_cfg->saved_pcix_command_reg) != PCIBIOS_SUCCESSFUL)
+        {
+            ipr_trace;
+            goto failure;
+        }
+    }
+
+    /* Turn the operational flag on */
+    ipr_cfg->flag |= IPR_OPERATIONAL;
+
+    LEAVE;
+
+    return IPR_RC_SUCCESS;
+
+failure:
+    return IPR_RC_FAILED;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Reset the device
+ * Context: Task level only - mid-layer's ERP thread
+ * Lock State: io_request_lock assumed to be held
+ * Returns: SUCCESS     - Success
+ *          FAILED      - Failure
+ * Notes: This command is only supported to GPDD devices
+ *---------------------------------------------------------------------------*/
+int ipr_dev_reset(Scsi_Cmnd *p_scsi_cmd)
+{
+    struct ipr_cmnd *p_reset_sis_cmnd;
+    ipr_host_config *ipr_cfg;
+    signed long time_left;
+    struct ipr_lun *p_lun;
+    struct ipr_resource_entry *p_resource_entry;
+    int rc, rc2, rc3, rc4;
+    int retries = 10;
+    char dev_loc_str[IPR_MAX_LOCATION_LEN];
+
+    ENTER;
+
+    if (!p_scsi_cmd)
+        return FAILED;
+
+    ipr_cfg = (ipr_host_config *) p_scsi_cmd->host->hostdata;
+
+    /* If we are currently going through reset/reload, return failed. This will force the
+     mid-layer to call ipr_host_reset, which will then go to sleep and wait for the
+     reset to complete */
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+        return FAILED;
+
+    if (ipr_cfg->shared.ioa_is_dead)
+        return FAILED;
+
+    p_lun = ipr_get_lun_scsi(ipr_cfg, p_scsi_cmd);
+
+    if (p_lun)
+    {
+        if (p_lun->is_valid_entry)
+            p_resource_entry = p_lun->p_resource_entry;
+        else /* Not a valid device */
+        {
+            ipr_trace;
+            return SUCCESS;
+        }
+    }
+    else
+    {
+        ipr_trace;
+        return SUCCESS;
+    }
+
+    /* We only support device reset to GPDD devices */
+    if (p_resource_entry->is_af)
+        return FAILED;
+
+    /* Cancel all outstanding ops to the device. */
+    rc = ipr_cancel_all(p_scsi_cmd);
+
+    /* Could not cancel outstanding ops. Cannot return success to mid-layer */
+    if (rc != SUCCESS)
+    {
+        ipr_trace;
+        return rc;
+    }
+
+    /* Get a command block for device reset command */
+    p_reset_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+
+    ipr_put_sis_cmnd_to_pending(ipr_cfg, p_reset_sis_cmnd);
+    p_reset_sis_cmnd->ccb.p_resource = p_resource_entry;
+    p_reset_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND | IPR_IOA_CMD;
+    p_reset_sis_cmnd->ccb.cdb[0] = IPR_RESET_DEVICE;
+
+    p_reset_sis_cmnd->ccb.cmd_len = 10;
+
+    ipr_queue_internal(&ipr_cfg->shared, &p_reset_sis_cmnd->ccb);
+
+    init_waitqueue_head(&p_reset_sis_cmnd->wait_q);
+
+    /* Sleep on the response and time it */
+    time_left = ipr_sleep_on_timeout(&io_request_lock, &p_reset_sis_cmnd->wait_q,
+                                        IPR_DEVICE_RESET_TIMEOUT);
+
+    rc2 = p_reset_sis_cmnd->ccb.completion;
+
+    if (time_left <= 0)
+        p_reset_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+    {
+        /* We are going through reset/reload for some reason and should not
+         be talking to the adapter */
+        ipr_trace;
+        return FAILED;
+    }
+    else if (time_left <= 0)
+    {
+        ipr_dev_loc_str(&ipr_cfg->shared, p_resource_entry, dev_loc_str);
+
+        /* Reset device timed out - reset the adapter */
+        ipr_log_err("reset device to %s timed out."IPR_EOL, dev_loc_str);
+        return ipr_host_reset(p_scsi_cmd);
+    }
+
+    /* The upper layer device drivers assume that commands can continue as
+     soon as we return. Since the device was just reset, it may take some time
+     before it is ready for a command again. */
+    while(retries--)
+    {
+        /* Re-initialize the command block for re-use */
+        ipr_initialize_sis_cmnd(p_reset_sis_cmnd);
+
+        /* Put this cmd blk back on the pending queue */
+        ipr_put_sis_cmnd_to_pending(ipr_cfg, p_reset_sis_cmnd);
+
+        /* Setup resource entry pointer */
+        p_reset_sis_cmnd->ccb.p_resource = p_resource_entry;
+
+        /* Send a test unit ready */
+        p_reset_sis_cmnd->ccb.cdb[0] = TEST_UNIT_READY;
+        p_reset_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND;
+
+        p_reset_sis_cmnd->ccb.cmd_len = 6;
+
+        ipr_queue_internal(&ipr_cfg->shared, &p_reset_sis_cmnd->ccb);
+
+        init_waitqueue_head(&p_reset_sis_cmnd->wait_q);
+
+        /* Sleep on the response and time it */
+        time_left = ipr_sleep_on_timeout(&io_request_lock, &p_reset_sis_cmnd->wait_q,
+                                            IPR_INTERNAL_TIMEOUT);
+
+        rc3 = p_reset_sis_cmnd->ccb.completion;
+
+        if (time_left <= 0)
+            p_reset_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+
+        if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+        {
+            /* We are going through reset/reload for some reason and should not
+             be talking to the adapter */
+            ipr_trace;
+            return FAILED;
+        }
+        else if (time_left <= 0)
+        {
+            ipr_dev_loc_str(&ipr_cfg->shared, p_resource_entry, dev_loc_str);
+
+            /* Test Unit Ready timed out - reset the adapter */
+            ipr_log_err("test unit ready to %s timed out."IPR_EOL, dev_loc_str);
+            return ipr_host_reset(p_scsi_cmd);
+        }
+
+        /* If we were able to successfully send a test unit ready, the
+         device must be ready to accept new commands and we can return
+         to the mid-layer */
+        if (rc3 == IPR_RC_SUCCESS)
+            goto leave;
+
+        /* Re-initialize the command block for re-use */
+        ipr_initialize_sis_cmnd(p_reset_sis_cmnd);
+
+        /* Put this cmd blk back on the pending queue */
+        ipr_put_sis_cmnd_to_pending(ipr_cfg, p_reset_sis_cmnd);
+
+        /* Setup resource entry pointer */
+        p_reset_sis_cmnd->ccb.p_resource = p_resource_entry;
+
+        /* Send the sync-complete */
+        p_reset_sis_cmnd->ccb.cdb[0] = IPR_SYNC_COMPLETE;
+
+        p_reset_sis_cmnd->ccb.cmd_len = 10;
+
+        /* Turn on IOA cmd flag */
+        p_reset_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND | IPR_IOA_CMD;
+
+        ipr_queue_internal(&ipr_cfg->shared, &p_reset_sis_cmnd->ccb);
+
+        init_waitqueue_head(&p_reset_sis_cmnd->wait_q);
+
+        /* Sleep on the response and time it */
+        time_left = ipr_sleep_on_timeout(&io_request_lock, &p_reset_sis_cmnd->wait_q,
+                                            IPR_INTERNAL_TIMEOUT);
+
+        rc4 = p_reset_sis_cmnd->ccb.completion;
+
+        if (time_left <= 0)
+            p_reset_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+
+        if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+        {
+            /* We are going through reset/reload for some reason and should not
+             be talking to the adapter */
+            ipr_trace;
+            return FAILED;
+        }
+        else if (time_left <= 0)
+        {
+            ipr_dev_loc_str(&ipr_cfg->shared, p_resource_entry, dev_loc_str);
+
+            /* Sync complete timed out - reset the adapter */
+            ipr_log_err("sync complete to %s timed out."IPR_EOL, dev_loc_str);
+            return ipr_host_reset(p_scsi_cmd);
+        }
+
+        /* Sleep for 2 seconds */
+        ipr_sleep(2000);
+    }
+
+leave:
+    ipr_put_sis_cmnd_to_free(ipr_cfg, p_reset_sis_cmnd);
+
+    LEAVE;
+
+    if (rc2 == IPR_RC_FAILED)
+    {
+        ipr_trace;
+        return FAILED;
+    }
+
+    return SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Cancel all requests to a device
+ * Context: Task level only 
+ * Lock State: io_request_lock assumed to be held
+ * Returns: SUCCESS     - Success
+ *          FAILED      - Failure
+ * Notes: This command is only supported to tape/optical devices
+ *---------------------------------------------------------------------------*/
+static int ipr_cancel_all(Scsi_Cmnd *p_scsi_cmd)
+{
+    struct ipr_cmnd *p_sis_cmnd, *p_cancel_sis_cmnd;
+    ipr_host_config *ipr_cfg;
+    signed long time_left;
+    struct ipr_lun *p_lun;
+    struct ipr_resource_entry *p_resource_entry;
+    int rc, rc2;
+    char dev_loc_str[IPR_MAX_LOCATION_LEN];
+
+    ENTER;
+
+    ipr_cfg = (ipr_host_config *) p_scsi_cmd->host->hostdata;
+
+    p_lun = ipr_get_lun_scsi(ipr_cfg, p_scsi_cmd);
+
+    p_resource_entry = p_lun->p_resource_entry;
+
+    /* Now we need to look for all outstanding command for this device and
+     mark them as aborting */
+
+    /* Look for ops to this device on the pending queue */
+    p_sis_cmnd = ipr_cfg->qPendingH;
+
+    while (p_sis_cmnd != NULL)
+    {
+        if (p_sis_cmnd->ccb.p_resource == p_resource_entry)
+        {
+            /* Turn on the aborting bit */
+            p_sis_cmnd->ccb.flags |= IPR_ABORTING;
+
+            /* Restore the command if we were doing ERP  */
+            if (p_sis_cmnd->ccb.flags & IPR_ERP_CMD)
+                ipr_end_erp(p_sis_cmnd);
+        }
+        p_sis_cmnd = p_sis_cmnd->p_next;
+    }
+
+    /* Look for ops to this device on the completed queue */
+    p_sis_cmnd = ipr_cfg->qCompletedH;
+
+    while (p_sis_cmnd != NULL)
+    {
+        if (p_sis_cmnd->ccb.p_resource == p_resource_entry)
+        {
+            /* Turn on the aborting bit */
+            p_sis_cmnd->ccb.flags |= IPR_ABORTING;
+
+            /* Restore the command if we were doing ERP  */
+            if (p_sis_cmnd->ccb.flags & IPR_ERP_CMD)
+                ipr_end_erp(p_sis_cmnd);
+        }
+        p_sis_cmnd = p_sis_cmnd->p_next;
+    }
+
+    /* Look for ops to this device on the error queue */
+    p_sis_cmnd = ipr_cfg->qErrorH;
+
+    while (p_sis_cmnd != NULL)
+    {
+        if (p_sis_cmnd->ccb.p_resource == p_resource_entry)
+        {
+            /* Remove from the error queue and put on completed queue */
+            ipr_remove_sis_cmnd_from_error(ipr_cfg, p_sis_cmnd);
+            ipr_put_sis_cmnd_to_completed(ipr_cfg, p_sis_cmnd);
+
+            /* Mark the op as aborting */
+            p_sis_cmnd->ccb.flags |= IPR_ABORTING;
+
+            /* Restore the command if we were doing ERP  */
+            if (p_sis_cmnd->ccb.flags & IPR_ERP_CMD)
+                ipr_end_erp(p_sis_cmnd);
+        }
+        p_sis_cmnd = p_sis_cmnd->p_next;
+    }
+
+    /* Send all the ops back */
+    ipr_ops_done(ipr_cfg);
+
+    /* Get a command block for Cancel All Requests command */
+    p_cancel_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+
+    ipr_put_sis_cmnd_to_pending(ipr_cfg, p_cancel_sis_cmnd);
+    p_cancel_sis_cmnd->ccb.p_resource = p_resource_entry;
+
+    /* Note: IPR_CMD_SYNC_OVERRIDE is required on 2748, 2763, and 2778 adapters */
+    p_cancel_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND |
+        IPR_CMD_SYNC_OVERRIDE | IPR_IOA_CMD;
+    p_cancel_sis_cmnd->ccb.cdb[0] = IPR_CANCEL_ALL_REQUESTS;
+
+    p_cancel_sis_cmnd->ccb.cmd_len = 10;
+
+    ipr_queue_internal(&ipr_cfg->shared, &p_cancel_sis_cmnd->ccb);
+
+    init_waitqueue_head(&p_cancel_sis_cmnd->wait_q);
+
+    /* Sleep on the response and time it */
+    time_left = ipr_sleep_on_timeout(&io_request_lock,
+                                        &p_cancel_sis_cmnd->wait_q,
+                                        IPR_CANCEL_ALL_TIMEOUT);
+
+    rc = p_cancel_sis_cmnd->ccb.completion;
+
+    if (time_left <= 0)
+        p_cancel_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+    {
+        ipr_trace;
+        return FAILED;
+    }
+    else if (time_left <= 0)
+    {
+        ipr_dev_loc_str(&ipr_cfg->shared, p_resource_entry, dev_loc_str);
+
+        /* Cancel all timed out - reset the adapter */
+        ipr_log_err("cancel all to %s timed out."IPR_EOL, dev_loc_str);
+        return ipr_host_reset(p_scsi_cmd);
+    }
+
+    /* Re-initialize the command block for re-use */
+    ipr_initialize_sis_cmnd(p_cancel_sis_cmnd);
+
+    /* Put this cmd blk back on the pending queue */
+    ipr_put_sis_cmnd_to_pending(ipr_cfg, p_cancel_sis_cmnd);
+
+    p_cancel_sis_cmnd->ccb.p_resource = p_resource_entry;
+
+    /* Send the sync-complete */
+    p_cancel_sis_cmnd->ccb.cdb[0] = IPR_SYNC_COMPLETE;
+
+    p_cancel_sis_cmnd->ccb.cmd_len = 10;
+    p_cancel_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND | IPR_IOA_CMD;
+
+    ipr_queue_internal(&ipr_cfg->shared, &p_cancel_sis_cmnd->ccb);
+
+    init_waitqueue_head(&p_cancel_sis_cmnd->wait_q);
+
+    /* Sleep on the response and time it */
+    time_left = ipr_sleep_on_timeout(&io_request_lock,
+                                        &p_cancel_sis_cmnd->wait_q,
+                                        IPR_INTERNAL_TIMEOUT);
+
+    rc2 = p_cancel_sis_cmnd->ccb.completion;
+
+    if (time_left <= 0)
+        p_cancel_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+
+    if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+    {
+        ipr_trace;
+        return FAILED;
+    }
+    else if (time_left <= 0)
+    {
+        ipr_dev_loc_str(&ipr_cfg->shared, p_resource_entry, dev_loc_str);
+
+        /* Sync complete timed out - reset the adapter */
+        ipr_log_err("sync complete to %s timed out."IPR_EOL,
+                       dev_loc_str);
+        return ipr_host_reset(p_scsi_cmd);
+    }
+
+    ipr_put_sis_cmnd_to_free(ipr_cfg, p_cancel_sis_cmnd);
+
+    LEAVE;
+
+    if ((rc != IPR_RC_SUCCESS) || (rc2 != IPR_RC_SUCCESS))
+    {
+        ipr_trace;
+        return FAILED;
+    }
+    else
+    {
+        return SUCCESS;
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Queue an external request
+ * Context: Task level only 
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0   - Success
+ *          1   - Command could not be queued
+ *---------------------------------------------------------------------------*/
+int ipr_queue(Scsi_Cmnd *p_scsi_cmd, void (*done) (Scsi_Cmnd *))
+{
+    ipr_host_config *ipr_cfg = NULL;
+    u32 found = 0, rc = 0;
+    u8 bus;
+    u16 lun_num;
+    struct ipr_lun *p_lun = NULL;
+    struct ipr_resource_entry *p_resource = NULL;
+    struct ipr_cmnd *p_sis_cmnd = NULL;
+    struct ipr_std_inq_data std_inq_data;
+
+    p_scsi_cmd->scsi_done = done;
+
+    ipr_cfg = (ipr_host_config *)p_scsi_cmd->host->hostdata;
+
+    /* This MUST be done, since retries following aborts do not
+     re-initialize this field */
+    p_scsi_cmd->result = DID_OK << 16;
+
+    if (ipr_cfg->block_host_ops)
+    {
+        /* We are currently blocking all devices due to a host reset 
+         We have told the host to stop giving us new requests, but
+         retries on failed ops don't count. Therefore, we return success and
+         forget about the command, allowing the host to enter ERP when
+         the command times out */
+        ipr_dbg;
+        return 0;
+    }
+
+    if (ipr_cfg->shared.ioa_is_dead)
+    {
+        memset (p_scsi_cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
+        p_scsi_cmd->result = (DID_NO_CONNECT << 16);
+        p_scsi_cmd->scsi_done(p_scsi_cmd);
+        return 0;
+    }
+
+    /* Look to see if device is attached */
+    if (p_scsi_cmd->lun < IPR_MAX_NUM_LUNS_PER_TARGET)
+    {
+        p_lun = ipr_get_lun_scsi(ipr_cfg, p_scsi_cmd);
+
+        if (p_lun && p_lun->is_valid_entry)
+        {
+            p_resource = p_lun->p_resource_entry;
+            found = 1;
+        }
+    }
+
+    /* Dummy up a connection timeout response since device is not attached
+     or we are hiding the device from the mid-layer */
+    if ((found == 0) || p_resource->is_hidden)
+    {
+        /* First check if multi-lun configuration present for
+         responding correctly to inquiry */
+        if ((p_scsi_cmd->cmnd[0] == INQUIRY) &&
+            ((p_scsi_cmd->cmnd[1] & 0x01) == 0))
+        {
+            /* Since the SCSI mid-layer does not scan for sparse LUNs,
+             we must dummy up inquiry data for for them if they exist */
+
+            bus = p_scsi_cmd->channel + 1;
+
+            for (lun_num = p_scsi_cmd->lun;
+                 lun_num < IPR_MAX_NUM_LUNS_PER_TARGET;
+                 lun_num++)
+            {
+                if (bus <= IPR_MAX_NUM_BUSES)
+                {
+                    p_lun = &ipr_cfg->shared.bus[bus].
+                        target[p_scsi_cmd->target].lun[lun_num];
+
+                    if (p_lun->is_valid_entry) 
+                    {
+                        p_resource = p_lun->p_resource_entry;
+                        if (!p_resource->is_hidden)
+                        {
+                            /* Send back fabricated inquiry data
+                             so mid-layer processing continues through
+                             lun list to find active lun */
+                            memcpy(&std_inq_data, &p_resource->std_inq_data,
+                                               sizeof(p_resource->std_inq_data));
+                            std_inq_data.peri_qual = 0;
+                            std_inq_data.peri_dev_type = 0x1f;
+
+                            /* Zero out the serial number */
+                            memset(std_inq_data.serial_num, '0',
+                                              IPR_SERIAL_NUM_LEN);
+
+                            memcpy(p_scsi_cmd->buffer, &std_inq_data,
+                                               sizeof(struct ipr_std_inq_data));
+                            p_scsi_cmd->scsi_done(p_scsi_cmd);
+                            return 0;
+                        }
+                    }
+                }
+            }
+        }
+
+        /* No device to send command to */
+        memset (p_scsi_cmd->sense_buffer, 0, SCSI_SENSE_BUFFERSIZE);
+        p_scsi_cmd->result = (DID_NO_CONNECT << 16);
+        p_scsi_cmd->scsi_done(p_scsi_cmd);
+        return 0;
+    }
+    else if (p_lun->stop_new_requests)
+    {
+        /* We are currently blocking requests to this device */
+        /* Note: The midlayer has an assumption that if we give them
+         a QUEUE_FULL response that we have at least one op queued to
+         the device. If not, the device queue will lock up. We can
+         guarantee that in this path since we are doing ERP for a GPDD
+         op and are holding on to the original op */
+        p_scsi_cmd->result |= (QUEUE_FULL << 1);
+        p_scsi_cmd->scsi_done(p_scsi_cmd);
+        ipr_dbg;
+        return 0;
+    }
+
+    p_sis_cmnd = ipr_build_cmd(ipr_cfg, p_scsi_cmd, p_resource);
+
+    if (p_sis_cmnd != NULL)
+        rc = ipr_queue_internal(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+    else
+    {
+        /* We return busy here rather than queue full or host full
+         since we cannot guarantee we actually have any ops outstanding
+         at this point. We will only hit this path if the DMA mapping
+         fails, which should really never happen, but if it does we
+         just want a retry */
+        p_scsi_cmd->result |= (DID_BUS_BUSY << 16);
+        p_scsi_cmd->scsi_done(p_scsi_cmd);
+        return 0;
+    }
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        /* Copy over the sense data and push scsi done */
+        /* Change the return code since the command was successfully built
+         and sent, but was unsucessfully executed. */
+        memcpy(p_scsi_cmd->sense_buffer, p_sis_cmnd->ccb.sense_buffer,
+                           IPR_SENSE_BUFFERSIZE);
+        p_scsi_cmd->result |= (DID_ERROR << 16);
+        p_scsi_cmd->scsi_done(p_scsi_cmd);
+
+        /* Free up sis cmd block */
+        ipr_put_sis_cmnd_from_pending(ipr_cfg, p_sis_cmnd);
+    }
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return the BIOS parameters for fdisk. We want to make sure we
+ *          return something that places partitions on 4k boundaries for
+ *          best performance with the IOA
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Returns: 0   - Success
+ *---------------------------------------------------------------------------*/
+int ipr_biosparam(Disk *p_disk, kdev_t kdev, int *parm)
+{
+    int heads, sectors, cylinders;
+
+    heads = 128;
+    sectors = 32;
+
+    cylinders = (p_disk->capacity / (heads * sectors));
+
+    /* return result */
+    parm[0] = heads;
+    parm[1] = sectors;
+    parm[2] = cylinders;
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Our default /proc entry
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Returns: number of bytes in /proc entry
+ * Notes: The format of existing entries cannot be changed easily
+ *        without breaking userspace tools
+ *        We only support reading out of the /proc entry
+ *---------------------------------------------------------------------------*/
+int ipr_proc_info(char *buffer, char **start, off_t offset,
+                     int length, int hostno, int inout)
+{
+    u32 len = 0;
+    u32 size = 0;
+    int i;
+    ipr_host_config *ipr_cfg;
+    char temp_string[15];
+    int cache_size;
+    char ioa_name[65];
+    struct ipr_inquiry_page3 *p_ucode_vpd;
+    unsigned long io_flags = 0;
+
+    /* We only support reading of our /proc file */
+    if (inout)
+        return 0;
+
+    spin_lock_irqsave(&io_request_lock, io_flags);
+
+    for (i = 0, ipr_cfg = ipr_cfg_head;
+         ipr_cfg != NULL;
+         ipr_cfg = ipr_cfg->p_next, i++)
+    {
+        if (ipr_cfg->host->host_no == hostno)
+            break;
+    }
+
+    if (ipr_cfg == NULL)
+    {
+        spin_unlock_irqrestore(&io_request_lock, io_flags);
+        return 0;
+    }
+
+    p_ucode_vpd = ipr_cfg->shared.p_ucode_vpd;
+
+    size = sprintf(buffer + len, "IBM %X Disk Array Controller", ipr_cfg->shared.ccin);
+    len += size;
+    size = sprintf(buffer + len, " \nDriver Version: "IPR_FULL_VERSION);
+    len += size;
+
+    size = sprintf(buffer + len, " \nFirmware Version: %02X%02X%02X%02X",
+                   p_ucode_vpd->major_release, p_ucode_vpd->card_type,
+                   p_ucode_vpd->minor_release[0], p_ucode_vpd->minor_release[1]);
+
+    len += size;
+    ipr_get_ioa_name(ipr_cfg, ioa_name);
+    size = sprintf(buffer + len, " \nResource Name: %s", ioa_name);
+    len += size;
+    size = sprintf(buffer + len, " \nMajor Number: %d",
+                   ipr_cfg->major_num);
+    len += size;
+    size = sprintf(buffer + len, " \nMinor Number: %d",
+                   ipr_cfg->minor_num);
+    len += size;
+    size = sprintf(buffer + len, "\nHost Address: %x", ipr_cfg->host->unique_id);
+    len += size;
+    size = sprintf(buffer + len, " \nSerial Number: ");
+    len += size;
+    memcpy(buffer + len, ipr_cfg->shared.ioa_resource.serial_num,
+                       IPR_SERIAL_NUM_LEN);
+    len += IPR_SERIAL_NUM_LEN;
+    size = sprintf(buffer + len, " \nCard Part Number: ");
+    len += size;
+    memcpy(buffer + len, ipr_cfg->shared.p_ioa_vpd->ascii_part_num, 12);
+    size += 12;
+    size = sprintf(buffer + len, " \nPlant of Manufacture: ");
+    len += size;
+    memcpy(buffer + len, ipr_cfg->shared.p_ioa_vpd->ascii_plant_code, 4);
+    len += 4;
+    strncpy(temp_string, ipr_cfg->shared.p_cfc_vpd->cache_size, 3);
+    temp_string[3] = '\0';
+    cache_size = simple_strtoul(temp_string, NULL, 16);
+    size = sprintf(buffer + len, " \nCache Size: %d MB", cache_size);
+    len += size;
+    size = sprintf(buffer + len, " \nDRAM Size: %d MB", ipr_cfg->shared.dram_size);
+    len += size;
+    size = sprintf(buffer + len, " \nMain CB: 0x%p", ipr_cfg);
+    len += size;
+    size = sprintf(buffer + len, " \nPlatform: %s\n", ipr_platform);
+    len += size;
+    if (ipr_mem_debug)
+    {
+        size = sprintf(buffer + len, "ipr_kmalloced_mem: %d\n", ipr_kmalloced_mem);
+        len += size;
+    }
+
+    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+    return len;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Select the queue depth.
+ * Context: Task level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_select_q_depth(struct Scsi_Host *p_scsi_host,
+                           Scsi_Device *p_scsi_device_list)
+{
+    u8 bus;
+    struct ipr_lun *p_lun = NULL;
+    ipr_host_config *ipr_cfg;
+    struct ipr_resource_entry *p_resource_entry;
+    Scsi_Device *p_scsi_device;
+
+    ipr_cfg = (ipr_host_config *) p_scsi_host->hostdata;
+
+    for (p_scsi_device = p_scsi_device_list;
+         p_scsi_device != NULL;
+         p_scsi_device = p_scsi_device->next)
+    {
+        bus = (u8)(p_scsi_device->channel + 1);
+
+        if ((bus <= IPR_MAX_NUM_BUSES) &&
+            (p_scsi_device->id < IPR_MAX_NUM_TARGETS_PER_BUS) &&
+            (p_scsi_device->lun < IPR_MAX_NUM_LUNS_PER_TARGET))
+        {
+            p_lun = &ipr_cfg->shared.bus[bus].
+                target[p_scsi_device->id].lun[p_scsi_device->lun];
+        }
+
+        if (p_lun && p_lun->is_valid_entry)
+        {
+            p_resource_entry = p_lun->p_resource_entry;
+
+            if (ipr_is_vset_device(p_resource_entry))
+                p_scsi_device->queue_depth = IPR_MAX_CMD_PER_VSET;
+            else
+                p_scsi_device->queue_depth = IPR_MAX_CMD_PER_LUN;
+        }
+    }
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Fails the op back to the caller.
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static Scsi_Cmnd *ipr_fail_op(ipr_host_config *ipr_cfg,
+                                 struct ipr_cmnd* p_sis_cmnd,
+                                 Scsi_Cmnd *p_prev_scsi_cmd)
+{
+    Scsi_Cmnd *p_scsi_cmd;
+
+    /* Put onto completed queue */
+    ipr_put_sis_cmnd_to_completed(ipr_cfg, p_sis_cmnd);
+
+    p_sis_cmnd->ccb.status = 0;
+    p_sis_cmnd->ccb.completion = IPR_RC_DID_RESET;
+
+    if (p_sis_cmnd->ccb.flags & IPR_ERP_CMD)
+    {
+        ipr_end_erp(p_sis_cmnd);
+
+        p_sis_cmnd->p_scsi_cmd = p_sis_cmnd->p_saved_scsi_cmd;
+    }
+
+    p_scsi_cmd = p_sis_cmnd->p_scsi_cmd;
+
+    if (p_scsi_cmd != NULL)
+    {
+        /* Returning DID_ERROR will force the mid-layer to retry the op */
+        p_scsi_cmd->result |= (DID_ERROR << 16);
+
+        if (p_prev_scsi_cmd == NULL)
+        {
+            ipr_cfg->p_scsi_ops_to_fail =  p_scsi_cmd;
+            p_prev_scsi_cmd = p_scsi_cmd;
+        }
+        else
+        {
+            p_prev_scsi_cmd->SCp.ptr = (char *)p_scsi_cmd;
+            p_prev_scsi_cmd = p_scsi_cmd;
+        }
+        p_scsi_cmd->SCp.ptr = NULL;
+    }
+
+    return p_prev_scsi_cmd;
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Fails all outstanding ops
+ *          Any host requests that are outstanding are queued up and
+ *          the pointer to the head scsi_cmnd is setup in the global
+ *          control block. Calling this function does not call scsi_done for
+ *          host requests. It is the caller's responsibility to do this at
+ *          the appropriate time.
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_fail_all_ops(ipr_host_config *ipr_cfg)
+{
+    struct ipr_cmnd* p_sis_cmnd;
+    Scsi_Cmnd *p_prev_scsi_cmd = NULL;
+
+    ENTER;
+
+    /* Fail all ops on the pending queue */
+    while((p_sis_cmnd = ipr_cfg->qPendingH))
+    {
+        ipr_dbg;
+
+        /* Pull off of pending queue */
+        ipr_remove_sis_cmnd_from_pending(ipr_cfg, p_sis_cmnd);
+
+        /* Fail the op back to the caller */
+        p_prev_scsi_cmd = ipr_fail_op(ipr_cfg,
+                                         p_sis_cmnd,
+                                         p_prev_scsi_cmd);
+    }
+
+    /* Fail all ops on the error queue */
+    while(ipr_cfg->qErrorH)
+    {
+        ipr_dbg;
+
+        /* Pull off error queue */
+        ipr_remove_sis_cmnd_from_error(ipr_cfg, p_sis_cmnd);
+
+        /* Fail the op back to the caller */
+        p_prev_scsi_cmd = ipr_fail_op(ipr_cfg,
+                                         p_sis_cmnd,
+                                         p_prev_scsi_cmd);
+    }
+
+    ipr_ops_done(ipr_cfg);
+
+    LEAVE;
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Push all scsi_done functions to return them to the host
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_return_failed_ops(ipr_host_config *ipr_cfg)
+{
+    Scsi_Cmnd *p_next_cmnd;
+    Scsi_Cmnd *p_scsi_cmnd = ipr_cfg->p_scsi_ops_to_fail;
+
+    ENTER;
+
+    for (; p_scsi_cmnd != NULL; p_scsi_cmnd = p_next_cmnd)
+    {
+        p_next_cmnd = (Scsi_Cmnd *)p_scsi_cmnd->SCp.ptr;
+        p_scsi_cmnd->scsi_done(p_scsi_cmnd);
+    }
+
+    ipr_cfg->p_scsi_ops_to_fail = NULL;
+
+    LEAVE;
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Shutdown/Reboot notification
+ * Context: Task level only
+ * Lock State: No locks assumed to be held
+ * Returns: NOTIFY_DONE - Success
+ *---------------------------------------------------------------------------*/
+static int ipr_notify_sys(struct notifier_block *this, unsigned long code,
+                             void *unused)
+{
+    ipr_host_config *ipr_cfg = ipr_cfg_head;
+    unsigned long io_flags = 0;
+    u32 rc = 0;
+    DECLARE_WAIT_QUEUE_HEAD(internal_wait);
+    DECLARE_COMPLETION(completion);
+
+    ENTER;
+
+    spin_lock_irqsave(&io_request_lock, io_flags);
+
+    /* Loop through all the devices and issue prepare for shutdowns to them all */
+    while(ipr_cfg != NULL)
+    {
+        if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+        {
+            while(1)
+            {
+                /* Loop forever waiting for IOA to come out of reset/reload, checking once a second */
+                if ((ipr_cfg->flag & IPR_IN_RESET_RELOAD) == 0)
+                    break;
+                else 
+                    ipr_sleep_on_timeout(&io_request_lock, &internal_wait, HZ);
+            }
+        }
+
+        ipr_shutdown_ioa(ipr_cfg, IPR_SHUTDOWN_PREPARE_FOR_NORMAL);
+
+        ipr_cfg = ipr_cfg->p_next;
+    }
+
+    ipr_cfg = ipr_cfg_head;
+
+    /* Loop through all the devices and issue shutdowns to them all */
+    while(ipr_cfg != NULL)
+    {
+        if (ipr_cfg->flag & IPR_IN_RESET_RELOAD)
+        {
+            while(1)
+            {
+                /* Loop forever waiting for IOA to come out of reset/reload, checking once a second */
+                if ((ipr_cfg->flag & IPR_IN_RESET_RELOAD) == 0)
+                    break;
+                else 
+                    ipr_sleep_on_timeout(&io_request_lock, &internal_wait, HZ);
+            }
+        }
+
+        rc = ipr_shutdown_ioa(ipr_cfg, IPR_SHUTDOWN_NORMAL);
+
+        if (rc)
+        {
+            /* Delay for 5 seconds - this is to display an error message on the console
+             regarding not getting a clean shutdown to the IOA */
+            ipr_sleep(5000);
+        }
+
+        ipr_mask_interrupts(&ipr_cfg->shared);
+
+        /* Here we reset the IOA to get it back in a POR state */
+        ipr_ioa_reset(ipr_cfg, IPR_IRQ_DISABLED);
+
+        ipr_cfg = ipr_cfg->p_next;
+    }
+
+    spin_unlock_irqrestore(&io_request_lock,io_flags);
+
+    LEAVE;
+
+    return NOTIFY_DONE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Issues an IOA Shutdown command to the given IOA
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Shutdown failed
+ *          IPR_RC_QUAL_SUCCESS      - Qualified success
+ *          IPR_RC_TIMEOUT           - Shutdown timed out
+ *---------------------------------------------------------------------------*/
+static u32 ipr_shutdown_ioa(ipr_host_config *ipr_cfg,
+                               enum ipr_shutdown_type type)
+{
+    u32 rc = IPR_RC_SUCCESS;
+    struct ipr_cmnd *p_sis_cmnd;
+    u8 *p_sense_buffer;
+    u32 timeout;
+    signed long time_left;
+    bool error_log = false;
+
+    ENTER;
+
+    ipr_cfg->flag &= ~(IPR_ALLOW_HCAMS | IPR_ALLOW_REQUESTS);
+
+    if (type != IPR_SHUTDOWN_NONE)
+    {
+        if (!ipr_cfg->shared.ioa_operational ||
+            !ipr_cfg->shared.allow_interrupts ||
+            ipr_cfg->shared.ioa_is_dead)
+            return IPR_RC_QUAL_SUCCESS;
+
+        p_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+
+        p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+        p_sis_cmnd->ccb.p_resource = &ipr_cfg->shared.ioa_resource;
+
+        p_sis_cmnd->ccb.cmd_len = 10;
+
+        p_sis_cmnd->ccb.cdb[0] = IPR_IOA_SHUTDOWN;
+
+        if (type == IPR_SHUTDOWN_ABBREV)
+        {
+            p_sis_cmnd->ccb.cdb[1] = 0x80;
+            timeout = IPR_ABBREV_SHUTDOWN_TIMEOUT;
+        }
+        else if (type == IPR_SHUTDOWN_PREPARE_FOR_NORMAL)
+        {
+            p_sis_cmnd->ccb.cdb[1] = 0x40;
+            timeout = IPR_SHUTDOWN_TIMEOUT;
+        }
+        else
+        {
+            timeout = IPR_SHUTDOWN_TIMEOUT;
+        }
+
+        p_sis_cmnd->ccb.data_direction = IPR_DATA_NONE;
+
+        p_sis_cmnd->ccb.flags = IPR_BLOCKING_COMMAND;
+
+        ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+
+        rc = ipr_ioa_queue(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+
+        if (rc == IPR_RC_OP_NOT_SENT)
+        {
+            ipr_trace;
+            return IPR_RC_FAILED;
+        }
+
+        init_waitqueue_head(&p_sis_cmnd->wait_q);
+
+        time_left = ipr_sleep_on_timeout(&io_request_lock, &p_sis_cmnd->wait_q, timeout);
+
+        if (time_left <= 0)
+        {
+            /* The op timed out. The IOA still "owns" the command block, therefore
+             we can't free it and can't do retries */
+            p_sis_cmnd->ccb.flags |= IPR_TIMED_OUT;
+            rc = IPR_RC_TIMEOUT;
+            ipr_mask_interrupts(&ipr_cfg->shared);
+        }
+        else
+        {
+            /* We have a valid sense buffer */
+            if (ipr_sense_valid(p_sense_buffer[0]) &&
+                sense_error(p_sense_buffer[2]) == 0)
+            {
+                /* Op completed successfully with qualified success */
+                rc = IPR_RC_QUAL_SUCCESS;
+            }
+            else
+            {
+                rc = p_sis_cmnd->ccb.completion;
+            }
+        }
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            error_log = true;
+
+            if (rc == IPR_RC_TIMEOUT)
+            {
+                ipr_beg_err(KERN_WARNING);
+                ipr_log_warn("Shutdown to IOA timed out."IPR_EOL);
+            }
+            else if (rc == IPR_RC_QUAL_SUCCESS)
+            {
+                ipr_beg_err(KERN_WARNING);
+                ipr_log_warn("Shutdown to IOA did not complete successfully."IPR_EOL);
+            }
+            else if (sense_error(p_sense_buffer[2]) != 0x05)
+            {
+                ipr_beg_err(KERN_WARNING);
+                ipr_log_warn("Shutdown to IOA failed with RC: 0x%X."IPR_EOL, rc);
+                ipr_log_warn("SK: 0x%02X, SC: 0x%02X, SQ: 0x%02X"IPR_EOL,
+                                sense_error(p_sense_buffer[2]), p_sense_buffer[12], p_sense_buffer[13]);
+            }
+            else
+            {
+                error_log = false;
+            }
+
+            if (error_log)
+            {
+                ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_WARNING);
+                ipr_end_err(KERN_WARNING)
+            }
+        }
+
+        if (rc != IPR_RC_TIMEOUT)
+            ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+    }
+
+    LEAVE;
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Op done function for an IOCTL
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_ioctl_cmd_done(struct ipr_shared_config *p_shared_cfg,
+                                  struct ipr_ccb *p_sis_ccb)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+
+    p_sis_cmnd = (struct ipr_cmnd *)p_sis_ccb;
+
+    p_sis_cmnd->ccb.flags |= IPR_FINISHED;
+
+    wake_up(&p_sis_cmnd->wait_q);
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Sends an internal request to the requested resource and sleeps
+ *          until a response is received or is timed out.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Shutdown failed
+ *          IPR_RC_QUAL_SUCCESS      - Qualified success
+ *---------------------------------------------------------------------------*/
+static u32 ipr_send_blocking_ioctl(ipr_host_config *ipr_cfg,
+                                    struct ipr_cmnd *p_sis_cmnd,
+                                    u32 timeout,
+                                    u8 retries)
+{
+    u32 rc = IPR_RC_SUCCESS;
+    u8 *p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+    u16 flags = p_sis_cmnd->ccb.flags;
+
+    for (;retries; retries--)
+    {
+        p_sis_cmnd->ccb.flags = flags;
+
+        p_sis_cmnd->ccb.completion = IPR_RC_SUCCESS;
+        p_sis_cmnd->ccb.status = 0;
+
+        memset(p_sense_buffer, 0, IPR_SENSE_BUFFERSIZE);
+
+        init_waitqueue_head(&p_sis_cmnd->wait_q);
+
+        rc = ipr_do_req(&ipr_cfg->shared, &p_sis_cmnd->ccb,
+                           ipr_ioctl_cmd_done, timeout/HZ);
+
+        if (rc)
+        {
+            ipr_dbg_trace;
+            return IPR_RC_FAILED;
+        }
+
+        ipr_sleep_on(&io_request_lock, &p_sis_cmnd->wait_q);
+
+        if (p_sis_cmnd->ccb.completion == IPR_RC_DID_RESET)
+        {
+            ipr_dbg_trace;
+            return IPR_RC_FAILED;
+        }
+
+        if (p_sis_cmnd->ccb.completion != IPR_RC_SUCCESS)
+        {
+            /* We have a valid sense buffer */
+            if (ipr_sense_valid(p_sense_buffer[0]) &&
+                sense_error(p_sense_buffer[2]) == 0)
+            {
+                /* Op completed successfully with qualified success */
+                rc = IPR_RC_QUAL_SUCCESS;
+                break;
+            }
+            else
+            {
+                ipr_dbg_trace;
+                rc = IPR_RC_FAILED;
+            }
+        }
+        else
+            break;
+    }
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send an HCAM to the IOA
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *---------------------------------------------------------------------------*/
+u32 ipr_send_hcam(struct ipr_shared_config *p_shared_cfg, u8 type,
+                     struct ipr_hostrcb *p_hostrcb)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    ipr_host_config *ipr_cfg = (ipr_host_config *)p_shared_cfg;
+
+    if (ipr_cfg->flag & IPR_ALLOW_HCAMS)
+    {
+        p_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+        ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+        p_sis_cmnd->ccb.p_resource = &ipr_cfg->shared.ioa_resource;
+        p_sis_cmnd->ccb.cdb[0] = IPR_HOST_CONTROLLED_ASYNC;
+        p_sis_cmnd->ccb.cdb[1] = type;
+        p_sis_cmnd->ccb.cdb[7] = (sizeof(struct ipr_hostrcb) >> 8) & 0xff;
+        p_sis_cmnd->ccb.cdb[8] = sizeof(struct ipr_hostrcb) & 0xff;
+        p_sis_cmnd->ccb.buffer = p_hostrcb;
+        p_sis_cmnd->ccb.buffer_dma = ipr_get_hcam_dma_addr(ipr_cfg, p_hostrcb);
+        p_sis_cmnd->ccb.bufflen = sizeof(struct ipr_hostrcb);
+        p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+        p_sis_cmnd->ccb.cmd_len = 10;
+        p_sis_cmnd->ccb.use_sg = 1;
+        p_sis_cmnd->ccb.sglist[0].address = (u32)p_sis_cmnd->ccb.buffer_dma;
+        p_sis_cmnd->ccb.sglist[0].length = sizeof(struct ipr_hostrcb);
+
+        ipr_ioa_queue(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+    }
+    return IPR_RC_SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Free all allocated resources
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_free_all_resources(ipr_host_config *ipr_cfg,
+                                      int free_reboot_notif, int free_chrdev)
+{
+    struct pci_dev *pdev;
+    int i;
+
+    pdev = ipr_cfg->pdev;
+
+    ENTER;
+
+    spin_unlock_irq(&io_request_lock);
+    free_irq (ipr_cfg->host->irq, ipr_cfg);
+    spin_lock_irq(&io_request_lock);
+
+    ipr_kfree(ipr_cfg->shared.resource_entry_list,
+                 sizeof(struct ipr_resource_dll) * IPR_MAX_PHYSICAL_DEVS);
+    ipr_dma_free(&ipr_cfg->shared, sizeof(struct ipr_vpd_cbs),
+                    ipr_cfg->shared.p_vpd_cbs,
+                    ipr_cfg->shared.ioa_vpd_dma);
+
+    ipr_kfree(ipr_cfg->shared.p_page_28,
+                 sizeof(struct ipr_page_28_data));
+
+    ipr_dma_free(&ipr_cfg->shared, sizeof(struct ipr_element_desc_page) * IPR_MAX_NUM_BUSES,
+                    ipr_cfg->shared.p_ses_data[0], ipr_cfg->shared.ses_data_dma[0]);
+
+    if (ipr_cfg->sis_cmnd_list[0])
+    {
+        /* Free sense buffers and command blocks */
+        ipr_dma_free(&ipr_cfg->shared, IPR_SENSE_BUFFERSIZE * IPR_NUM_CMD_BLKS,
+                        ipr_cfg->sis_cmnd_list[0]->ccb.sense_buffer,
+                        ipr_cfg->sis_cmnd_list[0]->ccb.sense_buffer_dma);
+    }
+
+    for (i=0; i < IPR_NUM_CMD_BLKS; i++)
+        ipr_kfree(ipr_cfg->sis_cmnd_list[i],
+                     sizeof(struct ipr_cmnd));
+
+    ipr_dma_free(&ipr_cfg->shared, sizeof(struct ipr_hostrcb) * IPR_NUM_HCAMS,
+                    ipr_cfg->hostrcb[0], ipr_cfg->hostrcb_dma[0]);
+
+    if (ipr_cfg->p_ioa_cfg->sdt_reg_sel_size == IPR_SDT_REG_SEL_SIZE_1BYTE)
+    {
+        iounmap((void *)ipr_cfg->shared.hdw_bar_addr[3]);
+        release_mem_region(ipr_cfg->shared.hdw_bar_addr_pci[3],
+                           pci_resource_len(pdev, 3));
+
+        iounmap((void *)ipr_cfg->shared.hdw_bar_addr[2]);
+        release_mem_region(ipr_cfg->shared.hdw_bar_addr_pci[2],
+                           pci_resource_len(pdev, 2));
+    }
+
+    iounmap((void *)ipr_cfg->shared.hdw_dma_regs);
+    release_mem_region(ipr_cfg->shared.hdw_dma_regs_pci,
+                       pci_resource_len(pdev,ipr_cfg->p_ioa_cfg->bar_index));
+
+    if (free_chrdev)
+        devfs_unregister_chrdev(ipr_cfg->major_num, "ipr");
+
+    ipr_kfree(ipr_cfg->shared.p_location, sizeof(struct ipr_location_data));
+    ipr_free_mem(&ipr_cfg->shared);
+
+    if (free_reboot_notif)
+    {
+        unregister_reboot_notifier(&ipr_notifier);
+        unregister_ioctl32_conversion(IPR_IOCTL_SEND_COMMAND);
+    }
+
+    scsi_unregister(ipr_cfg->host);
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Log Data Handler
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_handle_log_data(ipr_host_config *ipr_cfg,
+                                   struct ipr_hostrcb *p_hostrcb)
+{
+    u32 error_index;
+    u16 ccin = ipr_cfg->shared.ccin;
+    int i, j;
+    struct ipr_resource_entry *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll;
+    u16 device_ccin;
+    char error_buffer[100];
+    int size = 0;
+    int len = 0;
+    char temp_ccin[5];
+    u32 errors_logged;
+    struct ipr_hostrcb_device_data_entry *p_dev_entry;
+    struct ipr_hostrcb_array_data_entry *p_array_entry;
+    int ioa_data_len;
+    u16 urc;
+    enum ipr_error_class err_class;
+    u32 class_index, ioasc;
+    char *printk_level;
+    char error_string[100];
+    u8 service_level = 0;
+    struct ipr_inquiry_page3 *p_ucode_vpd;
+    u8 *p_end_data;
+
+    temp_ccin[4] = '\0';
+
+    if (p_hostrcb->notificationType == IPR_HOST_RCB_NOTIF_TYPE_ERROR_LOG_ENTRY)
+    {
+        ioasc = sistoh32(p_hostrcb->data.error.failing_dev_ioasc);
+
+        if ((ioasc == IPR_IOASC_BUS_WAS_RESET) ||
+            (ioasc == IPR_IOASC_BUS_WAS_RESET_BY_OTHER))
+        {
+            /* Tell the midlayer we had a bus reset so it will handle the UA properly */
+            scsi_report_bus_reset(ipr_cfg->host,
+                                  p_hostrcb->data.error.failing_dev_res_addr.bus);
+        }
+
+        error_index = ipr_get_error(ioasc);
+
+        err_class = ipr_error_table[error_index].err_class;
+
+        for (class_index = 0; class_index < IPR_ERR_CLASS_MAX_CLASS; class_index++)
+            if (err_class == ipr_error_class_table[class_index].err_class)
+                break;
+
+        printk_level = ipr_error_class_table[class_index].printk_level;
+
+        if (error_index == 0)
+        {
+            /* IOASC was not found in the table */
+            ipr_beg_err(printk_level);
+            ipr_hcam_log("SRC: unknown");
+            ipr_hcam_log("Class: %s", ipr_error_class_table[class_index].p_class);
+            ipr_hcam_log("%s", ipr_error_table[error_index].p_error);
+            strncpy(error_buffer,
+                    ipr_cfg->shared.p_ioa_vpd->std_inq_data.serial_num,
+                    sizeof(ipr_cfg->shared.p_ioa_vpd->std_inq_data.serial_num));
+            error_buffer[sizeof(ipr_cfg->shared.p_ioa_vpd->std_inq_data.serial_num)] = '\0';
+            ipr_hcam_log("IOA Serial Number: %s", error_buffer);
+
+            ipr_get_ioa_name(ipr_cfg, error_buffer);
+            ipr_hcam_log("IOA is %s", error_buffer);
+
+            ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, printk_level);
+        }
+        else if (p_hostrcb->data.error.failing_dev_resource_handle == IPR_IOA_RESOURCE_HANDLE)
+        {
+            urc = ipr_adjust_urc(error_index,
+                                    p_hostrcb->data.error.failing_dev_res_addr,
+                                    ioasc,
+                                    0,
+                                    error_string);
+            if (urc == 0) 
+                return;
+
+            /* If this is an 8151 with this specific PRC and this is a 2780, it probably
+             needs a code download - lets eat the error and try to bring up the IOA again */
+            if ((urc == 0x8151) && (sistoh32(p_hostrcb->data.error.prc) == 0x14006262u) &&
+                !ipr_cfg->shared.needs_download &&
+                (ipr_cfg->shared.vendor_id == PCI_VENDOR_ID_IBM) &&
+                (ipr_cfg->shared.device_id == PCI_DEVICE_ID_IBM_SNIPE) &&
+                (ipr_cfg->shared.subsystem_id == IPR_SUBS_DEV_ID_2780))
+            {
+                ipr_cfg->shared.needs_download = 1;
+                return;
+            }
+
+            /* If we are currently running in the wrong mode, ignore 9001 errors */
+            if (ipr_cfg->shared.nr_ioa_microcode && (urc == 0x9001))
+                return;
+
+            ipr_beg_err(printk_level);
+            ipr_hcam_log("SRC: %X %04X", ccin, urc);
+            ipr_hcam_log("Class: %s", ipr_error_class_table[class_index].p_class);
+            ipr_hcam_log("%s", error_string);
+
+            strncpy(error_buffer,
+                    ipr_cfg->shared.p_ioa_vpd->std_inq_data.serial_num,
+                    sizeof(ipr_cfg->shared.p_ioa_vpd->std_inq_data.serial_num));
+            error_buffer[sizeof(ipr_cfg->shared.p_ioa_vpd->std_inq_data.serial_num)] = '\0';
+            ipr_hcam_log("IOA Serial Number: %s", error_buffer);
+
+            if ((p_hostrcb->data.error.failing_dev_res_addr.bus <
+                 IPR_MAX_NUM_BUSES) &&
+                (p_hostrcb->data.error.failing_dev_res_addr.target <
+                 IPR_MAX_NUM_TARGETS_PER_BUS) &&
+                (p_hostrcb->data.error.failing_dev_res_addr.lun <
+                 IPR_MAX_NUM_LUNS_PER_TARGET))
+            {
+                ipr_log_dev_physical_location(&ipr_cfg->shared,
+                                                 p_hostrcb->data.error.failing_dev_res_addr,
+                                                 printk_level);
+            }
+            else
+            {
+                ipr_log_ioa_physical_location(ipr_cfg->shared.p_location,
+                                                 printk_level);
+            }
+        }
+        else
+        {
+            urc = ipr_adjust_urc(error_index,
+                                    p_hostrcb->data.error.failing_dev_res_addr,
+                                    ioasc,
+                                    1,
+                                    error_string);
+
+            if (urc == 0)
+                return;
+
+            ipr_beg_err(printk_level);
+
+            device_ccin = 0x6600;
+            service_level = 1;
+
+            /* Loop through config table to find device */
+            for (p_resource_dll = ipr_cfg->shared.rsteUsedH;
+                 p_resource_dll != NULL;
+                 p_resource_dll = p_resource_dll->next)
+            {
+                p_resource_entry = &p_resource_dll->data;
+
+                if (p_resource_entry->resource_handle ==
+                    p_hostrcb->data.error.failing_dev_resource_handle)
+                {
+                    device_ccin = p_resource_entry->type;
+                    service_level = p_resource_entry->level;
+                    break;
+                }
+            }
+
+            ipr_hcam_log("SRC: %04X %04X", device_ccin, urc);
+            ipr_hcam_log("Class: %s", ipr_error_class_table[class_index].p_class);
+            ipr_hcam_log("%s", error_string);
+
+            ipr_log_dev_physical_location(&ipr_cfg->shared,
+                                             p_hostrcb->data.error.failing_dev_res_addr,
+                                             printk_level);
+
+            if (p_resource_entry != NULL)
+            {
+                ipr_hcam_log("Device Serial Number: %s", p_resource_entry->serial_num);
+                ipr_log_dev_vpd(p_resource_entry, printk_level);
+                if (p_resource_entry->is_af && (device_ccin != 0x6600))
+                    ipr_hcam_log("Device Service Level: %X", service_level);
+            }
+        }
+
+        ipr_hcam_log("IOASC: 0x%08X", ioasc);
+        ipr_hcam_log("PRC: 0x%08X", sistoh32(p_hostrcb->data.error.prc));
+
+        p_ucode_vpd = ipr_cfg->shared.p_ucode_vpd;
+
+        ipr_hcam_log("Driver version: "IPR_FULL_VERSION);
+        ipr_hcam_log("IOA Firmware version: %02X%02X%02X%02X",
+                        p_ucode_vpd->major_release, p_ucode_vpd->card_type,
+                        p_ucode_vpd->minor_release[0], p_ucode_vpd->minor_release[1]);
+        ipr_hcam_log("IOA revision id: %d", ipr_cfg->shared.chip_rev_id);
+
+        switch (p_hostrcb->overlayId)
+        {
+            case IPR_HOST_RCB_OVERLAY_ID_1:
+                ipr_hcam_log("Predictive Analysis Seeks/256 counter: %d",
+                                sistoh32(p_hostrcb->data.error.data.type_01_error.seek_counter));
+                ipr_hcam_log("Predictive Analysis Sectors Read/256 counter: %d",
+                                sistoh32(p_hostrcb->data.error.data.type_01_error.read_counter));
+
+                size = len = 0;
+                for (i = 0; i < 32; i++)
+                {
+                    size = sprintf(error_buffer + len, "%02X ",
+                                   p_hostrcb->data.error.data.type_01_error.sense_data[i]);
+                     len += size;
+                }
+                error_buffer[len] = '\0';
+                ipr_hcam_log("SCSI Sense Data: %s", error_buffer);
+
+                ioa_data_len = sistoh32(p_hostrcb->length )-
+                    ((u8 *)&p_hostrcb->data.error.data.type_01_error.ioa_data -
+                     (u8 *)&p_hostrcb->data.error);
+
+                if (ioa_data_len == 0)
+                {
+                    ipr_end_err(printk_level);
+                    break;
+                }
+                ipr_hcam_log("IOA Error Data:");
+                ipr_hcam_log("Offset              0 1 2 3  4 5 6 7  8 9 A B  C D E F");
+
+                /* We print out the hex so we get 4 words per line */
+                for (i = 0; i < ioa_data_len/4; i += 4)
+                {
+                    len = size = 0;
+                    for (j = 0; (j < 4) && ((i + j) < ioa_data_len/4); j++)
+                    {
+                        size = sprintf(error_buffer + len, "%08X ",
+                                       sistoh32(p_hostrcb->data.error.data.type_01_error.ioa_data[i + j]));
+                        len += size;
+                    }
+
+                    printk("%s"IPR_ERR": %08X            %s"IPR_EOL, printk_level, (i * 4),
+                           error_buffer);
+                }
+                ipr_end_err(printk_level);
+                break;
+            case IPR_HOST_RCB_OVERLAY_ID_2:
+
+                ipr_hcam_log("Current Configuration:");
+                ipr_hcam_log("  I/O Processor Information:");
+                ipr_print_ioa_vpd(&p_hostrcb->data.error.data.type_02_error.ioa_vpids, printk_level);
+                strncpy(error_buffer,
+                        p_hostrcb->data.error.data.type_02_error.ioa_sn,
+                        sizeof(p_hostrcb->data.error.data.type_02_error.ioa_sn));
+                error_buffer[sizeof(p_hostrcb->data.error.data.type_02_error.ioa_sn)] = '\0';
+                ipr_hcam_log("   Serial Number: %s", error_buffer);
+
+                ipr_hcam_log("  Cache Adapter Card Information:");
+                ipr_print_ioa_vpd(&p_hostrcb->data.error.data.type_02_error.cfc_vpids, printk_level);
+                strncpy(error_buffer,
+                        p_hostrcb->data.error.data.type_02_error.cfc_sn,
+                        sizeof(p_hostrcb->data.error.data.type_02_error.cfc_sn));
+                error_buffer[sizeof(p_hostrcb->data.error.data.type_02_error.cfc_sn)] = '\0';
+                ipr_hcam_log("   Serial Number: %s", error_buffer);
+
+                ipr_hcam_log("Expected Configuration:");
+                ipr_hcam_log("  I/O Processor Information:");
+                ipr_print_ioa_vpd(&p_hostrcb->data.error.data.type_02_error.ioa_last_attached_to_cfc_vpids,
+                                     printk_level);
+
+                strncpy(error_buffer,
+                        p_hostrcb->data.error.data.type_02_error.ioa_last_attached_to_cfc_sn,
+                        sizeof(p_hostrcb->data.error.data.type_02_error.ioa_last_attached_to_cfc_sn));
+                error_buffer[sizeof(p_hostrcb->data.error.data.type_02_error.ioa_last_attached_to_cfc_sn)] = '\0';
+                ipr_hcam_log("   Serial Number: %s", error_buffer);
+
+                ipr_hcam_log("  Cache Adapter Card Information:");
+                ipr_print_ioa_vpd(&p_hostrcb->data.error.data.type_02_error.cfc_last_attached_to_ioa_vpids,
+                                     printk_level);
+
+                strncpy(error_buffer,
+                        p_hostrcb->data.error.data.type_02_error.cfc_last_attached_to_ioa_sn,
+                        sizeof(p_hostrcb->data.error.data.type_02_error.cfc_last_attached_to_ioa_sn));
+                error_buffer[sizeof(p_hostrcb->data.error.data.type_02_error.cfc_last_attached_to_ioa_sn)] = '\0';
+                ipr_hcam_log("   Serial Number: %s", error_buffer);
+
+                ipr_hcam_log("Additional IOA Data: %08X %08X %08X",
+                                sistoh32(p_hostrcb->data.error.data.type_02_error.ioa_data[0]),
+                                sistoh32(p_hostrcb->data.error.data.type_02_error.ioa_data[1]),
+                                sistoh32(p_hostrcb->data.error.data.type_02_error.ioa_data[2]));
+                ipr_end_err(printk_level);
+                break;
+            case IPR_HOST_RCB_OVERLAY_ID_3:
+
+                ipr_hcam_log("Device Errors Detected: %d",
+                                sistoh32(p_hostrcb->data.error.data.type_03_error.errors_detected));
+
+                errors_logged = sistoh32(p_hostrcb->data.error.data.type_03_error.errors_logged);
+                ipr_hcam_log("Device Errors Logged: %d", errors_logged);
+
+                for (i = 0, p_dev_entry = p_hostrcb->data.error.data.type_03_error.dev_entry;
+                     i < errors_logged; i++, p_dev_entry++)
+                {
+                    ipr_err_separator;
+                    ipr_hcam_log("Device %d:", i+1);
+
+                    if (p_dev_entry->dev_res_addr.bus >= IPR_MAX_NUM_BUSES)
+                    {
+                        ipr_print_unknown_dev_phys_loc(printk_level);
+                    }
+                    else
+                    {
+                        ipr_log_dev_physical_location(&ipr_cfg->shared,
+                                                         p_dev_entry->dev_res_addr,
+                                                         printk_level);
+                    }
+
+
+                    ipr_log_array_dev_vpd(&p_dev_entry->dev_vpids, "6600", printk_level);
+                    strncpy(error_buffer, p_dev_entry->dev_sn, sizeof(p_dev_entry->dev_sn));
+                    error_buffer[sizeof(p_dev_entry->dev_sn)] = '\0';
+                    ipr_hcam_log("    Serial Number: %s", error_buffer);
+                    ipr_hcam_log(" New Device Information:");
+
+                    ipr_log_array_dev_vpd(&p_dev_entry->new_dev_vpids, "****", printk_level);
+
+                    strncpy(error_buffer, p_dev_entry->new_dev_sn, sizeof(p_dev_entry->new_dev_sn));
+                    error_buffer[sizeof(p_dev_entry->new_dev_sn)] = '\0';
+                    ipr_hcam_log("    Serial Number: %s", error_buffer);
+
+                    ipr_hcam_log(" I/O Processor Information:");
+                    ipr_print_ioa_vpd(&p_dev_entry->ioa_last_with_dev_vpids, printk_level);
+                    strncpy(error_buffer,p_dev_entry->ioa_last_with_dev_sn,
+                            sizeof(p_dev_entry->ioa_last_with_dev_sn));
+                    error_buffer[sizeof(p_dev_entry->ioa_last_with_dev_sn)] = '\0';
+                    ipr_hcam_log("    Serial Number: %s", error_buffer);
+
+                    ipr_hcam_log(" Cache Adapter Card Information:");
+                    ipr_print_ioa_vpd(&p_dev_entry->cfc_last_with_dev_vpids, printk_level);
+
+                    strncpy(error_buffer,p_dev_entry->cfc_last_with_dev_sn,
+                            sizeof(p_dev_entry->cfc_last_with_dev_sn));
+                    error_buffer[sizeof(p_dev_entry->cfc_last_with_dev_sn)] = '\0';
+                    ipr_hcam_log("    Serial Number: %s", error_buffer);
+                    ipr_hcam_log(" Additional IOA Data: %08X %08X %08X %08X %08X",
+                                  sistoh32(p_dev_entry->ioa_data[0]), sistoh32(p_dev_entry->ioa_data[1]),
+                                  sistoh32(p_dev_entry->ioa_data[2]), sistoh32(p_dev_entry->ioa_data[3]),
+                                  sistoh32(p_dev_entry->ioa_data[4]));
+                }
+                ipr_end_err(printk_level);
+                break;
+            case IPR_HOST_RCB_OVERLAY_ID_4:
+            case IPR_HOST_RCB_OVERLAY_ID_6:
+                ipr_err_separator;
+                p_end_data = (u8 *)&p_hostrcb->data.error + sistoh32(p_hostrcb->length);
+
+                for (i = 0,
+                     p_array_entry = p_hostrcb->data.error.data.type_04_error.array_member;
+                     ((i < 18) && ((unsigned long)p_array_entry < (unsigned long)p_end_data));
+                     (++i == 10) ?
+                     p_array_entry = p_hostrcb->data.error.data.type_04_error.array_member2:
+                     p_array_entry++)
+                {
+                    strncpy(error_buffer, p_array_entry->serial_num,
+                            sizeof(p_array_entry->serial_num));
+                    error_buffer[sizeof(p_array_entry->serial_num)] = '\0';
+
+                    if (!strcmp(error_buffer, "00000000"))
+                        continue;
+
+                    ipr_hcam_log("Array Member %d:", i);
+                    ipr_log_array_dev_vpd(&p_array_entry->vpids, "****", printk_level);
+                    ipr_hcam_log("   Serial Number: %s", error_buffer);
+
+                    ipr_log_dev_current_expected_locations(ipr_cfg,
+                                                              p_array_entry->dev_res_addr,
+                                                              p_array_entry->expected_dev_res_addr,
+                                                              printk_level);
+
+                    ipr_err_separator;
+                }
+
+                ipr_end_err(printk_level);
+                break; 
+            case IPR_HOST_RCB_OVERLAY_ID_DEFAULT:
+                ipr_hcam_log("IOA Error Data:");
+                ipr_hcam_log("Offset              0 1 2 3  4 5 6 7  8 9 A B  C D E F");
+
+                ioa_data_len = sistoh32(p_hostrcb->length )-
+                    ((u8 *)&p_hostrcb->data.error.data.type_ff_error.ioa_data -
+                     (u8 *)&p_hostrcb->data.error);
+
+                /* We print out the hex they way we do so we get 4 words per line */
+                for (i = 0; i < ioa_data_len/4; i += 4)
+                {
+                    len = size = 0;
+                    for (j = 0; (j < 4) && ((i + j) < ioa_data_len/4); j++)
+                    {
+                        size = sprintf(error_buffer + len, "%08X ",
+                                       sistoh32(p_hostrcb->data.error.data.type_ff_error.ioa_data[i + j]));
+                        len += size;
+                    }
+                    ipr_hcam_log("%08X            %s", (i * 4), error_buffer);
+                }
+                ipr_end_err(printk_level);
+                break;
+            default:
+                break;
+        }
+    }
+    else /* Informational */
+    {
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Returns index of ioasc in error structure
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: index       - index of ioasc into error table
+ *---------------------------------------------------------------------------*/
+static u32 ipr_get_error(u32 ioasc)
+{
+    int i;
+
+    for (i = 0; i < sizeof(ipr_error_table)/sizeof(struct ipr_error_table_t); i++)
+        if (ipr_error_table[i].ioasc == ioasc)
+            return i;
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: IOCTL interface 
+ * Context: Task level only
+ * Lock State: No locks assumed to be held
+ * Returns: 0           - Success
+ *          -ENXIO      - No such file or device
+ *          -EINVAL     - Invalid parameter
+ *          -ENOMEM     - Out of memory
+ *          others
+ *---------------------------------------------------------------------------*/
+static int ipr_ioctl(struct inode *inode, struct file *filp,
+                            unsigned int cmd, unsigned long arg)
+{
+    int rc = IPR_RC_SUCCESS;
+    ipr_host_config *ipr_cfg;
+    char cmnd[MAX_COMMAND_SIZE];
+    struct ipr_ioctl_cmd_type2 ioa_cmd;
+    int result = 0;
+    u32 timeout, length, dsa, ua, frame_id;
+    u8 *p_sense_buffer, *p_buffer;
+    struct scatterlist *scatterlist;
+    struct ipr_dnload_sglist *p_scatterlist;
+    struct ipr_cmnd *p_sis_cmnd, *p_loop_cmnd;
+    struct ipr_res_addr res_addr;
+    int i, j;
+    struct ipr_resource_dll *p_resource_dll;
+    struct ipr_resource_entry *p_resource, *p_loop_resource;
+    void  *p_cmd_buffer;
+    ipr_dma_addr p_cmd_buffer_dma;
+    u32 bus_num, target_num, lun_num;
+    u32 *trace_block_address, trace_block_length;
+    struct ipr_lun lun;
+    struct ipr_resource_hdr *p_resource_hdr;
+    u32 num_entries;
+    int copy_length;
+    unsigned long io_flags = 0;
+    void  *p_page_28_data;
+    struct ipr_mode_parm_hdr *p_mode_parm_header;
+    struct ipr_mode_page_28_header *p_modepage_28_header;
+    int dev_entry_length, mode_data_length;
+    struct ipr_mode_page_28_scsi_dev_bus_attr *p_dev_bus_entry;
+    struct ipr_driver_cfg *p_driver_cfg;
+    char *p_char;
+    u8 *p_defect_list_hdr;
+    u32 resource_handle, evaluate_quiece_time;
+    struct ipr_lun *p_lun;
+    struct ipr_dump_ioa_entry *p_dump_ioa_entry;
+    struct ipr_dump_driver_header *p_dump_driver_header;
+    int offline_dump = 0;
+
+    /* Have we been opened? */
+    if (filp->private_data == NULL)
+        return -ENXIO;
+
+    ipr_cfg = filp->private_data;
+
+    memset(cmnd, 0, sizeof(char) * MAX_COMMAND_SIZE);
+
+    /* If this is not the IOCTL we expect, fail it */
+    if (cmd != IPR_IOCTL_SEND_COMMAND)
+        return -EINVAL;
+
+    if ((result = copy_from_user(&ioa_cmd, (const void *)arg, sizeof(struct ipr_ioctl_cmd_type2))))
+    {
+        ipr_log_err("Copy from user failed"IPR_EOL);
+        return result;
+    }
+
+    /* Sanity check the callers command block */
+    if (ioa_cmd.type != IPR_IOCTL_TYPE_2)
+    {
+        ipr_log_err("Invalid or deprecated ioctl type. Please update your utilities."IPR_EOL);
+        return -EINVAL;
+    }
+
+    /* The user's data buffer immediately follows the command block */
+    p_buffer = (u8 *)(arg + sizeof(struct ipr_ioctl_cmd_type2));
+    cmd = ioa_cmd.cdb[0];
+
+    if (ioa_cmd.device_cmd)
+    {
+        bus_num = (u8)(ioa_cmd.resource_address.bus + 1);
+        target_num = ioa_cmd.resource_address.target;
+        lun_num = ioa_cmd.resource_address.lun;
+
+        if ((bus_num < (IPR_MAX_NUM_BUSES + 1)) &&
+            (target_num < IPR_MAX_NUM_TARGETS_PER_BUS) &&
+            (lun_num < IPR_MAX_NUM_LUNS_PER_TARGET))
+        {
+            lun = ipr_cfg->shared.bus[bus_num].target[target_num].lun[lun_num];
+
+            if (lun.is_valid_entry)
+            {
+                p_resource = lun.p_resource_entry;
+            }
+            else
+            {
+                ipr_log_err("Invalid resource address: 00%02X%02X%02X"IPR_EOL,
+                               ioa_cmd.resource_address.bus,
+                               ioa_cmd.resource_address.target,
+                               ioa_cmd.resource_address.lun);
+                return -EINVAL;
+            }
+        }
+        else
+        {
+            ipr_log_err("Invalid resource address: 00%02X%02X%02X"IPR_EOL,
+                           ioa_cmd.resource_address.bus,
+                           ioa_cmd.resource_address.target,
+                           ioa_cmd.resource_address.lun);
+            return -EINVAL;
+        }
+    }
+    else
+    {
+        p_resource = &ipr_cfg->shared.ioa_resource;
+    }
+
+    if (ioa_cmd.driver_cmd)
+    {
+        switch (cmd)
+        {
+            case IPR_DUMP_IOA:
+                if (ioa_cmd.buffer_len < IPR_MIN_DUMP_SIZE)
+                {
+                    ipr_log_err("Invalid buffer length on dump ioa %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    result = -EINVAL;
+                }
+                else if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on dump ioa failed"IPR_EOL);
+                }
+                else
+                {
+                    p_dump_ioa_entry = ipr_kcalloc(sizeof(struct ipr_dump_ioa_entry),
+                                                      IPR_ALLOC_CAN_SLEEP);
+
+                    if (p_dump_ioa_entry == NULL)
+                    {
+                        ipr_log_err("Dump memory allocation failed"IPR_EOL);
+                        result = -ENOMEM;
+                        break;
+                    }
+
+                    p_dump_driver_header = ipr_kcalloc(sizeof(struct ipr_dump_driver_header),
+                                                          IPR_ALLOC_CAN_SLEEP);
+
+                    if (p_dump_driver_header == NULL)
+                    {
+                        ipr_log_err("Dump memory allocation failed"IPR_EOL);
+                        result = -ENOMEM;
+                        ipr_kfree(p_dump_ioa_entry,
+                                     sizeof(struct ipr_dump_ioa_entry));
+                        break;
+                    }
+
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+
+                    if (INACTIVE != ipr_get_sdt_state)
+                    {
+                        ipr_log_err("Invalid request, dump ioa already active"IPR_EOL);
+                        result = -EIO;
+                    }
+                    else
+                    {
+                        p_ipr_dump_ioa_entry = p_dump_ioa_entry;
+                        p_ipr_dump_driver_header = p_dump_driver_header;
+
+                        /* check for offline adapters requiring dump to be
+                         taken */
+                        for (ipr_cfg = ipr_cfg_head;
+                             ipr_cfg != NULL;
+                             ipr_cfg = ipr_cfg->p_next)
+                        {
+                            if ((ipr_cfg->shared.ioa_is_dead) &&
+                                !(ipr_cfg->shared.offline_dump))
+                                
+                            {
+                                ipr_get_ioa_smart_dump(ipr_cfg);
+                                ipr_cfg->shared.offline_dump = 1;
+                                offline_dump = 1;
+                            }
+                        }
+
+
+                        if (!offline_dump)
+                        {
+                            init_waitqueue_head(&ipr_sdt_wait_q);
+
+                            ipr_get_sdt_state = WAIT_FOR_DUMP;
+
+                            while (1)
+                            {
+                                ipr_interruptible_sleep_on(&io_request_lock, &ipr_sdt_wait_q);
+
+                                if (signal_pending(current))
+                                {
+                                    if (GET_DUMP == ipr_get_sdt_state)
+                                    {
+                                        /* Simply flush the signal and go back to sleep if we are
+                                         currently getting a dump */
+                                        md_flush_signals();
+                                    }
+                                    else
+                                        break;
+                                }
+                                else
+                                    break;
+                            }
+                        }
+
+                        spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                        copy_length = IPR_MIN(ioa_cmd.buffer_len,
+                                                 sistoh32(p_ipr_dump_driver_header->
+                                                          header.total_length));
+
+                        result = ipr_copy_sdt_to_user(p_buffer, copy_length);
+
+                        spin_lock_irqsave(&io_request_lock, io_flags);
+
+                        p_ipr_dump_ioa_entry = NULL;
+                        p_ipr_dump_driver_header = NULL;
+
+                        ipr_get_sdt_state = INACTIVE;
+                    }
+
+                    ipr_kfree(p_dump_ioa_entry,
+                                 sizeof(struct ipr_dump_ioa_entry));
+                    ipr_kfree(p_dump_driver_header,
+                                 sizeof(struct ipr_dump_driver_header));
+
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                }
+                break;
+            case IPR_RESET_HOST_ADAPTER:
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                ipr_block_all_requests(ipr_cfg);
+
+                if (ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NORMAL) != SUCCESS)
+                    result = -EIO;
+
+                ipr_unblock_all_requests(ipr_cfg);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_READ_DRIVER_CFG:
+                if (ioa_cmd.buffer_len < sizeof(struct ipr_driver_cfg))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on driver config %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on 0x%02X failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                p_driver_cfg = ipr_kmalloc(ioa_cmd.buffer_len, IPR_ALLOC_CAN_SLEEP);
+
+                if (p_driver_cfg == NULL)
+                {
+                    ipr_log_err("Buffer allocation for driver config failed"IPR_EOL);
+                    return -ENOMEM;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+                p_driver_cfg->debug_level = ipr_cfg->shared.debug_level;
+                p_driver_cfg->trace_level = ipr_cfg->shared.trace;
+                p_driver_cfg->debug_level_max = IPR_ADVANCED_DEBUG;
+                p_driver_cfg->trace_level_max = IPR_TRACE;
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                result = copy_to_user(p_buffer, p_driver_cfg,
+                                      ioa_cmd.buffer_len);
+
+                ipr_kfree(p_driver_cfg, ioa_cmd.buffer_len);
+                break;
+            case IPR_WRITE_DRIVER_CFG:
+                if (ioa_cmd.buffer_len < sizeof(struct ipr_driver_cfg))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on driver config %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                /* First we need to copy the user's buffer into kernel memory */
+                p_driver_cfg = ipr_kmalloc(ioa_cmd.buffer_len, IPR_ALLOC_CAN_SLEEP);
+
+                if (p_driver_cfg == NULL)
+                {
+                    ipr_log_err("Buffer allocation for driver config failed"IPR_EOL);
+                    return -ENOMEM;
+                }
+
+                result = copy_from_user(p_driver_cfg, p_buffer, ioa_cmd.buffer_len);
+
+                if (result)
+                {
+                    ipr_log_err("Unable to access user data"IPR_EOL);
+                    ipr_kfree(p_driver_cfg, ioa_cmd.buffer_len);
+                    return result;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+                ipr_cfg->shared.debug_level = p_driver_cfg->debug_level;
+                ipr_cfg->shared.trace = p_driver_cfg->trace_level;
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                ipr_kfree(p_driver_cfg, ioa_cmd.buffer_len);
+                break;
+            case IPR_MODE_SENSE_PAGE_28:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                if ((ioa_cmd.buffer_len < sizeof(struct ipr_page_28)) ||
+                    (ioa_cmd.buffer_len > 0xff))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on mode sense %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on 0x%02X failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                p_page_28_data = ipr_kmalloc(sizeof(struct ipr_page_28), IPR_ALLOC_CAN_SLEEP);
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+                if ((ioa_cmd.cdb[2] >> 6) == IPR_CURRENT_PAGE)
+                {
+                    memcpy(p_page_28_data,
+                                       &ipr_cfg->shared.p_page_28->saved,
+                                       sizeof(struct ipr_page_28));
+                }
+                else if ((ioa_cmd.cdb[2] >> 6) == IPR_CHANGEABLE_PAGE)
+                {
+                    memcpy(p_page_28_data,
+                                       &ipr_cfg->shared.p_page_28->changeable,
+                                       sizeof(struct ipr_page_28));
+                }
+                else if ((ioa_cmd.cdb[2] >> 6) == IPR_DEFAULT_PAGE)
+                {
+                    memcpy(p_page_28_data,
+                                       &ipr_cfg->shared.p_page_28->dflt,
+                                       sizeof(struct ipr_page_28));
+                }
+                else
+                {
+                    /* invalid request, return canned sense data? */
+                    ipr_log_err("Invalid Page Control Field for Mode Sense Page 28"IPR_EOL);
+                    result = -EINVAL;
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                /* return  parms for mode page 28 */
+                result = copy_to_user(p_buffer,
+                                      p_page_28_data,
+                                      ioa_cmd.buffer_len);
+
+                ipr_kfree(p_page_28_data, sizeof(struct ipr_page_28));
+                break;
+            case IPR_MODE_SELECT_PAGE_28:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                if ((ioa_cmd.buffer_len < sizeof(struct ipr_page_28)) ||
+                    (ioa_cmd.buffer_len > 0xff))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on mode select %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                /* First we need to copy the user's buffer into kernel memory
+                 so it can't get swapped out */
+                p_page_28_data = ipr_kmalloc(ioa_cmd.buffer_len, IPR_ALLOC_CAN_SLEEP);
+
+                if (p_page_28_data == NULL)
+                {
+                    ipr_log_err("Buffer allocation for mode select failed"IPR_EOL);
+                    return -ENOMEM;
+                }
+
+                result = copy_from_user(p_page_28_data, p_buffer, ioa_cmd.buffer_len);
+
+                if (result)
+                {
+                    ipr_log_err("Unable to access user data"IPR_EOL);
+                    ipr_kfree(p_page_28_data, ioa_cmd.buffer_len);
+                    return result;
+                }
+
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 IPR_MODE_SENSE_28_SZ,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for mode sense failed"IPR_EOL);
+                    break;
+                }
+
+                /* need to get the mode sense data */
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                /* put usr settings to page 28 saved */
+                p_mode_parm_header = (struct ipr_mode_parm_hdr *) p_page_28_data;
+                p_modepage_28_header = (struct ipr_mode_page_28_header *) (p_mode_parm_header + 1);
+
+                dev_entry_length = sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+                /* Point to first device bus entry */
+                p_dev_bus_entry = (struct ipr_mode_page_28_scsi_dev_bus_attr *)
+                    (p_modepage_28_header + 1);
+
+                for (i = 0;
+                     (i < p_modepage_28_header->num_dev_entries) &&
+                         (i < IPR_MAX_NUM_BUSES);
+                     i++)
+                {
+                    for (j = 0;
+                         j < ipr_cfg->shared.p_page_28->saved.page_hdr.num_dev_entries;
+                         j++)
+                    {
+                        if (p_dev_bus_entry->res_addr.bus ==
+                            ipr_cfg->shared.p_page_28->saved.attr[j].res_addr.bus)
+                        {
+                            /* verify  max_xfer_rate does not exceed any restrictions */
+                            if (sistoh32(p_dev_bus_entry->max_xfer_rate) >
+                                sistoh32(ipr_cfg->shared.p_page_28->dflt.attr[j].max_xfer_rate))
+                            {
+                                ipr_log_err("Bus max transfer rate set higher than allowed, "
+                                               "resetting to max allowable"IPR_EOL);
+                                p_dev_bus_entry->max_xfer_rate =
+                                    ipr_cfg->shared.p_page_28->dflt.attr[j].max_xfer_rate;
+                            }
+
+                            /* found saved bus entry, copy to send mode select */
+                            memcpy(&ipr_cfg->shared.p_page_28->saved.attr[j],
+                                               p_dev_bus_entry,
+                                               sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr));
+                            break;
+                        }
+                    }
+                    /* Point to next device bus entry */
+                    p_dev_bus_entry = (struct ipr_mode_page_28_scsi_dev_bus_attr *)
+                        ((char *)p_dev_bus_entry + dev_entry_length);
+                }
+
+                ipr_kfree(p_page_28_data, ioa_cmd.buffer_len);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, IPR_MODE_SENSE_28_SZ,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = IPR_MODE_SENSE_28_SZ;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = IPR_MODE_SENSE;
+                p_sis_cmnd->ccb.cdb[2] = IPR_PAGE_CODE_28;
+                p_sis_cmnd->ccb.cdb[4] = IPR_MODE_SENSE_28_SZ;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_INTERNAL_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    if ((sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST)) ||
+                        (ipr_cfg->shared.nr_ioa_microcode))
+                        result = -EINVAL;
+                    else
+                    {
+                        ipr_print_sense(cmd, p_sense_buffer);
+                        result = -EIO;
+                    }
+                }
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                if (result)
+                {
+                    if (result != -EINVAL)
+                        ipr_log_err("Mode Sense for Page 28 failed"IPR_EOL);
+                    ipr_dma_free(&ipr_cfg->shared, IPR_MODE_SENSE_28_SZ,
+                                    p_cmd_buffer, p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                /* put users new data into mode select */
+                p_mode_parm_header = (struct ipr_mode_parm_hdr *) p_cmd_buffer;
+                p_modepage_28_header = (struct ipr_mode_page_28_header *) (p_mode_parm_header + 1);
+
+                for (bus_num = 0;
+                     bus_num < IPR_MAX_NUM_BUSES;
+                     bus_num++)
+                {
+                    /* Modify the IOAFP's Mode page 28 for specified
+                     SCSI bus */
+                    ipr_modify_ioafp_mode_page_28(&ipr_cfg->shared,
+                                                     p_modepage_28_header,
+                                                     bus_num);
+                }
+
+                /* Determine the amount of data to transfer on the Mode
+                 Select */
+                /* Note: Need to add 1 since the length field does not
+                 include itself. */
+                mode_data_length = p_mode_parm_header->length + 1;
+
+                /* Zero length field */
+                p_mode_parm_header->length = 0;
+
+                /* send mode select */
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, IPR_MODE_SENSE_28_SZ,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    return result;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = mode_data_length;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = IPR_MODE_SELECT;
+                p_sis_cmnd->ccb.cdb[1] = 0x11;
+                p_sis_cmnd->ccb.cdb[4] = mode_data_length;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                                IPR_INTERNAL_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                } 
+
+                ipr_dma_free(&ipr_cfg->shared, IPR_MODE_SENSE_28_SZ,
+                                p_cmd_buffer,p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_GET_TRACE:
+                if (ioa_cmd.buffer_len <= 0)
+                {
+                    ipr_log_err("Invalid buffer length on get trace %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    result = -EINVAL;
+                }
+                else if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on get trace failed"IPR_EOL);
+                    break;
+                }
+                else
+                {
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+
+                    /* internal trace table entry */
+                    ipr_get_internal_trace(&ipr_cfg->shared,
+                                              &trace_block_address,
+                                              &trace_block_length);
+
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                    p_cmd_buffer = ipr_kmalloc(trace_block_length, IPR_ALLOC_CAN_SLEEP);
+
+                    if (p_cmd_buffer == NULL)
+                    {
+                        result = -ENOMEM;
+                        break;
+                    }
+
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+
+                    memcpy(p_cmd_buffer, trace_block_address, trace_block_length);
+
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                    result = copy_to_user(p_buffer, p_cmd_buffer,
+                                          IPR_MIN(ioa_cmd.buffer_len, trace_block_length));
+
+                    ipr_kfree(p_cmd_buffer, trace_block_length);
+                }
+                break;
+            case IPR_RESET_DEV_CHANGED:
+                bus_num = (u8)(ioa_cmd.resource_address.bus + 1);
+                target_num = ioa_cmd.resource_address.target;
+                lun_num = ioa_cmd.resource_address.lun;
+
+                if ((bus_num < (IPR_MAX_NUM_BUSES + 1)) &&
+                    (target_num < IPR_MAX_NUM_TARGETS_PER_BUS) &&
+                    (lun_num < IPR_MAX_NUM_LUNS_PER_TARGET))
+                {
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+
+                    lun = ipr_cfg->shared.bus[bus_num].target[target_num].lun[lun_num];
+
+                    if (lun.is_valid_entry)
+                    {
+                        p_resource = lun.p_resource_entry;
+                        p_resource->dev_changed = 0;
+                    }
+                    else
+                    {
+                        ipr_log_err("Invalid resource address: 00%02X%02X%02X"IPR_EOL,
+                                       ioa_cmd.resource_address.bus,
+                                       ioa_cmd.resource_address.target,
+                                       ioa_cmd.resource_address.lun);
+                        result = -ENXIO;
+                    }
+
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                }
+                else
+                {
+                    ipr_log_err("Invalid resource address: 00%02X%02X%02X"IPR_EOL,
+                                   ioa_cmd.resource_address.bus,
+                                   ioa_cmd.resource_address.target,
+                                   ioa_cmd.resource_address.lun);
+                    return -ENXIO;
+                }
+                break;
+            case IPR_CONC_MAINT:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                /* Find the resource address for the device the concurrent maintenance
+                 action is directed at */
+                if (IPR_CONC_MAINT_GET_FMT(ioa_cmd.cdb[2]) == IPR_CONC_MAINT_FRAME_ID_FMT)
+                {
+                    frame_id = (ioa_cmd.cdb[4] << 8) | ioa_cmd.cdb[5];
+
+                    result = ipr_get_res_addr_fmt1(&ipr_cfg->shared,
+                                                      frame_id, &ioa_cmd.cdb[6],
+                                                      &res_addr);
+
+                    if (result)
+                    {
+                        spin_unlock_irqrestore(&io_request_lock, io_flags);
+                        break;
+                    }
+                }
+                else if (IPR_CONC_MAINT_GET_FMT(ioa_cmd.cdb[2]) == IPR_CONC_MAINT_DSA_FMT)
+                {
+                    dsa = (ioa_cmd.cdb[4] << 24) | (ioa_cmd.cdb[5] << 16) |
+                        (ioa_cmd.cdb[6] << 8) | ioa_cmd.cdb[7];
+                    ua = (ioa_cmd.cdb[8] << 24) | (ioa_cmd.cdb[9] << 16) |
+                        (ioa_cmd.cdb[10] << 8) | ioa_cmd.cdb[11];
+
+                    result = ipr_get_res_addr_fmt0(&ipr_cfg->shared,
+                                                      dsa, ua, &res_addr);
+
+                    if (result)
+                    {
+                        spin_unlock_irqrestore(&io_request_lock, io_flags);
+                        break;
+                    }
+                }
+                else if (IPR_CONC_MAINT_GET_FMT(ioa_cmd.cdb[2]) == IPR_CONC_MAINT_PSERIES_FMT)
+                {
+                    if ((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > IPR_MAX_PSERIES_LOCATION_LEN))
+                    {
+                        result = -EINVAL;
+                        spin_unlock_irqrestore(&io_request_lock, io_flags);
+                        break;
+                    }
+
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                    /* First we need to copy the user's buffer into kernel memory
+                     so we can access it */
+                    p_cmd_buffer = ipr_kmalloc(ioa_cmd.buffer_len+1, IPR_ALLOC_CAN_SLEEP);
+
+                    if (p_cmd_buffer == NULL)
+                    {
+                        ipr_log_err("Buffer allocation for concurrent maintenance failed"IPR_EOL);
+                        result = -ENOMEM;
+                        break;
+                    }
+
+                    result = copy_from_user(p_cmd_buffer, p_buffer, ioa_cmd.buffer_len);
+
+                    p_char = p_cmd_buffer;
+                    p_char[ioa_cmd.buffer_len] = '\0';
+
+                    if (result)
+                    {
+                        ipr_log_err("Unable to access user data"IPR_EOL);
+                        ipr_kfree(p_cmd_buffer, ioa_cmd.buffer_len+1);
+                        result = -ENOMEM;
+                        break;
+                    }
+
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+
+                    result = ipr_get_res_addr_fmt2(&ipr_cfg->shared,
+                                                      p_cmd_buffer, &res_addr);
+
+                    ipr_kfree(p_cmd_buffer, ioa_cmd.buffer_len+1);
+
+                    if (result)
+                    {
+                        spin_unlock_irqrestore(&io_request_lock, io_flags);
+                        break;
+                    }
+                }
+                else if (IPR_CONC_MAINT_GET_FMT(ioa_cmd.cdb[2]) == IPR_CONC_MAINT_XSERIES_FMT)
+                {
+                    result = ipr_get_res_addr_fmt3(&ipr_cfg->shared,
+                                                      (ioa_cmd.cdb[4] << 8) | ioa_cmd.cdb[5],
+                                                      (ioa_cmd.cdb[6] << 8) | ioa_cmd.cdb[7],
+                                                      ioa_cmd.cdb[8], ioa_cmd.cdb[9], ioa_cmd.cdb[10],
+                                                      &res_addr);
+
+                    if (result)
+                    {
+                        result = -EINVAL;
+                        spin_unlock_irqrestore(&io_request_lock, io_flags);
+                        break;
+                    }
+                }
+                else
+                {
+                    result = -EINVAL;
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                if (ioa_cmd.cdb[1] == IPR_CONC_MAINT_CHECK_ONLY)
+                {
+                    result = ipr_suspend_device_bus(ipr_cfg, res_addr, IPR_SDB_CHECK_ONLY);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                result = ipr_conc_maint(ipr_cfg,
+                                           res_addr,
+                                           IPR_CONC_MAINT_GET_TYPE(ioa_cmd.cdb[2]),
+                                           ioa_cmd.cdb[12]);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            default:
+                result = -EINVAL;
+                ipr_log_err("Invalid driver command issued: 0x%02X"IPR_EOL, cmd);
+                break;
+        }
+    }
+    else
+    {
+        switch (cmd)
+        {
+            case FORMAT_UNIT:
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 IPR_DEFECT_LIST_HDR_LEN,
+                                                 &p_cmd_buffer_dma, IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for 0x%02X failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                p_defect_list_hdr = p_cmd_buffer;
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, IPR_DEFECT_LIST_HDR_LEN,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.cmd_len = 6;
+                p_sis_cmnd->ccb.cdb[0] = FORMAT_UNIT;
+                p_sis_cmnd->ccb.cdb[4] = 1;
+
+                if (ipr_cfg->shared.use_immed_format)
+                {
+                    p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                    p_sis_cmnd->ccb.cdb[1] = IPR_FORMAT_DATA;
+                    p_defect_list_hdr[1] = IPR_FORMAT_IMMED;
+                    p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                    p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                    p_sis_cmnd->ccb.bufflen = IPR_DEFECT_LIST_HDR_LEN;
+                    p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+                }
+                else
+                    p_sis_cmnd->ccb.sc_data_direction = IPR_DATA_NONE;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd, IPR_FORMAT_UNIT_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                }
+
+                ipr_dma_free(&ipr_cfg->shared, IPR_DEFECT_LIST_HDR_LEN,
+                                p_cmd_buffer,p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_EVALUATE_DEVICE:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                resource_handle =
+                    htosis32((ioa_cmd.cdb[2] << 24) |
+                             (ioa_cmd.cdb[3] << 16) |
+                             (ioa_cmd.cdb[4] << 8) |
+                             ioa_cmd.cdb[5]);
+
+                /* Block any new requests from getting to us while we delete this device */
+                ipr_block_midlayer_requests(ipr_cfg);
+
+                /* Find resource entry we are trying to delete */
+                for (p_resource_dll = ipr_cfg->shared.rsteUsedH;
+                     p_resource_dll != NULL;
+                     p_resource_dll = p_resource_dll->next)
+                {
+                    p_loop_resource = &p_resource_dll->data;
+
+                    if (p_loop_resource->resource_handle == resource_handle)
+                    {
+                        p_lun = ipr_get_lun_res_addr(ipr_cfg,
+                                                        p_loop_resource->resource_address);
+
+                        if (p_lun && p_lun->is_valid_entry)
+                        {
+                            ipr_dbg_trace;
+
+                            if (p_loop_resource->in_init)
+                                p_loop_resource->redo_init = 1;
+
+                            evaluate_quiece_time = 600;
+
+                            /* Look to see if we have any ops in flight */
+                            while(evaluate_quiece_time)
+                            {
+                                p_loop_cmnd = ipr_cfg->qPendingH;
+
+                                /* Look for the op on the pending queue */
+                                while (p_loop_cmnd != NULL)
+                                {
+                                    if (p_loop_cmnd->ccb.p_resource == p_loop_resource)
+                                    {
+                                        ipr_dbg_err("Waiting for command to resource 0x%p"IPR_EOL,
+                                                       p_loop_cmnd);
+                                        ipr_sleep(100);
+                                        evaluate_quiece_time--;
+                                        break;
+                                    }
+                                    p_loop_cmnd = p_loop_cmnd->p_next;
+                                }
+
+                                /* Couldn't find it - Lets look on the completed queue */
+                                if (p_loop_cmnd == NULL)
+                                {
+                                    p_loop_cmnd = ipr_cfg->qCompletedH;
+
+                                    while (p_loop_cmnd != NULL)
+                                    {
+                                        if (p_loop_cmnd->ccb.p_resource == p_loop_resource)
+                                        {
+                                            ipr_dbg_err("Waiting for command to resource 0x%p"IPR_EOL,
+                                                           p_loop_cmnd);
+                                            ipr_sleep(100);
+                                            evaluate_quiece_time--;
+                                            break;
+                                        }
+                                        p_loop_cmnd = p_loop_cmnd->p_next;
+                                    }
+                                }
+                                else
+                                    continue;
+
+                                /* Couldn't find it - Lets look on the error queue */
+                                if (p_loop_cmnd == NULL)
+                                {
+                                    p_loop_cmnd = ipr_cfg->qErrorH;
+
+                                    while (p_loop_cmnd != NULL)
+                                    {
+                                        if (p_loop_cmnd->ccb.p_resource == p_loop_resource)
+                                        {
+                                            ipr_dbg_err("Waiting for command to resource 0x%p"IPR_EOL,
+                                                           p_loop_cmnd);
+                                            ipr_sleep(100);
+                                            evaluate_quiece_time--;
+                                            break;
+                                        }
+                                        p_loop_cmnd = p_loop_cmnd->p_next;
+                                    }
+                                }
+                                else
+                                    continue;
+
+                                break;;
+                            }
+
+                            if (evaluate_quiece_time == 0)
+                            {
+                                result = -EBUSY;
+                                ipr_log_err("Timed out waiting for ops to quiesce "
+                                               "for evaluate device capabilities"IPR_EOL);
+                                goto evaluate_leave;
+                            }   
+                        }
+                        break;
+                    }
+                }
+
+                if (p_resource_dll == NULL)
+                {
+                    result = -EINVAL;
+                    goto evaluate_leave;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_NONE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = IPR_EVALUATE_DEVICE;
+                p_sis_cmnd->ccb.cdb[2] = ioa_cmd.cdb[2];
+                p_sis_cmnd->ccb.cdb[3] = ioa_cmd.cdb[3];
+                p_sis_cmnd->ccb.cdb[4] = ioa_cmd.cdb[4];
+                p_sis_cmnd->ccb.cdb[5] = ioa_cmd.cdb[5];
+                p_sis_cmnd->ccb.flags = IPR_IOA_CMD;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_EVALUATE_DEVICE_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                    {
+                        ipr_print_sense(cmd, p_sense_buffer);
+                        result = -EIO;
+                    }
+                }
+
+evaluate_leave:
+                ipr_unblock_midlayer_requests(ipr_cfg);
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case START_STOP:
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_NONE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[4] = ioa_cmd.cdb[4];
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_START_STOP_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                }
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_QUERY_COMMAND_STATUS:
+            case IPR_QUERY_RESOURCE_STATE:
+            case IPR_QUERY_ARRAY_CONFIG:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on 0x%02X failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for 0x%02X failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[1] = ioa_cmd.cdb[1];
+                p_sis_cmnd->ccb.cdb[2] = ioa_cmd.cdb[2];
+                p_sis_cmnd->ccb.cdb[7] = (ioa_cmd.buffer_len & 0xff00) >> 8;
+                p_sis_cmnd->ccb.cdb[8] = ioa_cmd.buffer_len & 0xff;
+                p_sis_cmnd->ccb.flags = IPR_IOA_CMD | IPR_BUFFER_MAPPED;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_ARRAY_CMD_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    if ((sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST)) ||
+                        (ipr_cfg->shared.nr_ioa_microcode))
+                        result = -EINVAL;
+                    else
+                    {
+                        ipr_print_sense(cmd, p_sense_buffer);
+                        result = -EIO;
+                    }
+                }
+                else
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    result = copy_to_user(p_buffer, p_cmd_buffer, ioa_cmd.buffer_len);
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+                }
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer,p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case MODE_SENSE:
+                if ((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > 0xff))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on mode sense %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on mode sense failed"IPR_EOL);
+                    break;
+                }
+
+                /* Block mode sense request to the IOA focal point */
+                if (p_resource == &ipr_cfg->shared.ioa_resource)
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid mode sense command"IPR_EOL)
+                        break;
+                }
+
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for mode sense failed"IPR_EOL);
+                    break;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[2] = ioa_cmd.cdb[2];
+                p_sis_cmnd->ccb.cdb[4] = ioa_cmd.buffer_len;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_INTERNAL_DEV_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                }
+                else
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    result = copy_to_user(p_buffer, p_cmd_buffer, ioa_cmd.buffer_len);
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+                }
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer, p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_IOA_DEBUG:
+                if ((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > IPR_IOA_DEBUG_MAX_XFER))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on IOA debug %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on IOA debug failed"IPR_EOL);
+                    break;
+                }
+
+                /* Make sure we are going to the IOA focal point */
+                if (p_resource != &ipr_cfg->shared.ioa_resource)
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid IOA debug command"IPR_EOL);
+                    break;
+                }
+
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for IOA debug failed"IPR_EOL);
+                    break;
+                }
+
+                if (!ioa_cmd.read_not_write)
+                {
+                    result = copy_from_user(p_cmd_buffer, p_buffer, ioa_cmd.buffer_len);
+                    if (result)
+                    {
+                        ipr_log_err("Unable to access user data"IPR_EOL);
+                        ipr_kfree(p_cmd_buffer, ioa_cmd.buffer_len);
+                        break;
+                    }
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_IOA_CMD | IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                if (ioa_cmd.read_not_write)
+                    p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+                else
+                    p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+                p_sis_cmnd->ccb.cmd_len = IPR_CDB_LEN;
+                memcpy(p_sis_cmnd->ccb.cdb, ioa_cmd.cdb, IPR_CDB_LEN);
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_INTERNAL_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                }
+                else if (ioa_cmd.read_not_write)
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    result = copy_to_user(p_buffer, p_cmd_buffer, ioa_cmd.buffer_len);
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+                }
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer, p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case MODE_SELECT:
+                if ((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > 0xff))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on mode select %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                /* First we need to copy the user's buffer into kernel memory
+                 so it can't get swapped out */
+                p_cmd_buffer = ipr_dma_malloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    ipr_log_err("Buffer allocation for mode select failed"IPR_EOL);
+                    return -ENOMEM;
+                }
+
+                result = copy_from_user(p_cmd_buffer, p_buffer, ioa_cmd.buffer_len);
+
+                if (result)
+                {
+                    ipr_log_err("Unable to access user data"IPR_EOL);
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    return result;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    return result;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[1] = 0x10;
+                p_sis_cmnd->ccb.cdb[4] = ioa_cmd.buffer_len;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_INTERNAL_DEV_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                } 
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer,p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case READ_CAPACITY:
+            case IPR_SERVICE_ACTION_IN:
+            case INQUIRY:
+            case LOG_SENSE:
+                if ((ioa_cmd.buffer_len == 0) ||
+                    (ioa_cmd.buffer_len > 0xffff) ||
+                    ((ioa_cmd.buffer_len > 0xff) && (cmd != LOG_SENSE)))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on 0x%X command %d"IPR_EOL,
+                                   cmd, ioa_cmd.buffer_len);
+                    break;
+                }
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on 0x%X command failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for 0x%X failed"IPR_EOL, cmd);
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    break;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer, p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    return result;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+                p_sis_cmnd->ccb.cmd_len = COMMAND_SIZE(cmd);
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[1] = ioa_cmd.cdb[1];
+                p_sis_cmnd->ccb.cdb[2] = ioa_cmd.cdb[2];
+
+                if (cmd == INQUIRY)
+                    p_sis_cmnd->ccb.cdb[4] = ioa_cmd.buffer_len;
+                else if (cmd == LOG_SENSE)
+                {
+                    p_sis_cmnd->ccb.cdb[7] = ioa_cmd.buffer_len >> 8;
+                    p_sis_cmnd->ccb.cdb[8] = ioa_cmd.buffer_len & 0xff;
+                }
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_INTERNAL_DEV_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                } 
+                else
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    result = copy_to_user(p_buffer, p_cmd_buffer, ioa_cmd.buffer_len);
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+                }
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer, p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_START_ARRAY_PROTECTION:
+            case IPR_STOP_ARRAY_PROTECTION:
+            case IPR_REBUILD_DEVICE_DATA:
+            case IPR_ADD_ARRAY_DEVICE:
+            case IPR_RESYNC_ARRAY_PROTECTION:
+                if ((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > sizeof(struct ipr_array_query_data)))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on %02X: %d"IPR_EOL,
+                                   cmd, ioa_cmd.buffer_len);
+                    break;
+                }
+
+                p_cmd_buffer = ipr_dma_malloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for %02X failed"IPR_EOL, cmd);
+                    break;
+                }
+
+                result = copy_from_user(p_cmd_buffer, p_buffer, ioa_cmd.buffer_len);
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    ipr_log_err("copy_from_user for %02X failed"IPR_EOL, cmd);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer,p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    return result;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.flags = IPR_IOA_CMD | IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[1] = ioa_cmd.cdb[1];
+                p_sis_cmnd->ccb.cdb[4] = ioa_cmd.cdb[4];
+                p_sis_cmnd->ccb.cdb[5] = ioa_cmd.cdb[5];
+                p_sis_cmnd->ccb.cdb[6] = ioa_cmd.cdb[6];
+                p_sis_cmnd->ccb.cdb[7] = (ioa_cmd.buffer_len & 0xff00) >> 8;
+                p_sis_cmnd->ccb.cdb[8] = ioa_cmd.buffer_len & 0xff;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_ARRAY_CMD_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                } 
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer,p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_QUERY_IOA_CONFIG:
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                num_entries = 1;
+
+                for (p_resource_dll = ipr_cfg->shared.rsteUsedH;
+                     p_resource_dll != NULL;
+                     p_resource_dll = p_resource_dll->next)
+                {
+                    if (!p_resource_dll->data.is_ioa_resource)
+                        num_entries++;
+                }
+
+                length = (num_entries *
+                          sizeof(struct ipr_resource_entry)) + sizeof(struct ipr_resource_hdr);
+
+                if (ioa_cmd.buffer_len < length)
+                {
+                    ipr_log_err("Invalid buffer length size in query IOA config. %d, %d"IPR_EOL,
+                                   ioa_cmd.buffer_len, length);
+                    result = -EINVAL;
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                }
+                else
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                    if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                    {
+                        ipr_log_err("verify_area on query IOA config failed"IPR_EOL);
+                    }
+                    else
+                    {
+                        p_resource_hdr = ipr_kmalloc(length, IPR_ALLOC_CAN_SLEEP);
+
+                        if (p_resource_hdr == NULL)
+                        {
+                            ipr_log_err("Buffer allocation on query IOA config failed"IPR_EOL);
+                            result = -ENOMEM;
+                        }
+                        else
+                        {
+                            p_resource_hdr->num_entries = num_entries;
+
+                            copy_length = sizeof(struct ipr_resource_hdr);
+
+                            spin_lock_irqsave(&io_request_lock, io_flags);
+
+                            memcpy(((u8*)p_resource_hdr) + copy_length,
+                                               &ipr_cfg->shared.ioa_resource,
+                                               sizeof(struct ipr_resource_entry));
+
+                            copy_length += sizeof(struct ipr_resource_entry);
+
+                            for (p_resource_dll = ipr_cfg->shared.rsteUsedH;
+                                 p_resource_dll != NULL;
+                                 p_resource_dll = p_resource_dll->next)
+                            {
+                                /* Ignore IOA resource since it is already copied over */
+                                if (p_resource_dll->data.is_ioa_resource)
+                                    continue;
+
+                                memcpy(((u8*)p_resource_hdr) + copy_length,
+                                                   &p_resource_dll->data,
+                                                   sizeof(struct ipr_resource_entry));
+
+                                copy_length += sizeof(struct ipr_resource_entry);
+                            }
+
+                            spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+                            result = copy_to_user(p_buffer, p_resource_hdr, length);
+
+                            ipr_kfree(p_resource_hdr, length);
+                        }
+                    }
+                }
+                break;
+            case IPR_RECLAIM_CACHE_STORE:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                if ((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > sizeof(struct ipr_reclaim_query_data)))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on reclaim cache storage: %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                if ((ioa_cmd.cdb[1] & IPR_RECLAIM_ACTION) == IPR_RECLAIM_PERFORM)
+                    timeout = IPR_RECLAIM_TIMEOUT;
+                else
+                    timeout = IPR_INTERNAL_TIMEOUT;
+
+                if ((result = verify_area(VERIFY_WRITE, p_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_log_err("verify_area on reclaim cache storage failed"IPR_EOL);
+                    break;
+                }
+
+                p_cmd_buffer = ipr_dma_calloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for reclaim cache storage failed"IPR_EOL);
+                    break;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer, p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    break;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[1] = ioa_cmd.cdb[1];
+                p_sis_cmnd->ccb.cdb[7] = (ioa_cmd.buffer_len & 0xff00) >> 8;
+                p_sis_cmnd->ccb.cdb[8] = ioa_cmd.buffer_len & 0xff;
+                p_sis_cmnd->ccb.flags = IPR_IOA_CMD | IPR_BUFFER_MAPPED;
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd, timeout, 1);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    if ((sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST)) ||
+                        (ipr_cfg->shared.nr_ioa_microcode))
+                        result = -EINVAL;
+                    else
+                    {
+                        ipr_print_sense(cmd, p_sense_buffer);
+                        result = -EIO;
+                    }
+                }
+                else
+                {
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    result = copy_to_user(p_buffer, p_cmd_buffer, ioa_cmd.buffer_len);
+                    spin_lock_irqsave(&io_request_lock, io_flags);
+                }
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer, p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                if (timeout == IPR_RECLAIM_TIMEOUT)
+                {
+                    ipr_block_all_requests(ipr_cfg);
+
+                    if (ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NORMAL) != SUCCESS)
+                        result = -EIO;
+
+                    ipr_unblock_all_requests(ipr_cfg);
+                }
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case WRITE_BUFFER:
+                if((ioa_cmd.buffer_len == 0) || (ioa_cmd.buffer_len > IPR_MAX_WRITE_BUFFER_SIZE))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length size in write buffer. %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                /* First we need to copy the user's buffer into kernel memory
+                 so it can't get swapped out */
+                result = ipr_alloc_ucode_buffer(ioa_cmd.buffer_len, &p_scatterlist);
+
+                if (result)
+                {
+                    ipr_log_err("Microcode buffer allocation failed"IPR_EOL);
+                    break;
+                }
+
+                result = ipr_copy_ucode_buffer(p_scatterlist,
+                                                  p_buffer,
+                                                  ioa_cmd.buffer_len);
+
+                if (result)
+                {
+                    ipr_log_err("Microcode buffer copy to kernel memory failed"IPR_EOL);
+                    ipr_free_ucode_buffer(p_scatterlist);
+                    break;
+                }
+
+                scatterlist = p_scatterlist->scatterlist;
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                if (p_resource == &ipr_cfg->shared.ioa_resource)
+                {
+                    ipr_block_all_requests(ipr_cfg);
+
+                    rc = ipr_shutdown_ioa(ipr_cfg, IPR_SHUTDOWN_NORMAL);
+
+                    if ((rc != 0) && (rc != IPR_RC_QUAL_SUCCESS))
+                    {
+                        ipr_trace;
+                        result = -EIO;
+                        goto leave_write_buffer_reset;
+                    }
+                }
+
+                result = ipr_get_free_sis_cmnd_for_ioctl_internal(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                    goto leave_write_buffer_reset;
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.request_buffer = scatterlist;
+                p_sis_cmnd->ccb.scsi_use_sg = p_scatterlist->num_sg;
+                p_sis_cmnd->ccb.flags |= IPR_ALLOW_REQ_OVERRIDE;
+                p_sis_cmnd->ccb.cdb[0] = WRITE_BUFFER;
+                p_sis_cmnd->ccb.cdb[1] = 5;
+                p_sis_cmnd->ccb.cdb[6] = (ioa_cmd.buffer_len & 0xff0000) >> 16;
+                p_sis_cmnd->ccb.cdb[7] = (ioa_cmd.buffer_len & 0x00ff00) >> 8;
+                p_sis_cmnd->ccb.cdb[8]= ioa_cmd.buffer_len & 0x0000ff;
+                p_sis_cmnd->ccb.sc_data_direction = SCSI_DATA_WRITE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+
+                /* Note: This command cannot have retries since it uses a scatter/gather
+                 list. If we had a retry here we would end up mapping the data once for
+                 each retry, and have a TCE leak */
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                                IPR_WRITE_BUFFER_TIMEOUT, 1);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    ipr_print_sense(cmd, p_sis_cmnd->ccb.sense_buffer);
+                    result = -EIO;
+                }
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+            leave_write_buffer_reset:
+                if ((p_resource == &ipr_cfg->shared.ioa_resource) && rc != IPR_RC_TIMEOUT)
+                {
+                    if (ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NONE) != SUCCESS)
+                        result = -EIO;
+
+                    ipr_unblock_all_requests(ipr_cfg);
+                }
+
+                ipr_free_ucode_buffer(p_scatterlist);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            case IPR_DISCARD_CACHE_DATA:
+                if (ipr_cfg->shared.nr_ioa_microcode)
+                    return -EIO;
+
+                if (ioa_cmd.buffer_len != sizeof(struct ipr_discard_cache_data))
+                {
+                    result = -EINVAL;
+                    ipr_log_err("Invalid buffer length on discard cache data %d"IPR_EOL,
+                                   ioa_cmd.buffer_len);
+                    break;
+                }
+
+                p_cmd_buffer = ipr_dma_malloc(&ipr_cfg->shared,
+                                                 ioa_cmd.buffer_len,
+                                                 &p_cmd_buffer_dma,
+                                                 IPR_ALLOC_CAN_SLEEP);
+
+                if (p_cmd_buffer == NULL)
+                {
+                    result = -ENOMEM;
+                    ipr_log_err("Buffer allocation for discard cache data failed"IPR_EOL);
+                    break;
+                }
+
+                if ((result = copy_to_user(p_buffer, p_cmd_buffer, ioa_cmd.buffer_len)))
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer, p_cmd_buffer_dma);
+                    ipr_log_err("Copy to kernel memory failed"IPR_EOL);
+                    break;
+                }
+
+                spin_lock_irqsave(&io_request_lock, io_flags);
+
+                result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+                if (result)
+                {
+                    ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                    p_cmd_buffer, p_cmd_buffer_dma);
+                    spin_unlock_irqrestore(&io_request_lock, io_flags);
+                    return result;
+                }
+
+                p_sis_cmnd->ccb.p_resource = p_resource;
+                p_sis_cmnd->ccb.flags = IPR_BUFFER_MAPPED;
+                p_sis_cmnd->ccb.buffer = p_cmd_buffer;
+                p_sis_cmnd->ccb.buffer_dma = p_cmd_buffer_dma;
+                p_sis_cmnd->ccb.bufflen = ioa_cmd.buffer_len;
+                p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+                p_sis_cmnd->ccb.cmd_len = 10;
+                p_sis_cmnd->ccb.cdb[0] = cmd;
+                p_sis_cmnd->ccb.cdb[1] = ioa_cmd.cdb[1];
+
+                rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                              IPR_DISCARD_CACHE_DATA_TIMEOUT, 2);
+
+                if (rc == IPR_RC_FAILED)
+                {
+                    p_sense_buffer = p_sis_cmnd->ccb.sense_buffer;
+
+                    ipr_print_sense(cmd, p_sense_buffer);
+
+                    if (sense_error(p_sense_buffer[2] == ILLEGAL_REQUEST))
+                        result = -EINVAL;
+                    else
+                        result = -EIO;
+                } 
+
+                ipr_dma_free(&ipr_cfg->shared, ioa_cmd.buffer_len,
+                                p_cmd_buffer, p_cmd_buffer_dma);
+
+                ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                spin_unlock_irqrestore(&io_request_lock, io_flags);
+                break;
+            default:
+                ipr_log_err("Invalid SIS command issued 0x%02X"IPR_EOL, cmd);
+                result = -EINVAL;
+                break;
+        }
+    }
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Perform device concurrent mainenance
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -ENXIO      - No such file or device
+ *          -EINVAL     - Invalid parameter
+ *          -ENOMEM     - Out of memory
+ *          -EIO        - I/O error
+ *---------------------------------------------------------------------------*/
+static int ipr_conc_maint(ipr_host_config *ipr_cfg,
+                             struct ipr_res_addr res_addr, u32 type, u32 delay)
+{
+    struct ipr_resource_entry *p_resource;
+    struct ipr_encl_status_ctl_pg *p_ses_data;
+    struct ipr_drive_elem_status *p_drive_elem_status;
+    ipr_dma_addr ses_dma_addr;
+    int rc, result = -ETIME;
+    int loop_count = 0;
+    u8 status;
+    struct ipr_lun *p_lun;
+    int loops_left = (delay * 60) / IPR_SDB_SLEEP_TIME;
+
+    if ((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0)
+        return -EIO;
+
+    p_resource = ipr_get_ses_resource(ipr_cfg, res_addr);
+
+    if (p_resource == NULL)
+        return -ENXIO;
+
+    p_ses_data = ipr_dma_calloc(&ipr_cfg->shared,
+                                   sizeof(struct ipr_encl_status_ctl_pg),
+                                   &ses_dma_addr, IPR_ALLOC_ATOMIC);
+
+    if (p_ses_data == NULL)
+    {
+        ipr_trace;
+        return -ENOMEM;
+    }
+
+    p_lun = ipr_get_lun_res_addr(ipr_cfg, res_addr);
+
+    while (loops_left--)
+    {
+        /* Get Enclosure status/control page */
+        rc = ipr_ses_receive_diagnostics(ipr_cfg, 2, p_ses_data, ses_dma_addr,
+                                            sizeof(struct ipr_encl_status_ctl_pg), p_resource);
+
+        /* Receive diagnostics is done twice to conceal a problem found in ses which has
+         been fixed but may potentially cause confusion if fix not loaded on target device */
+        rc = ipr_ses_receive_diagnostics(ipr_cfg, 2, p_ses_data, ses_dma_addr,
+                                            sizeof(struct ipr_encl_status_ctl_pg), p_resource);
+
+        if (rc)
+        {
+            ipr_trace;
+            result = rc;
+            goto leave;
+        }
+
+        p_drive_elem_status = ipr_get_elem_status(p_ses_data, res_addr.target);
+
+        if (p_drive_elem_status == NULL)
+        {
+            ipr_trace;
+            result = -EIO;
+            goto leave;
+        }
+
+        status = p_drive_elem_status->status;
+
+        if (loop_count++ > 0)
+        {
+            switch (type)
+            {
+                case IPR_CONC_MAINT_INSERT:
+                    if (status == IPR_DRIVE_ELEM_STATUS_STATUS_EMPTY)
+                    {
+                        /* Not done */
+                    }
+                    else if (status == IPR_DRIVE_ELEM_STATUS_STATUS_POPULATED)
+                    {
+                        /* Done with concurrent maintenance */
+                        result = 0;
+                        goto leave;
+                    }
+                    else
+                    {
+                        result = -EIO;
+                        ipr_trace;
+                        goto leave;
+                    }
+                    break;
+                case IPR_CONC_MAINT_REMOVE:
+                    if (status == IPR_DRIVE_ELEM_STATUS_STATUS_EMPTY)
+                    {
+                        /* Done with concurrent maintenance */
+                        result = 0;
+                        goto leave;
+                    }
+                    else if (status == IPR_DRIVE_ELEM_STATUS_STATUS_POPULATED)
+                    {
+                        /* Not done */
+                    }
+                    else
+                    {
+                        result = -EIO;
+                        ipr_trace;
+                        goto leave;
+                    }
+                    break;
+                default:
+                    result = -EIO;
+                    ipr_trace;
+                    goto leave;
+                    break;
+            };
+        }
+
+        switch (type)
+        {
+            case IPR_CONC_MAINT_INSERT:
+                p_lun->expect_ccm = 1;
+                p_drive_elem_status->select = 1;
+                p_drive_elem_status->insert = 1;
+                break;
+            case IPR_CONC_MAINT_REMOVE:
+                p_drive_elem_status->select = 1;
+                p_drive_elem_status->remove = 1;
+                break;
+            default:
+                result = -EIO;
+                ipr_trace;
+                goto leave;
+                break;
+        };
+
+        /* set the flag in the overall status to disable SCSI reset 
+         upon detecting a device inserted */
+        p_ses_data->overall_status_select = 1;
+        p_ses_data->overall_status_disable_resets = 1;
+        p_ses_data->overall_status_insert = 0;
+        p_ses_data->overall_status_remove = 0;
+        p_ses_data->overall_status_identify = 0;
+
+        /* Issue a send diagnostics to blink the LED */
+        rc = ipr_ses_send_diagnostics(ipr_cfg, p_ses_data,
+                                         ses_dma_addr, sizeof(struct ipr_encl_status_ctl_pg),
+                                         p_resource);
+
+        if (rc != 0)
+        {
+            result = rc;
+            ipr_trace;
+            goto leave;
+        }
+
+        /* block requests to prevent timeouts */
+        ipr_block_midlayer_requests(ipr_cfg);
+
+        /* Suspend device bus */
+        rc = ipr_suspend_device_bus(ipr_cfg, res_addr, IPR_SDB_CHECK_AND_QUIESCE);
+
+        if (rc != 0)
+        {
+            result = rc;
+            ipr_trace;
+
+            /* unblock requests */
+            ipr_unblock_midlayer_requests(ipr_cfg);
+            goto leave;
+        }
+
+        /* Sleep for 15 seconds */
+        ipr_sleep(IPR_SDB_SLEEP_TIME * 1000);
+
+        /* Resume device bus */
+        rc = ipr_resume_device_bus(ipr_cfg, res_addr);
+
+        /* unblock requests */
+        ipr_unblock_midlayer_requests(ipr_cfg);
+
+        if (rc != 0)
+        {
+            result = rc;
+            ipr_trace;
+            goto leave;
+        }
+    }
+
+    leave:
+
+        if (loop_count > 0)
+        {
+            /* set the flag in the overall status to enable SCSI reset 
+             upon detecting a device inserted */
+            p_ses_data->overall_status_select = 1;
+            p_ses_data->overall_status_disable_resets = 0;
+            p_ses_data->overall_status_insert = 0;
+            p_ses_data->overall_status_remove = 0;
+            p_ses_data->overall_status_identify = 0;
+
+            switch (type)
+            {
+                case IPR_CONC_MAINT_INSERT:
+                    p_drive_elem_status->select = 1;
+                    p_drive_elem_status->insert = 0;
+                    p_drive_elem_status->remove = 0;
+                    break;
+                case IPR_CONC_MAINT_REMOVE:
+                    p_drive_elem_status->select = 1;
+                    p_drive_elem_status->insert = 0;
+                    p_drive_elem_status->remove = 0;
+                    p_drive_elem_status->identify = 0;
+                    break;
+                default:
+                    ipr_trace;
+                    break;
+            };
+
+            /* Issue a send diagnostics to stop blinking the LED */
+            rc = ipr_ses_send_diagnostics(ipr_cfg, p_ses_data,
+                                             ses_dma_addr, sizeof(struct ipr_encl_status_ctl_pg),
+                                             p_resource);
+
+            if (rc != 0)
+            {
+                ipr_trace;
+                result = rc;
+            }
+        }
+
+    ipr_dma_free(&ipr_cfg->shared, sizeof(struct ipr_encl_status_ctl_pg),
+                    p_ses_data,ses_dma_addr);
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Issue a request sense to a GPDD
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O error
+ *---------------------------------------------------------------------------*/
+static int ipr_request_sense(ipr_host_config *ipr_cfg,
+                                struct ipr_resource_entry *p_resource,
+                                struct ipr_cmnd *p_sis_cmnd)
+{
+    int rc;
+
+    if ((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0)
+        return -EIO;
+
+    ipr_initialize_sis_cmnd(p_sis_cmnd);
+
+    p_sis_cmnd->ccb.p_resource = p_resource;
+    p_sis_cmnd->ccb.buffer = p_sis_cmnd->ccb.sense_buffer;
+    p_sis_cmnd->ccb.buffer_dma = p_sis_cmnd->ccb.sense_buffer_dma;
+    p_sis_cmnd->ccb.bufflen = IPR_SENSE_BUFFERSIZE;
+    p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+    p_sis_cmnd->ccb.cmd_len = 6;
+    p_sis_cmnd->ccb.use_sg = 1;
+
+    p_sis_cmnd->ccb.cdb[0] = REQUEST_SENSE;
+    p_sis_cmnd->ccb.flags = IPR_CMD_SYNC_OVERRIDE | IPR_BUFFER_MAPPED;
+
+    init_waitqueue_head(&p_sis_cmnd->wait_q);
+
+    rc = ipr_do_req(&ipr_cfg->shared, &p_sis_cmnd->ccb,
+                       ipr_ioctl_cmd_done, IPR_INTERNAL_TIMEOUT/HZ);
+
+    if (rc)
+    {
+        ipr_trace;
+        return -EIO;
+    }
+
+    ipr_sleep_on(&io_request_lock, &p_sis_cmnd->wait_q);
+
+    return p_sis_cmnd->ccb.completion;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Issue a receive diagnostics to a SES
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O error
+ *---------------------------------------------------------------------------*/
+static int ipr_ses_receive_diagnostics(ipr_host_config *ipr_cfg,
+                                          u8 page,
+                                          void *p_buffer,
+                                          ipr_dma_addr buffer_dma_addr,
+                                          u16 bufflen,
+                                          struct ipr_resource_entry *p_resource)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    int result = 0;
+    int rc;
+
+    result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+    if (result)
+        return result;
+
+    p_sis_cmnd->ccb.p_resource = p_resource;
+
+    /* Send a receive diagnostics to get the enclosure status/control page */
+    p_sis_cmnd->ccb.buffer = p_buffer;
+    p_sis_cmnd->ccb.buffer_dma = buffer_dma_addr;
+    p_sis_cmnd->ccb.bufflen = bufflen;
+    p_sis_cmnd->ccb.data_direction = IPR_DATA_READ;
+    p_sis_cmnd->ccb.cmd_len = 6;
+    p_sis_cmnd->ccb.cdb[0] = RECEIVE_DIAGNOSTIC;
+    p_sis_cmnd->ccb.cdb[1] = 0x01;      /* Page Code Valid */
+    p_sis_cmnd->ccb.cdb[2] = page;
+    p_sis_cmnd->ccb.cdb[3] = (bufflen >> 8) & 0xff;
+    p_sis_cmnd->ccb.cdb[4] = bufflen & 0xff;
+    p_sis_cmnd->ccb.cdb[5] = 0;
+    p_sis_cmnd->ccb.flags = IPR_GPDD_CMD | IPR_CMD_SYNC_OVERRIDE | IPR_BUFFER_MAPPED;
+    p_sis_cmnd->ccb.underflow = 0;
+
+    rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                  IPR_INTERNAL_TIMEOUT, 3);
+
+    if ((rc == IPR_RC_FAILED) && (status_byte(p_sis_cmnd->ccb.status) == CHECK_CONDITION))
+        ipr_request_sense(ipr_cfg, p_resource, p_sis_cmnd);
+
+    if (rc == IPR_RC_FAILED)
+    {
+        ipr_log_err("Receive diagnostics to %08X failed with rc 0x%x"IPR_EOL,
+                       IPR_GET_PHYSICAL_LOCATOR(p_resource->resource_address), rc);
+        ipr_print_sense(RECEIVE_DIAGNOSTIC, p_sis_cmnd->ccb.sense_buffer);
+        result = -EIO;
+    }
+
+    ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Suspend a given device bus
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O error
+ *          -EACCES     - Device cannot be removed
+ *---------------------------------------------------------------------------*/
+static int ipr_suspend_device_bus(ipr_host_config *ipr_cfg,
+                                     struct ipr_res_addr res_addr,
+                                     u8 option)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    int result = 0;
+    int rc;
+    struct ipr_resource_entry *p_resource;
+
+    p_resource = &ipr_cfg->shared.ioa_resource;
+
+    result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+    if (result)
+        return result;
+
+    p_sis_cmnd->ccb.p_resource = p_resource;
+
+    /* Suspend the device bus */
+    p_sis_cmnd->ccb.sc_data_direction = SCSI_DATA_NONE;
+    p_sis_cmnd->ccb.cmd_len = 10;
+    p_sis_cmnd->ccb.flags |= IPR_IOA_CMD | IPR_ALLOW_REQ_OVERRIDE;
+    p_sis_cmnd->ccb.cdb[0] = IPR_SUSPEND_DEV_BUS;
+    p_sis_cmnd->ccb.cdb[1] = option;
+    p_sis_cmnd->ccb.cdb[3] = res_addr.bus;
+    p_sis_cmnd->ccb.cdb[4] = res_addr.target;
+    p_sis_cmnd->ccb.cdb[5] = res_addr.lun;
+
+    rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                  IPR_SUSPEND_DEV_BUS_TIMEOUT, 3);
+
+    if (rc == IPR_RC_FAILED)
+    {
+        if (ipr_sense_valid(p_sis_cmnd->ccb.sense_buffer[0]) &&
+            (p_sis_cmnd->ccb.sense_buffer[2] == 0x0B) &&
+            (p_sis_cmnd->ccb.sense_buffer[12] == 0x53) &&
+            (p_sis_cmnd->ccb.sense_buffer[13] == 0x02))
+        {
+            result = -EACCES;
+        }
+        else
+        {
+            ipr_log_err("Suspend device bus to %08X failed."IPR_EOL,
+                           IPR_GET_PHYSICAL_LOCATOR(res_addr));
+            ipr_print_sense(IPR_SUSPEND_DEV_BUS, p_sis_cmnd->ccb.sense_buffer);
+            result = -EIO;
+        }
+    }
+
+    ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Resume a given device bus
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O error
+ *---------------------------------------------------------------------------*/
+static int ipr_resume_device_bus(ipr_host_config *ipr_cfg,
+                                    struct ipr_res_addr res_addr)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    int result = 0;
+    int rc;
+    struct ipr_resource_entry *p_resource;
+
+    p_resource = &ipr_cfg->shared.ioa_resource;
+
+    result = ipr_get_free_sis_cmnd_for_ioctl_internal(ipr_cfg, &p_sis_cmnd);
+
+    if (result)
+        return result;
+
+    p_sis_cmnd->ccb.p_resource = p_resource;
+
+    /* Suspend the device bus */
+    p_sis_cmnd->ccb.sc_data_direction = SCSI_DATA_NONE;
+    p_sis_cmnd->ccb.cmd_len = 10;
+    p_sis_cmnd->ccb.flags |= IPR_IOA_CMD | IPR_ALLOW_REQ_OVERRIDE;
+    p_sis_cmnd->ccb.cdb[0] = IPR_RESUME_DEVICE_BUS;
+    p_sis_cmnd->ccb.cdb[3] = res_addr.bus;
+    p_sis_cmnd->ccb.cdb[4] = res_addr.target;
+    p_sis_cmnd->ccb.cdb[5] = res_addr.lun;
+
+    rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                  IPR_INTERNAL_TIMEOUT, 3);
+
+    if (rc == IPR_RC_FAILED)
+    {
+        ipr_log_err("Resume device bus to %08X failed."IPR_EOL, IPR_GET_PHYSICAL_LOCATOR(res_addr));
+        ipr_print_sense(IPR_RESUME_DEVICE_BUS, p_sis_cmnd->ccb.sense_buffer);
+        result = -EIO;
+    }
+
+    ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Issue a send diagnostics to a SES
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          -EIO        - I/O error
+ *---------------------------------------------------------------------------*/
+static int ipr_ses_send_diagnostics(ipr_host_config *ipr_cfg,
+                                       void *p_buffer,
+                                       ipr_dma_addr buffer_dma_addr,
+                                       u16 bufflen,
+                                       struct ipr_resource_entry *p_resource)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    int result;
+    int rc;
+
+    result = 0;
+
+    result = ipr_get_free_sis_cmnd_for_ioctl(ipr_cfg, &p_sis_cmnd);
+
+    if (result)
+        return result;
+
+    p_sis_cmnd->ccb.p_resource = p_resource;
+
+    /* Send a send diagnostics to the SES */
+    p_sis_cmnd->ccb.buffer = p_buffer;
+    p_sis_cmnd->ccb.buffer_dma = buffer_dma_addr;
+    p_sis_cmnd->ccb.bufflen = bufflen;
+    p_sis_cmnd->ccb.data_direction = IPR_DATA_WRITE;
+    p_sis_cmnd->ccb.cmd_len = 6;
+    p_sis_cmnd->ccb.cdb[0] = SEND_DIAGNOSTIC;
+    p_sis_cmnd->ccb.cdb[1] = 0x10;      /* Page Format */
+    p_sis_cmnd->ccb.cdb[2] = 0;
+    p_sis_cmnd->ccb.cdb[3] = (bufflen >> 8) & 0xff;
+    p_sis_cmnd->ccb.cdb[4] = bufflen & 0xff;
+    p_sis_cmnd->ccb.cdb[5] = 0;
+    p_sis_cmnd->ccb.flags = IPR_GPDD_CMD | IPR_CMD_SYNC_OVERRIDE | IPR_BUFFER_MAPPED;
+
+    rc = ipr_send_blocking_ioctl(ipr_cfg, p_sis_cmnd,
+                                  IPR_INTERNAL_TIMEOUT, 3);
+
+    if ((rc == IPR_RC_FAILED) && (status_byte(p_sis_cmnd->ccb.status) == CHECK_CONDITION))
+        ipr_request_sense(ipr_cfg, p_resource, p_sis_cmnd);
+
+    if (rc == IPR_RC_FAILED)
+    {
+        ipr_log_err("Send diagnostics to %08X failed."IPR_EOL,
+                       IPR_GET_PHYSICAL_LOCATOR(p_resource->resource_address));
+        ipr_print_sense(SEND_DIAGNOSTIC, p_sis_cmnd->ccb.sense_buffer);
+        result = -EIO;
+    }
+
+    ipr_put_ioctl_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+    return result;
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Find the drive_elem_status entry for the given scsi id
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to drive_elem_status entry
+ *          NULL
+ *---------------------------------------------------------------------------*/
+static struct ipr_drive_elem_status*
+ipr_get_elem_status(struct ipr_encl_status_ctl_pg* p_encl_status_ctl_pg,
+                       u8 scsi_id)
+{
+    u32 slot;
+    struct ipr_drive_elem_status* p_drive_elem_status = NULL;
+
+    for (slot=0;
+         slot<((sistoh16(p_encl_status_ctl_pg->byte_count)-8)/sizeof(struct ipr_drive_elem_status));
+         slot++)
+    {
+        if (scsi_id == p_encl_status_ctl_pg->elem_status[slot].scsi_id)
+        {
+            p_drive_elem_status = &p_encl_status_ctl_pg->elem_status[slot];
+            return p_drive_elem_status;
+        }
+    }
+    return NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allocate a DMA'able buffer in chunks and assembles a
+ *          scatter/gather list to use for ucode download
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Note: This function may sleep
+ * Returns: 0           - Success
+ *          -EINVAL     - Invalid paramter
+ *          -ENOMEM     - Out of memory
+ *          others
+ *---------------------------------------------------------------------------*/
+static int ipr_alloc_ucode_buffer(u32 buf_len,
+                                     struct ipr_dnload_sglist **pp_scatterlist)
+{
+    int sg_size, order, result, bsize_elem, num_elem, i, j;
+    struct ipr_dnload_sglist *p_dnld;
+    struct scatterlist *scatterlist;
+
+    result = 0;
+
+    /* Get the minimum size per scatter/gather element */
+    sg_size = buf_len / (IPR_MAX_SGLIST - 1);
+
+    /* Get the actual size per element */
+    order = get_order (sg_size);
+
+    if (order > 5)
+    {
+        ipr_trace;
+        return -EINVAL;
+    }
+
+    /* Determine the actual number of bytes per element */
+    bsize_elem = PAGE_SIZE * (1 << order);
+
+    /* Determine the actual number of sg entries needed */
+    if (buf_len % bsize_elem)
+        num_elem = (buf_len / bsize_elem) + 1;
+    else
+        num_elem = buf_len / bsize_elem;
+
+    /* Allocate a scatter/gather list for the DMA */
+    p_dnld = ipr_kcalloc(sizeof(struct ipr_dnload_sglist) +
+                            (sizeof(struct scatterlist) * (num_elem-1)),
+                            IPR_ALLOC_CAN_SLEEP);
+
+    if (p_dnld == NULL)
+    {
+        ipr_trace;
+        return -ENOMEM;
+    }
+
+    scatterlist = p_dnld->scatterlist;
+
+    p_dnld->order = order;
+    p_dnld->num_sg = num_elem;
+
+    /* Allocate a bunch of sg elements */
+    for (i = 0; i < num_elem; i++)
+    {
+        scatterlist[i].address = ipr_get_free_pages(GFP_KERNEL | IPR_GFP_DMA, order);
+        if (scatterlist[i].address == NULL)
+        {
+            ipr_trace;
+
+            /* Free up what we already allocated */
+            for (j = i - 1; j >= 0; j--)
+                ipr_free_pages(scatterlist[j].address, order);
+            result = -ENOMEM;
+            ipr_kfree(p_dnld, sizeof(struct ipr_dnload_sglist) +
+                         (sizeof(struct scatterlist) * (num_elem-1)));
+            p_dnld = NULL;
+            break;
+        }
+
+        memset (scatterlist[i].address, 0, bsize_elem);
+    }
+
+    *pp_scatterlist = p_dnld;
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Free a DMA'able ucode download buffer previously allocated with
+ *          ipr_alloc_ucode_buffer
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Returns: 0           - Success
+ *          -EINVAL     - Invalid paramter
+ *          -ENOMEM     - Out of memory
+ *          others
+ *---------------------------------------------------------------------------*/
+static void ipr_free_ucode_buffer(struct ipr_dnload_sglist *p_dnld)
+{
+    int i;
+    u32 order = p_dnld->order;
+    u32 num_sg = p_dnld->num_sg;
+    struct scatterlist *scatterlist = p_dnld->scatterlist;
+
+    for (i = 0; i < num_sg; i++)
+        ipr_free_pages(scatterlist[i].address, order);
+    ipr_kfree(p_dnld,
+                 sizeof(struct ipr_dnload_sglist) +
+                 (sizeof(struct scatterlist) * (num_sg-1)));
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Copy IOA or device ucode from userspace to kernel space
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Returns: 0           - Success
+ *          others      - Failed
+ *---------------------------------------------------------------------------*/
+static int ipr_copy_ucode_buffer(struct ipr_dnload_sglist *p_scatterlist,
+                                    u8 *p_write_buffer,
+                                    u32 buf_len)
+{
+    int bsize_elem, result, i;
+    struct scatterlist *scatterlist;
+
+    /* Determine the actual number of bytes per element */
+    bsize_elem = PAGE_SIZE * (1 << p_scatterlist->order);
+
+    scatterlist = p_scatterlist->scatterlist;
+
+    for (i = 0; i < (buf_len / bsize_elem); i++, p_write_buffer += bsize_elem)
+    {
+        result = copy_from_user(scatterlist[i].address, p_write_buffer, bsize_elem);
+        scatterlist[i].length = bsize_elem;
+
+        if (result != 0)
+        {
+            ipr_trace;
+            return result;
+        }
+    }
+
+    if (buf_len % bsize_elem)
+    {
+        result = copy_from_user(scatterlist[i].address, p_write_buffer,
+                                buf_len % bsize_elem);
+        scatterlist[i].length =  buf_len % bsize_elem;
+    }
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Open connection ipr char device
+ * Context: Task level only
+ * Lock State: No locks assumed to be held
+ * Returns: 0           - Success
+ *          -ENXIO      - No such device
+ *---------------------------------------------------------------------------*/
+static int ipr_open(struct inode *inode, struct file *filp)
+{
+    ipr_host_config *ipr_cfg;
+    int dev;
+    unsigned long io_flags = 0;
+
+    spin_lock_irqsave(&io_request_lock,io_flags);
+    if (filp->private_data == NULL)
+    {
+        dev = MINOR(inode->i_rdev);
+        ipr_cfg = ipr_get_host(dev);
+        filp->private_data = ipr_cfg;
+    }
+    else
+        ipr_cfg = filp->private_data;
+
+    if (ipr_cfg == NULL)
+    {
+        spin_unlock_irqrestore(&io_request_lock,io_flags);
+        return -ENXIO;
+    }
+
+    MOD_INC_USE_COUNT;
+
+    spin_unlock_irqrestore(&io_request_lock,io_flags);
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Use minor number to get pointer to main CB
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to main CB or NULL if does not exist
+ *---------------------------------------------------------------------------*/
+static ipr_host_config * ipr_get_host(int dev)
+{
+    ipr_host_config * ipr_cfg = NULL;
+    int i;
+
+    if ((ipr_num_ctlrs > 0) && (ipr_cfg_head != NULL))
+    {
+        for (i = 0, ipr_cfg = ipr_cfg_head;
+             i < ipr_num_ctlrs;
+             i++, ipr_cfg = ipr_cfg->p_next)
+        {
+            if (ipr_cfg->minor_num == dev)
+                break;
+        }
+    }
+    return ipr_cfg;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Close connection to ipr char device
+ * Context: Task level only
+ * Lock State: No locks assumed to be held
+ * Returns: 0           - Success
+ *          -ENXIO      - No such device
+ *---------------------------------------------------------------------------*/
+static int ipr_close(struct inode *inode, struct file *filp)
+{
+    int result = 0;
+    unsigned long io_flags = 0;
+
+    if (filp->private_data == NULL)
+        return -ENXIO;
+
+    spin_lock_irqsave(&io_request_lock,io_flags);
+    MOD_DEC_USE_COUNT;
+    spin_unlock_irqrestore(&io_request_lock,io_flags);
+
+    return result;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Prepare a command block to be used for ERP
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_start_erp(struct ipr_cmnd *p_sis_cmnd)
+{
+    p_sis_cmnd->p_saved_scsi_cmd = p_sis_cmnd->p_scsi_cmd;
+    p_sis_cmnd->p_scsi_cmd = NULL;
+    p_sis_cmnd->ccb.saved_data_direction = p_sis_cmnd->ccb.data_direction;
+    p_sis_cmnd->ccb.data_direction = 0;
+    p_sis_cmnd->ccb.saved_use_sg = p_sis_cmnd->ccb.use_sg;
+    p_sis_cmnd->ccb.use_sg = 0;
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Restore command block which was used for ERP
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_end_erp(struct ipr_cmnd *p_sis_cmnd)
+{
+    p_sis_cmnd->ccb.flags &= ~IPR_ERP_CMD;
+    p_sis_cmnd->p_scsi_cmd = p_sis_cmnd->p_saved_scsi_cmd;
+    p_sis_cmnd->ccb.data_direction = p_sis_cmnd->ccb.saved_data_direction;
+    p_sis_cmnd->ccb.use_sg = p_sis_cmnd->ccb.saved_use_sg;
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Task-Level Entry Point to Send off more HCAMs, process Unit
+ *          Check buffer, and do some ERP
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_mailbox(ipr_host_config *ipr_cfg)
+{
+    int i;
+    struct ipr_cmnd *p_sis_cmnd;
+    Scsi_Cmnd     *p_scsi_cmd;
+    u8 *p_cdb;
+    struct ipr_lun *p_lun;
+    struct ipr_hostrcb *p_hostrcb;
+    u32 delay = 1000;
+    const struct ipr_ioa_cfg_t *p_ioa_cfg = ipr_cfg->p_ioa_cfg;
+
+    if (ipr_cfg->flag & IPR_UNIT_CHECKED)
+    {
+        if (ipr_cfg->flag & IPR_OPERATIONAL)
+        {
+            ipr_break_or_die_if_reset_reload_disabled;
+
+            /* Reset the IOA */
+            ipr_ioa_reset(ipr_cfg, IPR_IRQ_ENABLED);
+
+            if (p_ioa_cfg->cpu_rst_support == IPR_CPU_RST_SUPPORT_CFGSPC_403RST_BIT)
+            {
+                while ((pci_write_config_dword(ipr_cfg->pdev, IPR_RESET_403_OFFSET, IPR_RESET_403) !=
+                        PCIBIOS_SUCCESSFUL) && delay)
+                {
+                    delay -= 10;
+                    ipr_sleep(10);
+                }
+            }
+
+            if (delay == 0)
+            {
+                ipr_log_err("Gave up trying to reset 403"IPR_EOL);
+                ipr_unit_check_no_data(ipr_cfg);
+                ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NONE);
+                ipr_unblock_all_requests(ipr_cfg);
+            }
+            else
+            {
+                ipr_get_unit_check_buffer(ipr_cfg);
+                if (WAIT_FOR_DUMP == ipr_get_sdt_state)
+                {
+                    ipr_get_sdt_state = GET_DUMP;
+                    ipr_get_ioa_smart_dump(ipr_cfg);
+                }
+
+                ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NONE);
+                ipr_unblock_all_requests(ipr_cfg);
+                if (ipr_get_sdt_state == DUMP_OBTAINED)
+                    wake_up_interruptible(&ipr_sdt_wait_q);
+            }
+        }
+    }
+    else if (ipr_cfg->flag & IPR_IOA_NEEDS_RESET)
+    {
+        if (ipr_cfg->flag & IPR_OPERATIONAL)
+        {
+            ipr_break_or_die_if_reset_reload_disabled;
+            if (WAIT_FOR_DUMP == ipr_get_sdt_state)
+                ipr_get_sdt_state = GET_DUMP;
+            ipr_reset_reload(ipr_cfg, IPR_SHUTDOWN_NONE);
+            ipr_unblock_all_requests(ipr_cfg);
+            if (ipr_get_sdt_state == DUMP_OBTAINED)
+                wake_up_interruptible(&ipr_sdt_wait_q);
+        }
+    }
+    else
+    {
+        /* Note: The path below is only for GPDD ops */
+        while(ipr_cfg->qErrorH)
+        {
+            p_sis_cmnd = ipr_cfg->qErrorH;
+            ipr_remove_sis_cmnd_from_error(ipr_cfg, p_sis_cmnd);
+
+            if (p_sis_cmnd->p_scsi_cmd != NULL)
+            {
+                p_scsi_cmd = p_sis_cmnd->p_scsi_cmd;
+                ipr_start_erp(p_sis_cmnd);
+            }
+            else
+                p_scsi_cmd = p_sis_cmnd->p_saved_scsi_cmd;
+
+            p_lun = ipr_get_lun_scsi(ipr_cfg, p_scsi_cmd);
+
+            if ((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0)
+            {
+                /* Put this op back on the pending queue to get failed
+                 back with all the others */
+                ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+
+                p_scsi_cmd->result |= (DID_ERROR << 16);
+                continue;
+            }
+
+            if (p_lun->stop_new_requests &&
+                ((p_sis_cmnd->ccb.flags & IPR_ERP_CMD) == 0))
+            {
+                ipr_end_erp(p_sis_cmnd);
+
+                /* Already doing ERP for this device */
+                ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                p_scsi_cmd->result |= (DID_ERROR << 16);
+
+                p_scsi_cmd->scsi_done(p_scsi_cmd);
+                continue;
+            }
+
+            p_cdb = p_sis_cmnd->ccb.cdb;
+            p_sis_cmnd->ccb.flags |= IPR_ERP_CMD;
+            p_lun->stop_new_requests = 1;
+
+            /* If the last command we sent with this command block was a
+             request sense and it did not fail, copy over the sense buffer */
+            if ((p_cdb[0] == REQUEST_SENSE) &&
+                (p_sis_cmnd->ccb.completion != IPR_RC_FAILED))
+                memcpy(p_scsi_cmd->sense_buffer, p_sis_cmnd->ccb.sense_buffer,
+                                   IPR_SENSE_BUFFER_COPY_SIZE);
+
+            /* If the last command issued received a check condition and
+             it was not a request sense command, issue a request sense */
+            if ((status_byte(p_sis_cmnd->ccb.status) == CHECK_CONDITION) &&
+                (p_cdb[0] != REQUEST_SENSE))
+            {
+                /* Save away check condition status to return to the host */
+                p_scsi_cmd->result |= (CHECK_CONDITION << 1);
+
+                /* Put this back on the pending queue */
+                ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+
+                p_sis_cmnd->ccb.completion = IPR_RC_SUCCESS;
+                p_sis_cmnd->ccb.status = 0;
+
+                memset(p_cdb, 0, IPR_CCB_CDB_LEN);
+
+                p_cdb[0] = REQUEST_SENSE;
+
+                ipr_auto_sense(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+            }
+            else if (p_cdb[0] != IPR_SYNC_COMPLETE)
+            {
+                /* Put this back on the pending queue */
+                ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+
+                memset(p_cdb, 0, IPR_CCB_CDB_LEN);
+
+                /* Re-use the cmd blk to send the sync-complete */
+                /* We will not send a response to the host until */
+                /* this comes back and the device is ready for another command */
+                p_cdb[0] = IPR_SYNC_COMPLETE;
+
+                p_sis_cmnd->ccb.completion = IPR_RC_SUCCESS;
+                p_sis_cmnd->ccb.status = 0;
+
+                p_sis_cmnd->ccb.flags |= IPR_IOA_CMD;
+
+                ipr_queue_internal(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+            }
+            else
+            {
+                if (status_byte(p_scsi_cmd->result) != CHECK_CONDITION)
+                {
+                    /* If we only got in here because we got back sync required
+                     and never had a check condition, then set the DID_ERROR response
+                     to force the host to do a retry */
+                    p_scsi_cmd->result |= (DID_ERROR << 16);
+                }
+                else if (ipr_sense_valid(p_scsi_cmd->sense_buffer[0]))
+                {
+                    /* We got in here because of a check condition. Do not
+                     set the DID_ERROR bit and allow the host to do the right
+                     thing based on the SCSI sense data */
+
+                    if (ipr_debug && (sense_error(p_scsi_cmd->sense_buffer[2] ==
+                                                     ILLEGAL_REQUEST)))
+                        print_Scsi_Cmnd(p_scsi_cmd);
+
+                    /* Print out the sense data */
+                    IPR_DBG_CMD(print_sense(IPR_NAME, p_scsi_cmd));
+                }
+                else
+                {
+                    /* If we only got in here because of a check condition but something
+                     went wrong and we couldn't get the sense data. Set the DID_ERROR
+                     bit to force a retry */
+                    p_scsi_cmd->result |= (DID_ERROR << 16);
+                }
+
+                p_lun->stop_new_requests = 0;
+
+                ipr_end_erp(p_sis_cmnd);
+
+                ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+
+                p_scsi_cmd->scsi_done(p_scsi_cmd);
+            }
+        }
+    }
+
+    if (ipr_cfg->flag & IPR_ALLOW_HCAMS)
+    {
+        /* Send off any new HCAMs */
+        for (i = 0; i < IPR_NUM_HCAMS; i++)
+        {
+            p_hostrcb = ipr_cfg->new_hostrcb[i];
+
+            if (p_hostrcb != NULL)
+            {
+                if (p_hostrcb->op_code == IPR_HOST_RCB_OP_CODE_CONFIG_CHANGE)
+                {
+                    /* Ship it back to the IOA to be re-used */
+                    ipr_send_hcam(&ipr_cfg->shared,
+                                     IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE, p_hostrcb);
+                }
+                else
+                {
+                    /* Ship it back to the IOA to be re-used */
+                    ipr_send_hcam(&ipr_cfg->shared,
+                                     IPR_HCAM_CDB_OP_CODE_LOG_DATA, p_hostrcb);
+                }
+
+                ipr_cfg->new_hostrcb[i] = NULL;
+            }
+        }
+
+        /* Send back HCAMs already received */
+        for (i = 0; i < IPR_NUM_HCAMS;)
+        {
+            p_hostrcb = ipr_cfg->done_hostrcb[i];
+
+            if (p_hostrcb != NULL)
+            {
+                if (p_hostrcb->op_code == IPR_HOST_RCB_OP_CODE_CONFIG_CHANGE)
+                {
+                    if (ipr_cfg->flag & IPR_ALLOW_HCAMS)
+                    {
+                        /* Here we do not ship the HCAM back since it is the
+                         responsibility of the function below to do so */
+                        ipr_handle_config_change(&ipr_cfg->shared, p_hostrcb);
+                    }
+                }
+                else
+                {
+                    ipr_handle_log_data(ipr_cfg, p_hostrcb);
+
+                    /* Ship it back to the IOA to be re-used */
+                    ipr_send_hcam(&ipr_cfg->shared,
+                                     IPR_HCAM_CDB_OP_CODE_LOG_DATA, p_hostrcb);
+                }
+
+                ipr_cfg->done_hostrcb[i] = NULL;
+                i = 0;
+            }
+            else
+                i++;
+        }
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Process the unit check buffer
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_get_unit_check_buffer(ipr_host_config *ipr_cfg)
+{
+    unsigned long mailbox, sdt_start_addr, sdt_register_sel, sdt_entry_word;
+    unsigned long unit_check_buffer, dump_entry_length;
+    u32 num_table_entries, num_entries_used, sdt_state;
+    u32 start_offset, end_offset, swap, *p_buffer;
+    u8 sdt_entry_byte;
+    struct ipr_hostrcb *p_hostrcb;
+    int i, rc;
+    struct ipr_uc_sdt smart_dump_table;
+    u8 ipr_sdt_fmt;
+
+    ENTER;
+
+    if (ipr_cfg->shared.ioa_mailbox != (unsigned long)NULL)
+    {
+        mailbox = readl(ipr_cfg->shared.ioa_mailbox);
+        sdt_register_sel = (mailbox & ipr_cfg->p_ioa_cfg->mbx_bar_sel_mask) >>
+            ipr_cfg->p_ioa_cfg->mkr_bar_sel_shift;
+        start_offset = mailbox & ipr_cfg->p_ioa_cfg->mbx_addr_mask;
+
+        /* Figure out where the Smart Dump Table is located */
+        switch (sdt_register_sel)
+        {
+            case IPR_SDT_FMT1_BAR0_SEL:
+                sdt_start_addr = ipr_cfg->shared.hdw_bar_addr[0] + start_offset;
+                ipr_sdt_fmt = IPR_SDT_FMT1;
+                swap = 0;
+                break;
+            case IPR_SDT_FMT1_BAR2_SEL:
+                sdt_start_addr = ipr_cfg->shared.hdw_bar_addr[2] + start_offset;
+                ipr_sdt_fmt = IPR_SDT_FMT1;
+                swap = 1;
+                break;
+            case IPR_SDT_FMT1_BAR3_SEL:
+                sdt_start_addr = ipr_cfg->shared.hdw_bar_addr[3] + start_offset;
+                ipr_sdt_fmt = IPR_SDT_FMT1;
+                swap = 1;
+                break;
+            case IPR_SDT_FMT2_BAR0_SEL:
+            case IPR_SDT_FMT2_BAR1_SEL:
+            case IPR_SDT_FMT2_BAR2_SEL:
+            case IPR_SDT_FMT2_BAR3_SEL:
+            case IPR_SDT_FMT2_BAR4_SEL:
+                ipr_sdt_fmt = IPR_SDT_FMT2;
+                sdt_start_addr = mailbox;
+                swap = 0;
+                break;
+            default:
+                ipr_sdt_fmt = IPR_SDT_UNKNOWN;
+                sdt_start_addr = 0;
+                swap = 0;
+                break;
+        }
+
+        if (ipr_sdt_fmt == IPR_SDT_FMT1)
+        {
+            if (swap)
+                sdt_state = swab32(readl(sdt_start_addr));
+            else
+                sdt_state = readl(sdt_start_addr);
+
+            /* Smart Dump table is ready to use and the first entry is valid */
+            if (sdt_state == IPR_FMT1_SDT_READY_TO_USE)
+            {
+                if (swap)
+                {
+                    num_table_entries = swab32(readl(sdt_start_addr + 4));
+                    num_entries_used = swab32(readl(sdt_start_addr + 8));
+                }
+                else
+                {
+                    num_table_entries = readl(sdt_start_addr + 4);
+                    num_entries_used = readl(sdt_start_addr + 8);
+                }
+
+                if ((num_table_entries > 0) && (num_entries_used > 0))
+                {
+                    if (swap)
+                        sdt_entry_byte = swab32(readl(sdt_start_addr + 28)) >> 24;
+                    else
+                        sdt_entry_byte = readl(sdt_start_addr + 28) >> 24;
+
+                    /* Is Valid bit in first entry on? */
+                    if (sdt_entry_byte & 0x20)
+                    {
+                        p_hostrcb = ipr_cfg->hostrcb[0];
+                        memset(p_hostrcb, 0, sizeof(struct ipr_hostrcb));
+
+                        if (swap)
+                            sdt_entry_word = swab32(readl(sdt_start_addr + 16));
+                        else
+                            sdt_entry_word = readl(sdt_start_addr + 16);
+
+                        sdt_register_sel = (sdt_entry_word & IPR_CHUKAR_MBX_BAR_SEL_MASK) >>
+                            IPR_CHUKAR_MKR_BAR_SEL_SHIFT;
+                        start_offset = sdt_entry_word & IPR_CHUKAR_MBX_ADDR_MASK;
+
+                        if (swap)
+                            end_offset = swab32(readl(sdt_start_addr + 20));
+                        else
+                            end_offset = readl(sdt_start_addr + 20);
+
+                        switch (sdt_register_sel)
+                        {
+                            case IPR_SDT_FMT1_BAR0_SEL:
+                                unit_check_buffer = ipr_cfg->shared.hdw_bar_addr[0] + start_offset;
+                                swap = 0;
+                                break;
+                            case IPR_SDT_FMT1_BAR2_SEL:
+                                unit_check_buffer = ipr_cfg->shared.hdw_bar_addr[2] + start_offset;
+                                swap = 1;
+                                break;
+                            case IPR_SDT_FMT1_BAR3_SEL:
+                                unit_check_buffer = ipr_cfg->shared.hdw_bar_addr[3] + start_offset;
+                                swap = 1;
+                                break;
+                            default:
+                                unit_check_buffer = 0;
+                                break;
+                        }
+
+                        if (unit_check_buffer != 0)
+                        {
+                            /* Copy over unit check buffer */
+                            for (i = 0, p_buffer = (u32 *)p_hostrcb;
+                                 i < IPR_MIN((end_offset - start_offset),1024);
+                                 i += 4)
+                            {
+                                if (swap)
+                                    p_buffer[i/4] = swab32(readl(unit_check_buffer + i));
+                                else
+                                    p_buffer[i/4] = readl(unit_check_buffer + i);
+                            }
+
+                            ipr_handle_log_data(ipr_cfg, p_hostrcb);
+                        }
+                        else /* No unit check buffer */
+                        {
+                            ipr_dbg;
+                            ipr_unit_check_no_data(ipr_cfg);
+                        }
+                    }
+                    else /* SDT not valid */
+                    {
+                        ipr_dbg;
+                        ipr_unit_check_no_data(ipr_cfg);
+                    }
+                }
+                else /* SDT not valid */
+                {
+                    ipr_dbg;
+                    ipr_unit_check_no_data(ipr_cfg);
+                }
+            }
+            else /* SDT not ready to use */
+            {
+                ipr_dbg;
+                ipr_unit_check_no_data(ipr_cfg);
+            }
+        }
+        else if (ipr_sdt_fmt == IPR_SDT_FMT2)
+        {
+            memset(&smart_dump_table, 0, sizeof(struct ipr_uc_sdt));
+            rc = ipr_get_ldump_data_section(&ipr_cfg->shared,
+                                               sdt_start_addr,
+                                               (u32 *)&smart_dump_table,
+                                               (sizeof(struct ipr_uc_sdt))
+                                               / sizeof (u32));
+
+            /* If Smart Dump Table state is invalid OR no UC buff entry or not
+             valid */
+            if ((rc == IPR_RC_FAILED) ||
+                (sistoh32(smart_dump_table.sdt_header.dump_state) != IPR_FMT2_SDT_READY_TO_USE) || 
+                (smart_dump_table.sdt_entry[0].bar_str_offset == 0)  ||
+                (!(smart_dump_table.sdt_entry[0].valid_entry)))
+            {
+                ipr_dbg;
+                ipr_unit_check_no_data(ipr_cfg);
+                return;
+            }
+
+            /* Find length of the first sdt entry (UC buffer) */
+            dump_entry_length =
+                (sistoh32(smart_dump_table.sdt_entry[0].end_offset) -
+                 sistoh32(smart_dump_table.sdt_entry[0].bar_str_offset)) &
+                IPR_FMT2_MBX_ADDR_MASK;
+
+            p_hostrcb = ipr_cfg->hostrcb[0];
+            memset(p_hostrcb, 0, sizeof(struct ipr_hostrcb));
+            rc = ipr_get_ldump_data_section(&ipr_cfg->shared,
+                                               sistoh32(smart_dump_table.sdt_entry[0].bar_str_offset),
+                                               (u32 *)p_hostrcb,
+                                               IPR_MIN(dump_entry_length/sizeof(u32), 256));
+
+            if (rc == IPR_RC_SUCCESS)
+                ipr_handle_log_data(ipr_cfg, p_hostrcb);
+            else
+            {
+                ipr_trace;
+                ipr_unit_check_no_data(ipr_cfg);
+            }
+        }
+        else /* No smart dump table */
+        {
+            ipr_dbg;
+            ipr_unit_check_no_data(ipr_cfg);
+        }
+    }
+    else /* No mailbox pointer */
+    {
+        ipr_dbg;
+        ipr_unit_check_no_data(ipr_cfg);
+    }
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Log error for unit check no data
+ * Context: Task or interrupt level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_unit_check_no_data(ipr_host_config *ipr_cfg)
+{
+    /* If this is a 2780, it might need a code download -
+     lets eat the error and try to bring up the IOA again */
+    if (!ipr_cfg->shared.needs_download &&
+        (ipr_cfg->shared.vendor_id == PCI_VENDOR_ID_IBM) &&
+        (ipr_cfg->shared.device_id == PCI_DEVICE_ID_IBM_SNIPE) &&
+        (ipr_cfg->shared.subsystem_id == IPR_SUBS_DEV_ID_2780))
+    {
+        ipr_cfg->shared.needs_download = 1;
+    }
+    else
+    {
+        ipr_beg_err(KERN_CRIT);
+        ipr_log_crit("IOA unit check with no data"IPR_EOL);
+        ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_CRIT);
+        ipr_end_err(KERN_CRIT);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get DMA address of given HCAM buffer
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: DMA address of HCAM - will panic if it cannot be found
+ *---------------------------------------------------------------------------*/
+static ipr_dma_addr ipr_get_hcam_dma_addr(ipr_host_config *ipr_cfg,
+                                                struct ipr_hostrcb *p_hostrcb)
+{
+    int i;
+
+    for (i = 0; i < IPR_NUM_HCAMS; i++)
+    {
+        if (ipr_cfg->hostrcb[i] == p_hostrcb)
+            return ipr_cfg->hostrcb_dma[i];
+    }
+    panic(IPR_ERR": HostRCB was not found!!"IPR_EOL);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Kernel thread for ERP and HCAMS
+ * Context: Task level only
+ * Lock State: No lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+int ipr_task_thread(void *data)
+{
+    unsigned long io_flags;
+    ipr_host_config *ipr_cfg = (ipr_host_config *)data;
+
+    lock_kernel();
+
+    daemonize();
+    reparent_to_init();
+
+    sprintf(current->comm, IPR_NAME"_%d", ipr_cfg->host->host_no);
+
+    ipr_cfg->task_thread = current;
+
+    siginitsetinv(&current->blocked, SHUTDOWN_SIGS);
+
+    md_flush_signals();
+
+    unlock_kernel();
+
+    complete(ipr_cfg->completion); /* OK for caller to continue */
+
+    spin_lock_irqsave(&io_request_lock, io_flags);
+
+    init_waitqueue_head(&ipr_cfg->wait_q);
+
+    while(1)
+    {
+        ipr_interruptible_sleep_on(&io_request_lock, &ipr_cfg->wait_q);
+
+        if (signal_pending(current))
+        {
+            if (ipr_cfg->flag & IPR_KILL_KERNEL_THREAD)
+                break;
+            else
+            {
+                /* Ignore the signal */
+                md_flush_signals();
+                continue;
+            }
+        }
+
+        ipr_mailbox(ipr_cfg);
+    }
+
+    ipr_cfg->task_thread = NULL;
+
+    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+    if( ipr_cfg->completion != NULL )
+        complete(ipr_cfg->completion);
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Munges the URC
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: urc - munged urc
+ *---------------------------------------------------------------------------*/
+static u16 ipr_adjust_urc(u32 error_index,
+                             struct ipr_res_addr resource_addr,
+                             u32 ioasc,
+                             u32 dev_urc,
+                             char *p_error_string)
+{
+    u16 urc;
+
+    if (dev_urc)
+        urc = ipr_error_table[error_index].dev_urc;
+    else
+        urc = ipr_error_table[error_index].iop_urc;
+
+    strcpy(p_error_string, ipr_error_table[error_index].p_error);
+
+    switch (ioasc)
+    {
+        case 0x01080000:
+            if (!dev_urc) /* 8140 and 813x */
+                strcpy(p_error_string, "IOA detected recoverable device bus error");
+
+            if (IPR_GET_PHYSICAL_LOCATOR(resource_addr) != IPR_IOA_RESOURCE_ADDRESS)
+            {
+                if (dev_urc)
+                    urc = 0xfffe;
+                else
+                    urc = 0x8130 | (resource_addr.bus & 0xf);
+            }
+            break;
+        case 0x015D0000:
+            if (!dev_urc)
+            {
+                if (IPR_GET_PHYSICAL_LOCATOR(resource_addr) != IPR_IOA_RESOURCE_ADDRESS)
+                    urc = 0x8146;
+                else /* 8145 */
+                    strcpy(p_error_string, "A recoverable IOA error occurred");
+            }
+            break;
+        case 0x04080000:
+        case 0x04088000:
+        case 0x06288000:
+        case 0x06678000:
+            urc |= (resource_addr.bus & 0xf);
+            break;
+        case 0x06670600:
+            if (!dev_urc)
+                urc |= (resource_addr.bus & 0xf);
+            break;
+        case 0x04080100:
+            if (IPR_GET_PHYSICAL_LOCATOR(resource_addr) == IPR_IOA_RESOURCE_ADDRESS)
+            {
+                if (dev_urc)
+                    urc = 0;
+                else
+                {
+                    urc = 0x8150;
+                    strcpy(p_error_string, "A permanent IOA failure occurred");
+                }
+            }
+            break;
+        default:
+            break;
+    }
+
+    if (urc == 0x8141)
+        strcpy(p_error_string, "IOA detected recoverable device error");
+    else if (urc == 0x3400)
+        strcpy(p_error_string, "IOA detected device error");
+    else if (urc == 0xFFFB)
+        strcpy(p_error_string, "SCSI bus reset occurred");
+
+    return urc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Interface for us to issue requests internally to resources
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Failure
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+int ipr_do_req(struct ipr_shared_config *p_shared_cfg,
+                  struct ipr_ccb *p_sis_ccb,
+                  void (*done) (struct ipr_shared_config *, struct ipr_ccb *),
+                  u32 timeout_in_sec)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    u32 rc;
+    ipr_host_config *ipr_cfg = (ipr_host_config *)p_shared_cfg;
+    struct ipr_lun *p_lun;
+
+    if ((ipr_cfg->shared.ioa_operational == 0) ||
+        (((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0) &&
+         ((p_sis_ccb->flags & IPR_ALLOW_REQ_OVERRIDE) == 0)))
+    {
+        ipr_dbg_trace;
+        return IPR_RC_OP_NOT_SENT;
+    }
+
+    p_sis_cmnd = (struct ipr_cmnd *)p_sis_ccb;
+
+    p_lun = ipr_get_lun_res_addr(ipr_cfg, p_sis_cmnd->ccb.p_resource->resource_address);
+
+    if (p_lun && p_lun->stop_new_requests)
+    {
+        ipr_dbg_trace;
+        return IPR_RC_OP_NOT_SENT;
+    }
+
+    ipr_put_sis_cmnd_to_pending(ipr_cfg, p_sis_cmnd);
+
+    rc = ipr_build_sglist(ipr_cfg, p_sis_cmnd);
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        ipr_remove_sis_cmnd_from_pending(ipr_cfg, p_sis_cmnd);
+        return rc;
+    }
+
+    p_sis_cmnd->done = done;
+
+    p_sis_cmnd->ccb.flags |= IPR_INTERNAL_REQ;
+
+    if (!p_sis_cmnd->ccb.p_resource->is_ioa_resource &&
+             !p_sis_cmnd->ccb.p_resource->is_af)
+    {
+        p_sis_cmnd->ccb.flags |= IPR_GPDD_CMD;
+
+        /* Double the timeout value to use as we will use the adapter
+         as the primary timing mechanism */
+        if (1 == IPR_TIMEOUT_MULTIPLIER)
+            p_sis_cmnd->ccb.timeout = 0x3fff;
+        else
+        {
+            p_sis_cmnd->ccb.timeout = timeout_in_sec;
+            timeout_in_sec *= 2;
+        }
+    }
+    else if (p_sis_cmnd->ccb.p_resource->is_ioa_resource &&
+             (p_sis_cmnd->ccb.cdb[0] == IPR_SUSPEND_DEV_BUS))
+    {
+        /* Double the timeout value to use as we will use the adapter
+         as the primary timing mechanism */
+        if (1 == IPR_TIMEOUT_MULTIPLIER)
+            p_sis_cmnd->ccb.timeout = 0x3fff;
+        else
+        {
+            p_sis_cmnd->ccb.timeout = timeout_in_sec;
+            timeout_in_sec *= 2;
+        }
+    }
+
+    init_timer(&p_sis_cmnd->timer);
+
+    p_sis_cmnd->timer.data = (unsigned long)ipr_cfg;
+    p_sis_cmnd->timer.expires = jiffies + (timeout_in_sec * HZ);
+    p_sis_cmnd->timer.function = (void (*)(unsigned long))ipr_timeout;
+
+    add_timer(&p_sis_cmnd->timer);
+
+    if (p_sis_cmnd->ccb.p_resource == &ipr_cfg->shared.ioa_resource)
+        rc = ipr_ioa_queue(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+    else
+        rc = ipr_queue_internal(&ipr_cfg->shared, &p_sis_cmnd->ccb);
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        ipr_dbg_trace;
+        del_timer(&p_sis_cmnd->timer);
+        ipr_remove_sis_cmnd_from_pending(ipr_cfg, p_sis_cmnd);
+    }
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: req a reset of the adapter, log no errors, and take no dump
+ * Context: Task or Interrupt level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: None
+ *---------------------------------------------------------------------------*/
+void ipr_req_reset(struct ipr_shared_config *p_shared_cfg)
+{
+    ipr_host_config *ipr_cfg = (ipr_host_config *)p_shared_cfg;
+
+    ENTER;
+
+    /* Prevent ourselves from getting any more requests */
+    ipr_block_all_requests(ipr_cfg);
+
+    ipr_cfg->flag |= IPR_IOA_NEEDS_RESET;
+
+    /* Wake up task level thread to reset adapter */
+    ipr_wake_task(ipr_cfg);
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: An internally generated op has timed out
+ * Context: Interrupt level only
+ * Lock State: no locks assumed to be held
+ * Returns: None
+ *---------------------------------------------------------------------------*/
+void ipr_timeout(ipr_host_config *ipr_cfg)
+{
+    unsigned long io_flags = 0;
+
+    ENTER;
+
+    spin_lock_irqsave(&io_request_lock, io_flags);
+
+    ipr_beg_err(KERN_ERR);
+    ipr_log_err("Adapter being reset as a result of system timeout."IPR_EOL);
+    ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_ERR);
+    ipr_end_err(KERN_ERR);
+
+    /* Prevent ourselves from getting any more requests */
+    ipr_block_all_requests(ipr_cfg);
+
+    ipr_cfg->flag |= IPR_IOA_NEEDS_RESET;
+
+    /* Wake up task level thread to reset adapter */
+    ipr_wake_task(ipr_cfg);
+
+    spin_unlock_irqrestore(&io_request_lock, io_flags);
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allocate a ccb for an internal request
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Pointer to ccb
+ *---------------------------------------------------------------------------*/
+struct ipr_ccb * ipr_allocate_ccb(struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    ipr_host_config *ipr_cfg = (ipr_host_config *)p_shared_cfg;
+
+    if ((ipr_cfg->flag & IPR_ALLOW_REQUESTS) == 0)
+        return NULL;
+
+    p_sis_cmnd = ipr_get_free_sis_cmnd(ipr_cfg);
+
+    return &p_sis_cmnd->ccb;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Free a ccb that was allocated with ipr_allocate_ccb
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_release_ccb(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_ccb *p_sis_ccb)
+{
+    struct ipr_cmnd *p_sis_cmnd;
+    ipr_host_config *ipr_cfg = (ipr_host_config *)p_shared_cfg;
+
+    p_sis_cmnd = (struct ipr_cmnd *)p_sis_ccb;
+    ipr_put_sis_cmnd_to_free(ipr_cfg, p_sis_cmnd);
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Stop the host from issuing new requests.
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_block_all_requests(ipr_host_config *ipr_cfg)
+{
+    ENTER;
+
+    if (0 == ipr_cfg->block_host_ops++)
+    {
+        ipr_cfg->flag &= ~(IPR_ALLOW_HCAMS | IPR_ALLOW_REQUESTS);
+
+        /* Stop new requests from coming in */
+        scsi_block_requests(ipr_cfg->host);
+    }
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allow the host to send requests again
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_unblock_all_requests(ipr_host_config *ipr_cfg)
+{
+    ENTER;
+
+    if (0 == --ipr_cfg->block_host_ops)
+    {
+        spin_unlock_irq(&io_request_lock);
+        scsi_unblock_requests(ipr_cfg->host);
+        spin_lock_irq(&io_request_lock);
+
+        ipr_cfg->flag |= IPR_ALLOW_HCAMS | IPR_ALLOW_REQUESTS;
+
+        /* Send back any failed ops to the host */
+        ipr_return_failed_ops(ipr_cfg);
+    }
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Stop the host from issuing new requests.
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_block_midlayer_requests(ipr_host_config *ipr_cfg)
+{
+    ENTER;
+
+    if (0 == ipr_cfg->block_host_ops++)
+    {
+        /* Stop new requests from coming in */
+        scsi_block_requests(ipr_cfg->host);
+    }
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allow the host to send requests again
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_unblock_midlayer_requests(ipr_host_config *ipr_cfg)
+{
+    ENTER;
+
+    if (0 == --ipr_cfg->block_host_ops)
+    {
+        spin_unlock_irq(&io_request_lock);
+        scsi_unblock_requests(ipr_cfg->host);
+        spin_lock_irq(&io_request_lock);
+    }
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Returns the /dev entry name of the IOA
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_get_ioa_name(ipr_host_config *ipr_cfg,
+                                char *dev_name)
+{
+    sprintf(dev_name, "/dev/"IPR_NAME"%d", ipr_cfg->minor_num);
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Find SES resource for given device resource address
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to resource entry or NULL
+ *---------------------------------------------------------------------------*/
+static struct ipr_resource_entry *ipr_get_ses_resource(ipr_host_config *ipr_cfg,
+                                                             struct ipr_res_addr res_addr)
+{
+    struct ipr_resource_entry *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll;
+
+    /* Loop through config table to find device */
+    for (p_resource_dll = ipr_cfg->shared.rsteUsedH;
+         p_resource_dll != NULL;
+         p_resource_dll = p_resource_dll->next)
+    {
+        p_resource_entry = &p_resource_dll->data;
+
+        if ((p_resource_entry->resource_address.bus == res_addr.bus) &&
+            IPR_IS_SES_DEVICE(p_resource_entry->std_inq_data))
+        {
+            return p_resource_entry;
+        }
+    }
+    return NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Copy smart dump data from kernel space to user space.
+ * Context: Task level only
+ * Lock State: io_request_lock not held
+ * Returns: 0           - Success
+ *          others      - Failed
+ *---------------------------------------------------------------------------*/
+static int ipr_copy_sdt_to_user(u8 *p_dest_buffer, u32 length)
+{
+    u32 *p_src_buffer;
+    int page_index = 0;
+    int bytes_to_copy = PAGE_SIZE;
+    int result = IPR_RC_SUCCESS;
+
+    if ((p_ipr_dump_driver_header == NULL) || (p_ipr_dump_ioa_entry == NULL))
+        return -ENOMEM;
+
+    if (ipr_get_sdt_state != DUMP_OBTAINED)
+        return -EIO;
+
+    result = copy_to_user(p_dest_buffer, p_ipr_dump_driver_header,
+                          sizeof(struct ipr_dump_driver_header));
+
+    p_dest_buffer += sizeof(struct ipr_dump_driver_header);
+
+    length -= sizeof(struct ipr_dump_driver_header);
+
+    if (!result)
+    {
+        result = copy_to_user(p_dest_buffer, &p_ipr_dump_ioa_entry->header,
+                              sizeof(struct ipr_dump_entry_header));
+
+        p_dest_buffer += sizeof(struct ipr_dump_entry_header);
+
+        length -= sizeof(struct ipr_dump_entry_header);
+    }
+
+    if (!result)
+    {
+        result = copy_to_user(p_dest_buffer, &p_ipr_dump_ioa_entry->sdt,
+                              sizeof(struct ipr_sdt));
+
+        p_dest_buffer += sizeof(struct ipr_sdt);
+
+        length -= sizeof(struct ipr_sdt);
+    }
+
+    while ((p_src_buffer = p_ipr_dump_ioa_entry->p_ioa_data[page_index]))
+    {
+        if (length)
+        {
+            if (length > PAGE_SIZE)
+                length -= PAGE_SIZE;
+            else
+            {
+                bytes_to_copy = length;
+                length = 0;
+            }
+
+            if (!result)
+            {
+                result = copy_to_user(p_dest_buffer, p_src_buffer, bytes_to_copy);
+                p_dest_buffer += bytes_to_copy;
+            }
+        }
+
+        ipr_free_page(p_src_buffer);
+        p_ipr_dump_ioa_entry->p_ioa_data[page_index] = NULL;
+        page_index++;
+    }
+
+    return result;
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Obtain smart dump data
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0           - Success
+ *          others      - Failed
+ * Note: Since we could be running on both big and little endian machines
+ *       we store the dump as if we were running on a big endian machine
+ *       so the analysis tools only have to deal with one format of dump
+ *---------------------------------------------------------------------------*/
+static int ipr_get_ioa_smart_dump(ipr_host_config *ipr_cfg)
+{
+    unsigned long mailbox, sdt_start_addr, sdt_register_sel, sdt_entry_word, dump_data_buffer;
+    u32 num_table_entries, num_entries_used, start_offset, end_offset, swap;
+    u32 rc = PCIBIOS_SUCCESSFUL, ret_val;
+    u32 byte_index, bytes_to_copy, bytes_copied;
+    u32 *p_buffer;
+    const struct ipr_ioa_cfg_t *p_ioa_cfg = ipr_cfg->p_ioa_cfg;
+    struct ipr_sdt *p_sdt;
+    int sdt_entry_index;
+    unsigned long timeout;
+
+    ENTER;
+
+    if ((p_ipr_dump_ioa_entry == NULL) || (p_ipr_dump_driver_header == NULL))
+    {
+        ipr_trace;
+        return -EINVAL;
+    }
+
+    if (p_ioa_cfg->cpu_rst_support == IPR_CPU_RST_SUPPORT_CFGSPC_403RST_BIT)
+    {
+        /* Hold the 403 in reset so we can get the dump */
+        rc = pci_write_config_dword(ipr_cfg->pdev, IPR_RESET_403_OFFSET, IPR_RESET_403);
+    }
+
+    if (rc != PCIBIOS_SUCCESSFUL)
+    {
+        ipr_trace;
+        return -ENXIO;
+    }
+
+    if (ipr_cfg->shared.ioa_mailbox == (unsigned long)NULL)
+    {
+        ipr_trace;
+        return -ENXIO;
+    }
+
+    mailbox = readl(ipr_cfg->shared.ioa_mailbox);
+    sdt_register_sel = (mailbox & ipr_cfg->p_ioa_cfg->mbx_bar_sel_mask) >>
+        ipr_cfg->p_ioa_cfg->mkr_bar_sel_shift;
+    start_offset = mailbox & ipr_cfg->p_ioa_cfg->mbx_addr_mask;
+
+    /* Figure out where the Smart Dump Table is located */
+    switch (sdt_register_sel)
+    {
+        case IPR_SDT_FMT1_BAR0_SEL:
+            sdt_start_addr = ipr_cfg->shared.hdw_bar_addr[0] + start_offset;
+            p_ipr_dump_ioa_entry->format = IPR_SDT_FMT1;
+            swap = 0;
+            break;
+        case IPR_SDT_FMT1_BAR2_SEL:
+            sdt_start_addr = ipr_cfg->shared.hdw_bar_addr[2] + start_offset;
+            p_ipr_dump_ioa_entry->format = IPR_SDT_FMT1;
+            swap = 1;
+            break;
+        case IPR_SDT_FMT1_BAR3_SEL:
+            sdt_start_addr = ipr_cfg->shared.hdw_bar_addr[3] + start_offset;
+            p_ipr_dump_ioa_entry->format = IPR_SDT_FMT1;
+            swap = 1;
+            break;
+        case IPR_SDT_FMT2_BAR0_SEL:
+        case IPR_SDT_FMT2_BAR1_SEL:
+        case IPR_SDT_FMT2_BAR2_SEL:
+        case IPR_SDT_FMT2_BAR3_SEL:
+        case IPR_SDT_FMT2_BAR4_SEL:
+            p_ipr_dump_ioa_entry->format = IPR_SDT_FMT2;
+            sdt_start_addr = mailbox;
+            swap = 0;
+            break;
+        default:
+            ipr_log_err("Invalid SDT format: %lx"IPR_EOL, sdt_register_sel);
+            sdt_start_addr = 0;
+            swap = 0;
+            break;
+    }
+
+    if (sdt_start_addr != 0)
+    {
+        ipr_log_err("Dump of IOA at %s initiated."IPR_EOL,
+                       ipr_cfg->shared.ioa_host_str);
+
+        /* Determine a timeout value to use */
+        timeout = jiffies + IPR_MAX_DUMP_FETCH_TIME;
+
+        /* Initialize the overall dump header */
+        p_ipr_dump_driver_header->header.total_length =
+            htosis32(sizeof(struct ipr_dump_driver_header));
+
+        p_ipr_dump_driver_header->header.num_elems = htosis32(1);
+
+        p_ipr_dump_driver_header->header.first_entry_offset =
+            htosis32(sizeof(struct ipr_dump_header));
+
+        p_ipr_dump_driver_header->header.status = htosis32(IPR_RC_SUCCESS);
+
+        /* IOA location data */
+        p_ipr_dump_driver_header->location_entry.header.length =
+            htosis32(sizeof(struct ipr_dump_location_entry) -
+                     sizeof(struct ipr_dump_entry_header));
+        p_ipr_dump_driver_header->location_entry.header.id = htosis32(IPR_DUMP_TEXT_ID);
+
+        strcpy(p_ipr_dump_driver_header->location_entry.location,
+               ipr_cfg->shared.ioa_host_str);
+
+        /* Internal trace table entry */
+        ipr_copy_internal_trace_for_dump(&ipr_cfg->shared,
+                                            p_ipr_dump_driver_header->trace_entry.trace,
+                                            IPR_DUMP_TRACE_ENTRY_SIZE);
+
+        p_ipr_dump_driver_header->header.num_elems =
+            htosis32(sistoh32(p_ipr_dump_driver_header->header.num_elems) + 1);
+
+        p_ipr_dump_driver_header->trace_entry.header.length =
+            htosis32(sizeof(struct ipr_dump_trace_entry) -
+                     sizeof(struct ipr_dump_entry_header));
+        p_ipr_dump_driver_header->trace_entry.header.id =
+            htosis32(IPR_DUMP_TRACE_ID);
+
+        /* IOA Dump entry */
+        p_ipr_dump_ioa_entry->header.length = 0;
+        p_ipr_dump_ioa_entry->header.id = htosis32(IPR_DUMP_IOA_DUMP_ID);
+
+        /* Update dump_header */
+        p_ipr_dump_driver_header->header.total_length =
+            htosis32(sistoh32(p_ipr_dump_driver_header->header.total_length) +
+                     sizeof(struct ipr_dump_entry_header));
+
+        p_ipr_dump_driver_header->header.num_elems =
+            htosis32(sistoh32(p_ipr_dump_driver_header->header.num_elems) + 1);
+
+        p_buffer = (u32 *)&p_ipr_dump_ioa_entry->sdt;
+
+        /* Get the IOA Smart Dump Table */
+        if (p_ipr_dump_ioa_entry->format == IPR_SDT_FMT1)
+        {
+            rc = IPR_RC_SUCCESS;
+
+            for (byte_index = 0;
+                 byte_index < sizeof(struct ipr_sdt);
+                 byte_index += 4)
+            {
+                if (swap)
+                    p_buffer[byte_index/4] = swab32(readl(sdt_start_addr + byte_index));
+                else
+                    p_buffer[byte_index/4] = readl(sdt_start_addr + byte_index);
+            }
+        }
+        else
+        {
+            rc = ipr_get_ldump_data_section(&ipr_cfg->shared,
+                                               sdt_start_addr, p_buffer,
+                                               sizeof(struct ipr_sdt)/sizeof(u32));
+        }
+
+        /* First entries in sdt are actually a list of dump addresses and
+         lengths to gather the real dump data.  p_sdt represents the pointer
+         to the ioa generated dump table.  Dump data will be extracted based
+         on entries in this table */
+        p_sdt = &p_ipr_dump_ioa_entry->sdt;
+
+        /* Smart Dump table is ready to use and the first entry is valid */
+        if  ((rc == IPR_RC_FAILED) ||
+             ((sistoh32(p_sdt->sdt_header.dump_state) != IPR_FMT1_SDT_READY_TO_USE) &&
+              (sistoh32(p_sdt->sdt_header.dump_state) != IPR_FMT2_SDT_READY_TO_USE)))
+        {
+            ipr_log_err("Dump of IOA at %s failed. Dump table not valid."IPR_EOL,
+                           ipr_cfg->shared.ioa_host_str);
+            p_ipr_dump_driver_header->header.status = htosis32(IPR_RC_FAILED);
+            ipr_get_sdt_state = DUMP_OBTAINED;
+            return IPR_RC_SUCCESS;
+        }
+
+        num_table_entries = sistoh32(p_sdt->sdt_header.num_entries);
+        num_entries_used = sistoh32(p_sdt->sdt_header.num_entries_used);
+
+        for (sdt_entry_index = 0;
+             (sdt_entry_index < num_entries_used) &&
+                 (sdt_entry_index < num_table_entries) &&
+                 (sdt_entry_index < IPR_NUM_SDT_ENTRIES) &&
+                 time_after_eq(timeout, jiffies) &&
+                 (sistoh32(p_ipr_dump_ioa_entry->header.length) < IPR_MAX_IOA_DUMP_SIZE);
+             sdt_entry_index++)
+        {
+            if (p_sdt->sdt_entry[sdt_entry_index].valid_entry)
+            {
+                sdt_entry_word = sistoh32(p_sdt->sdt_entry[sdt_entry_index].bar_str_offset);
+                sdt_register_sel = (sdt_entry_word & ipr_cfg->p_ioa_cfg->mbx_bar_sel_mask)
+                    >> ipr_cfg->p_ioa_cfg->mkr_bar_sel_shift;
+                start_offset = sdt_entry_word & ipr_cfg->p_ioa_cfg->mbx_addr_mask;
+                end_offset = sistoh32(p_sdt->sdt_entry[sdt_entry_index].end_offset);
+
+                /* Figure out where the Smart Dump Table is located */
+                switch (sdt_register_sel)
+                {
+                    case IPR_SDT_FMT1_BAR0_SEL:
+                        dump_data_buffer = ipr_cfg->shared.hdw_bar_addr[0] + start_offset;
+                        swap = 0;
+                        break;
+                    case IPR_SDT_FMT1_BAR2_SEL:
+                        dump_data_buffer = ipr_cfg->shared.hdw_bar_addr[2] + start_offset;
+                        swap = 1;
+                        break;
+                    case IPR_SDT_FMT1_BAR3_SEL:
+                        dump_data_buffer = ipr_cfg->shared.hdw_bar_addr[3] + start_offset;
+                        swap = 1;
+                        break;
+                    case IPR_SDT_FMT2_BAR0_SEL:
+                    case IPR_SDT_FMT2_BAR1_SEL:
+                    case IPR_SDT_FMT2_BAR2_SEL:
+                    case IPR_SDT_FMT2_BAR3_SEL:
+                    case IPR_SDT_FMT2_BAR4_SEL:
+                        dump_data_buffer = sdt_entry_word;
+                        swap = 0;
+                        break;
+                    default:
+                        dump_data_buffer = 0;
+                        swap = 0;
+                        break;
+                }
+
+                if (dump_data_buffer != 0)
+                {
+                    /* Dump_header will be updated after all ioa sdt
+                       dump entries have been obtained. */
+                    /* Copy data from adapter to driver buffers */
+                    bytes_to_copy = (end_offset - start_offset);
+                    bytes_copied = ipr_sdt_copy(ipr_cfg, dump_data_buffer,
+                                                   bytes_to_copy, swap, timeout);
+
+                    /* Update dump_entry_header length */
+                    p_ipr_dump_ioa_entry->header.length =
+                        htosis32(sistoh32(p_ipr_dump_ioa_entry->header.length) + bytes_copied);
+
+                    if (bytes_copied != bytes_to_copy)
+                    {
+                        ipr_log_err("Dump of IOA at %s completed."IPR_EOL,
+                                       ipr_cfg->shared.ioa_host_str);
+                        p_ipr_dump_driver_header->header.status = htosis32(IPR_RC_QUAL_SUCCESS);
+
+                        if (time_before_eq(timeout, jiffies))
+                        {
+                            ipr_dbg_trace;
+                        }
+                        else
+                        {
+                            ipr_dbg_trace;
+                        }
+
+                        p_ipr_dump_driver_header->header.total_length =
+                            htosis32(sistoh32(p_ipr_dump_driver_header->header.total_length) +
+                            sistoh32(p_ipr_dump_ioa_entry->header.length));
+                        ipr_get_sdt_state = DUMP_OBTAINED;
+                        return IPR_RC_SUCCESS;
+                    }
+                }
+            }
+        }
+
+        ipr_log_err("Dump of IOA at %s completed."IPR_EOL,
+                       ipr_cfg->shared.ioa_host_str);
+
+        /* Update dump_header */
+        p_ipr_dump_driver_header->header.total_length =
+            htosis32(sistoh32(p_ipr_dump_driver_header->header.total_length) +
+            sistoh32(p_ipr_dump_ioa_entry->header.length));
+
+        ipr_get_sdt_state = DUMP_OBTAINED;
+        ret_val = IPR_RC_SUCCESS;
+    }
+    else
+        ret_val = IPR_RC_FAILED;
+
+    LEAVE;
+
+    return ret_val;
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Copy data from PCI adapter to driver buffer to user space.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Return:  number of bytes copied to copy buffer
+ *
+ * NOTE:  lengths of requests MUST be 4 byte bounded.
+ *---------------------------------------------------------------------------*/
+static int ipr_sdt_copy(ipr_host_config *ipr_cfg, unsigned long pci_address,
+                           u32 length, u32 swap, unsigned long timeout)
+{
+    int bytes_copied = 0;
+    int current_length, rc;
+    u32 *p_page = NULL;
+
+    while ((bytes_copied < length) && time_after_eq(timeout, jiffies) &&
+           ((sistoh32(p_ipr_dump_ioa_entry->header.length) + bytes_copied) <
+            IPR_MAX_IOA_DUMP_SIZE))
+    {
+        if ((p_ipr_dump_ioa_entry->page_offset >= PAGE_SIZE) ||
+            (p_ipr_dump_ioa_entry->page_offset == 0))
+        {
+            p_page = ipr_get_free_page(GFP_ATOMIC);
+
+            if (NULL == p_page)
+            {
+                ipr_trace;
+                return bytes_copied;
+            }
+
+            p_ipr_dump_ioa_entry->page_offset = 0;
+            p_ipr_dump_ioa_entry->p_ioa_data[p_ipr_dump_ioa_entry->next_page_index] = p_page;
+            p_ipr_dump_ioa_entry->next_page_index++;
+        }
+        else
+            p_page = p_ipr_dump_ioa_entry->p_ioa_data[p_ipr_dump_ioa_entry->next_page_index - 1];
+
+        if (p_ipr_dump_ioa_entry->format == IPR_SDT_FMT1)
+        {
+            if (swap)
+            {
+                p_page[p_ipr_dump_ioa_entry->page_offset/4] =
+                    swab32(readl(pci_address + bytes_copied));
+            }
+            else
+            {
+                p_page[p_ipr_dump_ioa_entry->page_offset/4] =
+                    readl(pci_address + bytes_copied);
+            }
+
+            p_ipr_dump_ioa_entry->page_offset += 4;
+            bytes_copied += 4;
+        }
+        else
+        {
+            /* Copy the min of remaining length to copy and the remaining space in this page */
+            current_length = IPR_MIN((length - bytes_copied),
+                                        (PAGE_SIZE - p_ipr_dump_ioa_entry->page_offset));
+
+            rc = ipr_get_ldump_data_section(&ipr_cfg->shared,
+                                               pci_address + bytes_copied,
+                                               (u32*)&p_page[p_ipr_dump_ioa_entry->page_offset/4],
+                                               (current_length / sizeof (u32)));
+
+            if (rc == IPR_RC_SUCCESS)
+            {
+                p_ipr_dump_ioa_entry->page_offset += current_length;
+                bytes_copied += current_length;
+            }
+            else
+            {
+                ipr_trace;
+                break;
+            }
+
+            /* Since our dump could take a while, we want to let other people
+             have some processor time while we dump */
+            ipr_sleep(1);
+        }
+    }
+
+    return bytes_copied;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: delay usecs
+ * Context: Task level only
+ * Lock State: io_request_lock can be in any state
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_udelay(signed long delay)
+{
+    if ((delay/1000) > MAX_UDELAY_MS)
+        mdelay(delay/1000);
+    else
+        udelay(delay);
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Sleeps for delay msecs
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_sleep(signed long delay)
+{
+    spin_unlock_irq(&io_request_lock);
+    ipr_sleep_no_lock(delay);
+    spin_lock_irq(&io_request_lock);
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Sleeps for delay msecs
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to not be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_sleep_no_lock(signed long delay)
+{
+    DECLARE_WAIT_QUEUE_HEAD(internal_wait);
+
+    sleep_on_timeout(&internal_wait, (delay * HZ)/1000);
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print to the kernel log and to the current tty if appropriate
+ * Context: Task or interrupt level
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_print_tty(char *s, ...)
+{
+    va_list args;
+    struct tty_struct *p_tty;
+    char *endline;
+    char *p_buffer;
+
+    va_start(args, s);
+    vsprintf(ipr_buf, s, args);
+    va_end(args);
+
+    printk(ipr_buf);
+
+    if (!ipr_init_finished)
+    {
+        /* Print to the tty as well if we can */
+        p_tty = current->tty;
+        p_buffer = ipr_buf;
+
+        if (p_tty && p_tty->driver.write)
+        {
+            endline = strchr(p_buffer, '\n');
+            if (endline)
+            {
+                *endline = '\0';
+                strcat(p_buffer, "\015\012");
+            }
+
+            /* Strip off KERN_ERR part */
+            endline = strchr(p_buffer, '<');
+            if (endline == p_buffer)
+            {
+                p_buffer += 3;
+            }
+
+            /* Strip off our prefix */
+            endline = strstr(p_buffer, IPR_ERR);
+            if (endline)
+            {
+                p_buffer += (IPR_ERR_LEN + 2);
+            }
+            else
+            {
+                endline = strstr(p_buffer, IPR_NAME);
+                if (endline)
+                {
+                    p_buffer += (IPR_NAME_LEN + 2);
+                }
+            }
+
+            p_tty->driver.write(p_tty, 0, p_buffer, strlen(p_buffer));
+        }
+    }
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Translate ipr malloc flags to kmalloc flags
+ * Context: Task or interrupt level
+ * Lock State: no locks required
+ * Returns: kmalloc flags
+ *---------------------------------------------------------------------------*/
+static u32 ipr_xlate_malloc_flags(u32 flags)
+{
+    u32 kmalloc_flags = 0;
+
+    if (flags & IPR_ALLOC_CAN_SLEEP)
+        kmalloc_flags |= GFP_KERNEL;
+    else if (flags & IPR_ALLOC_ATOMIC)
+        kmalloc_flags |= GFP_ATOMIC;
+    else if (ipr_mem_debug)
+        panic(IPR_ERR"Invalid kmalloc flags: %x"IPR_EOL, flags);
+    return kmalloc_flags;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: kmalloc wrapper
+ * Context: Task level only
+ * Lock State: no locks required
+ * Returns: pointer to storage or NULL on failure
+ *---------------------------------------------------------------------------*/
+void *ipr_kmalloc(u32 size, u32 flags)
+{
+    void * rc;
+
+    rc = kmalloc(size, ipr_xlate_malloc_flags(flags));
+    if (ipr_mem_debug && rc)
+        ipr_kmalloced_mem += size;
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: kmalloc memory and zero it
+ * Context: Task level only
+ * Lock State: no locks required
+ * Returns: pointer to storage or NULL on failure
+ *---------------------------------------------------------------------------*/
+void *ipr_kcalloc(u32 size, u32 flags)
+{
+    void * rc;
+    rc = kmalloc(size, ipr_xlate_malloc_flags(flags));
+    if (rc)
+    {
+        memset(rc, 0, size);
+        if (ipr_mem_debug)
+            ipr_kmalloced_mem += size;
+    }
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: __get_free_pages wrapper
+ * Context: Task level only
+ * Lock State: no locks required
+ * Returns: pointer to storage or NULL on failure
+ *---------------------------------------------------------------------------*/
+static void *ipr_get_free_pages(u32 flags, u32 order)
+{
+    void *rc = (void *)__get_free_pages(flags, order);
+
+    if (ipr_mem_debug && rc)
+        ipr_kmalloced_mem += ((1u << order) * PAGE_SIZE);
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: __get_free_page wrapper
+ * Context: Task level only
+ * Lock State: no locks required
+ * Returns: pointer to storage or NULL on failure
+ *---------------------------------------------------------------------------*/
+static void *ipr_get_free_page(u32 flags)
+{
+    void *rc = (void *)__get_free_page(flags);
+
+    if (ipr_mem_debug && rc)
+        ipr_kmalloced_mem += PAGE_SIZE;
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: free_pages wrapper
+ * Context: Task level only
+ * Lock State: no locks required
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_free_pages(void *ptr, u32 order)
+{
+    free_pages((unsigned long)ptr, order);
+    if (ipr_mem_debug)
+        ipr_kmalloced_mem -= ((1u << order) * PAGE_SIZE);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: free_page wrapper
+ * Context: Task level only
+ * Lock State: no locks required
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_free_page(void *ptr)
+{
+    free_page((unsigned long)ptr);
+    if (ipr_mem_debug)
+        ipr_kmalloced_mem -= PAGE_SIZE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: wrapper function to allocate mapped, DMA-able storage
+ * Context: Task or interrupt level
+ * Lock State: no locks required
+ * Returns: pointer to storage or NULL on failure
+ *---------------------------------------------------------------------------*/
+void *ipr_dma_malloc(struct ipr_shared_config *p_shared_cfg,
+                        u32 size, ipr_dma_addr *p_dma_addr, u32 flags)
+{
+    ipr_host_config *ipr_cfg;
+    void *p_buf;
+
+    ipr_cfg = (ipr_host_config *)p_shared_cfg;
+
+    if (p_dma_addr == NULL)
+        return NULL;
+
+    p_buf = kmalloc(size, ipr_xlate_malloc_flags(flags) | IPR_GFP_DMA );
+
+    if (p_buf == NULL)
+        return NULL;
+
+    *p_dma_addr = pci_map_single(ipr_cfg->pdev, p_buf, size, PCI_DMA_BIDIRECTIONAL);
+
+    if (*p_dma_addr == NO_TCE)
+    {
+        kfree(p_buf);
+        p_buf = NULL;
+    }
+    else if (ipr_mem_debug)
+        ipr_kmalloced_mem += size;
+
+    return p_buf;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: wrapper function to allocate mapped, zeroed, DMA-able storage
+ * Context: Task or interrupt level
+ * Lock State: no locks required
+ * Returns: pointer to storage or NULL on failure
+ *---------------------------------------------------------------------------*/
+void *ipr_dma_calloc(struct ipr_shared_config *p_shared_cfg,
+                        u32 size, ipr_dma_addr *p_dma_addr, u32 flags)
+{
+    void *p_buf;
+
+    p_buf = ipr_dma_malloc(p_shared_cfg, size, p_dma_addr, flags);
+    if (p_buf)
+        memset(p_buf, 0, size);
+
+    return p_buf;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: kfree wrapper
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_kfree(void *ptr, u32 size)
+{
+    if (ptr)
+    {
+        kfree(ptr);
+        if (ipr_mem_debug)
+            ipr_kmalloced_mem -= size;
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: wrapper function to free storage allocated with ipr_dma_malloc
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_dma_free(struct ipr_shared_config *p_shared_cfg,
+                     u32 size, void *ptr, ipr_dma_addr dma_addr)
+{
+    ipr_host_config *ipr_cfg;
+    ipr_cfg = (ipr_host_config *)p_shared_cfg;
+
+    if (ptr)
+    {
+        pci_unmap_single(ipr_cfg->pdev, dma_addr, size, PCI_DMA_BIDIRECTIONAL);
+        kfree(ptr);
+        if (ipr_mem_debug)
+            ipr_kmalloced_mem -= size;
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print out a sense buffer with minimal formatting
+ * Returns: nothing
+ * Notes: This is primarily used for debug purposes
+ *---------------------------------------------------------------------------*/
+#define IPR_PRINT_SENSE_BYTES        18
+static void ipr_print_sense(u8 cmd, unsigned char *p_buf)
+{
+    int byte, len;
+    unsigned char buffer[(IPR_PRINT_SENSE_BYTES * 3) + 1];
+
+    if (!ipr_debug &&
+        (p_buf[2] == NOT_READY) &&
+        (p_buf[12] == 0x40) &&  /* Diagnostic Failure */
+        (p_buf[13] == 0x85))    /* Component x85 braindead? */
+        return;
+
+    if (ipr_sense_valid(p_buf[0]))
+    {
+        for (byte = 0, len = 0; byte < IPR_PRINT_SENSE_BYTES; byte++)
+            len += sprintf(buffer + len, "%02X ", p_buf[byte]);
+        ipr_log_err("Cmd 0x%02x failed with Sense buffer: %s"IPR_EOL, cmd, buffer);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Go to sleep on a waitqueue.
+ * Context: Task level only
+ * Lock State: lock passed in paramter list assumed to be held
+ * Returns: timeout
+ *---------------------------------------------------------------------------*/
+static signed long ipr_sleep_on_timeout(spinlock_t *p_lock,
+                                           wait_queue_head_t *p_wait_head, long timeout)
+{
+    wait_queue_t wait_q_entry;
+
+    init_waitqueue_entry(&wait_q_entry, current);
+
+    /* Set our task's state to sleeping and add ourselves to the wait queue
+     prior to releasing the spinlock */
+    set_current_state(TASK_UNINTERRUPTIBLE);
+
+    add_wait_queue(p_wait_head, &wait_q_entry);
+
+    spin_unlock_irq(p_lock);
+
+    timeout = schedule_timeout(timeout);
+
+    spin_lock_irq(p_lock);
+
+    remove_wait_queue(p_wait_head, &wait_q_entry);
+
+    return timeout;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Go to sleep on a waitqueue.
+ * Context: Task level only
+ * Lock State: lock passed in paramter list assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_interruptible_sleep_on(spinlock_t *p_lock,
+                                          wait_queue_head_t *p_wait_head)
+{
+    wait_queue_t wait_q_entry;
+
+    init_waitqueue_entry(&wait_q_entry, current);
+
+    /* Set our task's state to sleeping and add ourselves to the wait queue
+     prior to releasing the spinlock */
+    set_current_state(TASK_INTERRUPTIBLE);
+
+    add_wait_queue(p_wait_head, &wait_q_entry);
+
+    spin_unlock_irq(p_lock);
+
+    schedule();
+
+    spin_lock_irq(p_lock);
+
+    remove_wait_queue(p_wait_head, &wait_q_entry);
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Go to sleep on a waitqueue.
+ * Context: Task level only
+ * Lock State: lock passed in paramter list assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_sleep_on(spinlock_t *p_lock,
+                            wait_queue_head_t *p_wait_head)
+{
+    wait_queue_t wait_q_entry;
+
+    init_waitqueue_entry(&wait_q_entry, current);
+
+    /* Set our task's state to sleeping and add ourselves to the wait queue
+     prior to releasing the spinlock */
+    set_current_state(TASK_UNINTERRUPTIBLE);
+
+    add_wait_queue(p_wait_head, &wait_q_entry);
+
+    spin_unlock_irq(p_lock);
+
+    schedule();
+
+    spin_lock_irq(p_lock);
+
+    remove_wait_queue(p_wait_head, &wait_q_entry);
+
+    return;
+}
+
+void * ipr_mem_copy( void * s, const void * ct, int n)
+{
+    return memcpy(s, ct, n);
+}
+
+void * ipr_mem_set( void * s, int c, int n)
+{
+    return memset(s, c, n);
+}
+
+static Scsi_Host_Template driver_template = IPR;
+
+#include "scsi_module.c"
diff -urNp linux-8230/drivers/addon/ipr/iprdd.h linux-8240/drivers/addon/ipr/iprdd.h
--- linux-8230/drivers/addon/ipr/iprdd.h
+++ linux-8240/drivers/addon/ipr/iprdd.h
@@ -0,0 +1,297 @@
+/*****************************************************************************/
+/* iprdd.h -- driver for IBM Power Linux RAID adapters                       */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprdd.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#ifndef iprdd_h
+#define iprdd_h
+
+#ifndef LINUX_VERSION_CODE
+#include <linux/version.h>
+#endif
+
+#include <scsi/scsi.h>
+#include <asm/semaphore.h>
+#include <linux/raid/md_compatible.h>
+
+#ifndef iprlib_h
+#include "iprlib.h"
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,4,7)
+#define init_completion(x)              init_MUTEX_LOCKED(x)
+#define DECLARE_COMPLETION(x)           DECLARE_MUTEX_LOCKED(x)
+#define wait_for_completion(x)          down(x)
+#define complete(x)                     up(x)
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)
+#define scsi_assign_lock(host, lock)
+#endif
+
+#define ipr_flush_signals md_flush_signals
+
+#define IPR \
+{\
+name:                           "IPR",               /* Driver Name               */\
+proc_info:                      ipr_proc_info,       /* /proc driver info         */\
+detect:                         ipr_detect,          /* Detect Host Adapter       */\
+release:                        ipr_release,         /* Release Host Adapter      */\
+info:                           ipr_info,            /* Driver Info Function      */\
+queuecommand:                   ipr_queue,           /* Queue Command Function    */\
+eh_abort_handler:               ipr_abort,           /* Abort Command Function    */\
+eh_device_reset_handler:        ipr_dev_reset,       /* Device Reset Function     */\
+eh_host_reset_handler:          ipr_host_reset,      /* Host Reset Function       */\
+bios_param:                     ipr_biosparam,       /* Disk BIOS Parameters      */\
+select_queue_depths:            ipr_select_q_depth,  /* Select Queue depth        */\
+can_queue:                      IPR_MAX_COMMANDS,    /* Can Queue                 */\
+this_id:                        -1,                  /* HBA Target ID             */\
+sg_tablesize:                   IPR_MAX_SGLIST,      /* Scatter/Gather Table Size */\
+max_sectors:                    IPR_MAX_SECTORS,     /* Max size per op           */\
+cmd_per_lun:                    IPR_MAX_CMD_PER_LUN, /* SCSI Commands per LUN     */\
+present:                        0,                   /* Present                   */\
+unchecked_isa_dma:              0,                   /* Default Unchecked ISA DMA */\
+use_clustering:                 ENABLE_CLUSTERING,   /* Enable Clustering         */\
+use_new_eh_code:                1                    /* Use the new EH code       */\
+}
+
+#define IPR_MAX_NUM_DUMP_PAGES               ((IPR_MAX_IOA_DUMP_SIZE / PAGE_SIZE) + 1)
+
+struct ipr_dump_ioa_entry
+{
+    struct ipr_dump_entry_header header;
+    u32 next_page_index;
+    u32 page_offset;
+    u32 format;
+#define IPR_SDT_FMT1    1
+#define IPR_SDT_FMT2    2
+#define IPR_SDT_UNKNOWN 3
+    u32 reserved;
+    struct ipr_sdt sdt;
+    u32 *p_ioa_data[IPR_MAX_NUM_DUMP_PAGES];
+};
+
+enum ipr_error_class
+{
+    IPR_NO_ERR_CLASS = 0,
+    IPR_ERR_CLASS_PERM,
+    IPR_ERR_CLASS_PRED_ANALYSIS,
+    IPR_ERR_CLASS_SERVICE_ACTION_PT,
+    IPR_ERR_CLASS_TEMP,
+    IPR_ERR_CLASS_RETRYABLE,
+    IPR_ERR_CLASS_INFO,
+    IPR_ERR_CLASS_MAX_CLASS
+};
+
+struct ipr_error_class_table_t
+{
+    enum ipr_error_class err_class;
+    char *printk_level;
+    char *p_class;
+};
+
+struct ipr_error_table_t
+{
+    u32 ioasc;
+    u16 dev_urc;
+    u16 iop_urc;
+    enum ipr_error_class err_class;
+    char *p_error;
+};
+
+struct ipr_cmnd
+{
+    struct ipr_ccb ccb;
+    struct ipr_cmnd *p_next;
+    struct ipr_cmnd *p_prev;
+    struct ipr_cmnd *p_cancel_op;
+    Scsi_Cmnd *p_scsi_cmd;
+    Scsi_Cmnd *p_saved_scsi_cmd;
+    wait_queue_head_t wait_q;
+    struct timer_list timer;
+    void (*done) (struct ipr_shared_config *, struct ipr_ccb *);
+    struct ipr_sglist sglist[IPR_MAX_SGLIST];
+};
+
+struct ipr_ioctl_cmnd
+{
+    struct ipr_cmnd sis_cmd;
+    struct ipr_ioctl_cmnd *p_next;
+    struct ipr_ioctl_cmnd *p_prev;
+};
+
+struct ipr_dnload_sglist
+{
+    u32 order;
+    u32 num_sg;
+    struct scatterlist scatterlist[1];
+};
+
+/* Per-controller data */
+typedef struct _sis_host_config {
+    struct ipr_shared_config shared;
+
+    struct _sis_host_config *p_next;
+
+    u32 flag;
+#define IPR_OPERATIONAL              0x00000001      /* We can talk to the IOA */
+#define IPR_UNIT_CHECKED             0x00000002      /* The IOA has unit checked */
+#define IPR_IOA_NEEDS_RESET          0x00000004      /* IOA fatal error, not UC */
+#define IPR_KILL_KERNEL_THREAD       0x00000008      /* Kill the kernel thread */
+#define IPR_ALLOW_HCAMS              0x00000010      /* Allow HCAMS to be processed/sent to IOA */
+#define IPR_IN_RESET_RELOAD          0x00000020      /* IOA in reset/reload processing */
+#define IPR_ALLOW_REQUESTS           0x00000040      /* ipr_do_req can accept requests */
+
+    u16 minor_num;
+    u16 major_num;
+
+    /* Queue for free command blocks that we can use for incoming ops */
+    char ipr_free_label[8];
+#define IPR_FREEQ_LABEL      "free-q"
+    struct ipr_cmnd *qFreeH;
+    struct ipr_cmnd *qFreeT;
+
+    /* Queue for command blocks that are currently outstanding to the adapter */
+    char ipr_pending_label[8];
+#define IPR_PENDQ_LABEL      "pend-q"
+    struct ipr_cmnd *qPendingH;
+    struct ipr_cmnd *qPendingT;
+
+    /* Queue for command blocks that have been taken off the HRRQ, but not processed yet */
+    char ipr_comp_label[8];
+#define IPR_COMPQ_LABEL      "comp-q"
+    struct ipr_cmnd *qCompletedH;
+    struct ipr_cmnd *qCompletedT;
+
+    /* Queue for command blocks that need ERP - put on at interrupt level and
+     taken off at task level. This queue is only used for GPDD ops. */
+    char ipr_err_label[8];
+#define IPR_ERRQ_LABEL       "err-q"
+    struct ipr_cmnd *qErrorH;
+    struct ipr_cmnd *qErrorT;
+
+    struct Scsi_Host *host;
+    struct pci_dev *pdev;
+
+    struct task_struct *task_thread; /* our kernel thread */
+    int task_pid;
+    u32 block_host_ops;
+
+    struct semaphore ioctl_semaphore;
+
+    struct scsi_cmnd *p_scsi_ops_to_fail;
+    const struct ipr_ioa_cfg_t *p_ioa_cfg;
+
+    char ipr_hcam_label[8];
+#define IPR_HCAM_LABEL       "hcams"
+    struct ipr_hostrcb *hostrcb[IPR_NUM_HCAMS];
+    ipr_dma_addr hostrcb_dma[IPR_NUM_HCAMS];
+
+    struct ipr_hostrcb *new_hostrcb[IPR_NUM_HCAMS];
+    struct ipr_hostrcb *done_hostrcb[IPR_NUM_HCAMS];
+
+    void *completion;
+
+    wait_queue_head_t wait_q;
+
+#define IPR_CONFIG_SAVE_WORDS 64
+    u32 pci_cfg_buf[IPR_CONFIG_SAVE_WORDS];
+    u32 bar_size_reg;
+    u16 saved_pcix_command_reg;
+    u16 reserved;
+
+    char ipr_sis_cmd_label[8];
+#define IPR_SIS_CMD_LABEL    "sis_cmd"
+    struct ipr_cmnd *sis_cmnd_list[IPR_NUM_CMD_BLKS];
+
+} ipr_host_config;
+
+const char *ipr_info(struct Scsi_Host *);
+int ipr_detect(Scsi_Host_Template *);
+int ipr_release(struct Scsi_Host *);
+int ipr_abort(Scsi_Cmnd *);
+int ipr_dev_reset(Scsi_Cmnd *);
+int ipr_host_reset(Scsi_Cmnd *);
+int ipr_queue(Scsi_Cmnd *, void (*done) (Scsi_Cmnd *));
+int ipr_biosparam(Disk *, kdev_t, int *);
+int ipr_proc_info(char *buffer, char **start, off_t offset,
+                     int length, int hostno, int inout);
+void ipr_select_q_depth(struct Scsi_Host *, Scsi_Device *);
+
+int ipr_task_thread(void *data);
+void ipr_timeout(ipr_host_config *ipr_cfg);
+int ipr_toggle_reset(ipr_host_config *ipr_cfg) ;
+u32 ipr_get_unique_id(struct ipr_location_data *p_location);
+struct ipr_location_data *ipr_get_ioa_location_data(struct pci_dev *p_dev);
+void ipr_print_unknown_dev_phys_loc(char *printk_level);
+void ipr_log_dev_vpd(struct ipr_resource_entry *p_resource, char *printk_level);
+void ipr_log_array_dev_vpd(struct ipr_std_inq_vpids *p_vpids,
+                                char *default_ccin,
+                                char *printk_level);
+void ipr_print_ioa_vpd(struct ipr_std_inq_vpids *p_vpids,
+                          char *printk_level);
+void ipr_log_dev_current_expected_locations(ipr_host_config *ipr_cfg,
+                                               struct ipr_res_addr current_res_addr,
+                                               struct ipr_res_addr expected_res_addr,
+                                               char *printk_level);
+int ipr_invalid_adapter(ipr_host_config *ipr_cfg);
+
+#define ipr_ipl_err(ipr_cfg, ...) \
+{ \
+printk(KERN_ERR IPR_ERR\
+": begin-entry***********************************************"IPR_EOL); \
+printk(KERN_ERR IPR_ERR ": "__VA_ARGS__); \
+ipr_log_ioa_physical_location(ipr_cfg->shared.p_location, KERN_ERR); \
+printk(KERN_ERR IPR_ERR\
+": end-entry*************************************************"IPR_EOL); \
+}
+
+#define ipr_breakpoint_data KERN_ERR IPR_NAME\
+": %s: %s: Line: %d ipr_cfg: %p"IPR_EOL, __FILE__, \
+__FUNCTION__, __LINE__, ipr_cfg
+
+#define ipr_trace { \
+printk(KERN_ERR IPR_NAME\
+": %s: %s: Line: %d"IPR_EOL, __FILE__, __FUNCTION__, __LINE__); \
+}
+
+#if defined(CONFIG_KDB) && !defined(CONFIG_PPC_ISERIES)
+#define ipr_breakpoint {printk(ipr_breakpoint_data); KDB_ENTER();}
+#define ipr_breakpoint_or_die {printk(ipr_breakpoint_data); KDB_ENTER();}
+#else
+#define ipr_breakpoint
+#define ipr_breakpoint_or_die panic(ipr_breakpoint_data)
+#endif
+
+#if IPR_DISABLE_RESET_RELOAD == 1
+#define ipr_break_if_reset_reload_disabled ipr_breakpoint
+#define ipr_break_or_die_if_reset_reload_disabled ipr_breakpoint_or_die
+#else
+#define ipr_break_if_reset_reload_disabled
+#define ipr_break_or_die_if_reset_reload_disabled
+#endif
+
+#define ipr_dbg_trace IPR_DBG_CMD(ipr_trace)
+#endif
diff -urNp linux-8230/drivers/addon/ipr/iprlib.h linux-8240/drivers/addon/ipr/iprlib.h
--- linux-8230/drivers/addon/ipr/iprlib.h
+++ linux-8240/drivers/addon/ipr/iprlib.h
@@ -0,0 +1,359 @@
+/*****************************************************************************/
+/* iprlib.h -- driver for IBM Power Linux RAID adapters                      */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprlib.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#ifndef iprlib_h
+#define iprlib_h
+
+/******************************************************************/
+/* Includes                                                       */
+/******************************************************************/
+
+#ifndef iprlits_h
+#include "iprlits.h"
+#endif
+
+#ifndef iprtypes_h
+#include "iprtypes.h"
+#endif
+
+/******************************************************************/
+/* Macros                                                         */
+/******************************************************************/
+#define ipr_sense_valid(byte)        ((((byte) & 0x70) >> 4) == 7)
+
+#define IPR_MIN(a,b) (((a) < (b)) ? (a) : (b))
+
+#if IPR_DEBUG
+#define IPR_DBG_CMD(CMD)             \
+{                                       \
+(CMD);                                  \
+}
+#else
+#define IPR_DBG_CMD(CMD)
+#endif
+
+#define IPR_SET_MODE(change_mask, cur_val, new_val)  \
+{                                                       \
+int mod_bits = (cur_val ^ new_val);                     \
+if ((change_mask & mod_bits) == mod_bits)               \
+{                                                       \
+cur_val = new_val;                                      \
+}                                                       \
+}
+
+#define IPR_GET_CAP_REDUCTION(res_flags) \
+(((res_flags).capacity_reduction_hi << 1) | (res_flags).capacity_reduction_lo)
+
+/******************************************************************/
+/* Byte swapping macros                                           */
+/* Note: These should only be used when initializing static data  */
+/*       Normal runtime code should use the inline functions.     */
+/******************************************************************/
+#define _sw16(x) \
+((((x) & 0x00ff) << 8) | (((x) & 0xff00) >> 8))
+
+#define _sw32(x) \
+((((x) & 0x000000ff) << 24) | (((x) & 0x0000ff00) << 8) | \
+(((x) & 0x00ff0000) >> 8) | (((x) & 0xff000000) >> 24))
+
+/******************************************************************/
+/* Error logging macros                                           */
+/******************************************************************/
+#ifdef IPR_LIBRARY
+#define ipr_printk_i printk
+#define ipr_printk_i_tty ipr_print_tty
+#else
+#define ipr_printk_i printk
+#define ipr_printk_i_tty ipr_print_tty
+#endif
+
+#define ipr_log_err(...) ipr_printk_i(KERN_ERR IPR_ERR ": "__VA_ARGS__);
+#define ipr_log_info(...) ipr_printk_i(KERN_INFO IPR_NAME ": "__VA_ARGS__);
+#define ipr_log_crit(...) ipr_printk_i(KERN_CRIT IPR_ERR ": "__VA_ARGS__);
+#define ipr_log_warn(...) ipr_printk_i(KERN_WARNING IPR_ERR": "__VA_ARGS__);
+#define ipr_dbg_err(...) IPR_DBG_CMD(ipr_printk_i(KERN_ERR IPR_ERR ": "__VA_ARGS__));
+
+#define ipr_log_err_tty(...) ipr_printk_i_tty(KERN_ERR IPR_ERR ": "__VA_ARGS__);
+#define ipr_log_info_tty(...) ipr_printk_i_tty(KERN_INFO IPR_NAME ": "__VA_ARGS__);
+#define ipr_log_crit_tty(...) ipr_printk_i_tty(KERN_CRIT IPR_ERR ": "__VA_ARGS__);
+#define ipr_log_warn_tty(...) ipr_printk_i_tty(KERN_WARNING IPR_ERR": "__VA_ARGS__);
+#define ipr_dbg_err_tty(...) IPR_DBG_CMD(ipr_printk_i_tty(KERN_ERR IPR_ERR ": "__VA_ARGS__));
+
+#if IPR_DBG_TRACE
+#define ENTER ipr_printk_i(KERN_ERR IPR_NAME": Entering %s"IPR_EOL, __FUNCTION__);
+#define LEAVE ipr_printk_i(KERN_ERR IPR_NAME": Leaving %s"IPR_EOL, __FUNCTION__);
+#define ipr_dbg ipr_printk_i(KERN_ERR IPR_NAME": %s: %s: Line: %d"IPR_EOL, \
+                                   __FILE__, __FUNCTION__, __LINE__);
+#else
+#define ENTER
+#define LEAVE
+#define ipr_dbg
+#endif
+
+#define ipr_beg_err(level) { \
+ipr_printk_i("%s"IPR_ERR": \
+begin-entry***********************************************"IPR_EOL, level); \
+}
+#define ipr_end_err(level) { \
+ipr_printk_i("%s"IPR_ERR": \
+end-entry*************************************************"IPR_EOL, level); \
+}
+
+#define ipr_beg_err_tty(level) { \
+ipr_printk_i_tty("%s"IPR_ERR": \
+begin-entry***********************************************"IPR_EOL, level); \
+}
+#define ipr_end_err_tty(level) { \
+ipr_printk_i_tty("%s"IPR_ERR": \
+end-entry*************************************************"IPR_EOL, level); \
+}
+
+#define ipr_hcam_log(format, ...) \
+ipr_printk_i("%s"IPR_ERR": "format""IPR_EOL, printk_level, ##__VA_ARGS__)
+
+#define ipr_hcam_log_tty(format, ...) \
+ipr_printk_i_tty("%s"IPR_ERR": "format""IPR_EOL, printk_level, ##__VA_ARGS__)
+
+#define ipr_err_separator \
+ipr_hcam_log("----------------------------------------------------------")
+
+/******************************************************************/
+/* Function prototypes                                            */
+/******************************************************************/
+
+/* Wrapper functions for library */
+void *ipr_kmalloc(u32 size, u32 flags);
+void *ipr_kcalloc(u32 size, u32 flags);
+
+void *ipr_dma_malloc(struct ipr_shared_config *p_shared_cfg,
+                        u32 size, ipr_dma_addr *p_dma_addr, u32 flags);
+void *ipr_dma_calloc(struct ipr_shared_config *p_shared_cfg,
+                        u32 size, ipr_dma_addr *p_dma_addr, u32 flags);
+
+void ipr_kfree(void *ptr, u32 size);
+
+void ipr_dma_free(struct ipr_shared_config *p_shared_cfg,
+                     u32 size, void *ptr, ipr_dma_addr dma_addr);
+
+void ipr_print_tty(char *s, ...);
+
+void ipr_udelay(signed long delay);
+
+void ipr_req_reset(struct ipr_shared_config *p_shared_cfg);
+
+void ipr_sleep(signed long delay);
+
+void ipr_ioa_loc_str(struct ipr_location_data *p_location, char *p_buf);
+void ipr_dev_loc_str(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_resource_entry *p_resource, char *p_buf);
+
+void ipr_log_ioa_physical_location(struct ipr_location_data *p_location,
+                                        char *printk_level);
+
+void ipr_log_dev_physical_location(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_res_addr resource_address,
+                                      char *printk_level);
+
+struct ipr_ccb * ipr_allocate_ccb(struct ipr_shared_config *p_shared_cfg);
+void ipr_release_ccb(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_ccb *p_sis_ccb);
+int ipr_do_req(struct ipr_shared_config *p_shared_cfg,
+                  struct ipr_ccb *p_sis_ccb,
+                  void (*done) (struct ipr_shared_config *, struct ipr_ccb *),
+                  u32 timeout_in_sec);
+u32 ipr_send_hcam(struct ipr_shared_config *p_shared_cfg, u8 type,
+                     struct ipr_hostrcb *p_hostrcb);
+
+void ipr_get_card_pos(struct ipr_shared_config *ipr_cfg,
+                         struct ipr_res_addr resource_addr, char *p_buffer);
+
+int ipr_get_res_addr_fmt0(struct ipr_shared_config *p_shared_cfg,
+                             u32 dsa, u32 ua,
+                             struct ipr_res_addr *p_res_addr);
+
+int ipr_get_res_addr_fmt1(struct ipr_shared_config *p_shared_cfg,
+                             u32 frame, char *p_slot,
+                             struct ipr_res_addr *p_res_addr);
+
+int ipr_get_res_addr_fmt2(struct ipr_shared_config *p_shared_cfg,
+                              char *p_location, struct ipr_res_addr *p_res_addr);
+
+int ipr_get_res_addr_fmt3(struct ipr_shared_config *p_shared_cfg,
+                             u16 pci_bus, u16 pci_device, u8 bus, u8 target, u8 lun,
+                             struct ipr_res_addr *p_res_addr);
+
+void ipr_update_location_data(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_resource_entry *p_resource_entry);
+
+/* Library provided functions */
+int ipr_alloc_mem (struct ipr_shared_config *ipr_cfg);
+
+int ipr_free_mem (struct ipr_shared_config *ipr_cfg);
+
+int ipr_init_ioa_internal_part1 (struct ipr_shared_config *ipr_cfg);
+
+int ipr_init_ioa_internal_part2 (struct ipr_shared_config *ipr_cfg);
+
+u32 ipr_get_done_ops(struct ipr_shared_config *ipr_cfg,
+                        struct ipr_ccb **pp_sis_cmnd);
+
+int ipr_ioa_queue(struct ipr_shared_config *ipr_cfg,
+                     struct ipr_ccb *p_sis_cmd);
+
+void ipr_auto_sense(struct ipr_shared_config *ipr_cfg,
+                       struct ipr_ccb *p_sis_cmd);
+
+int ipr_queue_internal(struct ipr_shared_config *ipr_cfg,
+                          struct ipr_ccb *p_sis_cmd);
+
+void ipr_handle_config_change(struct ipr_shared_config *ipr_cfg,
+                                 struct ipr_hostrcb *p_hostrcb);
+
+u16 ipr_dasd_vpids_to_ccin(struct ipr_std_inq_vpids *p_vpids,
+                              u16 default_ccin);
+
+void ipr_dasd_vpids_to_ccin_str(struct ipr_std_inq_vpids *p_vpids,
+                                   char *p_ccin, char *p_default_ccin);
+
+void ipr_mask_interrupts(struct ipr_shared_config *ipr_cfg);
+
+int ipr_reset_allowed(struct ipr_shared_config *ipr_cfg);
+void ipr_reset_alert(struct ipr_shared_config *ipr_cfg);
+
+int ipr_get_ldump_data_section(struct ipr_shared_config *ipr_cfg,
+                                  u32 fmt2_start_addr,
+                                  u32 *p_dest,
+                                  u32 length_in_words);
+void ipr_get_internal_trace(struct ipr_shared_config *ipr_cfg,
+                               u32 **trace_block_address,
+                               u32 *trace_block_length);
+void ipr_copy_internal_trace_for_dump(struct ipr_shared_config *ipr_cfg,
+                                         u32 *p_buffer,
+                                         u32 buffer_len);
+void ipr_modify_ioafp_mode_page_28(struct ipr_shared_config *ipr_cfg,
+                                      struct ipr_mode_page_28_header *
+                                      p_modepage_28_header,
+                                      int scsi_bus);
+/******************************************************************/
+/* Inlines                                                        */
+/******************************************************************/
+
+/*---------------------------------------------------------------------------
+ * Purpose: Verify resource address has valid bus, target, lun values
+ * Lock State: N/A
+ * Returns: 0 if invalid resource address
+ *          1 if valid resource address
+ *---------------------------------------------------------------------------*/
+static inline int ipr_is_res_addr_valid(struct ipr_res_addr *res_addr)
+{
+    if (((res_addr->lun < IPR_MAX_NUM_LUNS_PER_TARGET) ||
+         (res_addr->lun == 0xff)) &&
+        ((res_addr->bus < IPR_MAX_NUM_BUSES) ||
+         (res_addr->bus == 0xff)) &&
+        ((res_addr->target < IPR_MAX_NUM_TARGETS_PER_BUS) ||
+         (res_addr->target == 0xff)))
+    {
+        return 1;
+    }
+    else
+    {
+        return 0;
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Identify Advanced Function DASD present
+ * Lock State: N/A
+ * Returns: 0 if not AF DASD
+ *          1 if AF DASD
+ *---------------------------------------------------------------------------*/
+static inline int ipr_is_af_dasd_device(struct ipr_resource_entry *p_resource_entry)
+{
+    if (IPR_IS_DASD_DEVICE(p_resource_entry->std_inq_data) &&
+        (!p_resource_entry->is_ioa_resource) &&
+        (p_resource_entry->subtype == IPR_SUBTYPE_AF_DASD))
+        return 1;
+    else
+        return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Identify volume set resources
+ * Lock State: N/A
+ * Returns: 0 if not VSET
+ *          1 if VSET
+ *---------------------------------------------------------------------------*/
+static inline int ipr_is_vset_device(struct ipr_resource_entry *p_resource_entry)
+{
+    if (IPR_IS_DASD_DEVICE(p_resource_entry->std_inq_data) &&
+        (!p_resource_entry->is_ioa_resource) &&
+        (p_resource_entry->subtype == IPR_SUBTYPE_VOLUME_SET))
+        return 1;
+    else
+        return 0;
+}
+
+/******************************************************************/
+/* Sense data inlines                                             */
+/******************************************************************/
+static inline u8 ipr_sense_key(u8 *p_sense_buffer)
+{
+    u8 byte0 = p_sense_buffer[0] & 0x7f;
+
+    if ((byte0 == 0x70) || (byte0 == 0x71))
+        return p_sense_buffer[2];
+    else if ((byte0 == 0x72) || (byte0 == 0x73))
+        return p_sense_buffer[1];
+    else
+        return 0;
+}
+
+static inline u8 ipr_sense_code(u8 *p_sense_buffer)
+{
+    u8 byte0 = p_sense_buffer[0] & 0x7f;
+
+    if ((byte0 == 0x70) || (byte0 == 0x71))
+        return p_sense_buffer[12];
+    else if ((byte0 == 0x72) || (byte0 == 0x73))
+        return p_sense_buffer[2];
+    else
+        return 0;
+}
+
+static inline u8 ipr_sense_qual(u8 *p_sense_buffer)
+{
+    u8 byte0 = p_sense_buffer[0] & 0x7f;
+
+    if ((byte0 == 0x70) || (byte0 == 0x71))
+        return p_sense_buffer[13];
+    else if ((byte0 == 0x72) || (byte0 == 0x73))
+        return p_sense_buffer[3];
+    else
+        return 0;
+}
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/iprlits.h linux-8240/drivers/addon/ipr/iprlits.h
--- linux-8230/drivers/addon/ipr/iprlits.h
+++ linux-8240/drivers/addon/ipr/iprlits.h
@@ -0,0 +1,489 @@
+/*****************************************************************************/
+/* iprlits.h -- driver for IBM Power Linux RAID adapters                     */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprlits.h,v 1.3.2.2 2003/11/10 19:19:51 bjking1 Exp $
+ */
+
+#ifndef iprlits_h
+#define iprlits_h
+
+/******************************************************************/
+/* Literals                                                       */
+/******************************************************************/
+
+#define IPR_DISABLE_RESET_RELOAD  0
+
+#ifdef IPR_DEBUG_ALL
+
+#define IPR_INL
+#ifndef IPR_DEBUG
+#define IPR_DEBUG                2
+#endif
+#ifndef IPR_DBG_TRACE
+#define IPR_DBG_TRACE            1
+#endif
+#ifndef IPR_MEMORY_DEBUG
+#define IPR_MEMORY_DEBUG         1
+#endif
+
+#else
+
+#define IPR_INL                  inline
+#ifndef IPR_DEBUG
+#define IPR_DEBUG                0
+#endif
+#ifndef IPR_DBG_TRACE
+#define IPR_DBG_TRACE            0
+#endif
+#ifndef IPR_MEMORY_DEBUG
+#define IPR_MEMORY_DEBUG         0
+#endif
+
+#endif
+
+#ifndef PCI_VENDOR_ID_IBM
+#define PCI_VENDOR_ID_IBM           0x1014
+#endif
+
+#ifndef PCI_DEVICE_ID_IBM_SNIPE
+#define PCI_DEVICE_ID_IBM_SNIPE     0x0180
+#endif
+
+#ifndef PCI_DEVICE_ID_GEMSTONE
+#define PCI_DEVICE_ID_GEMSTONE      0xB166
+#endif
+
+#ifndef PCI_VENDOR_ID_MYLEX
+#define PCI_VENDOR_ID_MYLEX         0x1069
+#endif
+
+#define IPR_PCIX_COMMAND_REG_ID              0x07
+#define IPR_PCIX_CMD_DATA_PARITY_RECOVER     0x0001
+#define IPR_PCIX_CMD_RELAXED_ORDERING        0x0002
+
+#define IPR_SUBS_DEV_ID_2780 0x0264
+#define IPR_SUBS_DEV_ID_5702 0x0266
+#define IPR_SUBS_DEV_ID_5703 0x0278
+
+#define IPR_NAME                 "ipr"
+#define IPR_NAME_LEN             3
+#define IPR_ERR                  "ipr-err"
+#define IPR_ERR_LEN              7
+
+#ifdef CONFIG_SMP
+#define IPR_FULL_VERSION IPR_VERSION_STR" SMP"
+#else
+#define IPR_FULL_VERSION IPR_VERSION_STR" UP"
+#endif
+
+/******************************************************************/
+/* Return codes                                                   */
+/******************************************************************/
+#define IPR_RC_SUCCESS                 0
+#define IPR_RC_DID_RESET               0xffff0000
+#define IPR_RC_UNKNOWN                 0xfefefeff
+#define IPR_RC_FAILED                  0xffffffff
+#define IPR_RC_TIMEOUT                 0x04080100
+#define IPR_RC_NOMEM                   0x00000001
+#define IPR_RC_QUAL_SUCCESS            0x00000002
+#define IPR_RC_ABORTED                 0x00000003
+#define IPR_RC_OP_NOT_SENT             0xff000001
+#define IPR_RC_XFER_FAILED             0xf0000001
+#define IPR_NO_HRRQ                    0xf0000002
+#define IPR_IOARRIN_LOST               0xf0000003
+#define IPR_MMIO_ERROR                 0xf0000004
+#define IPR_IOA_UNIT_CHECKED           0xf0000005
+#define IPR_403_ERR_STATE              0xf0000006
+#define IPR_SPURIOUS_INT               0xf0000007
+#define IPR_RESET_ADAPTER              0xf0000008
+#define IPR_RC_QUAL_SUCCESS_SHUTDOWN   0x00808000
+
+/******************************************************************/
+/* IOASCs                                                         */
+/******************************************************************/
+#define IPR_IOASC_RCV_RECOMMEND_REALLOC   0x01180500
+#define IPR_IOASC_SYNC_REQUIRED           0x023f0000
+#define IPR_IOASC_NR_IOA_MICROCODE        0x02408500
+#define IPR_IOASC_MED_RECOMMEND_REALLOC   0x03110B00
+#define IPR_IOASC_MED_DO_NOT_REALLOC      0x03110C00
+#define IPR_IOASC_HW_SEL_TIMEOUT          0x04050000
+#define IPR_IOASC_TIME_OUT                0x04080100
+#define IPR_IOASC_BUS_WAS_RESET           0x06290000
+#define IPR_IOASC_BUS_WAS_RESET_BY_OTHER  0x06298000
+
+#define IPR_NUM_LOG_HCAMS                 2
+#define IPR_NUM_CFG_CHG_HCAMS             2
+#define IPR_NUM_HCAMS   (IPR_NUM_LOG_HCAMS + IPR_NUM_CFG_CHG_HCAMS)
+#define IPR_MAX_NUM_TARGETS_PER_BUS     0x10
+#define IPR_MAX_NUM_LUNS_PER_TARGET     8
+
+/* IPR_MAX_CMD_PER_LUN MUST be < 8. If more than 8 commands are queued to a
+ tape or optical device, the IOA will unit check. This includes any ERP commands that
+ might be sent to the device, like cancel, cancel all, or device reset. */
+#define IPR_MAX_CMD_PER_LUN            6
+
+#define IPR_MAX_CMD_PER_VSET           64
+
+/* We need resources for HCAMS, IOA shutdown, and ERP */
+#define IPR_NUM_INTERNAL_CMD_BLKS   (IPR_NUM_HCAMS + 2 + 4)
+
+/* This is the number of command blocks we allocate for the mid-layer to use */
+#define IPR_NUM_BASE_CMD_BLKS       100
+
+/* This is maximum number of IOCTLs we can have at any one time */
+#define IPR_NUM_IOCTL_CMD_BLKS      (24 + 1)
+
+#define IPR_MAX_COMMANDS            IPR_NUM_BASE_CMD_BLKS
+#define IPR_NUM_CMD_BLKS            (IPR_NUM_BASE_CMD_BLKS + \
+                                        IPR_NUM_INTERNAL_CMD_BLKS +\
+                                        IPR_NUM_IOCTL_CMD_BLKS)
+
+#define IPR_MAX_BUS_TO_SCAN             255
+#define IPR_MAX_NUM_BUSES               4
+
+#define IPR_MAX_PHYSICAL_DEVS           192
+
+#define IPR_MAX_SGLIST                  64
+#define IPR_MAX_SECTORS                 512
+
+#define IPR_DEFAULT_MAX_BUS_SPEED       320
+
+#define IPR_IOA_RESOURCE_HANDLE         0xffffffff
+#define IPR_IOA_RESOURCE_ADDRESS        0x00ffffff
+#define IPR_IOA_RES_ADDR_BUS            0xff
+#define IPR_IOA_RES_ADDR_TARGET         0xff
+#define IPR_IOA_RES_ADDR_LUN            0xff
+#define IPR_IOA_DEFAULT_MODEL           1
+
+#define IPR_MAX_WRITE_BUFFER_SIZE       (4 * 1024 * 1024)
+
+#define IPR_NUM_RESET_RELOAD_RETRIES    3
+
+#define IPR_MAX_LOCATION_LEN            64
+#define IPR_MAX_PSERIES_LOCATION_LEN    48
+
+#define IPR_QAC_BUFFER_SIZE             16000
+#define IPR_IOCTL_SEND_COMMAND          0xf1f1
+
+/******************************************************************/
+/* SIS Commands                                                   */
+/******************************************************************/
+#define IPR_TEST_UNIT_READY                  0x00u
+#define IPR_REQUEST_SENSE                    0x03u
+#define IPR_FORMAT_UNIT                      0x04u
+#define IPR_REASSIGN_BLOCKS                  0x07u
+#define IPR_INQUIRY                          0x12u
+#define IPR_MODE_SELECT                      0x15u
+#define IPR_MODE_SENSE                       0x1Au
+#define IPR_START_STOP                       0x1Bu
+#define  IPR_START_STOP_START                0x01u
+#define  IPR_START_STOP_STOP                 0x00u
+#define IPR_RECEIVE_DIAGNOSTIC               0x1Cu
+#define IPR_SEND_DIAGNOSTIC                  0x1Du
+#define IPR_READ_CAPACITY                    0x25u
+#define IPR_READ_6                           0x08u
+#define IPR_READ_10                          0x28u
+#define IPR_READ_16                          0x88u
+#define IPR_WRITE_6                          0x0Au
+#define IPR_WRITE_10                         0x2Au
+#define IPR_WRITE_16                         0x8Au
+#define IPR_WRITE_VERIFY                     0x2Eu
+#define IPR_WRITE_VERIFY_16                  0x8Eu
+#define IPR_VERIFY                           0x2Fu
+#define IPR_WRITE_BUFFER                     0x3Bu
+#define  IPR_WR_BUF_DOWNLOAD_AND_SAVE        0x05u
+#define IPR_INVALID_RESH                     0x25u
+#define IPR_SYNC_REQUIRED                    0x3Fu
+#define IPR_WRITE_SAME                       0x41u
+#define IPR_LOG_SENSE                        0x4Du
+#define IPR_SERVICE_ACTION_IN                0x9Eu
+#define  IPR_READ_CAPACITY_16                0x10u
+#define IPR_REPORT_LUNS                      0xA0u
+#define IPR_CANCEL_REQUEST                   0xC0u
+#define IPR_SYNC_COMPLETE                    0xC1u
+#define IPR_QUERY_RESOURCE_STATE             0xC2u
+#define IPR_RESET_DEVICE                     0xC3u
+#define IPR_QUERY_IOA_CONFIG                 0xC5u
+
+#define IPR_SUSPEND_DEV_BUS                  0xC8u
+#define  IPR_SDB_CHECK_AND_QUIESCE           0x00u
+#define  IPR_SDB_CHECK_ONLY                  0x40u
+#define  IPR_SDB_QUIESE_ONLY                 0x80u
+#define  IPR_SDB_SLEEP_TIME                  15
+
+#define IPR_CONC_MAINT                       0xC8u
+#define  IPR_CONC_MAINT_CHECK_AND_QUIESCE    IPR_SDB_CHECK_AND_QUIESCE
+#define  IPR_CONC_MAINT_CHECK_ONLY           IPR_SDB_CHECK_ONLY
+#define  IPR_CONC_MAINT_QUIESE_ONLY          IPR_SDB_QUIESE_ONLY
+
+#define  IPR_CONC_MAINT_FMT_MASK             0x0Fu
+#define  IPR_CONC_MAINT_FMT_SHIFT            0
+#define  IPR_CONC_MAINT_GET_FMT(fmt) \
+((fmt & IPR_CONC_MAINT_FMT_MASK) >> IPR_CONC_MAINT_FMT_SHIFT)
+#define  IPR_CONC_MAINT_DSA_FMT              0x00u
+#define  IPR_CONC_MAINT_FRAME_ID_FMT         0x01u
+#define  IPR_CONC_MAINT_PSERIES_FMT          0x02u
+#define  IPR_CONC_MAINT_XSERIES_FMT          0x03u
+
+#define  IPR_CONC_MAINT_TYPE_MASK            0x30u
+#define  IPR_CONC_MAINT_TYPE_SHIFT           4
+#define  IPR_CONC_MAINT_GET_TYPE(type) \
+((type & IPR_CONC_MAINT_TYPE_MASK) >> IPR_CONC_MAINT_TYPE_SHIFT)
+#define  IPR_CONC_MAINT_INSERT               0x0u
+#define  IPR_CONC_MAINT_REMOVE               0x1u
+
+#define IPR_RESUME_DEVICE_BUS                0xC9u
+#define IPR_QUERY_COMMAND_STATUS             0xCBu
+#define IPR_CANCEL_ALL_REQUESTS              0xCEu
+#define IPR_HOST_CONTROLLED_ASYNC            0xCFu
+#define IPR_EVALUATE_DEVICE                  0xE4u
+#define IPR_ZERO_UNIT                        0xEDu
+#define IPR_QUERY_ARRAY_CONFIG               0xF0u
+#define IPR_START_ARRAY_PROTECTION           0xF1u
+#define IPR_STOP_ARRAY_PROTECTION            0xF2u
+#define IPR_RESYNC_ARRAY_PROTECTION          0xF3u
+#define IPR_ADD_ARRAY_DEVICE                 0xF4u
+#define IPR_REMOVE_ARRAY_DEVICE              0xF5u
+#define IPR_REBUILD_DEVICE_DATA              0xF6u
+#define IPR_IOA_SHUTDOWN                     0xF7u
+#define IPR_RECLAIM_CACHE_STORE              0xF8u
+#define  IPR_RECLAIM_ACTION                  0x60u
+#define  IPR_RECLAIM_PERFORM                 0x00u
+#define  IPR_RECLAIM_EXTENDED_INFO           0x10u
+#define  IPR_RECLAIM_QUERY                   0x20u
+#define  IPR_RECLAIM_RESET                   0x40u
+#define  IPR_RECLAIM_FORCE_BATTERY_ERROR     0x60u
+#define  IPR_RECLAIM_UNKNOWN_PERM            0x80u
+#define IPR_DISCARD_CACHE_DATA               0xF9u
+#define  IPR_PROHIBIT_CORR_INFO_UPDATE       0x80u
+
+#define IPR_IOA_DEBUG                        0xDDu
+#define   IPR_IOA_DEBUG_READ_IOA_MEM         0x00u
+#define   IPR_IOA_DEBUG_WRITE_IOA_MEM        0x01u
+#define   IPR_IOA_DEBUG_READ_FLIT            0x03u
+#define IPR_IOA_DEBUG_MAX_XFER               (16*1024*1024)
+#define IPR_ZERO_ARRAY_DEVICE_DATA           0xFFu
+#define IPR_INVALID_ARRAY_ID                 0xFFu
+
+/******************************************************************/
+/* Driver Commands                                                */
+/******************************************************************/
+#define IPR_GET_TRACE                        0xE1u
+#define IPR_RESET_DEV_CHANGED                0xE8u
+#define IPR_DUMP_IOA                         0xD7u
+#define IPR_MODE_SENSE_PAGE_28               0xD8u
+#define IPR_MODE_SELECT_PAGE_28              0xD9u
+#define IPR_RESET_HOST_ADAPTER               0xDAu
+#define IPR_READ_DRIVER_CFG                  0xDBu
+#define IPR_WRITE_DRIVER_CFG                 0xDCu
+
+/******************************************************************/
+/* Timeouts                                                       */
+/******************************************************************/
+
+#define IPR_TIMEOUT_MULTIPLIER               2
+#define IPR_MAX_SIS_TIMEOUT                  0x3fff            /* 4.5 hours */
+#define IPR_SHUTDOWN_TIMEOUT                 (10 * 60 * HZ)    /* 10 minutes */
+#define IPR_ABBREV_SHUTDOWN_TIMEOUT          (10 * HZ)         /* 10 seconds */
+#define IPR_DEVICE_RESET_TIMEOUT             (2 * 60 * HZ)     /* 2 minutes */
+#define IPR_CANCEL_TIMEOUT                   (3 * 60 * HZ)     /* 3 minutes */
+#define IPR_CANCEL_ALL_TIMEOUT               (2 * 60 * HZ)     /* 2 minutes */
+#define IPR_INTERNAL_TIMEOUT                 (30 * HZ)         /* 30 seconds */
+#define IPR_INTERNAL_DEV_TIMEOUT             (2 * 60 * HZ)     /* 2 minutes */
+#define IPR_SUSPEND_DEV_BUS_TIMEOUT          (35 * HZ)         /* 35 seconds */
+#define IPR_RECLAIM_TIMEOUT                  (10 * 60 * HZ)    /* 10 minutes */
+#define IPR_FORMAT_UNIT_TIMEOUT              (4 * 60 * 60 * HZ)  /* 4 hours */
+#define IPR_WRITE_BUFFER_TIMEOUT             (10 * 60 * HZ)    /* 10 minutes */
+#define IPR_ARRAY_CMD_TIMEOUT                (2 * 60 * HZ)     /* 2 minutes */
+#define IPR_QUERY_CMD_STAT_TIMEOUT           (30 * HZ)         /* 30 seconds */
+#define IPR_DISCARD_CACHE_DATA_TIMEOUT       (30 * HZ)         /* 30 seconds */
+#define IPR_EVALUATE_DEVICE_TIMEOUT          (2 * 60 * HZ)     /* 2 minutes */
+#define IPR_START_STOP_TIMEOUT               IPR_SHUTDOWN_TIMEOUT
+
+/******************************************************************/
+/* SES Related Literals                                           */
+/******************************************************************/
+#define IPR_DRIVE_ELEM_STATUS_STATUS_EMPTY           5
+#define IPR_DRIVE_ELEM_STATUS_STATUS_POPULATED       1
+#define IPR_NUM_DRIVE_ELEM_STATUS_ENTRIES            16
+#define IPR_MAX_NUM_ELEM_DESCRIPTORS                 8
+#define IPR_GLOBAL_DESC_12BYTES                      0xC
+#define IPR_GLOBAL_DESC_13BYTES                      0xD
+
+
+/******************************************************************/
+/* SIS Literals                                                   */
+/******************************************************************/
+#define  IPR_PERI_TYPE_DISK            0x00u
+#define  IPR_PERI_TYPE_SES             0x0Du
+
+#define  IPR_IS_DASD_DEVICE(std_inq_data) \
+    ((((std_inq_data).peri_dev_type) == IPR_PERI_TYPE_DISK) && !((std_inq_data).removeable_medium))
+
+#define  IPR_IS_SES_DEVICE(std_inq_data) \
+    (((std_inq_data).peri_dev_type) == IPR_PERI_TYPE_SES)
+
+#define IPR_HOST_RCB_OP_CODE_CONFIG_CHANGE        (u8)0xE1
+#define IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE        (u8)0x01
+#define IPR_HOST_RCB_OP_CODE_LOG_DATA             (u8)0xE2
+#define IPR_HCAM_CDB_OP_CODE_LOG_DATA             (u8)0x02
+
+#define IPR_HOST_RCB_NOTIF_TYPE_EXISTING_CHANGED  (u8)0x00
+#define IPR_HOST_RCB_NOTIF_TYPE_NEW_ENTRY         (u8)0x01
+#define IPR_HOST_RCB_NOTIF_TYPE_REM_ENTRY         (u8)0x02
+#define IPR_HOST_RCB_NOTIF_TYPE_ERROR_LOG_ENTRY   (u8)0x10
+#define IPR_HOST_RCB_NOTIF_TYPE_INFORMATION_ENTRY (u8)0x11
+
+#define IPR_HOST_RCB_NO_NOTIFICATIONS_LOST        (u8)0
+#define IPR_HOST_RCB_NOTIFICATIONS_LOST           BIT0OF8
+
+#define IPR_HOST_RCB_OVERLAY_ID_1                 (u8)0x01
+#define IPR_HOST_RCB_OVERLAY_ID_2                 (u8)0x02
+#define IPR_HOST_RCB_OVERLAY_ID_3                 (u8)0x03
+#define IPR_HOST_RCB_OVERLAY_ID_4                 (u8)0x04
+#define IPR_HOST_RCB_OVERLAY_ID_6                 (u8)0x06
+#define IPR_HOST_RCB_OVERLAY_ID_DEFAULT           (u8)0xFF
+
+#define IPR_NO_REDUCTION             0
+#define IPR_HALF_REDUCTION           1
+#define IPR_QUARTER_REDUCTION        2
+#define IPR_EIGHTH_REDUCTION         4
+#define IPR_SIXTEENTH_REDUCTION      6
+#define IPR_UNKNOWN_REDUCTION        7
+
+#define IPR_RECLAIM_NUM_BLOCKS_MULTIPLIER    256
+
+#define IPR_VENDOR_ID_LEN            8
+#define IPR_PROD_ID_LEN              16
+#define IPR_SERIAL_NUM_LEN           8
+
+#define IPR_MAX_NUM_SUPP_INQ_PAGES   8
+#define IPR_SUBTYPE_AF_DASD          0x0
+#define IPR_SUBTYPE_GENERIC_SCSI     0x1
+#define IPR_SUBTYPE_VOLUME_SET       0x2
+
+#define IPR_HOST_SPARE_MODEL         90
+#define IPR_VSET_MODEL_NUMBER        200
+
+#define IPR_SENSE_BUFFERSIZE         64
+
+#define IPR_SCSI_SENSE_INFO          0
+
+/******************************************************************/
+/* Hardware literals                                              */
+/******************************************************************/
+#define IPR_CHUKAR_MAILBOX_OFFSET            0x18D78
+#define IPR_SNIPE_MAILBOX_OFFSET             0x0052C
+#define IPR_GEMSTONE_MAILBOX_OFFSET          0x0042C
+#define IPR_RESET_403_OFFSET                 0x44
+#define IPR_RESET_403                        0x00000001
+#define IPR_CHUKAR_MBX_ADDR_MASK             0x00ffffff
+#define IPR_CHUKAR_MBX_BAR_SEL_MASK          0xff000000
+#define IPR_CHUKAR_MKR_BAR_SEL_SHIFT         24
+#define IPR_FMT2_MBX_ADDR_MASK               0x0fffffff
+#define IPR_FMT2_MBX_BAR_SEL_MASK            0xf0000000
+#define IPR_FMT2_MKR_BAR_SEL_SHIFT           28
+#define IPR_SDT_FMT1_BAR0_SEL                0x10
+#define IPR_SDT_FMT1_BAR1_SEL                0x14
+#define IPR_SDT_FMT1_BAR2_SEL                0x18
+#define IPR_SDT_FMT1_BAR3_SEL                0x1C
+#define IPR_SDT_FMT1_BAR4_SEL                0x30
+#define IPR_SDT_FMT2_BAR0_SEL                0x0
+#define IPR_SDT_FMT2_BAR1_SEL                0x1
+#define IPR_SDT_FMT2_BAR2_SEL                0x2
+#define IPR_SDT_FMT2_BAR3_SEL                0x3
+#define IPR_SDT_FMT2_BAR4_SEL                0x4
+#define IPR_FMT1_SDT_READY_TO_USE            0xC4D4E3C2
+#define IPR_FMT2_SDT_READY_TO_USE            0xC4D4E3F2
+#define IPR_BAR0_ADDRESS_BITS                0xfffe0000
+
+/******************************************************************/
+/* Dump literals                                                  */
+/******************************************************************/
+#define IPR_DUMP_TRACE_ENTRY_SIZE            8192
+#define IPR_MIN_DUMP_SIZE                    (1 * 1024 * 1024)
+#define IPR_MAX_IOA_DUMP_SIZE                (4 * 1024 * 1024)
+#define IPR_MAX_DUMP_FETCH_TIME              (30 * HZ)
+#define IPR_NUM_SDT_ENTRIES                  511
+
+/******************************************************************/
+/* Misc literals                                                  */
+/******************************************************************/
+#define IPR_EOL                              "\n"
+#define SHUTDOWN_SIGS                           (sigmask(SIGTERM))
+
+#define IPR_ALLOC_ATOMIC            0x00000001
+#define IPR_ALLOC_CAN_SLEEP         0x00000002
+
+#define IPR_ALIGNED_2               0x00000001
+#define IPR_ALIGNED_4               0x00000003
+#define IPR_ALIGNED_8               0x00000007
+#define IPR_ALIGNED_16              0x0000000F
+
+#define IPR_BYTE_ALIGN_2            0x00000001
+#define IPR_BYTE_ALIGN_4            0x00000002
+#define IPR_BYTE_ALIGN_8            0x00000004
+#define IPR_BYTE_ALIGN_16           0x00000008
+
+#define IPR_COPY_1                  0x00000001
+#define IPR_COPY_2                  0x00000002
+#define IPR_COPY_4                  0x00000004
+#define IPR_COPY_8                  0x00000008
+#define IPR_COPY_16                 0x00000010
+#define IPR_COPY_32                 0x00000020
+
+#define IPR_COMPARE_1               IPR_COPY_1
+#define IPR_COMPARE_2               IPR_COPY_2
+#define IPR_COMPARE_4               IPR_COPY_4
+#define IPR_COMPARE_8               IPR_COPY_8
+#define IPR_COMPARE_16              IPR_COPY_16
+#define IPR_COMPARE_32              IPR_COPY_32
+
+#define IPR_PAGE_CODE_MASK          0x3F
+#define IPR_PAGE_CODE_28            0x28
+#define IPR_MODE_SENSE_28_SZ        0xff
+#define IPR_CURRENT_PAGE            0x0
+#define IPR_CHANGEABLE_PAGE         0x1
+#define IPR_DEFAULT_PAGE            0x2
+
+#define IPR_STD_INQ_Z0_TERM_LEN      8
+#define IPR_STD_INQ_Z1_TERM_LEN      12
+#define IPR_STD_INQ_Z2_TERM_LEN      4
+#define IPR_STD_INQ_Z3_TERM_LEN      5
+#define IPR_STD_INQ_Z4_TERM_LEN      4
+#define IPR_STD_INQ_Z5_TERM_LEN      2
+#define IPR_STD_INQ_Z6_TERM_LEN      10
+#define IPR_STD_INQ_PART_NUM_LEN     12
+#define IPR_STD_INQ_EC_LEVEL_LEN     10
+#define IPR_STD_INQ_FRU_NUM_LEN      12
+
+#define IPR_DEFECT_LIST_HDR_LEN      4
+#define IPR_FORMAT_IMMED             2
+#define IPR_FORMAT_DATA              0x10u
+
+#define IPR_ARCH_GENERIC             0
+#define IPR_ARCH_ISERIES             1
+#define IPR_ARCH_PSERIES             2
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/iprtypes.h linux-8240/drivers/addon/ipr/iprtypes.h
--- linux-8230/drivers/addon/ipr/iprtypes.h
+++ linux-8240/drivers/addon/ipr/iprtypes.h
@@ -0,0 +1,989 @@
+/*****************************************************************************/
+/* iprtypes.h -- driver for IBM Power Linux RAID adapters                    */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprtypes.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+#ifndef iprtypes_h
+#define iprtypes_h
+
+struct ipr_std_inq_vpids
+{
+    u8 vendor_id[IPR_VENDOR_ID_LEN];          /* Vendor ID */
+    u8 product_id[IPR_PROD_ID_LEN];           /* Product ID */
+};
+
+struct ipr_res_addr
+{
+    u8 reserved;
+    u8 bus;
+    u8 target;
+    u8 lun;
+#define IPR_GET_PHYSICAL_LOCATOR(res_addr) \
+(((res_addr).bus << 16) | ((res_addr).target << 8) | (res_addr).lun)
+};
+
+struct ipr_read_cap
+{
+    u32 max_user_lba;
+    u32 block_length;
+};
+
+struct ipr_read_cap16
+{
+    u32 max_user_lba_hi;
+    u32 max_user_lba_lo;
+    u32 block_length;
+};
+
+struct ipr_hostrcb_device_data_entry
+{
+    struct ipr_std_inq_vpids dev_vpids;
+    u8 dev_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_res_addr dev_res_addr;
+    struct ipr_std_inq_vpids new_dev_vpids;
+    u8 new_dev_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids ioa_last_with_dev_vpids;
+    u8 ioa_last_with_dev_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids cfc_last_with_dev_vpids;
+    u8 cfc_last_with_dev_sn[IPR_SERIAL_NUM_LEN];
+    u32 ioa_data[5];
+};
+
+struct ipr_hostrcb_array_data_entry
+{
+    struct ipr_std_inq_vpids vpids;
+    u8 serial_num[IPR_SERIAL_NUM_LEN];
+    struct ipr_res_addr expected_dev_res_addr;
+    struct ipr_res_addr dev_res_addr;
+};
+
+struct ipr_hostrcb_type_ff_error
+{
+    u32 ioa_data[246];
+};
+
+struct ipr_hostrcb_type_01_error
+{
+    u32 seek_counter;
+    u32 read_counter;
+    u8  sense_data[32];
+    u32 ioa_data[236];
+};
+
+struct ipr_hostrcb_type_02_error
+{
+    struct ipr_std_inq_vpids ioa_vpids;
+    u8 ioa_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids cfc_vpids;
+    u8 cfc_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids ioa_last_attached_to_cfc_vpids;
+    u8 ioa_last_attached_to_cfc_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids cfc_last_attached_to_ioa_vpids;
+    u8 cfc_last_attached_to_ioa_sn[IPR_SERIAL_NUM_LEN];
+    u32 ioa_data[3];
+    u8 reserved[844];
+};
+
+struct ipr_hostrcb_type_03_error
+{
+    struct ipr_std_inq_vpids ioa_vpids;
+    u8 ioa_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids cfc_vpids;
+    u8 cfc_sn[IPR_SERIAL_NUM_LEN];
+    u32 errors_detected;
+    u32 errors_logged;
+    u8 ioa_data[12];
+    struct ipr_hostrcb_device_data_entry dev_entry[3];
+    u8 reserved[444];
+};
+
+struct ipr_hostrcb_type_04_error
+{
+    struct ipr_std_inq_vpids ioa_vpids;
+    u8 ioa_sn[IPR_SERIAL_NUM_LEN];
+    struct ipr_std_inq_vpids cfc_vpids;
+    u8 cfc_sn[IPR_SERIAL_NUM_LEN];
+    u8 ioa_data[12];
+    struct ipr_hostrcb_array_data_entry array_member[10];
+    u32 exposed_mode_adn;
+    u32 array_id;
+    struct ipr_std_inq_vpids incomp_dev_vpids;
+    u8 incomp_dev_sn[IPR_SERIAL_NUM_LEN];
+    u32 ioa_data2;
+
+    struct ipr_hostrcb_array_data_entry array_member2[8];
+    struct ipr_res_addr last_functional_vset_res_addr;
+    u8 vset_serial_num[IPR_SERIAL_NUM_LEN];
+    u8 protection_level[8];
+    u8 reserved[124];
+};
+
+struct ipr_hostrcb_error
+{
+    u32 failing_dev_ioasc;
+    struct ipr_res_addr failing_dev_res_addr;
+    u32 failing_dev_resource_handle;
+    u32 prc;
+    union {
+        struct ipr_hostrcb_type_ff_error type_ff_error;
+        struct ipr_hostrcb_type_01_error type_01_error;
+        struct ipr_hostrcb_type_02_error type_02_error;
+        struct ipr_hostrcb_type_03_error type_03_error;
+        struct ipr_hostrcb_type_04_error type_04_error;
+    }data;
+};
+
+struct ipr_hostrcb_cfg_ch_not
+{
+    u8 reserved[1024];
+};
+
+struct ipr_record_common
+{
+    u16 record_id;
+    u16 record_len;
+};
+
+struct ipr_supported_arrays
+{
+    struct ipr_record_common common;
+    u16                         num_entries;
+    u16                         entry_length;
+    u8                          data[0];
+};
+
+#if (defined(__KERNEL__) && defined(__LITTLE_ENDIAN)) || \
+(!defined(__KERNEL__) && (__BYTE_ORDER == __LITTLE_ENDIAN))
+#ifndef iprtypesle_h
+#include "iprtypesle.h"
+#endif
+#elif (defined(__KERNEL__) && defined(__BIG_ENDIAN)) || \
+(!defined(__KERNEL__) && (__BYTE_ORDER == __BIG_ENDIAN))
+#ifndef iprtypesbe_h
+#include "iprtypesbe.h"
+#endif
+#else
+#error "Neither __LITTLE_ENDIAN nor __BIG_ENDIAN defined"
+#endif
+
+#define IPR_RECORD_ID_SUPPORTED_ARRAYS       _i16((u16)0)
+#define IPR_RECORD_ID_ARRAY_RECORD           _i16((u16)1)
+#define IPR_RECORD_ID_DEVICE_RECORD          _i16((u16)2)
+#define IPR_RECORD_ID_COMP_RECORD            _i16((u16)3)
+#define IPR_RECORD_ID_ARRAY2_RECORD          _i16((u16)4)
+#define IPR_RECORD_ID_DEVICE2_RECORD         _i16((u16)5)
+
+typedef u32 ipr_dma_addr;
+
+#ifdef __KERNEL__
+enum boolean
+{
+    false = 0,
+    true = 1
+};
+
+typedef enum boolean bool;
+#endif
+
+/* NOTE: The structure below is a shared structure with user-land tools */
+/* We need to make sure we don't put pointers in here as the
+ utilities could be running in 32 bit mode on a 64 bit kernel. */
+struct ipr_ioctl_cmd_type2
+{
+    u32 type:8;  /* type is used to distinguish between ioctl_cmd structure formats */
+#define IPR_IOCTL_TYPE_2     0x03
+    u32 reserved:21;
+    u32 read_not_write:1; /* data direction */
+    u32 device_cmd:1; /* used to pass commands to specific devices identified by resource address */
+    u32 driver_cmd:1; /* used exclusively to pass commands to the device driver, 0 otherwise */
+    struct ipr_res_addr resource_address;
+#define IPR_CDB_LEN          16
+    u8 cdb[IPR_CDB_LEN];
+    u32 buffer_len;
+    u8 buffer[0];
+};
+
+/* The structures below are deprecated and should not be used. Use the
+ structure above to send ioctls instead */
+struct ipr_ioctl_cmd_internal
+{
+    u32 read_not_write:1;
+    u32 device_cmd:1;
+    u32 driver_cmd:1;
+    u32 reserved:29;
+    struct ipr_res_addr resource_address;
+#define IPR_CDB_LEN     16
+    u8 cdb[IPR_CDB_LEN];
+    void *buffer;
+    u32 buffer_len;
+};
+
+struct ipr_driver_cfg
+{
+    u16 debug_level;
+    u16 trace_level;
+    u16 debug_level_max;
+    u16 trace_level_max;
+};
+
+struct ipr_drive_global_desc_hdr
+{
+    u32 length;
+};
+
+/******************************************************************/
+/* SES Structures                                                 */
+/******************************************************************/
+
+struct ipr_drive_global_desc_c
+{
+    u8 fru_label_hdr[3];
+    u8 fru_label[4];
+    u8 frame_id_hdr[3];
+    u8 frame_id[2];
+};
+
+struct ipr_drive_global_desc_d
+{
+    u8 fru_label_hdr[3];
+    u8 fru_label[5];
+    u8 frame_id_hdr[3];
+    u8 frame_id[2];
+};
+
+struct ipr_ses_slot_map
+{
+    u8 scsi_id;
+    u8 label[3];
+    u8 slot_populated;
+    u8 carrier_info;
+    u8 bus_info;
+    u8 slot_info;
+    u8 left_pitch;
+    u8 right_pitch;
+    u8 reserved[6];
+};
+
+struct ipr_drive_element_desc
+{
+    u8     hdr_bytes[4];
+    struct ipr_ses_slot_map slot_map;
+};
+
+struct ipr_element_desc_page_c /* Diag page to get Element descriptors (vpd info) */
+{
+    struct ipr_drive_global_desc_c  drive_global_desc;
+    struct ipr_drive_element_desc drive_elem_desc[IPR_MAX_NUM_ELEM_DESCRIPTORS];
+};
+
+struct ipr_element_desc_page_d /* Diag page to get Element descriptors (vpd info) */
+{
+    struct ipr_drive_global_desc_d  drive_global_desc;
+    struct ipr_drive_element_desc drive_elem_desc[IPR_MAX_NUM_ELEM_DESCRIPTORS];
+};
+
+struct ipr_element_desc_page /* Diag page to get Element descriptors (vpd info) */
+{
+    u8                    pageCode;            /* Byte 0 */
+    u8                    reserved;            /* Byte 1 */
+    u8                    byte_count_hi;       /* Byte 2 */
+    u8                    byte_count_lo;       /* Byte 3 */
+    u8                    reserved1[4];        /* Byte 4-7 */
+    struct ipr_drive_global_desc_hdr global_desc_hdr;
+    union {
+        struct ipr_element_desc_page_c  drive_elem_desc_c;
+        struct ipr_element_desc_page_d  drive_elem_desc_d;
+    }desc;
+};
+
+/******************************************************************/
+/* SCSI Structures                                                */
+/******************************************************************/
+
+struct ipr_scsi_command {
+    u8 cmd;
+    u8 data[4];
+    u8 control;
+};
+
+struct ipr_mode_parm_hdr
+{
+    u8 length;
+    u8 medium_type;
+    u8 device_spec_parms;
+    u8 block_desc_len;
+};
+
+struct ipr_block_desc {
+    u8 num_blocks[4];
+    u8 density_code;
+    u8 block_length[3];
+};
+
+struct ipr_mode_page_28_header
+{
+    struct ipr_mode_page_hdr header;
+    u8 num_dev_entries;
+    u8 dev_entry_length;
+};
+
+struct ipr_lun
+{
+    struct ipr_resource_entry *p_resource_entry;
+    u32 is_valid_entry:1;
+    u32 stop_new_requests:1;
+    u32 expect_ccm:1;
+    u32 reserved:1;
+    u32 dev_changed:1;
+    u32 reserved1:27;
+    u32 reserved_pad;
+};
+
+struct ipr_target
+{
+    struct ipr_lun lun[IPR_MAX_NUM_LUNS_PER_TARGET];
+};
+
+struct ipr_bus
+{
+    struct ipr_target target[IPR_MAX_NUM_TARGETS_PER_BUS];
+};
+
+struct ipr_std_inq_vpids_sn
+{
+    struct ipr_std_inq_vpids vpids;
+    u8 serial_num[IPR_SERIAL_NUM_LEN];
+};
+
+struct ipr_ioa_vpd {
+    struct ipr_std_inq_data std_inq_data;
+    u8 ascii_part_num[12];
+    u8 reserved[40];
+    u8 ascii_plant_code[4];
+};
+
+struct ipr_cfc_vpd {
+    u8 peri_dev_type;
+    u8 page_code;
+    u8 reserved1;
+    u8 add_page_len;
+    u8 ascii_len;
+    u8 cache_size[3];
+    struct ipr_std_inq_vpids vpids;
+    u8 model_num[3];
+    u8 reserved2[9];
+    u8 revision_level[4];
+    u8 serial_num[IPR_SERIAL_NUM_LEN];
+    u8 ascii_part_num[12];
+    u8 reserved3[40];
+    u8 ascii_plant_code[4];
+};
+
+struct ipr_dram_vpd {
+    u8 peri_dev_type;
+    u8 page_code;
+    u8 reserved1;
+    u8 add_page_len;
+    u8 ascii_len;
+    u8 dram_size[3];
+};
+
+struct ipr_inquiry_page0  /* Supported Vital Product Data Pages */
+{
+    u8 peri_qual_dev_type;
+    u8 page_code;
+    u8 reserved1;
+    u8 page_length;
+    u8 supported_page_codes[IPR_MAX_NUM_SUPP_INQ_PAGES];
+};
+
+struct ipr_inquiry_page3
+{
+    u8 peri_qual_dev_type;
+    u8 page_code;
+    u8 reserved1;
+    u8 page_length;
+    u8 ascii_len;
+    u8 reserved2[3];
+    u8 load_id[4];
+    u8 major_release;
+    u8 card_type;
+    u8 minor_release[2];
+    u8 ptf_number[4];
+    u8 patch_number[4];
+};
+
+struct ipr_dasd_inquiry_page3
+{
+    u8 peri_qual_dev_type;
+    u8 page_code;
+    u8 reserved1;
+    u8 page_length;
+    u8 ascii_len;
+    u8 reserved2[3];
+    u8 load_id[4];
+    u8 release_level[4];
+};
+
+struct ipr_dasd_ucode_header
+{
+    u8 length[3];
+    u8 load_id[4];
+    u8 modification_level[4];
+    u8 ptf_number[4];
+    u8 patch_number[4];
+};
+
+struct ipr_software_inq_lid_info
+{
+    u32  load_id;
+    u32  timestamp[3];
+};
+
+struct ipr_inquiry_page_cx  /* Extended Software Inquiry  */
+{
+    u8 peri_qual_dev_type;
+    u8 page_code;
+    u8 reserved1;
+    u8 page_length;
+    u8 ascii_length;
+    u8 reserved2[3];
+
+    struct ipr_software_inq_lid_info lidinfo[15];
+};
+
+struct ipr_log_sense_supported_pages
+{
+    u8 page_code;
+    u8 reserved;
+    u16 page_length;
+    u8 page[100];
+};
+
+struct ipr_log_sense_perf_page /* DASD Performance counters */
+{
+    u8 page_code;
+    u8 reserved;
+    u16 page_length;
+    u8 reserved2[3];
+    u8 parm_length;
+    u16 num_seeks_zero_len;
+    u16 num_seeks_gt_two_thirds;
+    u16 num_seeks_one_third_two_thirds;
+    u16 num_seeks_one_sixth_one_third;
+    u16 num_seeks_one_twelfth_one_sixth;
+    u16 num_seeks_zero_one_twelfth;
+    u32 reserved3;
+    u16 num_dev_read_buffer_overruns;
+    u16 num_dev_write_buffer_underruns;
+    u32 num_dev_cache_read_hits;
+    u32 num_dev_cache_partial_read_hits;
+    u32 num_dev_cache_write_hits;
+    u32 num_dev_cache_fast_writes;
+    u32 reserved4[2];
+    u32 num_dev_read_ops;
+    u32 num_dev_write_ops;
+    u32 num_ioa_cache_read_hits;
+    u32 num_ioa_cache_partial_read_hits;
+    u32 num_ioa_cache_write_hits;
+    u32 num_ioa_cache_fast_writes;
+    u32 num_ioa_emulated_read_cache_hits;
+    u32 ioa_idle_loop_count[2];
+    u32 ioa_idle_count_value;
+    u8 ioa_idle_count_value_units;
+    u8 reserved5[3];
+};
+
+struct ipr_resource_entry
+{
+    u8 is_ioa_resource:1;
+    u8 is_compressed:1;
+    u8 is_array_member:1;
+    u8 format_allowed:1;
+    u8 dev_changed:1;
+    u8 in_init:1;
+    u8 redo_init:1;
+    u8 rw_protected:1;
+
+    u8 level;
+    u8 array_id;
+    u8 subtype;
+
+    struct ipr_res_addr resource_address;
+
+    u16 type;
+
+    u16 model;
+
+    /* The following two fields are used only for DASD */
+    u32 sw_load_id;
+
+    u32 sw_release_level;
+
+    char serial_num[IPR_SERIAL_NUM_LEN+1]; /* Null terminated ascii */
+
+    u8 is_hidden:1;
+    u8 is_af:1;
+    u8 is_hot_spare:1;
+    u8 supports_qas:1;
+    u8 nr_ioa_microcode:1;
+    u8 ioa_dead:1;
+    u8 reserved4:2;
+
+    u16 host_no;
+
+    u32 resource_handle;                /* In big endian byteorder */
+
+    /* NOTE: DSA/UA and frame_id/slot_label are only valid in iSeries Linux */
+    /*       In other architectures, DSA/UA will be set to zero and         */
+    /*       frame_id/slot_label will be initialized to ASCII spaces        */
+    u32 dsa;
+#define IPR_SYS_IPR_BUS_MASK              0xffff0000
+#define IPR_SYS_CARD_MASK                    0x0000ff00
+#define IPR_IO_ADAPTER_MASK                  0x000000ff
+#define IPR_GET_SYS_BUS(dsa)                                        \
+    ((dsa & IPR_SYS_IPR_BUS_MASK) >> 16)
+#define IPR_GET_SYS_CARD(dsa)                                       \
+    ((dsa & IPR_SYS_CARD_MASK) >> 8)
+#define IPR_GET_IO_ADAPTER(dsa)                                     \
+    (dsa & IPR_IO_ADAPTER_MASK)
+
+    u32 unit_address;
+#define IPR_IO_BUS_MASK                     0x0f000000
+#define IPR_CTL_MASK                        0x00ff0000
+#define IPR_DEV_MASK                        0x0000ff00
+#define IPR_GET_IO_BUS(ua)                                          \
+    ((ua & IPR_IO_BUS_MASK) >> 24)
+#define IPR_GET_CTL(ua)                                             \
+    ((ua & IPR_CTL_MASK) >> 16)
+#define IPR_GET_DEV(ua)                                             \
+    ((ua & IPR_DEV_MASK) >> 8)
+
+    u32 pci_bus_number;
+    u32 pci_slot;
+
+    u8 frame_id[3];
+    u8 slot_label[4];
+    u8 pseries_location[IPR_MAX_PSERIES_LOCATION_LEN+1];
+
+    u8 part_number[IPR_STD_INQ_PART_NUM_LEN+1];
+    u8 ec_level[IPR_STD_INQ_EC_LEVEL_LEN+1];
+    u8 fru_number[IPR_STD_INQ_FRU_NUM_LEN+1];
+    u8 z1_term[IPR_STD_INQ_Z1_TERM_LEN+1];
+    u8 z2_term[IPR_STD_INQ_Z2_TERM_LEN+1];
+    u8 z3_term[IPR_STD_INQ_Z3_TERM_LEN+1];
+    u8 z4_term[IPR_STD_INQ_Z4_TERM_LEN+1];
+    u8 z5_term[IPR_STD_INQ_Z5_TERM_LEN+1];
+    u8 z6_term[IPR_STD_INQ_Z6_TERM_LEN+1];
+
+    struct ipr_std_inq_data std_inq_data;
+};
+
+struct ipr_resource_dll
+{
+    struct ipr_resource_entry data;
+    struct ipr_resource_dll *next;
+    struct ipr_resource_dll *prev;
+};
+
+struct ipr_resource_hdr
+{
+    u16 num_entries;
+    u16 reserved;
+};
+
+struct ipr_resource_table
+{
+    struct ipr_resource_hdr   hdr;
+    struct ipr_resource_entry dev[IPR_MAX_PHYSICAL_DEVS];
+};
+
+struct ipr_array_query_data
+{
+    u16 resp_len;
+    u8  reserved;
+    u8  num_records;
+    u8 data[IPR_QAC_BUFFER_SIZE];
+};
+
+struct ipr_discard_cache_data
+{
+    u32 length;
+    union { 
+        struct ipr_std_inq_vpids_sn vpids_sn;
+        u32 add_cmd_parms[10];
+    }data;
+};
+
+struct ipr_cmd_status_record
+{
+    u16 reserved1;
+    u16 length;
+    u8 array_id;
+    u8 command_code;
+    u8 status;
+#define IPR_CMD_STATUS_SUCCESSFUL            0
+#define IPR_CMD_STATUS_IN_PROGRESS           2
+#define IPR_CMD_STATUS_ATTRIB_CHANGE         3
+#define IPR_CMD_STATUS_FAILED                4
+#define IPR_CMD_STATUS_INSUFF_DATA_MOVED     5
+
+    u8 percent_complete;
+    struct ipr_res_addr failing_dev_res_addr;
+    u32 failing_dev_res_handle;
+    u32 failing_dev_ioasc;
+    u32 ilid;
+    u32 resource_handle;
+};
+
+struct ipr_cmd_status
+{
+    u16 resp_len;
+    u8  reserved;
+    u8  num_records;
+    struct ipr_cmd_status_record record[100];
+};
+
+/* The addresses in here must be PCI addresses */
+struct ipr_sglist
+{
+    u32 address;
+    u32 length;
+};
+
+struct ipr_ccb
+{
+    struct ipr_ccb *p_next_done;
+    struct ipr_resource_entry *p_resource;
+
+    u32 completion;
+    /* Valid Values: IPR_RC_SUCCESS      */
+    /*               IPR_RC_DID_RESET    */
+    /*               IPR_RC_FAILED       */
+
+
+    u8 status;          /* SCSI status byte */
+    u8 task_attributes:3;
+#define IPR_UNTAGGED_TASK            0x0u
+#define IPR_SIMPLE_TASK              0x1u
+#define IPR_ORDERED_TASK             0x2u
+#define IPR_HEAD_OF_QUEUE_TASK       0x3u
+#define IPR_ACA_TASK                 0x4u
+
+    u8 reserved:5;
+
+    u16 flags;
+#define IPR_BLOCKING_COMMAND         0x0001
+#define IPR_ABORTING                 0x0002
+#define IPR_TIMED_OUT                0x0004
+#define IPR_GPDD_CMD                 0x0008
+#define IPR_FINISHED                 0x0010
+#define IPR_ERP_CMD                  0x0020
+#define IPR_UNMAP_ON_DONE            0x0040
+#define IPR_INTERNAL_REQ             0x0080
+#define IPR_IOA_CMD                  0x0100
+#define IPR_CMD_SYNC_OVERRIDE        0x0200
+#define IPR_BUFFER_MAPPED            0x0400
+#define IPR_ALLOW_REQ_OVERRIDE       0x0800
+
+#define IPR_CCB_CDB_LEN      16
+    u8 cdb[IPR_CCB_CDB_LEN];
+    u8 cmd_len;                         /* Length of CDB */
+
+    u8 data_direction;                  /* Used by iprlib */
+#define IPR_DATA_UNKNOWN       0
+#define IPR_DATA_WRITE         1
+#define IPR_DATA_READ          2
+#define IPR_DATA_NONE          3
+
+    u8 saved_data_direction;            /* Used during ERP for GPDD */
+
+    u8 sc_data_direction;               /* Copy of data direction from midlayer */
+                                        /* iprlib should not touch this field */
+
+    u8 use_sg;                          /* Used by iprlib */
+
+    u8 saved_use_sg;                    /* Used during ERP for GPDD */
+
+    u8 scsi_use_sg;                     /* Copy of data direction from midlayer */
+                                        /* iprlib should not touch this field */
+
+    u8 job_step;                        /* Used during device bringup jobs */
+
+    u32 bufflen;                        /* Total length of data buffer */
+
+    void *buffer;                       /* Pointer to data buffer if scatter/gather not used */
+    void *request_buffer;               /* Pointer to scatter/gather list */
+    ipr_dma_addr buffer_dma;         /* DMA address of data buffer if scatter/gather not used */
+    u32 underflow;                      /* Return an error if less that underflow bytes transfered */
+    u32 residual;                       /* Residual byte count */
+    u32 timeout;                        /* Timeout is seconds */
+    u32 reserved2;
+    ipr_dma_addr sense_buffer_dma;   /* DMA address of SCSI sense buffer */
+    u8 *sense_buffer;                   /* SCSI sense buffer */
+    void *p_scratch;
+    struct ipr_sglist *sglist;       /* Pointer to mapped scatter/gather list */
+};
+
+struct ipr_shared_config
+{
+    char eye_catcher[16];
+#define IPR_SHARED_LABEL     "sis_start_share"
+
+    void *p_data;
+    void *p_end;
+
+    u32 ioa_operational:1;
+    u32 set_mode_page_20:1;
+    u32 allow_interrupts:1;
+    u32 use_immed_format:1;
+    u32 nr_ioa_microcode:1;
+    u32 ioa_is_dead:1;
+    u32 needs_download:1;
+    u32 offline_dump:1;
+    u32 reserved:24;
+    u32 dram_size;
+
+    unsigned long hdw_bar_addr[4];
+    unsigned long hdw_bar_addr_pci[4];
+    unsigned long hdw_dma_regs;         /* iomapped PCI memory space (Registers) */
+    unsigned long hdw_dma_regs_pci;     /* raw PCI memory space (Registers) */
+    unsigned long ioa_mailbox;
+
+    struct ipr_location_data *p_location;
+
+    u8 debug_level;
+#define IPR_ADVANCED_DEBUG        4
+#define IPR_DEFAULT_DEBUG_LEVEL   2
+    u8 trace;
+#define IPR_TRACE            1
+    u16 ccin;
+    char ccin_str[10];
+    u16 vendor_id;
+    u16 device_id;
+    u16 subsystem_id;
+    u8 chip_rev_id;
+    u8 reserved2[3];
+    u16 host_no;
+    u16 num_physical_buses;
+
+    char resource_table_label[8];
+#define IPR_RES_TABLE_LABEL          "res_tbl"
+    struct ipr_resource_dll *resource_entry_list;
+    struct ipr_resource_dll *rsteFreeH;
+    struct ipr_resource_dll *rsteFreeT;
+    struct ipr_resource_dll *rsteUsedH;
+    struct ipr_resource_dll *rsteUsedT;
+
+    char ses_table_start[8];
+#define IPR_DATA_SES_DATA_START      "ses"
+    struct ipr_element_desc_page *p_ses_data[IPR_MAX_NUM_BUSES];
+    ipr_dma_addr ses_data_dma[IPR_MAX_NUM_BUSES];
+
+    struct ipr_ioa_vpd *p_ioa_vpd;
+    struct ipr_cfc_vpd *p_cfc_vpd;
+    ipr_dma_addr cfc_vpd_dma;
+    ipr_dma_addr ioa_vpd_dma;
+
+    struct ipr_inquiry_page3 *p_ucode_vpd;
+    struct ipr_inquiry_page0 *p_page0_vpd;
+    ipr_dma_addr ucode_vpd_dma;
+    ipr_dma_addr page0_vpd_dma;
+
+    struct ipr_dram_vpd *p_dram_vpd;
+    ipr_dma_addr dram_vpd_dma;
+    u32 reserved_pad;
+    struct ipr_vpd_cbs *p_vpd_cbs;
+    struct ipr_page_28_data *p_page_28;
+
+    /* The size of this is + 1 to allow for volume sets on
+       converged adapters.  Volume sets are identified with
+       a bus of 0xff so to avoid a large array, any reference
+       to this data array will require the actual bus # + 1
+       as the index.  It is expected the 0xff index will
+       then become 0x00 */
+    struct ipr_bus bus[IPR_MAX_NUM_BUSES + 1];
+
+    struct ipr_resource_entry ioa_resource;
+
+    char ioa_host_str[IPR_MAX_LOCATION_LEN];
+
+    char end_eye_catcher[16];
+#define IPR_END_SHARED_LABEL         "sis_end_share"
+};
+
+struct ipr_vpd_cbs
+{
+    struct ipr_ioa_vpd ioa_vpd;
+    struct ipr_cfc_vpd cfc_vpd;
+    struct ipr_inquiry_page3 page3_data;
+    struct ipr_inquiry_page0 page0_data;
+    struct ipr_dram_vpd dram_vpd;
+};
+
+struct ipr_page_28
+{
+    struct ipr_mode_parm_hdr parm_hdr;
+    struct ipr_mode_page_28_header page_hdr;
+    struct ipr_mode_page_28_scsi_dev_bus_attr attr[IPR_MAX_NUM_BUSES];
+};
+
+struct ipr_page_28_data
+{
+    struct ipr_page_28 dflt;
+    struct ipr_page_28 saved;
+    struct ipr_page_28 changeable;
+};
+
+struct ipr_ioa_cfg_t
+{
+    u16 vendor_id;
+    u16 device_id;
+    u32 bar_index;
+    u32 mailbox;
+    u32 mbx_bar_sel_mask;
+    u32 mkr_bar_sel_shift;
+    u32 mbx_addr_mask;
+
+    u32 sdt_reg_sel_size:3;
+#define IPR_SDT_REG_SEL_SIZE_NONE                    0x4
+#define IPR_SDT_REG_SEL_SIZE_1NIBBLE                 0x2
+#define IPR_SDT_REG_SEL_SIZE_1BYTE                   0x1
+    u32 cpu_rst_support:2;
+#define IPR_CPU_RST_SUPPORT_NONE                     0x1
+#define IPR_CPU_RST_SUPPORT_CFGSPC_403RST_BIT        0x2
+    u32 fixups_required:3;
+#define IPR_FIXUPS_NONE                              0x0
+#define IPR_ENDIAN_SWAP_FIXUP                        0x1
+    u32 bar_size_reg:1;
+    u32 set_mode_page_20:1;
+#define IPR_IGNORE_MODE_PAGE_20                      0x0
+#define IPR_SET_MODE_PAGE_20                         0x1
+    u32 reserved_flags:22;
+
+    u32 cl_size_latency_timer;
+};
+
+struct ipr_sense_buffer
+{
+    u8 byte[IPR_SENSE_BUFFERSIZE];
+};
+
+struct ipr_sdt_header
+{
+    u32  dump_state;
+    u32  num_entries;
+    u32  num_entries_used;
+    u32  dump_size;
+};
+
+struct ipr_sdt
+{
+    struct ipr_sdt_header sdt_header;
+    struct ipr_sdt_entry sdt_entry[IPR_NUM_SDT_ENTRIES];
+};
+
+struct ipr_uc_sdt
+{
+    struct ipr_sdt_header sdt_header;
+    struct ipr_sdt_entry sdt_entry[1];
+};
+
+struct ipr_dump_header
+{
+    u32 total_length;
+    u32 num_elems;
+    u32 first_entry_offset;
+    u32 status;
+};
+
+struct ipr_dump_entry_header
+{
+    u32 length;  /* MUST be the first member of the structure */
+    u32 id;
+#define IPR_DUMP_IOA_DUMP_ID 2
+#define IPR_DUMP_TEXT_ID     3
+#define IPR_DUMP_TRACE_ID    4
+};
+
+struct ipr_dump_location_entry
+{
+    struct ipr_dump_entry_header header;
+    u8 location[IPR_MAX_LOCATION_LEN];
+};
+
+struct ipr_dump_trace_entry
+{
+    struct ipr_dump_entry_header header;
+    u32 trace[IPR_DUMP_TRACE_ENTRY_SIZE/sizeof(u32)];
+};
+
+struct ipr_dump_driver_header
+{
+    struct ipr_dump_header header;
+    struct ipr_dump_location_entry location_entry;
+    struct ipr_dump_trace_entry trace_entry;
+};
+
+enum ipr_irq_state
+{
+    IPR_IRQ_ENABLED = 0,
+    IPR_IRQ_DISABLED = 1
+};
+
+struct ipr_byte_pat_6
+{
+    u32 pat1;
+    u16 pat2;
+};
+
+struct ipr_byte_pat_8
+{
+    u32 pat1;
+    u32 pat2;
+};
+
+struct ipr_byte_pat_10
+{
+    u32 pat1;
+    u32 pat2;
+    u16 pat3;
+};
+
+struct ipr_byte_pat_16
+{
+    u32        pat1;
+    u32        pat2;
+    u32        pat3;
+    u32        pat4;
+};
+
+struct ipr_byte_pat_32
+{
+    struct ipr_byte_pat_16 pat1;
+    struct ipr_byte_pat_16 pat2;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/iprtypesbe.h linux-8240/drivers/addon/ipr/iprtypesbe.h
--- linux-8230/drivers/addon/ipr/iprtypesbe.h
+++ linux-8240/drivers/addon/ipr/iprtypesbe.h
@@ -0,0 +1,506 @@
+/*****************************************************************************/
+/* iprtypesbe.h -- driver for IBM Power Linux RAID adapters                  */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprtypesbe.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+/******************************************************************/
+/* Note: Any additions/changes here must be duplicated in         */
+/*       iprtypesle.h                                          */
+/******************************************************************/
+
+#ifndef iprtypesbe_h
+#define iprtypesbe_h
+
+/******************************************************************/
+/* Macros                                                         */
+/******************************************************************/
+
+#define htosis16(x) (x)
+#define htosis32(x) (x)
+#define sistoh16(x) (x)
+#define sistoh32(x) (x)
+#define _i16(x) (x)
+#define _i32(x) (x)
+
+#define IPR_BIG_ENDIAN       1
+#define IPR_LITTLE_ENDIAN    0
+
+/******************************************************************/
+/* Data Types                                                     */
+/* Note: All IOA/device data structures using bitfields MUST be   */
+/*       defined here.                                            */
+/******************************************************************/
+
+/******************************************************************/
+/* SES Structures                                                 */
+/******************************************************************/
+
+struct ipr_drive_elem_status
+{
+    u8 select:1;
+    u8 predictive_fault:1;
+    u8 reserved:1;
+    u8 swap:1;
+    u8 status:4;
+
+    u8 reserved2:4;
+    u8 scsi_id:4;
+
+    u8 reserved3:4;
+    u8 insert:1;
+    u8 remove:1;
+    u8 reserved4:1;
+    u8 identify:1;
+
+    u8 reserved5:1;
+    u8 fault_requested:1;
+    u8 fault_sensed:1;
+    u8 reserved6:5;
+};
+
+struct ipr_encl_status_ctl_pg
+{
+    u8 page_code;
+    u8 health_status;
+    u16 byte_count;
+    u8 reserved1[4];
+
+    u8 overall_status_select:1;
+    u8 overall_status_predictive_fault:1;
+    u8 overall_status_reserved:1;
+    u8 overall_status_swap:1;
+    u8 overall_status_reserved2:4;
+
+    u8 overall_status_reserved3;
+
+    u8 overall_status_reserved4:4;
+    u8 overall_status_insert:1;
+    u8 overall_status_remove:1;
+    u8 overall_status_reserved5:1;
+    u8 overall_status_identify:1;
+
+    u8 overall_status_reserved6:1;
+    u8 overall_status_fault_requested:1;
+    u8 overall_status_fault_sensed:1;
+    u8 overall_status_reserved7:4;
+    u8 overall_status_disable_resets:1;
+
+    struct ipr_drive_elem_status elem_status[IPR_NUM_DRIVE_ELEM_STATUS_ENTRIES];
+};
+
+/******************************************************************/
+/* SCSI/SIS Structures                                            */
+/******************************************************************/
+
+struct ipr_mode_page_hdr
+{
+    u8 parms_saveable:1;
+    u8 reserved1:1;
+    u8 page_code:6;
+    u8 page_length;
+};
+
+struct ipr_mode_page_28_scsi_dev_bus_attr
+{
+    struct ipr_res_addr res_addr;
+    u8 qas_capability:2;
+#define IPR_MODEPAGE28_QAS_CAPABILITY_NO_CHANGE      0  
+#define IPR_MODEPAGE28_QAS_CAPABILITY_DISABLE_ALL    1        
+#define IPR_MODEPAGE28_QAS_CAPABILITY_ENABLE_ALL     2
+/* NOTE:   Due to current operation conditions QAS should
+ never be enabled so the change mask will be set to 0 */
+#define IPR_MODEPAGE28_QAS_CAPABILITY_CHANGE_MASK    0
+
+    u8 enable_target_mode:1;
+    u8 term_power_absent:1;
+    u8 target_mode_supported:1;
+    u8 lvd_to_se_transition_not_allowed:1;
+    u8 reserved2:2;
+
+    u8 scsi_id;
+#define IPR_MODEPAGE28_SCSI_ID_NO_CHANGE             0x80u
+#define IPR_MODEPAGE28_SCSI_ID_NO_ID                 0xFFu
+
+    u8 bus_width;
+#define IPR_MODEPAGE28_BUS_WIDTH_NO_CHANGE           0
+
+    u8 extended_reset_delay;
+#define IPR_EXTENDED_RESET_DELAY                     7
+
+    u32 max_xfer_rate;
+#define IPR_MODEPAGE28_MAX_XFR_RATE_NO_CHANGE        0
+
+    u8  min_time_delay;
+#define IPR_DEFAULT_SPINUP_DELAY                     0xFFu
+#define IPR_INIT_SPINUP_DELAY                        5
+    u8  reserved3;
+    u16 reserved4;
+};
+
+struct ipr_control_mode_page
+{
+    /* Mode page 0x0A */
+    struct ipr_mode_page_hdr header;
+    u8 tst:3;
+    u8 reserved1:3;
+    u8 gltsd:1;
+    u8 rlec:1;
+    u8 queue_algorithm_modifier:4;
+    u8 reserved2:1;
+    u8 qerr:2;
+    u8 dque:1;
+    u8 reserved3:1;
+    u8 rac:1;
+    u8 reserved4:2;
+    u8 swp:1;
+    u8 raerp:1;
+    u8 uaaerp:1;
+    u8 eaerp:1;
+    u8 reserved5;
+    u16 ready_aen_holdoff_period;
+    u16 busy_timeout_period;
+    u16 reserved6;
+};
+
+/* 44 bytes */
+struct ipr_std_inq_data{
+    u8 peri_qual:3;
+    u8 peri_dev_type:5;
+
+    u8 removeable_medium:1;
+    u8 reserved1:7;
+
+    u8 version;
+
+    u8 aen:1;
+    u8 obsolete1:1;
+    u8 norm_aca:1;
+    u8 hi_sup:1;
+    u8 resp_data_fmt:4;
+
+    u8 additional_len;
+
+    u8 sccs:1;
+    u8 reserved2:7;
+
+    u8 bque:1;
+    u8 enc_serv:1;
+    u8 vs:1;
+    u8 multi_port:1;
+    u8 mchngr:1;
+    u8 obsolete2:2;
+    u8 addr16:1;
+
+    u8 rel_adr:1;
+    u8 obsolete3:1;
+    u8 wbus16:1;
+    u8 sync:1;
+    u8 linked:1;
+    u8 trans_dis:1;
+    u8 cmd_que:1;
+    u8 vs2:1;
+
+    /* Vendor and Product ID */
+    struct ipr_std_inq_vpids vpids;
+
+    /* ROS and RAM levels */
+    u8 ros_rsvd_ram_rsvd[4];
+
+    /* Serial Number */
+    u8 serial_num[IPR_SERIAL_NUM_LEN];
+};
+
+struct ipr_std_inq_data_long
+{
+    struct ipr_std_inq_data std_inq_data;
+    u8 z1_term[IPR_STD_INQ_Z1_TERM_LEN];
+    u8 reserved:4;
+    u8 clocking:2;
+    u8 qas:1;
+    u8 ius:1;
+    u8 reserved1[41];
+    u8 z2_term[IPR_STD_INQ_Z2_TERM_LEN];
+    u8 z3_term[IPR_STD_INQ_Z3_TERM_LEN];
+    u8 reserved2;
+    u8 z4_term[IPR_STD_INQ_Z4_TERM_LEN];
+    u8 z5_term[IPR_STD_INQ_Z5_TERM_LEN];
+    u8 part_number[IPR_STD_INQ_PART_NUM_LEN];
+    u8 ec_level[IPR_STD_INQ_EC_LEVEL_LEN];
+    u8 fru_number[IPR_STD_INQ_FRU_NUM_LEN];
+    u8 z6_term[IPR_STD_INQ_Z6_TERM_LEN];
+};
+
+/* 1024 bytes */
+struct ipr_hostrcb
+{
+    u8 op_code;
+
+    u8  notificationType;
+
+    u8  notificationsLost;
+
+    u8  internal_oper_flag:1;
+    u8  error_resp_sent:1;
+    u8  reserved0:6;
+
+    u8  overlayId;
+
+    u8  reserved1[3];
+    u32 ilid;
+    u32 timeSinceLastIoaReset;
+    u32 reserved2;
+    u32 length;
+
+    union {
+        struct ipr_hostrcb_error error;
+        struct ipr_hostrcb_cfg_ch_not ccn;
+    }data;
+};
+
+struct ipr_array_cap_entry
+{
+    u8                          prot_level;
+#define IPR_DEFAULT_RAID_LVL "5"
+    u8                          include_allowed:1;
+    u8                          reserved:7;
+    u16                         reserved2;
+    u8                          reserved3;
+    u8                          max_num_array_devices;
+    u8                          min_num_array_devices;
+    u8                          min_mult_array_devices;
+    u16                         reserved4;
+    u16                         supported_stripe_sizes;
+    u16                         reserved5;
+    u16                         recommended_stripe_size;
+    u8                          prot_level_str[8];
+};
+
+struct ipr_array_record
+{
+    struct ipr_record_common common;
+    u8  issue_cmd:1;
+    u8  known_zeroed:1;
+    u8  reserved:6;
+    u8  reserved1;
+    u8  established:1;
+    u8  exposed:1;
+    u8  non_func:1;
+    u8  reserved2:5;
+    u8  start_cand:1;
+    u8  stop_cand:1;
+    u8  resync_cand:1;
+    u8  reserved3:5;
+    u8  reserved4[3];
+    u8  array_id;
+    u32 reserved5;
+};
+
+struct ipr_array2_record
+{
+    struct ipr_record_common common;
+
+    u8  issue_cmd:1;
+    u8  known_zeroed:1;
+    u8  reserved1:6;
+
+    u8  reserved2;
+
+    u8  established:1;
+    u8  exposed:1;
+    u8  non_func:1;
+    u8  high_avail:1;
+    u8  no_config_entry:1;
+    u8  reserved3:3;
+
+    u8  start_cand:1;
+    u8  stop_cand:1;
+    u8  resync_cand:1;
+    u8  reserved4:5;
+
+    u16 stripe_size;
+
+    u8  raid_level;
+    u8  array_id;
+    u32 resource_handle;
+    u32 resource_address;
+    struct ipr_res_addr last_resource_address;
+    u8  vendor_id[8];
+    u8  product_id[16];
+    u8  serial_number[8];
+    u32 reserved;
+};
+
+struct ipr_resource_flags
+{
+    u8 is_ioa_resource:1;
+    u8 is_compressed:1;
+    u8 is_array_member:1;
+    u8 reserved1:1;
+    u8 aff:1;
+    u8 reserved2:1;
+    u8 capacity_reduction_hi:2;
+
+    u8 capacity_reduction_lo:1;
+    u8 reserved3:7;
+};
+
+struct ipr_device_record
+{
+    struct ipr_record_common common;
+    u8  issue_cmd:1;
+    u8  known_zeroed:1;
+    u8  reserved:6;
+
+    u8  reserved1;
+
+    u8  array_member:1;
+    u8  has_parity:1;
+    u8  is_exposed_device:1;
+    u8  is_hot_spare:1;
+    u8  no_cfgte_vol:1;
+    u8  no_cfgte_dev:1;
+    u8  reserved2:2;
+
+    u8  start_cand:1;
+    u8  parity_cand:1;
+    u8  stop_cand:1;
+    u8  resync_cand:1;
+    u8  include_cand:1;
+    u8  exclude_cand:1;
+    u8  rebuild_cand:1;
+    u8  zero_cand:1;
+
+    u8  add_hot_spare_cand:1;
+    u8  rmv_hot_spare_cand:1;
+    u8  reserved3:6;
+
+    u8  reserved4[2];
+    u8  array_id;
+    u32 resource_handle;
+    u16 reserved5;
+    struct ipr_resource_flags resource_flags_to_become;
+    u32 user_area_size_to_become;  
+};
+
+struct ipr_reclaim_query_data
+{
+    u8 action_status;
+#define IPR_ACTION_SUCCESSFUL               0
+#define IPR_ACTION_NOT_REQUIRED             1
+#define IPR_ACTION_NOT_PERFORMED            2
+    u8 reclaim_known_needed:1;
+    u8 reclaim_unknown_needed:1;
+    u8 reserved2:2;
+    u8 reclaim_known_performed:1;
+    u8 reclaim_unknown_performed:1;
+    u8 reserved3:1;
+    u8 num_blocks_needs_multiplier:1;
+
+    u16 num_blocks;
+
+    u8 rechargeable_battery_type;
+#define IPR_BATTERY_TYPE_NO_BATTERY          0
+#define IPR_BATTERY_TYPE_NICD                1
+#define IPR_BATTERY_TYPE_NIMH                2
+#define IPR_BATTERY_TYPE_LIION               3
+
+    u8 rechargeable_battery_error_state;
+#define IPR_BATTERY_NO_ERROR_STATE           0
+#define IPR_BATTERY_WARNING_STATE            1
+#define IPR_BATTERY_ERROR_STATE              2
+
+    u8 reserved4[2];
+
+    u16 raw_power_on_time;
+    u16 adjusted_power_on_time;
+    u16 estimated_time_to_battery_warning;
+    u16 estimated_time_to_battery_failure;
+
+    u8 reserved5[240];
+};
+
+struct ipr_vset_res_state
+{
+    u16 stripe_size;
+    u8 prot_level;
+    u8 num_devices_in_vset;
+    u32 reserved6;
+};
+
+struct ipr_dasd_res_state
+{
+    u32 data_path_width;  /* bits */
+    u32 data_xfer_rate;   /* 100 KBytes/second */
+};
+
+struct ipr_query_res_state
+{
+    u8 reserved1:1;
+    u8 not_oper:1;
+    u8 not_ready:1;
+    u8 not_func:1;
+    u8 reserved2:4;
+
+    u8 read_write_prot:1;
+    u8 reserved3:7;
+
+    u8 prot_dev_failed:1;
+    u8 prot_suspended:1;
+    u8 prot_resuming:1;
+    u8 degraded_oper:1;
+    u8 service_req:1;
+    u8 reserved4:3;
+
+    u8 reserved5;
+
+    union
+    {
+        struct ipr_vset_res_state vset;
+        struct ipr_dasd_res_state dasd;
+    }dev;
+
+    u32 ilid;
+    u32 failing_dev_ioasc;
+    struct ipr_res_addr failing_dev_res_addr;
+    u32 failing_dev_res_handle;
+    u8 protection_level_str[8];
+};
+
+/* IBM's SIS smart dump table structures */
+struct ipr_sdt_entry
+{
+    u32 bar_str_offset;
+    u32 end_offset;
+    u8  entry_byte;
+    u8  reserved[3];
+    u8  endian:1;
+    u8  reserved1:1;
+    u8  valid_entry:1;
+    u8  reserved2:5;
+    u8  resv;
+    u16 priority;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/iprtypesle.h linux-8240/drivers/addon/ipr/iprtypesle.h
--- linux-8230/drivers/addon/ipr/iprtypesle.h
+++ linux-8240/drivers/addon/ipr/iprtypesle.h
@@ -0,0 +1,511 @@
+/*****************************************************************************/
+/* iprtypesle.h -- driver for IBM Power Linux RAID adapters                  */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/iprtypesle.h,v 1.2 2003/10/24 20:52:17 bjking1 Exp $
+ */
+
+/******************************************************************/
+/* Note: Any additions/changes here must be duplicated in         */
+/*       iprtypesbe.h                                          */
+/******************************************************************/
+
+#ifndef iprtypesle_h
+#define iprtypesle_h
+
+/******************************************************************/
+/* Macros                                                         */
+/******************************************************************/
+
+#define htosis16(x) swab16(x)
+#define htosis32(x) swab32(x)
+#define sistoh16(x) swab16(x)
+#define sistoh32(x) swab32(x)
+
+#define _i16(x) _sw16(x)
+#define _i32(x) _sw32(x)
+
+#define IPR_BIG_ENDIAN       0
+#define IPR_LITTLE_ENDIAN    1
+
+/******************************************************************/
+/* Data Types                                                     */
+/* Note: All IOA/device data structures using bitfields MUST be   */
+/*       defined here with their bit fields in reverse order      */
+/******************************************************************/
+
+/******************************************************************/
+/* SES Structures                                                 */
+/******************************************************************/
+
+struct ipr_drive_elem_status
+{
+    u8 status:4;
+    u8 swap:1;
+    u8 reserved:1;
+    u8 predictive_fault:1;
+    u8 select:1;
+
+    u8 scsi_id:4;
+    u8 reserved2:4;
+
+    u8 identify:1;
+    u8 reserved4:1;
+    u8 remove:1;
+    u8 insert:1;
+    u8 reserved3:4;
+
+    u8 reserved6:5;
+    u8 fault_sensed:1;
+    u8 fault_requested:1;
+    u8 reserved5:1;
+};
+
+struct ipr_encl_status_ctl_pg
+{
+    u8 page_code;
+    u8 health_status;
+    u16 byte_count;
+    u8 reserved1[4];
+
+    u8 overall_status_reserved2:4;
+    u8 overall_status_swap:1;
+    u8 overall_status_reserved:1;
+    u8 overall_status_predictive_fault:1;
+    u8 overall_status_select:1;
+
+    u8 overall_status_reserved3;
+
+    u8 overall_status_identify:1;
+    u8 overall_status_reserved5:1;
+    u8 overall_status_remove:1;
+    u8 overall_status_insert:1;
+    u8 overall_status_reserved4:4;
+
+    u8 overall_status_disable_resets:1;
+    u8 overall_status_reserved7:4;
+    u8 overall_status_fault_sensed:1;
+    u8 overall_status_fault_requested:1;
+    u8 overall_status_reserved6:1;
+
+    struct ipr_drive_elem_status elem_status[IPR_NUM_DRIVE_ELEM_STATUS_ENTRIES];
+};
+
+/******************************************************************/
+/* SCSI/SIS Structures                                            */
+/******************************************************************/
+
+struct ipr_mode_page_hdr
+{
+    u8 page_code:6;
+    u8 reserved1:1;
+    u8 parms_saveable:1;
+    u8 page_length;
+};
+
+struct ipr_mode_page_28_scsi_dev_bus_attr
+{
+    struct ipr_res_addr res_addr;
+
+    u8 reserved2:2;
+    u8 lvd_to_se_transition_not_allowed:1;
+    u8 target_mode_supported:1;
+    u8 term_power_absent:1;
+    u8 enable_target_mode:1;
+    u8 qas_capability:2;
+#define IPR_MODEPAGE28_QAS_CAPABILITY_NO_CHANGE      0  
+#define IPR_MODEPAGE28_QAS_CAPABILITY_DISABLE_ALL    1        
+#define IPR_MODEPAGE28_QAS_CAPABILITY_ENABLE_ALL     2
+/* NOTE:   Due to current operation conditions QAS should
+ never be enabled so the change mask will be set to 0 */
+#define IPR_MODEPAGE28_QAS_CAPABILITY_CHANGE_MASK    0
+
+    u8 scsi_id;
+#define IPR_MODEPAGE28_SCSI_ID_NO_CHANGE             0x80u
+#define IPR_MODEPAGE28_SCSI_ID_NO_ID                 0xFFu
+
+    u8 bus_width;
+#define IPR_MODEPAGE28_BUS_WIDTH_NO_CHANGE           0
+
+    u8 extended_reset_delay;
+#define IPR_EXTENDED_RESET_DELAY                     7
+
+    u32 max_xfer_rate;
+#define IPR_MODEPAGE28_MAX_XFR_RATE_NO_CHANGE        0
+
+    u8  min_time_delay;
+#define IPR_DEFAULT_SPINUP_DELAY                     0xFFu
+#define IPR_INIT_SPINUP_DELAY                        5
+    u8  reserved3;
+    u16 reserved4;
+};
+
+struct ipr_control_mode_page
+{
+    /* Mode page 0x0A */
+    struct ipr_mode_page_hdr header;
+    u8 rlec:1;
+    u8 gltsd:1;
+    u8 reserved1:3;
+    u8 tst:3;
+    u8 dque:1;
+    u8 qerr:2;
+    u8 reserved2:1;
+    u8 queue_algorithm_modifier:4;
+    u8 eaerp:1;
+    u8 uaaerp:1;
+    u8 raerp:1;
+    u8 swp:1;
+    u8 reserved4:2;
+    u8 rac:1;
+    u8 reserved3:1;
+
+    u8 reserved5;
+    u16 ready_aen_holdoff_period;
+    u16 busy_timeout_period;
+    u16 reserved6;
+};
+
+/* 44 bytes */
+struct ipr_std_inq_data{
+    u8 peri_dev_type:5;
+    u8 peri_qual:3;
+
+    u8 reserved1:7;
+    u8 removeable_medium:1;
+
+    u8 version;
+
+    u8 resp_data_fmt:4;
+    u8 hi_sup:1;
+    u8 norm_aca:1;
+    u8 obsolete1:1;
+    u8 aen:1;
+
+    u8 additional_len;
+
+    u8 reserved2:7;
+    u8 sccs:1;
+
+    u8 addr16:1;
+    u8 obsolete2:2;
+    u8 mchngr:1;
+    u8 multi_port:1;
+    u8 vs:1;
+    u8 enc_serv:1;
+    u8 bque:1;
+
+    u8 vs2:1;
+    u8 cmd_que:1;
+    u8 trans_dis:1;
+    u8 linked:1;
+    u8 sync:1;
+    u8 wbus16:1;
+    u8 obsolete3:1;
+    u8 rel_adr:1;
+
+    /* Vendor and Product ID */
+    struct ipr_std_inq_vpids vpids;
+
+    /* ROS and RAM levels */
+    u8 ros_rsvd_ram_rsvd[4];
+
+    /* Serial Number */
+    u8 serial_num[IPR_SERIAL_NUM_LEN];
+};
+
+struct ipr_std_inq_data_long
+{
+    struct ipr_std_inq_data std_inq_data;
+    u8 z1_term[IPR_STD_INQ_Z1_TERM_LEN];
+    u8 ius:1;
+    u8 qas:1;
+    u8 clocking:2;
+    u8 reserved:4;
+    u8 reserved1[41];
+    u8 z2_term[IPR_STD_INQ_Z2_TERM_LEN];
+    u8 z3_term[IPR_STD_INQ_Z3_TERM_LEN];
+    u8 reserved2;
+    u8 z4_term[IPR_STD_INQ_Z4_TERM_LEN];
+    u8 z5_term[IPR_STD_INQ_Z5_TERM_LEN];
+    u8 part_number[IPR_STD_INQ_PART_NUM_LEN];
+    u8 ec_level[IPR_STD_INQ_EC_LEVEL_LEN];
+    u8 fru_number[IPR_STD_INQ_FRU_NUM_LEN];
+    u8 z6_term[IPR_STD_INQ_Z6_TERM_LEN];
+};
+
+/* 1024 bytes */
+struct ipr_hostrcb
+{
+    u8 op_code;
+
+    u8  notificationType;
+
+    u8  notificationsLost;
+
+    u8  reserved0:6;
+    u8  error_resp_sent:1;
+    u8  internal_oper_flag:1;
+
+    u8  overlayId;
+
+    u8  reserved1[3];
+    u32 ilid;
+    u32 timeSinceLastIoaReset;
+    u32 reserved2;
+    u32 length;
+
+    union {
+        struct ipr_hostrcb_error error;
+        struct ipr_hostrcb_cfg_ch_not ccn;
+    }data;
+};
+
+struct ipr_array_cap_entry
+{
+    u8                          prot_level;
+#define IPR_DEFAULT_RAID_LVL "5"
+    u8                          reserved:7;
+    u8                          include_allowed:1;
+    u16                         reserved2;
+    u8                          reserved3;
+    u8                          max_num_array_devices;
+    u8                          min_num_array_devices;
+    u8                          min_mult_array_devices;
+    u16                         reserved4;
+    u16                         supported_stripe_sizes;
+    u16                         reserved5;
+    u16                         recommended_stripe_size;
+    u8                          prot_level_str[8];
+};
+
+struct ipr_array_record
+{
+    struct ipr_record_common common;
+    u8  reserved:6;
+    u8  known_zeroed:1;
+    u8  issue_cmd:1;
+    u8  reserved1;
+
+    u8  reserved2:5;
+    u8  non_func:1;
+    u8  exposed:1;
+    u8  established:1;
+
+    u8  reserved3:5;
+    u8  resync_cand:1;
+    u8  stop_cand:1;
+    u8  start_cand:1;
+
+    u8  reserved4[3];
+    u8  array_id;
+    u32 reserved5;
+};
+
+struct ipr_array2_record
+{
+    struct ipr_record_common common;
+
+    u8  reserved1:6;
+    u8  known_zeroed:1;
+    u8  issue_cmd:1;
+
+    u8  reserved2;
+
+    u8  reserved3:3;
+    u8  no_config_entry:1;
+    u8  high_avail:1;
+    u8  non_func:1;
+    u8  exposed:1;
+    u8  established:1;
+
+    u8  reserved4:5;
+    u8  resync_cand:1;
+    u8  stop_cand:1;
+    u8  start_cand:1;
+
+    u16 stripe_size;
+
+    u8  raid_level;
+    u8  array_id;
+    u32 resource_handle;
+    u32 resource_address;
+    struct ipr_res_addr last_resource_address;
+    u8  vendor_id[8];
+    u8  product_id[16];
+    u8  serial_number[8];
+    u32 reserved;
+};
+
+struct ipr_resource_flags
+{
+    u8 capacity_reduction_hi:2;
+    u8 reserved2:1;
+    u8 aff:1;
+    u8 reserved1:1;
+    u8 is_array_member:1;
+    u8 is_compressed:1;
+    u8 is_ioa_resource:1;
+
+    u8 reserved3:7;
+    u8 capacity_reduction_lo:1;
+};
+
+struct ipr_device_record
+{
+    struct ipr_record_common common;
+    u8  reserved:6;
+    u8  known_zeroed:1;
+    u8  issue_cmd:1;
+
+    u8  reserved1;
+
+    u8  reserved2:2;
+    u8  no_cfgte_dev:1;
+    u8  no_cfgte_vol:1;
+    u8  is_hot_spare:1;
+    u8  is_exposed_device:1;
+    u8  has_parity:1;
+    u8  array_member:1;
+
+    u8  zero_cand:1;
+    u8  rebuild_cand:1;
+    u8  exclude_cand:1;
+    u8  include_cand:1;
+    u8  resync_cand:1;
+    u8  stop_cand:1;
+    u8  parity_cand:1;
+    u8  start_cand:1;
+
+    u8  reserved3:6;
+    u8  rmv_hot_spare_cand:1;
+    u8  add_hot_spare_cand:1;
+
+    u8  reserved4[2];
+    u8  array_id;
+    u32 resource_handle;
+    u16 reserved5;
+    struct ipr_resource_flags resource_flags_to_become;
+    u32 user_area_size_to_become;  
+};
+
+struct ipr_reclaim_query_data
+{
+    u8 action_status;
+#define IPR_ACTION_SUCCESSFUL               0
+#define IPR_ACTION_NOT_REQUIRED             1
+#define IPR_ACTION_NOT_PERFORMED            2
+    u8 num_blocks_needs_multiplier:1;
+    u8 reserved3:1;
+    u8 reclaim_unknown_performed:1;
+    u8 reclaim_known_performed:1;
+    u8 reserved2:2;
+    u8 reclaim_unknown_needed:1;
+    u8 reclaim_known_needed:1;
+
+    u16 num_blocks;
+
+    u8 rechargeable_battery_type;
+#define IPR_BATTERY_TYPE_NO_BATTERY          0
+#define IPR_BATTERY_TYPE_NICD                1
+#define IPR_BATTERY_TYPE_NIMH                2
+#define IPR_BATTERY_TYPE_LIION               3
+
+    u8 rechargeable_battery_error_state;
+#define IPR_BATTERY_NO_ERROR_STATE           0
+#define IPR_BATTERY_WARNING_STATE            1
+#define IPR_BATTERY_ERROR_STATE              2
+
+    u8 reserved4[2];
+
+    u16 raw_power_on_time;
+    u16 adjusted_power_on_time;
+    u16 estimated_time_to_battery_warning;
+    u16 estimated_time_to_battery_failure;
+
+    u8 reserved5[240];
+};
+
+struct ipr_vset_res_state
+{
+    u16 stripe_size;
+    u8 prot_level;
+    u8 num_devices_in_vset;
+    u32 reserved6;
+};
+
+struct ipr_dasd_res_state
+{
+    u32 data_path_width;  /* bits */
+    u32 data_xfer_rate;   /* 100 KBytes/second */
+};
+
+struct ipr_query_res_state
+{
+    u8 reserved2:4;
+    u8 not_func:1;
+    u8 not_ready:1;
+    u8 not_oper:1;
+    u8 reserved1:1;
+
+    u8 reserved3:7;
+    u8 read_write_prot:1;
+
+    u8 reserved4:3;
+    u8 service_req:1;
+    u8 degraded_oper:1;
+    u8 prot_resuming:1;
+    u8 prot_suspended:1;
+    u8 prot_dev_failed:1;
+
+    u8 reserved5;
+
+    union
+    {
+        struct ipr_vset_res_state vset;
+        struct ipr_dasd_res_state dasd;
+    }dev;
+
+    u32 ilid;
+    u32 failing_dev_ioasc;
+    struct ipr_res_addr failing_dev_res_addr;
+    u32 failing_dev_res_handle;
+    u8 protection_level_str[8];
+};
+
+/* IBM's SIS smart dump table structures */
+struct ipr_sdt_entry
+{
+    u32 bar_str_offset;
+    u32 end_offset;
+    u8  entry_byte;
+    u8  reserved[3];
+    u8  reserved2:5;
+    u8  valid_entry:1;
+    u8  reserved1:1;
+    u8  endian:1;
+    u8  resv;
+    u16 priority;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/lib/iprlib.c linux-8240/drivers/addon/ipr/lib/iprlib.c
--- linux-8230/drivers/addon/ipr/lib/iprlib.c
+++ linux-8240/drivers/addon/ipr/lib/iprlib.c
@@ -0,0 +1,6656 @@
+/*****************************************************************************/
+/* iprlib.c -- driver for IBM Power Linux RAID adapters                      */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/lib/iprlib.c,v 1.5.2.1 2003/10/27 20:05:00 bjking1 Exp $
+ */
+
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/kernel.h>
+#include <linux/ioport.h>
+#include <linux/delay.h>
+#include <linux/pci.h>
+#include <linux/proc_fs.h>
+#include <linux/blk.h>
+#include <linux/wait.h>
+#include <linux/tqueue.h>
+#include <linux/spinlock.h>
+#include <linux/pci_ids.h>
+#include <linux/notifier.h>
+#include <linux/reboot.h>
+#include <linux/ctype.h>
+#include <linux/devfs_fs.h>
+#include <linux/devfs_fs_kernel.h>
+#include <linux/sched.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <linux/tty.h>
+#include <linux/errno.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/uaccess.h>
+#include <asm/processor.h>
+#include <asm/semaphore.h>
+#include <asm/page.h>
+#ifdef CONFIG_KDB
+#include <asm/kdb.h>
+#endif
+
+#ifndef iprliblits_h
+#include "iprliblits.h"
+#endif
+
+#ifndef iprlibtypes_h
+#include "iprlibtypes.h"
+#endif
+
+#ifndef iprlib_h
+#include "iprlib.h"
+#endif
+
+extern const int ipr_arch;
+
+static const int ipr_debug = IPR_DEBUG;
+
+static const
+struct ipr_error_int_decode_t ipr_error_int_decode [] = {
+    {IPR_PCII_IOARCB_XFER_FAILED,    "IOARCB transfer failed"},
+    {IPR_PCII_IOA_UNIT_CHECKED,      "IOA Unit checked"},
+    {IPR_PCII_NO_HOST_RRQ,           "No Host Request/Response queue"},
+    {IPR_PCII_IOARRIN_LOST,          "IOARRIN lost"},
+    {IPR_PCII_MMIO_ERROR,            "MMIO error"},
+    {IPR_PCII_PROC_ERR_STATE,        "Processor in error state"},
+    {0xffffffff,                        "Unknown error"}
+};
+
+static const
+struct ipr_error_rc_decode_t ipr_error_rc_decode [] = {
+    {IPR_RC_FAILED,          "Op failed"},
+    {IPR_RC_TIMEOUT,         "Timeout"},
+    {IPR_RC_XFER_FAILED,     "IOARCB transfer failed"},
+    {IPR_IOA_UNIT_CHECKED,   "IOA Unit checked"},
+    {IPR_NO_HRRQ,            "No Host Request/Response queue"},
+    {IPR_IOARRIN_LOST,       "IOARRIN lost"},
+    {IPR_MMIO_ERROR,         "MMIO error"},
+    {IPR_403_ERR_STATE,      "Processor in error state"},
+    {IPR_RESET_ADAPTER,      "Adapter reset requested"},
+    {IPR_RC_UNKNOWN,         "Unknown error"}
+};
+
+/*  A constant array of Supported Device Entries */
+#define IPR_NUM_NON15K_DASD 9
+#define IPR_NUM_15K_DASD    7
+static const struct
+{
+    struct ipr_supported_device dev_non15k[IPR_NUM_NON15K_DASD];
+    struct ipr_supported_device dev_15k[IPR_NUM_15K_DASD];
+} ipr_supported_dev_list = 
+{
+    {
+        { /* Starfire Fast/Wide 4G - DFHSS4W - 6607 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'D', 'F', 'H', 'S', 'S', '4', 'W', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF6, 0xF6, 0xF0, 0xF7}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Scorpion Fast/Wide 8G - DCHS09W - 6713 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'D', 'C', 'H', 'S', '0', '9', 'W', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF6, 0xF7, 0xF1, 0xF3}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Marlin Fast/Wide 17G - DGHS18U - 6714 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'D', 'G', 'H', 'S', '1', '8', 'U', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF6, 0xF7, 0xF1, 0xF4}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Thresher 8G - DGVS09U - 6717 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'D', 'G', 'V', 'S', '0', '9', 'U', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF6, 0xF7, 0xF1, 0xF7}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Solid State DASD 1 GB - QUANTUM SSQD107 - 6730 */
+            {{'Q', 'U', 'A', 'N', 'T', 'U', 'M', ' '},
+            {'S', 'S', 'Q', 'D', '1', '0', '7', ' ', ' ', ' ', ' ', ' ', ' ', '(', 'C', ')'}},
+            {0xF6, 0xF7, 0xF3, 0xF0}, 0xF0, 0x40, {0x80, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Solid State DASD 1.6 GB - QUANTUM SSQD160 - 6731 */
+            {{'Q', 'U', 'A', 'N', 'T', 'U', 'M', ' '},
+            {'S', 'S', 'Q', 'D', '1', '6', '0', ' ', ' ', ' ', ' ', ' ', ' ', '(', 'C', ')'}},
+            {0xF6, 0xF7, 0xF3, 0xF1}, 0xF0, 0x40, {0x80, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Hammerhead DASD 18 GB - DRVS18D - 6718 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'D', 'R', 'V', 'S', '1', '8', 'D', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF6, 0xF7, 0xF1, 0xF8}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Discovery 36 GB, 10k RPM - DDYS36M - 6719 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'D', 'D', 'Y', 'S', '3', '6', 'M', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF6, 0xF7, 0xF1, 0xF9}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Daytona 70 GB, 10k RPM - UCD2070 - 4320 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'U', 'C', 'D', '2', '0', '7', '0', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF0}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+    },
+    {
+        { /* Piranha 18 GB, 15k RPM 160 MB/s - UCPR018 - 4322 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'U', 'C', 'P', 'R', '0', '1', '8', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF2}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Piranha 18 GB, 15k RPM 320 MB/s - XCPR018 - 4325 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'X', 'C', 'P', 'R', '0', '1', '8', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF5}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        }, 
+
+        { /* Piranha 35 GB, 15k RPM 160 MB/s - UCPR036 - 4323 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'U', 'C', 'P', 'R', '0', '3', '6', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF3}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        }, 
+
+        { /* Piranha 35 GB, 15k RPM 320 MB/s - XCPR036 - 4326 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'X', 'C', 'P', 'R', '0', '3', '6', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF6}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Monza 70 GB, 15k RPM 320 MB/s - XCPR073 - 4327 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'X', 'C', 'P', 'R', '0', '7', '3', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF7}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Monza 141 GB, 15k RPM 320 MB/s - XCPR146 - 4328 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'X', 'C', 'P', 'R', '1', '4', '6', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF8}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        },
+
+        { /* Monaco 282 GB, 15k RPM 320 MB/s - XCPR282 - 4329 */
+            {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+            {'X', 'C', 'P', 'R', '2', '8', '2', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+            {0xF4, 0xF3, 0xF2, 0xF9}, 0xF1, 0x40, {0x00, 0x00},
+            {0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40, 0x40}
+        }
+
+        /* IMPORTANT NOTE :
+         IF A NEW DEVICE IS TO BE SUPPORTED, MAKE SURE IT IS ADDED TO
+         THE RIGHT POSITION WITHIN THE ABOVE LIST.
+         IF IT IS NOT A 15K DRIVE, INSERT IT IN FRONT OF THE FIRST 15K DEVICE
+         (18G PIRANHA).
+         IF THE NEW DEVICE IS A 15K DRIVE, APPEND IT TO THE BOTTOM OF THE LIST.
+         AND INCREMENT THE FOLLOWING CONSTANTS: IPR_NUM_15K_DASD */
+    }
+};
+
+struct ipr_supported_device *ipr_supported_dev_list_ptr =
+(struct ipr_supported_device *)&ipr_supported_dev_list;
+
+struct ipr_dev_config
+{
+    struct ipr_std_inq_vpids vpids;
+    void (*set_page0x00)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_vendor_unique_page *p_ch,
+                         struct ipr_vendor_unique_page *p_buf);
+
+    void (*set_page0x01)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_rw_err_mode_page *p_ch,
+                         struct ipr_rw_err_mode_page *p_buf);
+
+    void (*set_page0x02)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_disc_reconn_page *p_ch,
+                         struct ipr_disc_reconn_page *p_buf);
+
+    void (*set_page0x07)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_verify_err_rec_page *p_ch,
+                         struct ipr_verify_err_rec_page *p_buf);
+
+    void (*set_page0x08)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_caching_page *p_ch,
+                         struct ipr_caching_page *p_buf);
+
+    void (*set_page0x0a)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_control_mode_page *p_ch,
+                         struct ipr_control_mode_page *p_buf);
+
+    void (*set_page0x20)(struct ipr_resource_entry *p_resource_entry,
+                         struct ipr_ioa_dasd_page_20 *p_buf);
+
+    u8 is_15k_device:1;
+    u8 enable_qas:1;
+    u8 reserved:6;
+    u8 reserved2;
+    u16 vpd_len;
+};
+
+/*  A constant array of DASD Timeouts */
+static const
+struct ipr_dasd_timeout_record ipr_dasd_timeout_list[] =
+{
+    {IPR_TEST_UNIT_READY,    0x00, _i16(30)},
+    {IPR_REQUEST_SENSE,      0x00, _i16(30)},
+    {IPR_INQUIRY,            0x00, _i16(30)},
+    {IPR_MODE_SELECT,        0x00, _i16(30)},
+    {IPR_MODE_SENSE,         0x00, _i16(30)},
+    {IPR_READ_CAPACITY,      0x00, _i16(30)},
+    {IPR_READ_10,            0x00, _i16(30)},
+    {IPR_WRITE_10,           0x00, _i16(30)},
+    {IPR_WRITE_VERIFY,       0x00, _i16(30)},
+    {IPR_FORMAT_UNIT,        0x00, _i16(7200)},  /* 2 Hours */
+    {IPR_REASSIGN_BLOCKS,    0x00, _i16(600)},   /* 10 minutes */
+    {IPR_START_STOP,         0x00, _i16(120)},
+    {IPR_SEND_DIAGNOSTIC,    0x00, _i16(300)},   /* 5 minutes */
+    {IPR_VERIFY,             0x00, _i16(300)},   /* 5 minutes */
+    {IPR_WRITE_BUFFER,       0x00, _i16(300)},   /* 5 minutes */
+    {IPR_WRITE_SAME,         0x00, _i16(14400)}, /* 4 hours */
+    {IPR_LOG_SENSE,          0x00, _i16(30)},
+    {IPR_REPORT_LUNS,        0x00, _i16(30)},
+    {IPR_SKIP_READ,          0x00, _i16(30)},
+    {IPR_SKIP_WRITE,         0x00, _i16(30)}
+};
+
+struct ipr_dasd_timeouts
+{
+    u32 length;
+    struct ipr_dasd_timeout_record
+        record[sizeof(ipr_dasd_timeout_list) / sizeof(struct ipr_dasd_timeout_record)];
+};
+
+struct ipr_dasd_init_bufs
+{
+    struct ipr_dasd_timeouts dasd_timeouts;
+    ipr_dma_addr dasd_timeouts_dma;
+    struct ipr_mode_parm_hdr mode_pages;
+    char pad1[255 - sizeof(struct ipr_mode_parm_hdr)];
+    ipr_dma_addr mode_pages_dma;
+    struct ipr_mode_parm_hdr changeable_parms;
+    char pad2[255 - sizeof(struct ipr_mode_parm_hdr)];
+    ipr_dma_addr changeable_parms_dma;
+    struct ipr_dasd_inquiry_page3 page3_inq;
+    ipr_dma_addr page3_inq_dma;
+    struct ipr_std_inq_data_long std_inq;
+    ipr_dma_addr std_inq_dma;
+    struct ipr_ssd_header ssd_header;
+    struct ipr_supported_device supported_device;
+    ipr_dma_addr ssd_header_dma;
+    struct ipr_query_res_state res_query;
+    ipr_dma_addr res_query_dma;
+    struct ipr_dasd_init_bufs *p_next;
+    struct ipr_hostrcb *p_hostrcb;
+    struct ipr_resource_entry *p_dev_res;
+};
+
+/**********************************************************************/
+/*                                                                    */
+/* this  array is used to translate ebcdic to ascii.  the ebcdic char */
+/* is used as an index into the array, and the value at that index is */
+/* the  ascii representation of  that  character.  a  SP  (space)  is */
+/* returned if there is no translation for the given character.       */
+/*                                                                    */
+/**********************************************************************/
+static const char
+ipr_etoa[] = {
+    0x00, 0x01, 0x02, 0x03, 0x20, 0x09, 0x20, 0x7f,       /* 00-07 done */
+    /*NULL,SOH,  STX, ETX,  N/A,  HT,   N/A,  DEL                       */
+    0x20, 0x20, 0x20, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f,       /* 08-0f done */
+    /*N/A,N/A,  N/A,  VT,   FF,   CR,   SO,   SI                        */
+    0x10, 0x11, 0x12, 0x13, 0x20, 0x20, 0x08, 0x20,       /* 10-17 done */
+    /*DLE,DC1,  DC2,  DC3,  N/A,  N/A,  BS,   N/A                       */
+    0x18, 0x19, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 18-1f done */
+    /*CAN,  EM, N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x20, 0x20, 0x20, 0x20, 0x0a, 0x17, 0x1b,       /* 20-27 done */
+    /*N/A,N/A,  N/A,  N/A,  N/A,  LF,   ETB,  ESC                       */
+    0x20, 0x20, 0x20, 0x20, 0x20, 0x05, 0x06, 0x07,       /* 28-2f done */
+    /*N/A,N/A,  N/A,  N/A,  N/A,  ENQ,  ACK,  BEL                       */
+    0x20, 0x20, 0x16, 0x20, 0x20, 0x20, 0x20, 0x04,       /* 30-37 done */
+    /*N/A,N/A,  SYN,  N/A,  N/A,  N/A,  N/A,  EOT                       */
+    0x20, 0x20, 0x20, 0x20, 0x14, 0x15, 0x20, 0x1a,       /* 38-3f done */
+    /*N/A,N/A,  N/A,  N/A,  DC4,  NAK,  N/A,  SUB                       */
+    0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 40-47 done */
+    /*SP, N/A,  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x20, 0x20, 0x2e, 0x3c, 0x28, 0x2b, 0x20,       /* 48-4f done */
+    /*N/A,N/A,  N/A,  ".",  "<",  "(",  "+",  N/A                       */
+    0x26, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 50-57 done */
+    /*"&",N/A,  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x20, 0x21, 0x24, 0x2a, 0x29, 0x3b, 0x5e,       /* 58-5f done */
+    /*N/A,N/A,  "!",  "$",  "*",  ")",  ";",  "^"                       */
+    0x2d, 0x2f, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 60-67 done */
+    /*"-","/",  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x20, 0x7c, 0x2c, 0x25, 0x5f, 0x3e, 0x3f,       /* 68-6f done */
+    /*N/A,N/A,  "|",  ",",  "%",  "_",  ">",  "?"                       */
+    0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 70-77 done */
+    /*N/A,N/A,  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x60, 0x3a, 0x23, 0x40, 0x27, 0x3d, 0x22,       /* 78-7f done */
+    /*N/A,"`",  ":",  "#",  "@",  "'",  "=",  """                       */
+    0x20, 0x61, 0x62, 0x63, 0x64, 0x65, 0x66, 0x67,       /* 80-87 done */
+    /*N/A,"a",  "b",  "c",  "d",  "e",  "f",  "g"                       */
+    0x68, 0x69, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 88-8f done */
+    /*"h","i",  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x6a, 0x6b, 0x6c, 0x6d, 0x6e, 0x6f, 0x70,       /* 90-97 done */
+    /*N/A,"j",  "k",  "l",  "m",  "n",  "o",  "p"                       */
+    0x71, 0x72, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* 98-9f done */
+    /*"q","r",  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x7e, 0x73, 0x74, 0x75, 0x76, 0x77, 0x78,       /* a0-a7 done */
+    /*N/A,"~",  "s",  "t",  "u",  "v",  "w",  "x"                       */
+    0x79, 0x7a, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* a8-af done */
+    /*"y","z",  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* b0-b7 done */
+    /*N/A,N/A,  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* b8-bf done */
+    /*N/A,N/A,  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x7b, 0x41, 0x42, 0x43, 0x44, 0x45, 0x46, 0x47,       /* c0-c7 done */
+    /*"{","A",  "B",  "C",  "D",  "E",  "F",  "G"                       */
+    0x48, 0x49, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* c8-cf done */
+    /*"H","I",  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x7d, 0x4a, 0x4b, 0x4c, 0x4d, 0x4e, 0x4f, 0x50,       /* d0-d7 done */
+    /*"}","J",  "K",  "L",  "M",  "N",  "O",  "P"                       */
+    0x51, 0x52, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* d8-df done */
+    /*"Q","R",  N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x5c, 0x20, 0x53, 0x54, 0x55, 0x56, 0x57, 0x58,       /* e0-e7 done */
+    /*"\",N/A,  "S",  "T",  "U",  "V",  "W",  "X"                       */
+    0x59, 0x5a, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* e8-ef done */
+    /*"Y", "Z", N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+    0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37,       /* f0-f7 done */
+    /*"0", "1", "2",  "3",  "4",  "5",  "6",  "7"                       */
+    0x38, 0x39, 0x20, 0x20, 0x20, 0x20, 0x20, 0x20,       /* f8-ff done */
+    /*"8", "9", N/A,  N/A,  N/A,  N/A,  N/A,  N/A                       */
+};
+
+static const struct ipr_interrupt_table_t ipr_interrupt_table [] =
+{
+    {PCI_VENDOR_ID_IBM, PCI_DEVICE_ID_IBM_SNIPE,
+    {0x00288, 0x0028C, 0x00288, 0x00284, 0x00280, 0x00504, 0x00290, 0x00290, 0x00294}},
+
+    {PCI_VENDOR_ID_MYLEX, PCI_DEVICE_ID_GEMSTONE,
+    {0x0022C, 0x00230, 0x0022C, 0x00228, 0x00224, 0x00404, 0x00214, 0x00214, 0x00218}}
+};
+
+/* This structure is used to correlate operational parameters based on PCI Vendor/Device/Subsystem ID */
+static const
+struct ipr_ioa_parms_t ipr_ioa_parms[] =
+{
+    /* Gemstone based IOAs */
+    {
+        vendor_id: PCI_VENDOR_ID_MYLEX, device_id: PCI_DEVICE_ID_GEMSTONE,
+        subsystem_id: IPR_SUBS_DEV_ID_5702,
+        scsi_id_changeable:1, max_bus_speed_limit: 320
+    },
+    {
+        vendor_id: PCI_VENDOR_ID_MYLEX, device_id: PCI_DEVICE_ID_GEMSTONE,
+        subsystem_id: IPR_SUBS_DEV_ID_5703,
+        scsi_id_changeable:0, max_bus_speed_limit: 320
+    },
+    /* Snipe based IOAs */
+    {
+        vendor_id: PCI_VENDOR_ID_IBM, device_id: PCI_DEVICE_ID_IBM_SNIPE,
+        subsystem_id: IPR_SUBS_DEV_ID_2780,
+        scsi_id_changeable:0, max_bus_speed_limit: 320
+    }
+};
+
+static u32 ipr_poll_isr(struct ipr_shared_config *p_shared_cfg, u32 timeout);
+static u32 ipr_send_blocking_cmd(struct ipr_shared_config *p_shared_cfg,
+                                    u8 sis_cmd,
+                                    u32 timeout,
+                                    u8 parm,
+                                    void *p_data,
+                                    ipr_dma_addr dma_addr,
+                                    u32 xfer_len);
+static int ipr_set_mode_page28(struct ipr_shared_config *p_shared_cfg);
+static int ipr_build_slot_map(struct ipr_shared_config *p_shared_cfg);
+static int ipr_build_slot_map_runtime(struct ipr_shared_config *p_shared_cfg,
+                                         struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_hostrcb *p_hostrcb);
+static void ipr_gen_sense(struct ipr_resource_entry *p_resource,
+                             u8 *p_sense_buffer, struct ipr_ioasa *p_ioasa);
+static void ipr_dump_ioasa(struct ipr_shared_config *p_shared_cfg,
+                              struct ipr_resource_entry *p_resource,
+                              struct ipr_ioasa *p_ioasa);
+static u32 ipr_get_model(struct ipr_config_table_entry *p_cfgte);
+static void ipr_update_resource(struct ipr_shared_config *p_shared_cfg,
+                                   struct ipr_resource_entry *p_resource_entry,
+                                   struct ipr_config_table_entry *p_cfgte,
+                                   u32 device_changed);
+static struct ipr_resource_dll *ipr_get_resource_entry(struct ipr_shared_config *p_shared_cfg);
+static void ipr_put_resource_entry(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_resource_dll *p_resource_dll);
+static void ipr_log_config_error(struct ipr_shared_config *p_shared_cfg,
+                                    int is_ipl, struct ipr_resource_entry *p_resource);
+static void ipr_print_dev(struct ipr_shared_config *p_shared_cfg,
+                             struct ipr_resource_entry *p_resource);
+static u32 ipr_init_devices(struct ipr_shared_config *p_shared_cfg);
+static u32 ipr_init_single_dev(struct ipr_shared_config *p_shared_cfg,
+                                  struct ipr_resource_entry *p_resource_entry);
+static void *ipr_get_mode_page(struct ipr_mode_parm_hdr *p_mode_parm, u32 page_code, u32 len);
+static int ipr_blocking_dasd_cmd(struct ipr_shared_config *p_shared_cfg,
+                                    struct ipr_resource_entry *p_resource_entry,
+                                    ipr_dma_addr dma_buffer,
+                                    u8 cmd, u8 parm, u16 alloc_len);
+static int ipr_blocking_vset_cmd(struct ipr_shared_config *p_shared_cfg,
+                                    struct ipr_resource_entry *p_resource_entry,
+                                    ipr_dma_addr dma_buffer,
+                                    u8 cmd, u8 parm, u16 alloc_len);
+static int ipr_dasd_req(struct ipr_shared_config *p_shared_cfg,
+                           struct ipr_resource_entry *p_resource_entry,
+                           struct ipr_dasd_init_bufs *p_dasd_init_buf,
+                           void *p_buffer,
+                           ipr_dma_addr dma_addr,
+                           u8 cmd, u8 parm, u16 alloc_len, u8 job_step);
+static int ipr_vset_req(struct ipr_shared_config *p_shared_cfg,
+                           struct ipr_resource_entry *p_resource_entry,
+                           struct ipr_dasd_init_bufs *p_dasd_init_buf,
+                           void *p_buffer,
+                           ipr_dma_addr dma_addr,
+                           u8 cmd, u8 parm, u16 alloc_len, u8 job_step);
+static int ipr_ioa_req(struct ipr_shared_config *p_shared_cfg,
+                          void (*done) (struct ipr_shared_config *, struct ipr_ccb *),
+                          void *p_scratch,
+                          void *p_buffer,
+                          ipr_dma_addr dma_addr,
+                          u8 cmd, u8 parm, u16 alloc_len, u8 job_step);
+static void ipr_ebcdic_to_ascii(const u8 *ebcdic, u32 length,  u8 *ascii);
+static struct ipr_host_ioarcb* ipr_build_ioa_cmd(struct ipr_shared_config *p_shared_cfg,
+                                                       u8 sis_cmd,
+                                                       struct ipr_ccb *p_sis_cmd,
+                                                       u8 parm,
+                                                       void *p_data,
+                                                       ipr_dma_addr dma_addr,
+                                                       u32 xfer_len);
+static const struct ipr_dev_config *ipr_get_dev_config(struct ipr_resource_entry *p_resource_entry);
+static void ipr_set_page0x00(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_vendor_unique_page *p_ch,
+                                struct ipr_vendor_unique_page *p_buf);
+static void ipr_set_page0x00_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_vendor_unique_page *p_ch,
+                                         struct ipr_vendor_unique_page *p_buf);
+static void ipr_set_page0x00_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_vendor_unique_page *p_ch,
+                                      struct ipr_vendor_unique_page *p_buf);
+static void ipr_set_page0x00_TCQ(struct ipr_resource_entry *p_resource_entry,
+                                    struct ipr_vendor_unique_page *p_ch,
+                                    struct ipr_vendor_unique_page *p_buf);
+static void ipr_set_page0x01(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_rw_err_mode_page *p_ch,
+                                struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_rw_err_mode_page *p_ch,
+                                         struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_rw_err_mode_page *p_ch,
+                                      struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_TCQ(struct ipr_resource_entry *p_resource_entry,
+                                    struct ipr_rw_err_mode_page *p_ch,
+                                    struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_thresher_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_rw_err_mode_page *p_ch,
+                                             struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_hammerhead_18Gb(struct ipr_resource_entry *p_resource_entry,
+                                                struct ipr_rw_err_mode_page *p_ch,
+                                                struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_discovery_36Gb(struct ipr_resource_entry *p_resource_entry,
+                                               struct ipr_rw_err_mode_page *p_ch,
+                                               struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x01_daytona_70Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_rw_err_mode_page *p_ch,
+                                             struct ipr_rw_err_mode_page *p_buf);
+static void ipr_set_page0x02(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_disc_reconn_page *p_ch,
+                                struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_disc_reconn_page *p_ch,
+                                         struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_disc_reconn_page *p_ch,
+                                      struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_noop(struct ipr_resource_entry *p_resource_entry,
+                                     struct ipr_disc_reconn_page *p_ch,
+                                     struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_starfire_4Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_disc_reconn_page *p_ch,
+                                             struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_scorpion_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_disc_reconn_page *p_ch,
+                                             struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_marlin_17Gb(struct ipr_resource_entry *p_resource_entry,
+                                            struct ipr_disc_reconn_page *p_ch,
+                                            struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_thresher_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_disc_reconn_page *p_ch,
+                                             struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x02_hammerhead_18Gb(struct ipr_resource_entry *p_resource_entry,
+                                                struct ipr_disc_reconn_page *p_ch,
+                                                struct ipr_disc_reconn_page *p_buf);
+static void ipr_set_page0x07(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_verify_err_rec_page *p_ch,
+                                struct ipr_verify_err_rec_page *p_buf);
+static void ipr_set_page0x07_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_verify_err_rec_page *p_ch,
+                                         struct ipr_verify_err_rec_page *p_buf);
+static void ipr_set_page0x07_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_verify_err_rec_page *p_ch,
+                                      struct ipr_verify_err_rec_page *p_buf);
+static void ipr_set_page0x08(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_caching_page *p_ch,
+                                struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_caching_page *p_ch,
+                                         struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_caching_page *p_ch,
+                                      struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_TCQ(struct ipr_resource_entry *p_resource_entry,
+                                    struct ipr_caching_page *p_ch,
+                                    struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_scorpion_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_caching_page *p_ch,
+                                             struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_marlin_17Gb(struct ipr_resource_entry *p_resource_entry,
+                                            struct ipr_caching_page *p_ch,
+                                            struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_thresher_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_caching_page *p_ch,
+                                             struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_hammerhead_18Gb(struct ipr_resource_entry *p_resource_entry,
+                                                struct ipr_caching_page *p_ch,
+                                                struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_discovery_36Gb(struct ipr_resource_entry *p_resource_entry,
+                                               struct ipr_caching_page *p_ch,
+                                               struct ipr_caching_page *p_buf);
+static void ipr_set_page0x08_daytona_70Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_caching_page *p_ch,
+                                             struct ipr_caching_page *p_buf);
+static void ipr_set_page0x0a(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_control_mode_page *p_ch,
+                                struct ipr_control_mode_page *p_buf);
+static void ipr_set_page0x0a_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_control_mode_page *p_ch,
+                                         struct ipr_control_mode_page *p_buf);
+static void ipr_set_page0x0a_noTCQ(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_control_mode_page *p_ch,
+                                      struct ipr_control_mode_page *p_buf);
+static void ipr_set_page0x0a_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_control_mode_page *p_ch,
+                                      struct ipr_control_mode_page *p_buf);
+static void ipr_set_page0x20_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_ioa_dasd_page_20 *p_buf);
+static void ipr_set_page0x20_noTCQ(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_ioa_dasd_page_20 *p_buf);
+static void ipr_set_page0x20(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_ioa_dasd_page_20 *p_buf);
+static u8 ipr_set_mode_pages(struct ipr_shared_config *p_shared_cfg,
+                                struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_mode_parm_hdr *p_mode_parm,
+                                struct ipr_mode_parm_hdr *p_changeable_pages);
+static u32 ipr_init_single_dev_runtime(struct ipr_shared_config *p_shared_cfg,
+                                          struct ipr_resource_entry *p_resource_entry,
+                                          u32 is_ndn,
+                                          struct ipr_hostrcb *p_hostrcb);
+static void ipr_dasd_init_job(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_ccb *p_sis_ccb);
+static void ipr_vset_init_job(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_ccb *p_sis_ccb);
+static void ipr_bus_init_job(struct ipr_shared_config *p_shared_cfg,
+                                struct ipr_ccb *p_sis_ccb);
+static struct ipr_dasd_init_bufs *ipr_get_dasd_init_buffer(struct ipr_data *ipr_cfg);
+
+static void ipr_put_dasd_init_buffer(struct ipr_data *ipr_cfg,
+                                        struct ipr_dasd_init_bufs
+                                        *p_dasd_init_buffer);
+
+static void ipr_check_backplane(struct ipr_shared_config *p_shared_cfg,
+                                   struct ipr_config_table_entry *cfgte);
+
+#ifdef IPR_DEBUG_MODE_PAGES
+static void ipr_print_mode_sense_buffer(struct ipr_mode_parm_hdr *p_mode_parm);
+#endif
+
+static const struct ipr_dev_config ipr_dev_cfg_table[] =
+{
+    { /* Starfire 4 Gb */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'D', 'F', 'H', 'S', 'S', '4', 'W', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}}, 
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_as400,
+        set_page0x02: ipr_set_page0x02_starfire_4Gb,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_as400,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Scorpion 8Gb */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'D', 'C', 'H', 'S', '0', '9', 'W', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_as400,
+        set_page0x02: ipr_set_page0x02_scorpion_8Gb,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_scorpion_8Gb,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Thresher 8 Gb */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'D', 'G', 'V', 'S', '0', '9', 'U', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_thresher_8Gb,
+        set_page0x02: ipr_set_page0x02_thresher_8Gb,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_thresher_8Gb,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Marlin 17 Gb */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'D', 'G', 'H', 'S', '1', '8', 'U', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_as400,
+        set_page0x02: ipr_set_page0x02_marlin_17Gb,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_marlin_17Gb,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Hammerhead 18 Gb */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'D', 'R', 'V', 'S', '1', '8', 'D', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_hammerhead_18Gb,
+        set_page0x02: ipr_set_page0x02_hammerhead_18Gb,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_hammerhead_18Gb,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Discovery 36 Gb */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'D', 'D', 'Y', 'S', '3', '6', 'M', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_discovery_36Gb,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_discovery_36Gb,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Daytona 70 GB, 10k RPM */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'U', 'C', 'D', '2', '0', '7', '0', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_daytona_70Gb,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_daytona_70Gb,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Piranha 18 GB, 15k RPM 160 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'U', 'C', 'P', 'R', '0', '1', '8', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Piranha 18 GB, 15k RPM 320 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'X', 'C', 'P', 'R', '0', '1', '8', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        enable_qas:    1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Piranha 35 GB, 15k RPM 160 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'U', 'C', 'P', 'R', '0', '3', '6', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Piranha 35 GB, 15k RPM 320 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'X', 'C', 'P', 'R', '0', '3', '6', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        enable_qas:    1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+
+    { /* Monza 70 GB, 15k RPM 320 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'X', 'C', 'P', 'R', '0', '7', '3', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        enable_qas:    1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Monza 141 GB, 15k RPM 320 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'X', 'C', 'P', 'R', '1', '4', '6', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        enable_qas:    1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Monaco 282 GB, 15k RPM 320 MB/s */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {'X', 'C', 'P', 'R', '2', '8', '2', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_TCQ,
+        set_page0x01: ipr_set_page0x01_TCQ,
+        set_page0x02: ipr_set_page0x02_noop,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_TCQ,
+        set_page0x0a: ipr_set_page0x0a_as400,
+        is_15k_device: 1,
+        enable_qas:    1,
+        vpd_len: sizeof(struct ipr_std_inq_vpids)
+    },
+    { /* Default AS/400 DASD */
+        vpids: {{'I', 'B', 'M', 'A', 'S', '4', '0', '0'},
+        {' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '}},
+        set_page0x00: ipr_set_page0x00_as400,
+        set_page0x01: ipr_set_page0x01_as400,
+        set_page0x02: ipr_set_page0x02_as400,
+        set_page0x07: ipr_set_page0x07_as400,
+        set_page0x08: ipr_set_page0x08_as400,
+        set_page0x0a: ipr_set_page0x0a_noTCQ,
+        set_page0x20: ipr_set_page0x20_noTCQ,
+        vpd_len: IPR_VENDOR_ID_LEN
+    }
+};
+
+static const struct ipr_backplane_table_entry ipr_backplane_table [] =
+{
+    {
+        product_id: {"2104-DL1        "},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit: 80              /* 80 MB/sec limit */
+    },
+    {
+        product_id: {"2104-TL1        "},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit: 80              /* 80 MB/sec limit */
+    },
+    /* Hidive 7 slot */
+    {   /*                 H S B P      0 7 M       P   U 2     S C S I*/
+        product_id: {"HSBP07M P U2SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit: 80,             /* 80 MB/sec limit */
+        block_15k_devices:    1              /* block 15k devices */
+    },
+    /* Hidive 5 slot */
+    {
+        product_id: {"HSBP05M P U2SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit: 80,             /* 80 MB/sec limit */
+        block_15k_devices:    1              /* block 15k devices */
+    },
+    /* Bowtie */
+    {
+        product_id: {"HSBP05M S U2SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit: 80,             /* 80 MB/sec limit */
+        block_15k_devices:    1              /* block 15k devices */
+    },
+    /* MartinFenning */
+    {
+        product_id: {"HSBP06E ASU2SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit: 80,             /* 80 MB/sec limit */
+        block_15k_devices:    1              /* block 15k devices */
+    },
+    {
+        product_id: {"2104-DU3        "},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    },
+    {
+        product_id: {"2104-TU3        "},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    },
+    {
+        product_id: {"HSBP04C RSU2SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    },
+    {
+        product_id: {"HSBP06E RSU2SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    },
+    {
+        product_id: {"St  V1S2        "},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    },
+    {
+        product_id: {"HSBPD4M  PU3SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    },
+    {
+        product_id: {"VSBPD1H   U3SCSI"},
+        compare_product_id_byte:{1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1},
+        max_bus_speed_limit:160             /* 160 MB/sec limit */
+    }
+};
+
+/*---------------------------------------------------------------------------
+ * Purpose: Adds a trace entry to the driver trace
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL
+void ipr_trc_hook(struct ipr_shared_config *p_shared_cfg,
+                     u8 op_code, u8 type, u8 device_type, u16 host_ioarcb_index,
+                     u32 xfer_len, u32 add_data)
+{
+    struct ipr_internal_trace_entry *p_trace_entry;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    if (p_shared_cfg->trace)
+    {
+        p_trace_entry = &ipr_cfg->trace[ipr_cfg->trace_index++];
+        p_trace_entry->time = jiffies;
+        p_trace_entry->op_code = op_code;
+        p_trace_entry->type = type;
+        p_trace_entry->device_type = device_type;
+        p_trace_entry->host_ioarcb_index = host_ioarcb_index;
+        p_trace_entry->xfer_len = xfer_len;
+        p_trace_entry->data.ioasc = add_data;
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Removes a host IOARCB from the pending queue
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL
+void ipr_remove_host_ioarcb_from_pending(struct ipr_data *ipr_cfg,
+                                            struct ipr_host_ioarcb* p_host_ioarcb)
+{
+    if ((p_host_ioarcb == ipr_cfg->qPendingH) &&
+        (p_host_ioarcb == ipr_cfg->qPendingT))
+    {
+        ipr_cfg->qPendingH = ipr_cfg->qPendingT = NULL;
+    }
+    else if (p_host_ioarcb == ipr_cfg->qPendingH)
+    {
+        ipr_cfg->qPendingH = ipr_cfg->qPendingH->p_next;
+        ipr_cfg->qPendingH->p_prev = NULL;
+    }
+    else if (p_host_ioarcb == ipr_cfg->qPendingT)
+    {
+        ipr_cfg->qPendingT = ipr_cfg->qPendingT->p_prev;
+        ipr_cfg->qPendingT->p_next = NULL;
+    }
+    else
+    {
+        p_host_ioarcb->p_next->p_prev = p_host_ioarcb->p_prev;
+        p_host_ioarcb->p_prev->p_next = p_host_ioarcb->p_next;
+    }
+
+    p_host_ioarcb->p_next = NULL;
+    p_host_ioarcb->p_prev = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Puts a host ioarcb on the pending queue
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL
+void ipr_put_host_ioarcb_to_pending(struct ipr_data *ipr_cfg,
+                                       struct ipr_host_ioarcb* p_host_ioarcb)
+{
+    /* Put IOARCB on the pending list */
+    if (ipr_cfg->qPendingT != NULL)
+    {
+        ipr_cfg->qPendingT->p_next = p_host_ioarcb;
+        p_host_ioarcb->p_prev = ipr_cfg->qPendingT;
+        ipr_cfg->qPendingT = p_host_ioarcb;
+    }
+    else
+    {
+        ipr_cfg->qPendingT = ipr_cfg->qPendingH = p_host_ioarcb;
+        p_host_ioarcb->p_prev = NULL;
+    }
+    p_host_ioarcb->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a free host IOARCB and put it on the pending queue
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to host ioarcb
+ * Notes: Cannot run out - will kernel panic if it does.
+ *        Zeroes IOARCB, then initializes common fields
+ *---------------------------------------------------------------------------*/
+static IPR_INL
+struct ipr_host_ioarcb* ipr_get_free_host_ioarcb(struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_host_ioarcb* tmp_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_ioasa *p_ioasa;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    tmp_host_ioarcb = ipr_cfg->qFreeH;
+
+    if (tmp_host_ioarcb == NULL)
+        panic(IPR_ERR": Out of host_ioarcb's"IPR_EOL);
+
+    ipr_cfg->qFreeH = ipr_cfg->qFreeH->p_next;
+
+    if (ipr_cfg->qFreeH == NULL)
+        ipr_cfg->qFreeT = NULL;
+    else
+        ipr_cfg->qFreeH->p_prev = NULL;
+
+    p_ioarcb = &tmp_host_ioarcb->ioarcb;
+    p_ioasa = tmp_host_ioarcb->p_ioasa;
+
+    memset(&p_ioarcb->ioarcb_cmd_pkt, 0, sizeof(struct ipr_cmd_pkt));
+    p_ioarcb->write_data_transfer_length = 0;
+    p_ioarcb->read_data_transfer_length = 0;
+    p_ioarcb->write_ioadl_addr = 0;
+    p_ioarcb->write_ioadl_len = 0;
+    p_ioarcb->read_ioadl_addr = 0;
+    p_ioarcb->read_ioadl_len = 0;
+    tmp_host_ioarcb->p_sis_cmd = NULL;
+
+    p_ioasa->ioasc = 0;
+    p_ioasa->residual_data_len = 0;
+
+    ipr_put_host_ioarcb_to_pending(ipr_cfg, tmp_host_ioarcb);
+
+    return tmp_host_ioarcb;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Puts a host ioarcb on the free queue
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static IPR_INL
+void ipr_put_host_ioarcb_to_free(struct ipr_data *ipr_cfg,
+                                    struct ipr_host_ioarcb* p_host_ioarcb)
+{
+    /* Put IOARCB back on the free list */
+    if(ipr_cfg->qFreeT != NULL)
+    {
+        ipr_cfg->qFreeT->p_next = p_host_ioarcb;
+        p_host_ioarcb->p_prev = ipr_cfg->qFreeT;
+        ipr_cfg->qFreeT = p_host_ioarcb;
+    }
+    else
+    {
+        ipr_cfg->qFreeH = ipr_cfg->qFreeT = p_host_ioarcb;
+        p_host_ioarcb->p_prev = NULL;
+    }
+    p_host_ioarcb->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Builds an IOA data list
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+
+static void ipr_build_ioadl(struct ipr_shared_config *p_shared_cfg,
+                               struct ipr_host_ioarcb* p_host_ioarcb)
+{
+    struct ipr_ccb * p_sis_cmd;
+    int i;
+    struct ipr_ioadl_desc *p_ioadl;
+    struct ipr_ioadl_desc *tmp_ioadl;
+    struct ipr_sglist *p_tmp_sglist;
+    struct ipr_ioarcb *p_ioarcb;
+    u32 length;
+    u32 ioadl_length;
+    u32 ioadl_address;
+
+    p_sis_cmd = p_host_ioarcb->p_sis_cmd;
+    p_ioarcb = &p_host_ioarcb->ioarcb;
+    p_ioadl = p_host_ioarcb->p_ioadl;
+    length = p_sis_cmd->bufflen;
+
+    if (p_sis_cmd->use_sg)
+    {
+        if (p_sis_cmd->data_direction == IPR_DATA_READ)
+        {
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+
+            tmp_ioadl = p_ioadl;
+
+            for (i = 0, p_tmp_sglist = p_sis_cmd->sglist;
+                 i < (p_sis_cmd->use_sg);
+                 i++, tmp_ioadl++, p_tmp_sglist++)
+            {
+                ioadl_address = p_tmp_sglist->address;
+                ioadl_length = p_tmp_sglist->length;
+
+                tmp_ioadl->flags_and_data_len = 
+                    htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF | ioadl_length);
+                tmp_ioadl->address = htosis32(ioadl_address);
+            }
+
+            (tmp_ioadl - 1)->flags_and_data_len = 
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | ioadl_length);
+
+            p_ioarcb->read_data_transfer_length = htosis32(length);
+            p_ioarcb->read_ioadl_len =
+                htosis32(sizeof(struct ipr_ioadl_desc) * p_sis_cmd->use_sg);
+
+        }
+        else if (p_sis_cmd->data_direction == IPR_DATA_WRITE)
+        {
+            p_ioarcb->write_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+
+            p_ioarcb->write_data_transfer_length = htosis32(length);
+            p_ioarcb->write_ioadl_len =
+                htosis32(sizeof(struct ipr_ioadl_desc) * p_sis_cmd->use_sg);
+            tmp_ioadl = p_ioadl;
+
+            for (i = 0, p_tmp_sglist = p_sis_cmd->sglist;
+                 i < (p_sis_cmd->use_sg - 1);
+                 i++, tmp_ioadl++, p_tmp_sglist++)
+            {
+                tmp_ioadl->flags_and_data_len = 
+                    htosis32(IPR_IOADL_FLAGS_HOST_WR_BUF | p_tmp_sglist->length);
+                tmp_ioadl->address = htosis32(p_tmp_sglist->address);
+            }
+
+            tmp_ioadl->flags_and_data_len = 
+                htosis32(IPR_IOADL_FLAGS_HOST_WR_LAST_DATA | p_tmp_sglist->length);
+            tmp_ioadl->address = htosis32(p_tmp_sglist->address);
+
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+        }
+        else
+        {
+            panic(IPR_ERR": use_sg was set on a command, but data_direction was not "IPR_EOL);
+        }
+    }
+    else
+    { /* Not using scatter-gather */
+
+        if ((p_sis_cmd->data_direction == IPR_DATA_READ) ||
+            (p_sis_cmd->data_direction == IPR_DATA_WRITE))
+        {
+            panic("build_ioadl called without use_sg set"IPR_EOL);
+        }
+        else
+        {
+            /* No data to transfer */
+        }
+    }      
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Allocate memory for an adapter
+ * Context: Task level only
+ * Lock State: no locks assumed to be held
+ * Returns: IPR_RC_NOMEM  - Out of memory
+ *          IPR_RC_SUCCESS - Success
+ *          IPR_RC_FAILED  - Failure
+ *---------------------------------------------------------------------------*/
+int ipr_alloc_mem (struct ipr_shared_config *p_shared_cfg)
+{
+    int i, j, rc;
+    struct ipr_host_ioarcb *p_tmp_host_ioarcb;
+    struct ipr_data *ipr_cfg;
+    ipr_dma_addr dma_addr;
+    struct ipr_host_ioarcb_alloc *p_host_ioarcb_alloc;
+    int found = 0;
+    struct ipr_dasd_init_bufs *p_dasd_init_buf;
+
+    ENTER;
+
+    /* Allocate a zeroed buffer for our main control block */
+    ipr_cfg = (struct ipr_data *)ipr_kcalloc(sizeof(struct ipr_data),
+                                                   IPR_ALLOC_CAN_SLEEP);
+    p_shared_cfg->p_data = ipr_cfg;
+
+    if (ipr_cfg == NULL)
+    {
+        ipr_trace;
+        return IPR_RC_NOMEM;
+    }
+
+    /* Allocate a zeroed HRRQ buffer */
+    ipr_cfg->host_rrq = ipr_dma_calloc(p_shared_cfg,
+                                          sizeof(u32) * IPR_NUM_CMD_BLKS,
+                                          &ipr_cfg->host_rrq_dma,
+                                          IPR_ALLOC_CAN_SLEEP);
+
+    if (ipr_cfg->host_rrq == NULL)
+    {
+        ipr_trace;
+        rc = IPR_RC_NOMEM;
+        goto leave_hrrq;
+    }
+
+    for (i = 0; i < IPR_NUM_CMD_BLKS; i++)
+    {
+        /* Allocate zeroed memory for an IOARCB/IOASA/IOADL command block */
+        p_host_ioarcb_alloc =
+            ipr_dma_calloc(p_shared_cfg,
+                              sizeof(struct ipr_host_ioarcb_alloc),
+                              &dma_addr, IPR_ALLOC_CAN_SLEEP);
+
+        if (p_host_ioarcb_alloc == NULL)
+        {
+            ipr_trace;
+            rc = IPR_RC_NOMEM;
+            goto leave_ioarcbs;
+        }
+
+        p_tmp_host_ioarcb = (struct ipr_host_ioarcb *)p_host_ioarcb_alloc;
+        ipr_cfg->host_ioarcb_list[i] = p_tmp_host_ioarcb;
+        ipr_cfg->host_ioarcb_list_dma[i] = dma_addr;
+        p_tmp_host_ioarcb->ioarcb_dma = dma_addr;
+
+        p_tmp_host_ioarcb->p_ioadl = p_host_ioarcb_alloc->ioadl;
+        p_tmp_host_ioarcb->ioadl_dma = dma_addr + sizeof(struct ipr_host_ioarcb);
+
+        p_tmp_host_ioarcb->p_ioasa = &p_host_ioarcb_alloc->ioasa;
+        p_tmp_host_ioarcb->ioasa_dma = p_tmp_host_ioarcb->ioadl_dma + sizeof(p_host_ioarcb_alloc->ioadl);
+        p_tmp_host_ioarcb->ioarcb.ioasa_len = htosis16(sizeof(struct ipr_ioasa));
+
+        p_tmp_host_ioarcb->host_ioarcb_index = i;
+        p_tmp_host_ioarcb->ioarcb.host_response_handle = htosis32(i << 2);
+        p_tmp_host_ioarcb->ioarcb.ioasa_host_pci_addr = htosis32((u32)p_tmp_host_ioarcb->ioasa_dma);
+        p_tmp_host_ioarcb->ioarcb.ioarcb_host_pci_addr = htosis32(p_tmp_host_ioarcb->ioarcb_dma);
+    }
+
+    /* Allocate zeroed, DMA-able config table */
+    ipr_cfg->p_config_table = ipr_dma_calloc(p_shared_cfg,
+                                                sizeof(struct ipr_config_table),
+                                                &ipr_cfg->config_table_dma,
+                                                IPR_ALLOC_CAN_SLEEP);
+
+    for (i = 0; i < IPR_NUM_CFG_CHG_HCAMS; i++)
+    {
+        /* Allocate a DMA buffer for the DASD init job */
+        ipr_cfg->p_dasd_init_buf[i] = ipr_dma_calloc(p_shared_cfg,
+                                                        sizeof(struct ipr_dasd_init_bufs),
+                                                        &ipr_cfg->dasd_init_buf_dma[i],
+                                                        IPR_ALLOC_CAN_SLEEP);
+
+        if (ipr_cfg->p_dasd_init_buf[i] == NULL)
+        {
+            ipr_trace;
+            rc = IPR_RC_NOMEM;
+            goto leave_all;
+        }
+    }
+
+    /* Allocate zeroed memory for the internal trace */
+    ipr_cfg->trace = ipr_kcalloc(sizeof(struct ipr_internal_trace_entry) *
+                                    IPR_NUM_TRACE_ENTRIES,
+                                    IPR_ALLOC_CAN_SLEEP);
+
+    if (ipr_cfg->trace == NULL)
+    {
+        ipr_trace;
+        rc = IPR_RC_NOMEM;
+        goto leave_all;
+    }
+
+    /* Allocate a DMA buffer for the Set Supported Devices table */
+    ipr_cfg->p_ssd_header = ipr_dma_malloc(p_shared_cfg, sizeof(ipr_supported_dev_list) +
+                                              sizeof(struct ipr_ssd_header),
+                                              &ipr_cfg->ssd_header_dma,
+                                              IPR_ALLOC_CAN_SLEEP);
+
+    if ((ipr_cfg->p_config_table == NULL) || (ipr_cfg->p_ssd_header == NULL))
+    {
+        ipr_trace;
+        rc = IPR_RC_NOMEM;
+        goto leave_all;
+    }
+
+    ipr_cfg->trace_index = 0;
+
+    ipr_cfg->free_init_buf_head = NULL;
+
+    memcpy(ipr_cfg->p_ssd_header + 1,
+           ipr_supported_dev_list_ptr, sizeof(ipr_supported_dev_list));
+
+    ipr_cfg->p_ssd_header->data_length =
+        htosis16(sizeof(ipr_supported_dev_list) + sizeof(struct ipr_ssd_header));
+    ipr_cfg->p_ssd_header->reserved = 0;
+    ipr_cfg->p_ssd_header->num_records =
+        sizeof(ipr_supported_dev_list) / sizeof(struct ipr_supported_device);
+
+    for (i = 0; i < IPR_NUM_CFG_CHG_HCAMS; i++)
+    {
+        p_dasd_init_buf = ipr_cfg->p_dasd_init_buf[i];
+
+        /* Setup the DASD init DMA addresses */
+        p_dasd_init_buf->dasd_timeouts_dma = ipr_cfg->dasd_init_buf_dma[i];
+        p_dasd_init_buf->mode_pages_dma = p_dasd_init_buf->dasd_timeouts_dma +
+            ((unsigned long)&p_dasd_init_buf->mode_pages - (unsigned long)p_dasd_init_buf);
+        p_dasd_init_buf->changeable_parms_dma = p_dasd_init_buf->dasd_timeouts_dma +
+            ((unsigned long)&p_dasd_init_buf->changeable_parms - (unsigned long)p_dasd_init_buf);
+        p_dasd_init_buf->page3_inq_dma = p_dasd_init_buf->dasd_timeouts_dma +
+            ((unsigned long)&p_dasd_init_buf->page3_inq - (unsigned long)p_dasd_init_buf);
+        p_dasd_init_buf->std_inq_dma = p_dasd_init_buf->dasd_timeouts_dma +
+            ((unsigned long)&p_dasd_init_buf->std_inq - (unsigned long)p_dasd_init_buf);
+        p_dasd_init_buf->ssd_header_dma = p_dasd_init_buf->dasd_timeouts_dma +
+            ((unsigned long)&p_dasd_init_buf->ssd_header - (unsigned long)p_dasd_init_buf);
+        p_dasd_init_buf->res_query_dma = p_dasd_init_buf->dasd_timeouts_dma +
+            ((unsigned long)&p_dasd_init_buf->res_query - (unsigned long)p_dasd_init_buf);
+
+        ipr_put_dasd_init_buffer(ipr_cfg, p_dasd_init_buf);
+    }
+
+    /* Initialize register pointers */
+    for (i = 0; i < (sizeof(ipr_interrupt_table)/sizeof(struct ipr_interrupt_table_t)); i++)
+    {
+        if ((ipr_interrupt_table[i].vendor_id == p_shared_cfg->vendor_id) &&
+            (ipr_interrupt_table[i].device_id == p_shared_cfg->device_id))
+        {
+            ipr_cfg->regs = ipr_interrupt_table[i].regs;
+            found = 1;
+            break;
+        }
+    }
+
+    if (found == 0)
+    {
+        rc = IPR_RC_FAILED;
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err("Unknown IOA type: 0x%04X 0x%04X"IPR_EOL, p_shared_cfg->vendor_id,
+                       p_shared_cfg->device_id);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_end_err(KERN_ERR);
+        goto leave_all;
+    }
+
+    ipr_cfg->regs.set_interrupt_mask_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.clr_interrupt_mask_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.sense_interrupt_mask_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.clr_interrupt_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.sense_interrupt_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.ioarrin_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.sense_uproc_interrupt_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.set_uproc_interrupt_reg += p_shared_cfg->hdw_dma_regs;
+    ipr_cfg->regs.clr_uproc_interrupt_reg += p_shared_cfg->hdw_dma_regs;
+
+    return IPR_RC_SUCCESS;
+
+    leave_all:
+
+        for (i = 0; i < IPR_NUM_CFG_CHG_HCAMS; i++)
+        {
+            ipr_dma_free(p_shared_cfg, sizeof(struct ipr_dasd_init_bufs),
+                            ipr_cfg->p_dasd_init_buf[i],
+                            ipr_cfg->dasd_init_buf_dma[i]);
+        }
+
+    ipr_dma_free(p_shared_cfg, sizeof(struct ipr_config_table),
+                    ipr_cfg->p_config_table,
+                    ipr_cfg->config_table_dma);
+
+    ipr_dma_free(p_shared_cfg, sizeof(ipr_supported_dev_list) + sizeof(struct ipr_ssd_header),
+                    ipr_cfg->p_ssd_header, ipr_cfg->ssd_header_dma);
+    ipr_kfree(ipr_cfg->trace,
+                 sizeof(struct ipr_internal_trace_entry) *
+                 IPR_NUM_TRACE_ENTRIES);
+
+    leave_ioarcbs:
+        for (j=0; j < IPR_NUM_CMD_BLKS; j++)
+        {
+            ipr_dma_free(p_shared_cfg, sizeof(struct ipr_host_ioarcb_alloc),
+                            ipr_cfg->host_ioarcb_list[j], ipr_cfg->host_ioarcb_list_dma[j]);
+        }
+
+    ipr_dma_free(p_shared_cfg, sizeof(u32) * IPR_NUM_CMD_BLKS,
+                    ipr_cfg->host_rrq, ipr_cfg->host_rrq_dma);
+
+    leave_hrrq:
+        ipr_kfree(ipr_cfg, sizeof(struct ipr_data));
+
+    LEAVE;
+
+    return rc;
+
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Frees memory allocated by the binary
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *---------------------------------------------------------------------------*/
+int ipr_free_mem (struct ipr_shared_config *p_shared_cfg)
+{
+    int i;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    for (i=0; i < IPR_NUM_CMD_BLKS; i++)
+    {
+        ipr_dma_free(p_shared_cfg, sizeof(struct ipr_host_ioarcb_alloc),
+                        ipr_cfg->host_ioarcb_list[i], ipr_cfg->host_ioarcb_list_dma[i]);
+    }
+
+    for (i = 0; i < IPR_NUM_CFG_CHG_HCAMS; i++)
+    {
+        ipr_dma_free(p_shared_cfg, sizeof(struct ipr_dasd_init_bufs),
+                        ipr_cfg->p_dasd_init_buf[i],
+                        ipr_cfg->dasd_init_buf_dma[i]);
+    }
+
+    ipr_dma_free(p_shared_cfg, sizeof(u32) * IPR_NUM_CMD_BLKS,
+                    ipr_cfg->host_rrq, ipr_cfg->host_rrq_dma);
+
+    ipr_dma_free(p_shared_cfg, sizeof(struct ipr_config_table),
+                    ipr_cfg->p_config_table,
+                    ipr_cfg->config_table_dma);
+
+    ipr_dma_free(p_shared_cfg, sizeof(ipr_supported_dev_list) + sizeof(struct ipr_ssd_header),
+                    ipr_cfg->p_ssd_header, ipr_cfg->ssd_header_dma);
+
+    ipr_kfree(ipr_cfg->trace,
+                 sizeof(struct ipr_internal_trace_entry) *
+                 IPR_NUM_TRACE_ENTRIES);
+    ipr_kfree(ipr_cfg, sizeof(struct ipr_data));
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Part 1 of IOA initialization
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *          IPR_RC_FAILED            - Failed to write destruct. diag.
+ *---------------------------------------------------------------------------*/
+int ipr_init_ioa_internal_part1 (struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    int i;
+    volatile u32 temp_reg;
+
+    ENTER;
+
+    /* Zero out the HRRQ */
+    memset(ipr_cfg->host_rrq, 0, sizeof(u32)*IPR_NUM_CMD_BLKS);
+
+    /* Setup our eyecatchers for debug */
+    sprintf(ipr_cfg->eye_catcher, IPR_DATA_EYE_CATCHER);
+    sprintf(ipr_cfg->cfg_table_start, IPR_DATA_CFG_TBL_START);
+    sprintf(ipr_cfg->trace_start, IPR_DATA_TRACE_START);
+    sprintf(ipr_cfg->free_start, IPR_FREEQ_START);
+    sprintf(ipr_cfg->pendq_start, IPR_PENDQ_START);
+    sprintf(ipr_cfg->hrrq_label, IPR_HRRQ_LABEL);
+    sprintf(ipr_cfg->ioarcb_label, IPR_IOARCB_LABEL);
+
+    /* Initialize Host RRQ pointers */
+    ipr_cfg->host_rrq_start_addr = ipr_cfg->host_rrq;
+    ipr_cfg->host_rrq_end_addr = &ipr_cfg->host_rrq[IPR_NUM_CMD_BLKS - 1];
+    ipr_cfg->host_rrq_curr_ptr = ipr_cfg->host_rrq_start_addr;
+    ipr_cfg->toggle_bit = 1;
+
+    /* Zero queue pointers */
+    ipr_cfg->qFreeH = NULL;
+    ipr_cfg->qFreeT = NULL;
+    ipr_cfg->qPendingH = NULL;
+    ipr_cfg->qPendingT = NULL;
+
+    /* Zero out config table */
+    memset(ipr_cfg->p_config_table, 0, sizeof(struct ipr_config_table));
+
+    /* Put all the host ioarcbs on the free list */
+    for (i = 0; i < IPR_NUM_CMD_BLKS; i++)
+    {
+        ipr_put_host_ioarcb_to_free(ipr_cfg, ipr_cfg->host_ioarcb_list[i]);
+        ipr_cfg->host_ioarcb_list[i]->p_sis_cmd = NULL;
+    }
+
+    /* Mask all interrupts to allow polling */
+    p_shared_cfg->allow_interrupts = 0;
+    writel(~0, ipr_cfg->regs.set_interrupt_mask_reg);
+    temp_reg = readl(ipr_cfg->regs.sense_interrupt_mask_reg);
+
+    /* initialize old ses status information for 15k dasd limitations */
+    ipr_cfg->non15k_ses = 0;
+
+    for (i = 0; i < sizeof(ipr_ioa_parms)/sizeof(struct ipr_ioa_parms_t); i++)
+    {
+        if ((p_shared_cfg->vendor_id == ipr_ioa_parms[i].vendor_id) &&
+            (p_shared_cfg->device_id == ipr_ioa_parms[i].device_id) &&
+            (p_shared_cfg->subsystem_id == ipr_ioa_parms[i].subsystem_id))
+        {
+            ipr_cfg->p_ioa_cfg = &ipr_ioa_parms[i];
+
+            /* Enable destructive diagnostics on IOA */
+            writel (IPR_DOORBELL, ipr_cfg->regs.set_uproc_interrupt_reg);
+
+            LEAVE;
+            return IPR_RC_SUCCESS;
+        }
+    }
+
+    LEAVE;
+    return IPR_RC_FAILED;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Query whether or not IOA can be reset
+ * Context: Task level or interrupt level.
+ * Lock State: no locks assumed to be held
+ * Returns: TRUE        - IOA can be reset
+ *          FALSE       - IOA is in a critical operation
+ *---------------------------------------------------------------------------*/
+int ipr_reset_allowed(struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    volatile u32 temp_reg;
+
+    temp_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+
+    return ((temp_reg & IPR_PCII_CRITICAL_OPERATION) == 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Alert the IOA of a pending reset
+ * Context: Task level or interrupt level.
+ * Lock State: no locks assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_reset_alert(struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    writel(IPR_403I_RESET_ALERT, ipr_cfg->regs.set_uproc_interrupt_reg);
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Part 2 of IOA initialization
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS       - Success
+ *          IPR_RC_XFER_FAILED   - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ          - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST     - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR       - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED - IOA unit checked
+ *          IPR_RC_FAILED        - Initialization failed
+ *          IPR_RC_TIMEOUT       - IOA timed out
+ *---------------------------------------------------------------------------*/
+int ipr_init_ioa_internal_part2 (struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    volatile u32 temp_reg;
+    u32 delay = 0;
+    u32 rc = IPR_RC_SUCCESS;
+    char dram_size[4];
+    struct ipr_ioa_vpd *p_ioa_vpd;
+    struct ipr_cfc_vpd *p_cfc_vpd;
+    struct ipr_dram_vpd *p_dram_vpd;
+    struct ipr_inquiry_page0 *p_supp_vpd;
+    struct ipr_inquiry_page3 *p_ucode_vpd;
+    struct ipr_config_table_entry *p_cfgte;
+    struct ipr_resource_dll *p_sis_resource_dll;
+    int i, current_command;
+    char temp_ccin[5];
+
+    ENTER;
+
+    ipr_log_info_tty("Waiting for IBM %s at %s to come operational",
+                        p_shared_cfg->ccin_str, p_shared_cfg->ioa_host_str);
+
+    while(delay < IPR_OPERATIONAL_TIMEOUT)
+    {
+        temp_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+
+        if (temp_reg & IPR_PCII_ERROR_INTERRUPTS)
+        {
+            if (temp_reg & IPR_PCII_IOARCB_XFER_FAILED)
+                rc = IPR_RC_XFER_FAILED;
+            else if (temp_reg & IPR_PCII_NO_HOST_RRQ)
+                rc = IPR_NO_HRRQ;
+            else if (temp_reg & IPR_PCII_IOARRIN_LOST)
+                rc = IPR_IOARRIN_LOST;
+            else if (temp_reg & IPR_PCII_MMIO_ERROR)
+                rc = IPR_MMIO_ERROR;
+            else if (temp_reg & IPR_PCII_IOA_UNIT_CHECKED)
+                rc = IPR_IOA_UNIT_CHECKED;
+            else
+                rc = IPR_RC_FAILED;
+            break;
+        }
+        else if (temp_reg & IPR_PCII_IOA_TRANS_TO_OPER)
+        {
+            break;
+        }
+        else
+        {
+            /* Sleep for 1 second */
+            ipr_sleep(1000);
+            ipr_print_tty(".");
+            delay += 1; 
+        }
+    }
+
+    ipr_print_tty(IPR_EOL);
+
+    /* Timeout the IOA if it's not coming operational */
+    if (delay >= IPR_OPERATIONAL_TIMEOUT)
+    {
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err_tty("IOA timed out coming operational"IPR_EOL);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_end_err(KERN_ERR);
+        return IPR_RC_TIMEOUT;
+    }
+    else if (rc)
+    {
+        for (i=0;
+             i<(sizeof(ipr_error_int_decode)/sizeof(struct ipr_error_int_decode_t));
+             i++)
+        {
+            if ((ipr_error_int_decode[i].interrupt & temp_reg) ||
+                (ipr_error_int_decode[i].interrupt == 0xffffffff))
+                break;
+        }
+
+        if (ipr_error_int_decode[i].interrupt != IPR_PCII_IOA_UNIT_CHECKED)
+        {
+            ipr_beg_err(KERN_ERR);
+            ipr_log_err_tty("IOA failed initialization sequence. %s"IPR_EOL,
+                               ipr_error_int_decode[i].p_error);
+            ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+            ipr_end_err(KERN_ERR);
+        }
+        return rc;
+    }
+
+    delay = 0;
+
+    p_ioa_vpd = p_shared_cfg->p_ioa_vpd;
+    p_cfc_vpd = p_shared_cfg->p_cfc_vpd;
+    p_ucode_vpd = p_shared_cfg->p_ucode_vpd;
+    p_supp_vpd = p_shared_cfg->p_page0_vpd;
+    p_dram_vpd = p_shared_cfg->p_dram_vpd;
+
+    /* Zero DMA buffer for our IOA Inquiry data */
+    memset(p_ioa_vpd, 0, sizeof(struct ipr_ioa_vpd));
+
+    /* Zero DMA buffer for our CFC Inquiry data */
+    memset(p_cfc_vpd, 0, sizeof(struct ipr_cfc_vpd));
+
+    memset(p_dram_vpd, 0, sizeof(struct ipr_dram_vpd));
+    memset(p_ucode_vpd, 0, sizeof(struct ipr_inquiry_page3));
+    memset(p_supp_vpd, 0, sizeof(struct ipr_inquiry_page0));
+    strcpy(p_dram_vpd->dram_size, "00");
+
+    if (!rc)
+    {
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_ID_HOST_RR_Q,
+                                      IPR_INTERNAL_TIMEOUT,
+                                      0, NULL, 0, 0);
+        current_command = IPR_ID_HOST_RR_Q;
+    }
+
+    if (!rc) {
+        /* IOA has transitioned to operational - we can try to send a shutdown to it if we
+         need to */
+        p_shared_cfg->ioa_operational = 1;
+
+
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_INQUIRY,
+                                      IPR_INTERNAL_TIMEOUT, 0xff, p_ioa_vpd,
+                                      p_shared_cfg->ioa_vpd_dma,
+                                      sizeof(struct ipr_ioa_vpd));
+        current_command = IPR_INQUIRY;
+    }
+
+    if (!rc)
+    {
+        /* Grab the CCIN out of the VPD and store it away */
+        memcpy(temp_ccin, p_ioa_vpd->std_inq_data.vpids.product_id, 4);
+        temp_ccin[4] = '\0';
+
+        p_shared_cfg->ccin = simple_strtoul((char *)temp_ccin, NULL, 16);
+
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_INQUIRY,
+                                      IPR_INTERNAL_TIMEOUT, 0, p_supp_vpd,
+                                      p_shared_cfg->page0_vpd_dma, sizeof(struct ipr_inquiry_page0));
+    }
+
+    if (!rc && (p_supp_vpd->page_length <= IPR_MAX_NUM_SUPP_INQ_PAGES))
+    {
+        for (i = 0; (i < p_supp_vpd->page_length) && !rc; i++)
+        {
+            switch (p_supp_vpd->supported_page_codes[i])
+            {
+                case 0x01:
+                    ipr_send_blocking_cmd(p_shared_cfg, IPR_INQUIRY,
+                                             IPR_INTERNAL_TIMEOUT, 0x01,
+                                             p_cfc_vpd, p_shared_cfg->cfc_vpd_dma,
+                                             sizeof(struct ipr_cfc_vpd));
+                    break;
+                case 0x02:
+                    rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_INQUIRY,
+                                                  IPR_INTERNAL_TIMEOUT, 0x02,
+                                                  p_dram_vpd, p_shared_cfg->dram_vpd_dma,
+                                                  sizeof(struct ipr_dram_vpd));
+                    break;
+                default:
+                    /* Ignore this page - either unknown or required */
+                    break;
+            }
+        }
+    }
+
+    if (!rc)
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_INQUIRY,
+                                      IPR_INTERNAL_TIMEOUT, 0x03,
+                                      p_ucode_vpd, p_shared_cfg->ucode_vpd_dma,
+                                      sizeof(struct ipr_inquiry_page3));
+
+    if (!rc)
+    {
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_QUERY_IOA_CONFIG,
+                                      IPR_INTERNAL_TIMEOUT, 0, ipr_cfg->p_config_table,
+                                      ipr_cfg->config_table_dma,
+                                      sizeof(struct ipr_config_table));
+        current_command = IPR_QUERY_IOA_CONFIG;
+    }
+
+    if (!rc)
+    {
+        for (i = 0; i < ipr_cfg->p_config_table->num_entries; i++)
+        {
+            p_cfgte = &ipr_cfg->p_config_table->dev[i];
+
+            /* check backplane to determine if 15K dasd exclusion applies. */
+            ipr_check_backplane(p_shared_cfg, p_cfgte);
+        }
+    }
+
+    if (!rc)
+    {
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_SET_SUPPORTED_DEVICES,
+                                      IPR_SET_SUP_DEVICE_TIMEOUT, 0, ipr_cfg->p_ssd_header,
+                                      ipr_cfg->ssd_header_dma,
+                                      sistoh16(ipr_cfg->p_ssd_header->data_length));
+        current_command = IPR_SET_SUPPORTED_DEVICES;
+    }
+
+    if (!rc || (rc == IPR_IOASC_NR_IOA_MICROCODE))
+    {
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_QUERY_IOA_CONFIG,
+                                      IPR_INTERNAL_TIMEOUT, 0, ipr_cfg->p_config_table,
+                                      ipr_cfg->config_table_dma, sizeof(struct ipr_config_table));
+        current_command = IPR_QUERY_IOA_CONFIG;
+    }
+
+    if (!rc && (ipr_cfg->p_config_table->num_entries == 0))
+        ipr_cfg->p_config_table->num_entries = 1;
+
+    if (!rc)
+    {
+        strncpy(dram_size, p_dram_vpd->dram_size, 3);
+        dram_size[3] = '\0';
+
+        p_shared_cfg->dram_size = simple_strtoul(dram_size, NULL, 16);
+
+        for (i = 0; i < ipr_cfg->p_config_table->num_entries; i++)
+        {
+            p_cfgte = &ipr_cfg->p_config_table->dev[i];
+
+            if (!ipr_is_res_addr_valid(&p_cfgte->resource_address))
+            {
+                /* invalid resource address, log message and ignore entry */
+                ipr_log_err("Invalid resource address reported: 0x%08X"IPR_EOL,
+                               IPR_GET_PHYSICAL_LOCATOR(p_cfgte->resource_address));
+                continue;
+            }
+
+            p_sis_resource_dll = ipr_get_resource_entry(p_shared_cfg);
+
+            if (p_sis_resource_dll == NULL)
+            {
+                ipr_beg_err(KERN_ERR);
+                ipr_log_err("Too many devices attached"IPR_EOL);
+                ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+                ipr_end_err(KERN_ERR);
+                break;
+            }
+
+            ipr_update_resource(p_shared_cfg, &p_sis_resource_dll->data, p_cfgte, 0);
+        }
+    }
+
+    if (!rc)
+    {
+        rc = ipr_set_mode_page28(p_shared_cfg);
+        current_command = IPR_MODE_SENSE;
+    }
+
+    if ((!rc || (rc == IPR_IOASC_NR_IOA_MICROCODE)) && (ipr_arch == IPR_ARCH_ISERIES))
+    {
+        rc = ipr_build_slot_map(p_shared_cfg);
+        current_command = IPR_RECEIVE_DIAGNOSTIC;
+    }
+
+    if (!rc || (rc == IPR_IOASC_NR_IOA_MICROCODE))
+    {
+        rc = ipr_init_devices(p_shared_cfg);
+        current_command = IPR_SET_DASD_TIMEOUTS;
+    }
+
+    if (!rc)
+    {
+        ipr_log_config_error(p_shared_cfg, 1, NULL);
+
+        p_shared_cfg->allow_interrupts = 1;
+
+        /* Clear interrupt mask to allow interrupts */
+        writel(IPR_PCII_OPER_INTERRUPTS, ipr_cfg->regs.clr_interrupt_mask_reg);
+
+        /* Re-read the PCI interrupt mask reg to force clear */
+        temp_reg = readl(ipr_cfg->regs.sense_interrupt_mask_reg);
+    }
+    else
+    {
+        for (i=0;
+             i<((sizeof(ipr_error_rc_decode)/sizeof(struct ipr_error_rc_decode_t)) - 1);
+             i++)
+        {
+            if ((ipr_error_rc_decode[i].rc == rc))
+                break;
+        }
+
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err_tty("IOA failed to come operational on command %x, %s"IPR_EOL,
+                           current_command, ipr_error_rc_decode[i].p_error);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_end_err(KERN_ERR);
+    }
+
+    LEAVE;
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Determine if the xfer speed should be limited for a
+ *          given SCSI bus.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: 0 for no speed limit, else MB/sec limit
+ *---------------------------------------------------------------------------*/
+static u32 ipr_scsi_bus_speed_limit(struct ipr_shared_config *p_shared_cfg,
+                                       int scsi_bus)
+{
+    int backplane_entry_count, matches, j;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    struct ipr_resource_entry *p_rte;
+    struct ipr_resource_dll *p_resource_dll;
+    const struct ipr_backplane_table_entry *p_bte;
+
+    /* Loop through each config table entry in the config table buffer */
+    for (p_resource_dll = p_shared_cfg->rsteUsedH;
+         p_resource_dll != NULL;
+         p_resource_dll = p_resource_dll->next)
+    {
+        p_rte = &p_resource_dll->data;
+
+        if (scsi_bus != p_rte->resource_address.bus)
+            continue;
+
+        if (!(IPR_IS_SES_DEVICE(p_rte->std_inq_data)))
+            continue;
+
+        for /*! Loop through entries of the backplane table */
+            (backplane_entry_count = 0,
+             p_bte = &ipr_backplane_table[0];
+             backplane_entry_count <
+                 (sizeof(ipr_backplane_table) /
+                  sizeof(struct ipr_backplane_table_entry));
+             backplane_entry_count++, p_bte++)
+        {
+            /* Does the Product ID for this SCSI device match this entry in
+             the backplane table */
+
+            for (j = 0, matches = 0; j < IPR_PROD_ID_LEN; j++)
+            {
+                if (p_bte->compare_product_id_byte[j])
+                {
+                    if (p_rte->std_inq_data.vpids.product_id[j] == p_bte->product_id[j])
+                        matches++;
+                    else
+                        break;
+                }
+                else
+                    matches++;
+            }
+
+            if (matches == IPR_PROD_ID_LEN)
+            {
+                /* Return the max bus speed limit from the table entry */
+                return IPR_MIN(p_bte->max_bus_speed_limit,
+                                  ipr_cfg->p_ioa_cfg->max_bus_speed_limit);
+            }
+        }
+    }
+
+    /* Return 0 to indicate no backplane speed limitations */
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Set changeable parms for mode page 28 bus attributes.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: void
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page_28_changeable(struct ipr_shared_config *p_shared_cfg,
+                                          struct ipr_mode_page_28_scsi_dev_bus_attr *p_chg_dev_bus_entry,
+                                          struct ipr_mode_page_28_scsi_dev_bus_attr *p_dev_bus_entry)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    if (ipr_cfg->p_ioa_cfg->scsi_id_changeable)
+        p_chg_dev_bus_entry->scsi_id = 0xFF;
+
+    p_chg_dev_bus_entry->bus_width = 0xFF;
+    p_chg_dev_bus_entry->max_xfer_rate = 0xFFFFFFFF;
+    p_chg_dev_bus_entry->min_time_delay = 0xFF;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Routine to modify the IOAFP's mode page 28 for
+ *          a specified SCSI bus.
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: void
+ *---------------------------------------------------------------------------*/
+void ipr_modify_ioafp_mode_page_28(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_mode_page_28_header *
+                                      p_modepage_28_header,
+                                      int scsi_bus)
+{
+    int i, j, found;
+    int dev_entry_length;
+    u32 max_bus_speed;
+    u32 max_bus_speed_limit;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    struct ipr_mode_page_28_scsi_dev_bus_attr *p_dev_bus_entry;
+
+    dev_entry_length = p_modepage_28_header->dev_entry_length;
+
+    /* Point to first device bus entry */
+    p_dev_bus_entry = (struct ipr_mode_page_28_scsi_dev_bus_attr *)
+        (p_modepage_28_header + 1);
+
+    /* Loop for each device bus entry */
+    for (i = 0;
+         i < p_modepage_28_header->num_dev_entries;
+         i++,
+         p_dev_bus_entry = (struct ipr_mode_page_28_scsi_dev_bus_attr *)
+         ((char *)p_dev_bus_entry + dev_entry_length))
+    {
+        if (scsi_bus != p_dev_bus_entry->res_addr.bus)
+            continue;
+
+        for (j = 0,
+             found = 0;
+             j < p_shared_cfg->p_page_28->saved.page_hdr.num_dev_entries;
+             j++)
+        {
+            if (p_dev_bus_entry->res_addr.bus ==
+                p_shared_cfg->p_page_28->saved.attr[j].res_addr.bus)
+            {
+                found = 1;
+
+                /* found saved bus entry, copy to send mode select */
+                memcpy(p_dev_bus_entry,
+                       &p_shared_cfg->p_page_28->saved.attr[j],
+                       sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr));
+                break;
+            }
+        }
+
+        if (!found)
+        {
+            /* In case the adapter gave us bad data, initialize this to wide */
+            /* If this were zero, we would end up dividing by zero below */
+            if (p_dev_bus_entry->bus_width < 8)
+                p_dev_bus_entry->bus_width = 16;
+
+            /* Set Maximum transfer rate */
+            max_bus_speed = (sistoh32(p_dev_bus_entry->max_xfer_rate) *
+                             (p_dev_bus_entry->bus_width / 8))/10;
+
+            if ((max_bus_speed_limit = ipr_scsi_bus_speed_limit(p_shared_cfg,
+                                                                scsi_bus)))
+            {
+                if (max_bus_speed_limit < max_bus_speed)
+                    max_bus_speed = max_bus_speed_limit;
+            }
+
+            p_dev_bus_entry->max_xfer_rate =
+                htosis32(max_bus_speed * 10 / (p_dev_bus_entry->bus_width / 8));
+
+            p_dev_bus_entry->qas_capability =
+                IPR_MODEPAGE28_QAS_CAPABILITY_DISABLE_ALL;
+
+            /* New bus is being reported in page_28, need to save
+             off this new information */
+            memcpy(&p_shared_cfg->p_page_28->saved.attr[j],
+                   p_dev_bus_entry,
+                   sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr));
+
+            memcpy(&p_shared_cfg->p_page_28->dflt.attr[j],
+                   p_dev_bus_entry,
+                   sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr));
+
+            ipr_set_page_28_changeable(p_shared_cfg,
+                                       &p_shared_cfg->p_page_28->changeable.attr[j],
+                                       &p_shared_cfg->p_page_28->dflt.attr[j]);
+
+            /* Check if max_xfer_rate has been limited */
+            if (!max_bus_speed_limit)
+            {
+                p_shared_cfg->p_page_28->dflt.attr[j].max_xfer_rate =
+                    htosis32(ipr_cfg->p_ioa_cfg->max_bus_speed_limit * 10 /
+                             (p_dev_bus_entry->bus_width / 8));
+            }
+            else
+            {
+                p_shared_cfg->p_page_28->dflt.attr[j].max_xfer_rate =
+                    htosis32(max_bus_speed_limit * 10 /
+                             (p_dev_bus_entry->bus_width / 8));
+            }
+
+            p_shared_cfg->p_page_28->saved.page_hdr.num_dev_entries++;
+        }
+    }
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get and set mode page 28 parameters
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_TIMEOUT           - IOA timed out
+ *---------------------------------------------------------------------------*/
+static int ipr_set_mode_page28(struct ipr_shared_config *p_shared_cfg)
+{
+    int    bus_num, rc;
+    struct ipr_mode_parm_hdr *p_mode_parm_header;
+    struct ipr_mode_page_28_header *p_modepage_28_header;
+    void   *p_mode_page_28;
+    ipr_dma_addr p_mode_page_28_dma;
+    u32 mode_data_length;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    rc = IPR_RC_SUCCESS;
+
+    p_mode_page_28 = &ipr_cfg->p_dasd_init_buf[0]->mode_pages;
+    p_mode_page_28_dma = ipr_cfg->p_dasd_init_buf[0]->mode_pages_dma;
+
+    /* issue mode sense for page 28 to configure device bus attributes */
+    rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_MODE_SENSE,
+                                  IPR_INTERNAL_TIMEOUT,
+                                  IPR_PAGE_CODE_28, p_mode_page_28,
+                                  p_mode_page_28_dma, 255);
+
+    if (!rc)
+    {
+        /* Point to Mode data and Mode page 28 */
+        p_mode_parm_header = (struct ipr_mode_parm_hdr *) p_mode_page_28;
+        p_modepage_28_header = (struct ipr_mode_page_28_header *) (p_mode_parm_header + 1);
+
+        for (bus_num = 0;
+             bus_num < IPR_MAX_NUM_BUSES;
+             bus_num++)
+        {
+            ipr_modify_ioafp_mode_page_28(p_shared_cfg,
+                                             p_modepage_28_header,
+                                             bus_num);
+        }
+
+        /* copy over header information to page_28 saved */
+        memcpy(&p_shared_cfg->p_page_28->saved,
+               p_mode_page_28,
+               sizeof(struct ipr_mode_parm_hdr) +
+               sizeof(struct ipr_mode_page_28_header));
+        p_shared_cfg->p_page_28->saved.page_hdr.dev_entry_length =
+            sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+        /* copy over header information to page_28 changeable */
+        memcpy(&p_shared_cfg->p_page_28->changeable,
+               p_mode_page_28,
+               sizeof(struct ipr_mode_parm_hdr) +
+               sizeof(struct ipr_mode_page_28_header));
+        p_shared_cfg->p_page_28->changeable.page_hdr.dev_entry_length =
+            sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+        /* copy over header information to page_28 default */
+        memcpy(&p_shared_cfg->p_page_28->dflt,
+               p_mode_page_28,
+               sizeof(struct ipr_mode_parm_hdr) +
+               sizeof(struct ipr_mode_page_28_header));
+        p_shared_cfg->p_page_28->dflt.page_hdr.dev_entry_length =
+            sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+        mode_data_length = p_mode_parm_header->length + 1;
+
+        /* Zero length field */
+        p_mode_parm_header->length = 0;
+
+        /* Send IOAFP Mode Select command to IOA */
+        rc = ipr_send_blocking_cmd(p_shared_cfg, IPR_MODE_SELECT,
+                                      IPR_INTERNAL_TIMEOUT,
+                                      0x11, p_mode_page_28,
+                                      p_mode_page_28_dma,
+                                      mode_data_length);
+    }
+    else
+    {
+        if (rc == IPR_RC_FAILED)
+            rc = IPR_RC_SUCCESS;
+    }
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get slot/map data from the SES
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *          IPR_RC_TIMEOUT   - IOA timed out
+ *---------------------------------------------------------------------------*/
+static int ipr_build_slot_map(struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_resource_entry *p_rte, *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll, *p_resource_dll_ses;
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_ioadl_desc *p_ioadl;
+    int bus_num, length, rc;
+    int failed;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    u32 ioasc;
+
+    rc = IPR_RC_SUCCESS;
+
+    for (p_resource_dll_ses = p_shared_cfg->rsteUsedH;
+         p_resource_dll_ses != NULL;
+         p_resource_dll_ses = p_resource_dll_ses->next)
+    {
+        p_resource_entry = &p_resource_dll_ses->data;
+
+        if (IPR_IS_SES_DEVICE(p_resource_entry->std_inq_data))
+        {
+            bus_num = p_resource_entry->resource_address.bus;
+
+            if (bus_num > IPR_MAX_NUM_BUSES)
+            {
+                ipr_log_err("Invalid resource address 0x%08X returned for SES"IPR_EOL,
+                               IPR_GET_PHYSICAL_LOCATOR(p_resource_entry->resource_address));
+                continue;
+            }
+
+            p_host_ioarcb = ipr_get_free_host_ioarcb(p_shared_cfg);
+            p_ioarcb = &p_host_ioarcb->ioarcb; 
+            p_ioadl = p_host_ioarcb->p_ioadl;
+
+            length = sizeof(struct ipr_element_desc_page);
+
+            /* Setup IOARCB */
+            p_ioarcb->ioa_res_handle = p_resource_entry->resource_handle;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[0] = IPR_RECEIVE_DIAGNOSTIC;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[1] = 0x01; /* Page Code Valid */
+            p_ioarcb->ioarcb_cmd_pkt.cdb[2] = 7;    /* Page Code 7 */
+            p_ioarcb->ioarcb_cmd_pkt.cdb[3] = (length >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = length & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[5] = 0;
+
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_SCSICDB;
+
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 0;
+            p_ioarcb->ioarcb_cmd_pkt.cmd_sync_override = 1;
+            p_ioarcb->ioarcb_cmd_pkt.no_underlength_checking = 1;
+            p_ioarcb->ioarcb_cmd_pkt.cmd_timeout = htosis16(IPR_INTERNAL_TIMEOUT);
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | length);
+            p_ioadl->address = htosis32((u32)p_shared_cfg->ses_data_dma[bus_num]);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(length);
+
+            /* This will allow 1 retry. */
+            failed = 2; 
+
+            while(failed)
+            {
+                /* Zero out IOASA */
+                memset(p_host_ioarcb->p_ioasa, 0,
+                       sizeof(struct ipr_ioasa));
+
+                /* Poke the IOARRIN with the PCI address of the IOARCB */
+                writel(sistoh32(p_ioarcb->ioarcb_host_pci_addr),
+                              ipr_cfg->regs.ioarrin_reg);
+
+                rc = ipr_poll_isr(p_shared_cfg, IPR_INTERNAL_TIMEOUT*2);
+
+                /* If we timed the op out we want to return to the caller and have
+                 them do the appropriate recovery */
+                if (rc == IPR_RC_TIMEOUT)
+                    return rc;
+
+                ioasc = sistoh32(p_host_ioarcb->p_ioasa->ioasc);
+
+                if (rc == IPR_RC_SUCCESS)
+                {
+                    if (IPR_IOASC_SENSE_KEY(ioasc) == 0)
+                        break;
+                    else
+                        failed--;
+                }
+                else
+                {
+                    /* This means we got a nasty interrupt back from the IOA */
+                    return rc;
+                }
+
+                if (failed == 0)
+                {
+                    /* Command failed and we are out of retries */
+                    ipr_beg_err(KERN_ERR);
+                    ipr_log_err("Could not get Slot Map data. IOASC: 0x%08x"IPR_EOL, ioasc);
+                    ipr_log_dev_physical_location(p_shared_cfg,
+                                                     p_resource_entry->resource_address,
+                                                     KERN_ERR);
+                    ipr_end_err(KERN_ERR);
+                }
+            }
+
+            ipr_remove_host_ioarcb_from_pending(ipr_cfg, p_host_ioarcb);
+            ipr_put_host_ioarcb_to_free(ipr_cfg, p_host_ioarcb);
+
+            if (rc == IPR_RC_SUCCESS)
+            {
+                for (p_resource_dll = p_shared_cfg->rsteUsedH;
+                     p_resource_dll != NULL;
+                     p_resource_dll = p_resource_dll->next)
+                {
+                    p_rte = &p_resource_dll->data;
+
+                    if (p_rte->resource_address.bus == bus_num)
+                    {
+                        if ((IPR_IS_DASD_DEVICE(p_rte->std_inq_data)) &&
+                            (!p_rte->is_ioa_resource))
+                            ipr_get_card_pos(p_shared_cfg, p_rte->resource_address, p_rte->slot_label);
+                    }
+                }
+            }
+        }
+    }
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get slot/map data from the SES
+ * Context: Task level only
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *          IPR_RC_TIMEOUT   - IOA timed out
+ *---------------------------------------------------------------------------*/
+static int ipr_build_slot_map_runtime(struct ipr_shared_config *p_shared_cfg,
+                                         struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_hostrcb *p_hostrcb)
+{
+    int bus_num, length, rc;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_ccb *p_sis_ccb;
+    int timeout = IPR_INTERNAL_TIMEOUT;
+    struct ipr_dasd_init_bufs *p_dasd_init_buf;
+
+    rc = IPR_RC_SUCCESS;
+
+    bus_num = p_resource_entry->resource_address.bus;
+
+    if (bus_num > IPR_MAX_NUM_BUSES)
+    {
+        ipr_log_err("Invalid resource address returned for SES"IPR_EOL);
+        ipr_log_err("Resource address: 0x%08x"IPR_EOL,
+                       IPR_GET_PHYSICAL_LOCATOR(p_resource_entry->resource_address));
+        ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE, p_hostrcb);
+        return IPR_RC_FAILED;
+    }
+
+    length = sizeof(struct ipr_element_desc_page);
+
+    p_sis_ccb = ipr_allocate_ccb(p_shared_cfg);
+
+    if (p_sis_ccb == NULL)
+    {
+        /* Requests must not be allowed right now - we are probably going through
+         reset/reload right now */
+        ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE, p_hostrcb);
+        return IPR_RC_FAILED;
+    }
+
+    p_dasd_init_buf = ipr_get_dasd_init_buffer(ipr_cfg);
+
+    if (p_dasd_init_buf == NULL)
+    {
+        ipr_log_err("Failed to allocate dasd init buffer"IPR_EOL);
+        ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+        ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE, p_hostrcb);
+        return IPR_RC_FAILED;
+    }
+
+    p_dasd_init_buf->p_hostrcb = p_hostrcb;
+    p_dasd_init_buf->p_dev_res = p_resource_entry;
+
+    p_sis_ccb->p_resource = p_resource_entry;
+    p_sis_ccb->p_scratch = p_dasd_init_buf;
+    p_sis_ccb->job_step = IPR_SINIT_START;
+    p_sis_ccb->bufflen = length;
+    p_sis_ccb->buffer = p_shared_cfg->p_ses_data[bus_num];
+    p_sis_ccb->buffer_dma = (u32)p_shared_cfg->ses_data_dma[bus_num];
+    p_sis_ccb->scsi_use_sg = 0;
+    p_sis_ccb->cdb[0] = IPR_RECEIVE_DIAGNOSTIC;
+    p_sis_ccb->cdb[1] = 0x01; /* Page Code Valid */
+    p_sis_ccb->cdb[2] = 7;    /* Page Code 7 */
+    p_sis_ccb->cdb[3] = (length >> 8) & 0xff;
+    p_sis_ccb->cdb[4] = length & 0xff;
+    p_sis_ccb->cdb[5] = 0;
+    p_sis_ccb->cmd_len = 6;
+    p_sis_ccb->flags = IPR_BUFFER_MAPPED | IPR_CMD_SYNC_OVERRIDE;
+    p_sis_ccb->data_direction = IPR_DATA_READ;
+
+    rc = ipr_do_req(p_shared_cfg, p_sis_ccb,
+                       ipr_bus_init_job, timeout);
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Job router for runtime SES initialization
+ * Lock State: io_request_lock assumed to be held
+ * Context: Interrupt level
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_bus_init_job(struct ipr_shared_config *p_shared_cfg,
+                                struct ipr_ccb *p_sis_ccb)
+{
+    struct ipr_resource_entry *p_rte, *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll;
+    u32 rc = IPR_RC_SUCCESS;
+    int bus_num;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_dasd_init_bufs *p_dasd_init_buf = p_sis_ccb->p_scratch;
+    struct ipr_mode_parm_hdr *p_mode_parm_header;
+    struct ipr_mode_page_28_header *p_modepage_28_header;
+    void   *p_mode_page_28;
+    u32 mode_data_length;
+    int done = 0;
+
+    rc = p_sis_ccb->completion;
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        p_resource_entry = p_sis_ccb->p_resource;
+        bus_num = p_resource_entry->resource_address.bus;
+        if (ipr_sense_valid(p_sis_ccb->sense_buffer[0]))
+        {
+            /* We have a valid sense buffer */
+            if ((p_sis_ccb->sense_buffer[2] & 0xf) != 0)
+            {
+                rc = IPR_RC_FAILED;
+                IPR_DBG_CMD(ipr_beg_err(KERN_ERR));
+                ipr_dbg_err("0x%02x failed with SK: 0x%X ASC: 0x%X ASCQ: 0x%X"IPR_EOL,
+                               p_sis_ccb->cdb[0], (p_sis_ccb->sense_buffer[2] & 0xf),
+                               p_sis_ccb->sense_buffer[12], p_sis_ccb->sense_buffer[13]);
+                ipr_dbg_err("Failing device res_addr: %02X %02X %02X"IPR_EOL,
+                               bus_num, p_resource_entry->resource_address.target,
+                               p_resource_entry->resource_address.lun);
+                IPR_DBG_CMD(ipr_log_dev_physical_location(p_shared_cfg,
+                                                                p_resource_entry->resource_address,
+                                                                KERN_ERR));
+                ipr_dbg_err("Controlling IOA"IPR_EOL);
+                IPR_DBG_CMD(ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR));
+                IPR_DBG_CMD(ipr_end_err(KERN_ERR));
+            }
+        }
+        ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+        done = 1;
+    }
+    else
+    {
+        p_resource_entry = p_dasd_init_buf->p_dev_res;
+        bus_num = p_resource_entry->resource_address.bus;
+
+        switch (p_sis_ccb->job_step)
+        {
+            case IPR_SINIT_START:
+                for (p_resource_dll = p_shared_cfg->rsteUsedH;
+                     p_resource_dll != NULL;
+                     p_resource_dll = p_resource_dll->next)
+                {
+                    p_rte = &p_resource_dll->data;
+
+                    if (p_rte->resource_address.bus == bus_num)
+                    {
+                        if ((IPR_IS_DASD_DEVICE(p_rte->std_inq_data)) &&
+                            (!p_rte->is_ioa_resource))
+                            ipr_get_card_pos(p_shared_cfg, p_rte->resource_address, p_rte->slot_label);
+                    }
+                }
+
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                /* sense mode sense for page 28 */
+                p_mode_page_28 = &p_dasd_init_buf->mode_pages;
+
+                /* issue mode sense for page 28 to configure device bus attributes */
+                rc = ipr_ioa_req(p_shared_cfg, ipr_bus_init_job,
+                                    p_dasd_init_buf,
+                                    p_mode_page_28,
+                                    p_dasd_init_buf->mode_pages_dma,
+                                    IPR_MODE_SENSE, 0x28, 255,
+                                    IPR_SINIT_MODE_SENSE);
+                if (rc != IPR_RC_SUCCESS)
+                {
+                    ipr_log_err("Mode Sense Page 28 failed"IPR_EOL);
+                    done = 1;
+                }
+                break;
+            case IPR_SINIT_MODE_SENSE:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                /* Point to Mode data and Mode page 28 */
+                p_mode_page_28 = &p_dasd_init_buf->mode_pages;
+                p_mode_parm_header = (struct ipr_mode_parm_hdr *)
+                    p_mode_page_28;
+                p_modepage_28_header = (struct ipr_mode_page_28_header *)
+                    (p_mode_parm_header + 1);
+
+                /* Modify the IOAFP's Mode page 28 for specified
+                 SCSI bus */
+                ipr_modify_ioafp_mode_page_28(p_shared_cfg,
+                                                 p_modepage_28_header,
+                                                 bus_num);
+
+                /* copy over header information to page_28 saved */
+                memcpy(&p_shared_cfg->p_page_28->saved,
+                       p_mode_page_28,
+                       sizeof(struct ipr_mode_parm_hdr) +
+                       sizeof(struct ipr_mode_page_28_header));
+                p_shared_cfg->p_page_28->saved.page_hdr.dev_entry_length =
+                    sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+                /* copy over header information to page_28 changeable */
+                memcpy(&p_shared_cfg->p_page_28->changeable,
+                       p_mode_page_28,
+                       sizeof(struct ipr_mode_parm_hdr) +
+                       sizeof(struct ipr_mode_page_28_header));
+                p_shared_cfg->p_page_28->changeable.page_hdr.dev_entry_length =
+                    sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+                /* copy over header information to page_28 default */
+                memcpy(&p_shared_cfg->p_page_28->dflt,
+                       p_mode_page_28,
+                       sizeof(struct ipr_mode_parm_hdr) +
+                       sizeof(struct ipr_mode_page_28_header));
+                p_shared_cfg->p_page_28->dflt.page_hdr.dev_entry_length =
+                    sizeof(struct ipr_mode_page_28_scsi_dev_bus_attr);
+
+                /* Determine the amount of data to transfer on the Mode
+                 Select */
+                /* Note: Need to add 1 since the length field does not
+                 include itself. */
+                mode_data_length = p_mode_parm_header->length + 1;
+
+                /* Zero Mode parameter header */
+                /* Note: This is done to zero the Mode data length, which
+                 is reserved on the Mode Select. */
+                p_mode_parm_header->length = 0;
+
+                /* Send IOAFP Mode Select command to IOA */
+                rc = ipr_ioa_req(p_shared_cfg, ipr_bus_init_job,
+                                    p_dasd_init_buf,
+                                    p_mode_page_28,
+                                    p_dasd_init_buf->mode_pages_dma,
+                                    IPR_MODE_SELECT, 0x11, mode_data_length,
+                                    IPR_SINIT_MODE_SELECT);
+
+                if (rc != IPR_RC_SUCCESS)
+                {
+                    ipr_log_err("Mode Select page 28 failed"IPR_EOL);
+                    done = 1;
+                }
+                break;
+            case IPR_SINIT_MODE_SELECT:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+                done = 1;
+                break;
+            default:
+                break;
+        }
+    }
+
+    if (done)
+    {
+        ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                         p_dasd_init_buf->p_hostrcb);
+        ipr_put_dasd_init_buffer(ipr_cfg, p_dasd_init_buf);
+    }
+
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Peel ops off HRRQ
+ * Context: Interrupt level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS       - Success
+ *          IPR_RC_XFER_FAILED   - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ          - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST     - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR       - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED - IOA unit checked
+ *          IPR_SPURIOUS_INT     - IOA had a spurious interrupt
+ *          IPR_RESET_ADAPTER        - Adapter requests a reset
+ *---------------------------------------------------------------------------*/
+u32 ipr_get_done_ops(struct ipr_shared_config *p_shared_cfg,
+                        struct ipr_ccb **pp_sis_cmnd)
+{
+    volatile u32 temp_pci_reg, temp_mask_reg;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_ccb *p_doneq = NULL;
+    u32 rc = IPR_RC_SUCCESS;
+    u32 ioasc, host_ioarcb_index;
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    unsigned char *p_sense_buffer;
+    u8 device_type;
+
+    /* If interrupts are disabled, ignore the interrupt */
+    if (!p_shared_cfg->allow_interrupts)
+        return IPR_SPURIOUS_INT;
+
+    temp_mask_reg = readl(ipr_cfg->regs.sense_interrupt_mask_reg);
+    temp_pci_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+
+    temp_pci_reg &= ~temp_mask_reg;
+
+    /* If an interrupt on the adapter did not occur, ignore it */
+    if ((temp_pci_reg & IPR_PCII_OPER_INTERRUPTS) == 0)
+        return IPR_SPURIOUS_INT;
+
+    *pp_sis_cmnd = NULL;
+
+    while (1)
+    {
+        p_host_ioarcb = NULL;
+
+        while((sistoh32(*ipr_cfg->host_rrq_curr_ptr) & IPR_HRRQ_TOGGLE_BIT) == ipr_cfg->toggle_bit)
+        {
+            host_ioarcb_index =
+                (sistoh32(*ipr_cfg->host_rrq_curr_ptr) & IPR_HRRQ_REQ_RESP_HANDLE_MASK) >>
+                IPR_HRRQ_REQ_RESP_HANDLE_SHIFT;
+
+            if (host_ioarcb_index >= IPR_NUM_CMD_BLKS)
+            {
+                ipr_log_err("Invalid response handle from IOA"IPR_EOL);
+
+                ipr_mask_interrupts(p_shared_cfg);
+
+                return IPR_RESET_ADAPTER;
+            }
+
+            p_host_ioarcb = ipr_cfg->host_ioarcb_list[host_ioarcb_index];
+
+            if (p_doneq == NULL)
+            {
+                p_doneq = p_host_ioarcb->p_sis_cmd;
+                *pp_sis_cmnd = p_doneq;
+            }
+            else
+            {
+                p_doneq->p_next_done = p_host_ioarcb->p_sis_cmd;
+                p_doneq = p_doneq->p_next_done;
+            }
+
+            p_doneq->p_next_done = NULL;
+            ioasc = sistoh32(p_host_ioarcb->p_ioasa->ioasc);
+
+            if (p_doneq->p_resource->is_ioa_resource)
+                device_type = IPR_TRACE_IOA;
+            else if (p_doneq->flags & IPR_GPDD_CMD)
+                device_type = IPR_TRACE_GEN;
+            else
+                device_type = IPR_TRACE_DASD;
+
+            ipr_trc_hook(p_shared_cfg,
+                            p_doneq->cdb[0],
+                            IPR_TRACE_FINISH,
+                            device_type,
+                            host_ioarcb_index,
+                            p_doneq->bufflen,
+                            ioasc);
+
+            if (p_doneq->flags & IPR_GPDD_CMD)
+            {
+                p_doneq->residual = sistoh32(p_host_ioarcb->p_ioasa->residual_data_len);
+
+                if (IPR_IOASC_SENSE_KEY(ioasc) < 2)
+                {
+                    /* Command completed successfully */
+                }
+                else if (((ioasc & 0xffffff00) == 0x04448500))
+                {
+                    /* Device bus status error */
+                    p_doneq->completion = IPR_RC_FAILED;
+                    p_doneq->status = IPR_IOASC_SENSE_STATUS(ioasc);
+                }
+                else
+                {
+                    /* Error, not a device bus status error */
+                    p_doneq->completion = IPR_RC_FAILED;
+                    ipr_gen_sense(p_doneq->p_resource,
+                                     p_doneq->sense_buffer, p_host_ioarcb->p_ioasa);
+
+                    if (p_shared_cfg->debug_level >= 2)
+                        ipr_dump_ioasa(p_shared_cfg, p_doneq->p_resource,
+                                          p_host_ioarcb->p_ioasa);
+                }
+            }
+            else /* Non GPDD command */
+            {
+                if (IPR_IOASC_SENSE_KEY(ioasc) >= 2)
+                {
+                    if (p_shared_cfg->debug_level >= 3)
+                        ipr_dump_ioasa(p_shared_cfg, p_doneq->p_resource,
+                                          p_host_ioarcb->p_ioasa);
+
+                    /* Set residual byte count to entire length of the op since
+                     what is in the IOA may have been computed with a different
+                     sector size */
+                    p_doneq->residual = p_doneq->bufflen;
+
+                    p_sense_buffer = p_doneq->sense_buffer;
+
+                    ipr_gen_sense(p_doneq->p_resource,
+                                     p_sense_buffer, p_host_ioarcb->p_ioasa);
+
+                    p_doneq->completion = IPR_RC_FAILED;
+
+                    ipr_dbg_err("Op failed with opcode: 0x%02X, ioasc: 0x%08X"IPR_EOL,
+                                   p_doneq->cdb[0], ioasc);
+                }
+            }
+
+            /* Pull off of pending queue */
+            ipr_remove_host_ioarcb_from_pending(ipr_cfg, p_host_ioarcb);
+            ipr_put_host_ioarcb_to_free(ipr_cfg, p_host_ioarcb);
+
+            if (ipr_cfg->host_rrq_curr_ptr < ipr_cfg->host_rrq_end_addr)
+            {
+                ipr_cfg->host_rrq_curr_ptr++;
+            }
+            else
+            {
+                ipr_cfg->host_rrq_curr_ptr = ipr_cfg->host_rrq_start_addr;
+                ipr_cfg->toggle_bit ^= 1u;
+            }
+        }
+
+        if (p_host_ioarcb != NULL)
+        {
+            /* Clear the PCI interrupt */
+            writel (IPR_PCII_HOST_RRQ_UPDATED, ipr_cfg->regs.clr_interrupt_reg);
+
+            /* Re-read the PCI interrupt reg to force clear */
+            temp_pci_reg = (readl(ipr_cfg->regs.sense_interrupt_reg) & ~temp_mask_reg);
+        }
+        else
+            break;
+    }
+
+    if (*pp_sis_cmnd == NULL)
+    {
+        if (temp_pci_reg & IPR_PCII_IOARCB_XFER_FAILED)
+            rc = IPR_RC_XFER_FAILED;
+        else if (temp_pci_reg & IPR_PCII_NO_HOST_RRQ)
+            rc = IPR_NO_HRRQ;
+        else if (temp_pci_reg & IPR_PCII_IOARRIN_LOST)
+            rc = IPR_IOARRIN_LOST;
+        else if (temp_pci_reg & IPR_PCII_MMIO_ERROR)
+            rc = IPR_MMIO_ERROR;
+        else if (temp_pci_reg & IPR_PCII_IOA_UNIT_CHECKED)
+            rc = IPR_IOA_UNIT_CHECKED;
+        else
+            rc = IPR_SPURIOUS_INT;
+
+        if (rc != IPR_SPURIOUS_INT)
+            ipr_mask_interrupts(p_shared_cfg);
+
+        /* Clear the PCI interrupt */
+        writel (temp_pci_reg, ipr_cfg->regs.clr_interrupt_reg);
+
+        /* Re-read the PCI interrupt reg to force clear */
+        temp_pci_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+    }
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Generate SCSI sense data based on IOASC
+ * Context: Interrupt or task level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: None
+ *---------------------------------------------------------------------------*/
+static void ipr_gen_sense(struct ipr_resource_entry *p_resource,
+                             u8 *p_sense_buffer, struct ipr_ioasa *p_ioasa)
+{
+    u32 ioasc = sistoh32(p_ioasa->ioasc);
+    u32 failing_lba;
+
+    memset(p_sense_buffer, 0, IPR_SENSE_BUFFERSIZE);
+
+    if (ipr_is_vset_device(p_resource) &&
+        (ioasc == IPR_IOASC_MED_DO_NOT_REALLOC) &&
+        (p_ioasa->failing_lba_hi != 0))
+    {
+        /* Logically Bad and the failing LBA does not fit in 32 bits of LBA */
+        /* We must use the new sense data format to report the failing LBA */
+        p_sense_buffer[0] = 0x72;
+        p_sense_buffer[1] = IPR_IOASC_SENSE_KEY(ioasc);
+        p_sense_buffer[2] = IPR_IOASC_SENSE_CODE(ioasc);
+        p_sense_buffer[3] = IPR_IOASC_SENSE_QUAL(ioasc);
+
+        p_sense_buffer[7] = 12;
+        p_sense_buffer[8] = IPR_SCSI_SENSE_INFO;
+        p_sense_buffer[9] = 0x0A;
+        p_sense_buffer[10] = 0x80;
+
+        failing_lba = sistoh32(p_ioasa->failing_lba_hi);
+
+        p_sense_buffer[12] = ((failing_lba & 0xff000000) >> 24);
+        p_sense_buffer[13] = ((failing_lba & 0x00ff0000) >> 16);
+        p_sense_buffer[14] = ((failing_lba & 0x0000ff00) >> 8);
+        p_sense_buffer[15] = (failing_lba & 0x000000ff);
+
+        failing_lba = sistoh32(p_ioasa->failing_lba_lo);
+
+        p_sense_buffer[16] = ((failing_lba & 0xff000000) >> 24);
+        p_sense_buffer[17] = ((failing_lba & 0x00ff0000) >> 16);
+        p_sense_buffer[18] = ((failing_lba & 0x0000ff00) >> 8);
+        p_sense_buffer[19] = (failing_lba & 0x000000ff);
+    }
+    else
+    {
+        p_sense_buffer[0] = 0x70;
+        p_sense_buffer[2] = IPR_IOASC_SENSE_KEY(ioasc);
+        p_sense_buffer[12] = IPR_IOASC_SENSE_CODE(ioasc);
+        p_sense_buffer[13] = IPR_IOASC_SENSE_QUAL(ioasc);
+
+        /* Illegal request */
+        if ((IPR_IOASC_SENSE_KEY(ioasc) == 0x05) &&
+            (sistoh32(p_ioasa->ioasc_specific) & IPR_FIELD_POINTER_VALID))
+        {
+            p_sense_buffer[7] = 10;  /* additional length */
+
+            /* IOARCB was in error */
+            if (IPR_IOASC_SENSE_CODE(ioasc) == 0x24)
+                p_sense_buffer[15] = 0xC0;
+            else /* Parameter data was invalid */
+                p_sense_buffer[15] = 0x80;
+
+            p_sense_buffer[16] = ((IPR_FIELD_POINTER_MASK & sistoh32(p_ioasa->ioasc_specific)) >> 8) & 0xff;
+            p_sense_buffer[17] = (IPR_FIELD_POINTER_MASK & sistoh32(p_ioasa->ioasc_specific)) & 0xff;
+        }
+        else
+        {
+            if ((ioasc == IPR_IOASC_RCV_RECOMMEND_REALLOC) ||
+                (ioasc == IPR_IOASC_MED_RECOMMEND_REALLOC) ||
+                (ioasc == IPR_IOASC_MED_DO_NOT_REALLOC))
+            {
+                if (ipr_is_vset_device(p_resource))
+                    failing_lba = sistoh32(p_ioasa->failing_lba_lo);
+                else
+                    failing_lba = sistoh32(p_ioasa->failing_lba_hi);
+
+                p_sense_buffer[0] |= 0x80;  /* Or in the Valid bit */
+                p_sense_buffer[3] = ((failing_lba & 0xff000000) >> 24);
+                p_sense_buffer[4] = ((failing_lba & 0x00ff0000) >> 16);
+                p_sense_buffer[5] = ((failing_lba & 0x0000ff00) >> 8);
+                p_sense_buffer[6] = (failing_lba & 0x000000ff);
+            }
+
+            p_sense_buffer[7] = 6;  /* additional length */
+        }
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Dump contents of IOASA for debug
+ * Context: Interrupt or task level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: None
+ *---------------------------------------------------------------------------*/
+static void ipr_dump_ioasa(struct ipr_shared_config *p_shared_cfg,
+                              struct ipr_resource_entry *p_resource,
+                              struct ipr_ioasa *p_ioasa)
+{
+    static u8 buffer[1024];
+    u32 i = 0;
+    u32 j;
+    u32 *p_ioasa_data = (u32 *)p_ioasa;
+    u16 data_len;
+    u32 count = 0;
+    u32 ioasc = sistoh32(p_ioasa->ioasc);
+
+    if (0 == ioasc)
+        return;
+
+    /* Don't bother dumping sync required IOASAs */
+    if (IPR_IOASC_SYNC_REQUIRED == ioasc)
+        return;
+
+    if (p_shared_cfg->debug_level < IPR_ADVANCED_DEBUG)
+    {
+        /* Don't bother dumping selection timeout IOASAs */
+        if (IPR_IOASC_HW_SEL_TIMEOUT == ioasc)
+            return;
+
+        /* Don't dump recovered errors */
+        if (IPR_IOASC_SENSE_KEY(ioasc) < 2)
+            return;
+
+        /* Don't log an error if the IOA already logged one */
+        if (p_ioasa->ilid != 0)
+            return;
+    }
+
+    if (sizeof(struct ipr_ioasa) < sistoh16(p_ioasa->ret_stat_len))
+        data_len = sizeof(struct ipr_ioasa);
+    else
+        data_len = sistoh16(p_ioasa->ret_stat_len);
+
+    ipr_beg_err(KERN_ERR);
+    ipr_log_err("Device error"IPR_EOL);
+    ipr_log_dev_physical_location(p_shared_cfg,
+                                     p_resource->resource_address,
+                                     KERN_ERR);
+
+    while (i < data_len/4)
+    { 
+        count += sprintf(buffer + count, KERN_ERR""IPR_ERR": ioasa[0x%02x] ",i*4);
+        for (j=0; (j < 4) && (i < data_len/4); j++,i++)
+            count += sprintf(buffer + count, "%08x ",sistoh32(p_ioasa_data[i]));
+        count += sprintf(buffer + count,IPR_EOL);
+        if (count > (1024 - 128)) break; /* be sure not to exceed buffer limit */
+    }
+
+    printk(buffer);
+    ipr_end_err(KERN_ERR);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Queue an op to the IOA Focal Point
+ * Context: Task or interrupt level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+int ipr_ioa_queue(struct ipr_shared_config *p_shared_cfg, struct ipr_ccb *p_sis_cmd)
+{
+    struct ipr_host_ioarcb* p_host_ioarcb;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    p_host_ioarcb = ipr_build_ioa_cmd(p_shared_cfg,
+                                         p_sis_cmd->cdb[0],
+                                         p_sis_cmd,
+                                         0,
+                                         p_sis_cmd->buffer,
+                                         p_sis_cmd->buffer_dma,
+                                         p_sis_cmd->bufflen);
+
+    if (p_host_ioarcb != NULL)
+    {
+        ipr_trc_hook(p_shared_cfg,
+                        p_sis_cmd->cdb[0],
+                        IPR_TRACE_START,
+                        IPR_TRACE_IOA,
+                        p_host_ioarcb->host_ioarcb_index,
+                        p_sis_cmd->bufflen,
+                        IPR_IOA_RESOURCE_ADDRESS);
+
+        writel(sistoh32(p_host_ioarcb->ioarcb.ioarcb_host_pci_addr),
+                      ipr_cfg->regs.ioarrin_reg);
+    }
+    else
+        return IPR_RC_OP_NOT_SENT;
+
+    return IPR_RC_SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send a request sense to a GPDD
+ * Context: Task level.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: None
+ *---------------------------------------------------------------------------*/
+void ipr_auto_sense(struct ipr_shared_config *p_shared_cfg,
+                       struct ipr_ccb *p_sis_cmd)
+{
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_cmd_pkt *p_cmd_pkt;
+    struct ipr_ioadl_desc *p_ioadl;
+    u8 *p_cdb;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_resource_entry *p_resource = p_sis_cmd->p_resource;
+
+    p_host_ioarcb = ipr_get_free_host_ioarcb(p_shared_cfg);
+    p_ioarcb = &p_host_ioarcb->ioarcb;
+    p_host_ioarcb->p_sis_cmd = p_sis_cmd;
+    p_ioadl = p_host_ioarcb->p_ioadl;
+    p_cmd_pkt = &p_ioarcb->ioarcb_cmd_pkt;
+    p_cdb = p_cmd_pkt->cdb;
+    p_ioarcb->ioa_res_handle = p_resource->resource_handle;
+    p_cmd_pkt->reserved = 0;
+
+    /* Send off a request sense */
+    p_cdb[0] = IPR_REQUEST_SENSE;
+    p_cdb[1] = p_cdb[2] = p_cdb[3] = p_cdb[5] = 0;
+    p_cdb[4] = IPR_SENSE_BUFFERSIZE;
+    p_cmd_pkt->cmd_sync_override = 1;
+    p_cmd_pkt->no_underlength_checking = 1;
+    p_cmd_pkt->write_not_read = 0;
+
+    p_cmd_pkt->cmd_timeout = htosis16(IPR_REQUEST_SENSE_TIMEOUT);
+
+    p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+
+    p_ioadl->flags_and_data_len = 
+        htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | IPR_SENSE_BUFFERSIZE);
+    p_ioadl->address = htosis32((u32)p_sis_cmd->sense_buffer_dma);
+
+    p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+    p_ioarcb->read_data_transfer_length = htosis32(IPR_SENSE_BUFFERSIZE);
+
+    memset(p_host_ioarcb->p_ioasa, 0, sizeof(struct ipr_ioasa));
+
+    ipr_trc_hook(p_shared_cfg,
+                    p_cdb[0],
+                    IPR_TRACE_START,
+                    IPR_TRACE_GEN,
+                    p_host_ioarcb->host_ioarcb_index,
+                    IPR_SENSE_BUFFERSIZE,
+                    IPR_GET_PHYSICAL_LOCATOR(p_resource->resource_address));
+
+    /* Poke the IOARRIN with the PCI address of the IOARCB */
+    writel(sistoh32(p_ioarcb->ioarcb_host_pci_addr),
+                  ipr_cfg->regs.ioarrin_reg);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Queue an op to a device
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+int ipr_queue_internal(struct ipr_shared_config *p_shared_cfg,
+                          struct ipr_ccb *p_sis_cmd)
+{
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_ioadl_desc *p_ioadl;
+    unsigned char *p_sense_buffer;
+    u8 cmnd;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_resource_entry *p_resource = p_sis_cmd->p_resource;
+
+    cmnd = p_sis_cmd->cdb[0];
+
+    /* Are we read/write protecting the device? */
+    if (p_resource->rw_protected)
+    {
+        if ((cmnd == IPR_READ_6) || (cmnd == IPR_WRITE_6) ||
+            (cmnd == IPR_READ_10) || (cmnd == IPR_WRITE_10) ||
+            (cmnd == IPR_WRITE_VERIFY) || (cmnd == IPR_READ_16) ||
+            (cmnd == IPR_WRITE_16) || (cmnd == IPR_WRITE_VERIFY_16))
+        {
+            /* Device is blocked and op is a read or write */
+            /* Send back a data protect error */
+            p_sense_buffer = p_sis_cmd->sense_buffer;
+            memset(p_sense_buffer, 0, IPR_SENSE_BUFFERSIZE);
+
+            p_sense_buffer[0] = 0xf0;
+            p_sense_buffer[2] = 0x07;
+            p_sense_buffer[3] = p_sis_cmd->cdb[2];
+            p_sense_buffer[4] = p_sis_cmd->cdb[3];
+            p_sense_buffer[5] = p_sis_cmd->cdb[4];
+            p_sense_buffer[6] = p_sis_cmd->cdb[5];
+            p_sense_buffer[7] = 6;
+            p_sense_buffer[12] = 0x27;
+            p_sense_buffer[13] = 0x00;
+
+            return IPR_RC_OP_NOT_SENT;
+        }
+    }
+
+    p_host_ioarcb = ipr_get_free_host_ioarcb(p_shared_cfg);
+
+    p_ioarcb = &p_host_ioarcb->ioarcb;
+    p_ioadl = p_host_ioarcb->p_ioadl;
+    p_host_ioarcb->p_sis_cmd = p_sis_cmd;
+
+    p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_SCSICDB;
+    p_ioarcb->ioa_res_handle = p_resource->resource_handle;
+
+    memcpy(p_ioarcb->ioarcb_cmd_pkt.cdb, p_sis_cmd->cdb, IPR_CCB_CDB_LEN);
+
+    /* Is this a GPDD op? */
+    if (!p_resource->is_af)
+    {
+        ipr_trc_hook(p_shared_cfg,
+                        cmnd,
+                        IPR_TRACE_START,
+                        IPR_TRACE_GEN,
+                        p_host_ioarcb->host_ioarcb_index,
+                        p_sis_cmd->bufflen,
+                        IPR_GET_PHYSICAL_LOCATOR(p_resource->resource_address));
+
+        if (p_sis_cmd->flags & IPR_IOA_CMD)
+        {
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_ioarcb->ioarcb_cmd_pkt.reserved = 0;
+            p_ioarcb->ioarcb_cmd_pkt.cmd_timeout = 0;
+        }
+        else
+            p_ioarcb->ioarcb_cmd_pkt.cmd_timeout = htosis16(p_sis_cmd->timeout);
+
+        /* Setup the IOADL */
+        ipr_build_ioadl(p_shared_cfg, p_host_ioarcb);
+
+        if (p_sis_cmd->data_direction == IPR_DATA_WRITE)
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+
+        if (p_sis_cmd->underflow == 0)
+            p_ioarcb->ioarcb_cmd_pkt.no_underlength_checking = 1;
+
+        if (p_sis_cmd->flags & IPR_CMD_SYNC_OVERRIDE)
+            p_ioarcb->ioarcb_cmd_pkt.cmd_sync_override = 1;
+    }
+    else /* AF DASD or VSET op */
+    {
+        ipr_trc_hook(p_shared_cfg,
+                        cmnd,
+                        IPR_TRACE_START,
+                        IPR_TRACE_DASD,
+                        p_host_ioarcb->host_ioarcb_index,
+                        p_sis_cmd->bufflen,
+                        IPR_GET_PHYSICAL_LOCATOR(p_resource->resource_address));
+
+        if ((cmnd == IPR_READ_10) ||
+            (cmnd == IPR_WRITE_10) ||
+            (cmnd == IPR_WRITE_VERIFY) ||
+            (cmnd == IPR_READ_16) ||
+            (cmnd == IPR_WRITE_16) ||
+            (cmnd == IPR_WRITE_VERIFY_16))
+        {
+            if (p_sis_cmd->bufflen > IPR_MAX_OP_SIZE)
+                panic(IPR_ERR": Too large of an op issued!!!"IPR_EOL);
+
+            ipr_build_ioadl(p_shared_cfg, p_host_ioarcb);
+        }
+        else
+        {
+            if (p_sis_cmd->flags & IPR_IOA_CMD)
+                p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+
+            ipr_build_ioadl(p_shared_cfg, p_host_ioarcb);
+        }
+    }
+
+    writel(sistoh32(p_ioarcb->ioarcb_host_pci_addr),
+           ipr_cfg->regs.ioarrin_reg);
+
+    return 0;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return the model number for a given device
+ * Lock State: io_request_lock assumed to be held
+ * Returns: DASD model number
+ * Note: If updating this, you must also update the same function in sisconfig
+ *---------------------------------------------------------------------------*/
+static u32 ipr_get_model(struct ipr_config_table_entry *p_cfgte)
+{
+    u32 model_number;
+
+    if (p_cfgte->is_ioa_resource)
+        return 1;
+
+    if (p_cfgte->is_array_member)
+    {
+        model_number = 70;
+
+        switch (IPRLIB_GET_CAP_REDUCTION(*p_cfgte))
+        {
+            case IPR_HALF_REDUCTION:
+                model_number += 8;
+                break;
+            case IPR_QUARTER_REDUCTION:
+                model_number += 4;
+                break;
+            case IPR_EIGHTH_REDUCTION:
+                model_number += 2;
+                break;
+            case IPR_SIXTEENTH_REDUCTION:
+                model_number += 1;
+                break;
+            case IPR_UNKNOWN_REDUCTION:
+                model_number += 9;
+                break;
+        }
+    }
+    else if (p_cfgte->is_hot_spare)
+        model_number = IPR_HOST_SPARE_MODEL;
+    else if (p_cfgte->subtype == IPR_SUBTYPE_AF_DASD)
+        model_number = 50;
+    else if (p_cfgte->subtype == IPR_SUBTYPE_GENERIC_SCSI)
+        model_number = 20;
+    else /* Volume set resource */
+        model_number = IPR_VSET_MODEL_NUMBER;
+
+    if (p_cfgte->is_compressed)
+        model_number += 10;
+
+    return model_number;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Do CCN processing
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_handle_config_change(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_hostrcb *p_hostrcb)
+{
+    struct ipr_resource_entry *p_resource_entry = NULL;
+    struct ipr_resource_dll *p_resource_dll;
+    struct ipr_config_table_entry *p_cfgte_buf;
+    struct ipr_lun *p_lun;
+    u8  bus_num;
+    u32 dev_changed = 0;
+    u32 is_ndn = 1;
+
+    p_cfgte_buf = &((struct ipr_hostrcb_cfg_ch_not_bin *)
+                    &p_hostrcb->data.ccn)->cfgte;
+
+    for (p_resource_dll = p_shared_cfg->rsteUsedH;
+         p_resource_dll != NULL;
+         p_resource_dll = p_resource_dll->next)
+    {
+        p_resource_entry = &p_resource_dll->data;
+
+        if (p_resource_entry->resource_handle == p_cfgte_buf->resource_handle)
+        {
+            is_ndn = 0;
+
+            if (!ipr_is_res_addr_valid(&p_cfgte_buf->resource_address))
+            {
+                /* invalid resource address, log message and ignore entry */
+                ipr_log_err("Invalid resource address reported: 0x%08X"IPR_EOL,
+                               IPR_GET_PHYSICAL_LOCATOR(p_cfgte_buf->resource_address));
+
+                ipr_send_hcam(p_shared_cfg,
+                                 IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                                 p_hostrcb);
+                return;
+            }
+
+            bus_num = p_cfgte_buf->resource_address.bus + 1;
+            p_lun = &p_shared_cfg->bus[bus_num].
+                target[p_cfgte_buf->resource_address.target].
+                lun[p_cfgte_buf->resource_address.lun];
+
+            p_lun->p_resource_entry = p_resource_entry;
+
+            if ((p_resource_entry->is_array_member !=
+                 p_cfgte_buf->is_array_member) ||
+                (p_resource_entry->is_compressed !=
+                 p_cfgte_buf->is_compressed) ||
+                (p_lun->expect_ccm))
+            {
+                dev_changed = 1;
+            }
+            break;
+        }
+    }
+
+    if (is_ndn)
+    {
+        /* check if resource address is valid */
+        if (!ipr_is_res_addr_valid(&p_cfgte_buf->resource_address))
+        {
+            /* invalid resource address, log message and ignore entry */
+            ipr_log_err("Invalid resource address reported: 0x%08X"IPR_EOL,
+                           IPR_GET_PHYSICAL_LOCATOR(p_cfgte_buf->resource_address));
+
+            ipr_send_hcam(p_shared_cfg,
+                             IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                             p_hostrcb);
+            return;
+        }
+
+        p_resource_dll = ipr_get_resource_entry(p_shared_cfg);
+
+        if (p_resource_dll == NULL)
+        {
+            ipr_send_hcam(p_shared_cfg,
+                             IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                             p_hostrcb);
+            return;
+        }
+
+        p_resource_entry = &p_resource_dll->data;
+
+        bus_num = p_cfgte_buf->resource_address.bus + 1;
+        p_lun = &p_shared_cfg->bus[bus_num].
+            target[p_cfgte_buf->resource_address.target].
+            lun[p_cfgte_buf->resource_address.lun];
+
+        p_lun->is_valid_entry = 1;
+        p_lun->p_resource_entry = p_resource_entry;
+        p_lun->stop_new_requests = 0;
+        p_lun->dev_changed = 1;
+
+        dev_changed = 1;
+    }
+
+    if (p_hostrcb->notificationType == IPR_HOST_RCB_NOTIF_TYPE_REM_ENTRY)
+    {
+        p_resource_entry = &p_resource_dll->data;
+
+        bus_num = p_resource_entry->resource_address.bus + 1;
+        p_lun = &p_shared_cfg->bus[bus_num].
+            target[p_resource_entry->resource_address.target].
+            lun[p_resource_entry->resource_address.lun];
+
+        p_lun->is_valid_entry = 0;
+        p_lun->p_resource_entry = NULL;
+        p_lun->stop_new_requests = 0;
+        p_lun->dev_changed = 0;
+
+        ipr_put_resource_entry(p_shared_cfg, p_resource_dll);
+        ipr_send_hcam(p_shared_cfg,
+                         IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                         p_hostrcb);
+    }
+    else
+    {
+        ipr_check_backplane(p_shared_cfg, p_cfgte_buf);
+        ipr_update_resource(p_shared_cfg,
+                               p_resource_entry,
+                               p_cfgte_buf,
+                               dev_changed);
+        ipr_init_single_dev_runtime(p_shared_cfg,
+                                       p_resource_entry,
+                                       is_ndn, p_hostrcb);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Update the given device resource
+ * Lock State: io_request_lock assumed to be held
+ * Returns: None
+ *---------------------------------------------------------------------------*/
+static void ipr_update_resource(struct ipr_shared_config *p_shared_cfg,
+                                   struct ipr_resource_entry *p_resource_entry,
+                                   struct ipr_config_table_entry *p_cfgte,
+                                   u32 device_changed)
+{
+    const struct ipr_dev_config *p_dev_cfg;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    char level[2];
+
+    p_resource_entry->is_ioa_resource = p_cfgte->is_ioa_resource;
+    p_resource_entry->is_compressed = p_cfgte->is_compressed;
+    p_resource_entry->is_array_member = p_cfgte->is_array_member;
+    p_resource_entry->is_hot_spare = p_cfgte->is_hot_spare;
+    p_resource_entry->subtype = p_cfgte->subtype;
+    p_resource_entry->resource_address.bus = p_cfgte->resource_address.bus;
+    p_resource_entry->resource_address.target = p_cfgte->resource_address.target;
+    p_resource_entry->resource_address.lun = p_cfgte->resource_address.lun;
+    level[0] = p_cfgte->service_level;
+    level[1] = '\0';
+    p_resource_entry->level = simple_strtoul(level, NULL, 16);
+    p_resource_entry->array_id = p_cfgte->array_id;
+    p_resource_entry->type = ipr_dasd_vpids_to_ccin(&p_cfgte->std_inq_data.vpids, 0x6600);
+    p_resource_entry->model = ipr_get_model(p_cfgte);
+    memcpy(p_resource_entry->serial_num, p_cfgte->std_inq_data.serial_num,
+           IPR_SERIAL_NUM_LEN);
+    p_resource_entry->serial_num[IPR_SERIAL_NUM_LEN] = '\0';
+    p_resource_entry->resource_handle = p_cfgte->resource_handle;
+    p_resource_entry->host_no = p_shared_cfg->host_no;
+    p_resource_entry->std_inq_data = p_cfgte->std_inq_data;
+
+    ipr_update_location_data(p_shared_cfg, p_resource_entry);
+
+    p_resource_entry->is_hidden = 0;
+
+    if (ipr_is_af_dasd_device(p_resource_entry) ||
+        IPR_IS_SES_DEVICE(p_resource_entry->std_inq_data))
+    {
+        p_resource_entry->is_hidden = 1;
+    }
+
+    p_resource_entry->is_af =
+        IPR_IS_DASD_DEVICE(p_resource_entry->std_inq_data) &&
+        (!p_resource_entry->is_ioa_resource) &&
+        ((p_resource_entry->subtype == IPR_SUBTYPE_AF_DASD) ||
+         (p_resource_entry->subtype == IPR_SUBTYPE_VOLUME_SET));
+
+    p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_dev_cfg != NULL)
+    {
+        p_resource_entry->rw_protected = (p_dev_cfg->is_15k_device && ipr_cfg->non15k_ses);
+        p_resource_entry->format_allowed = (!p_dev_cfg->is_15k_device || !ipr_cfg->non15k_ses);
+    }
+    else
+    {
+        p_resource_entry->rw_protected = 0;
+        p_resource_entry->format_allowed = 1;
+    }
+
+    if (p_resource_entry->is_ioa_resource)
+    {
+        p_resource_entry->type = p_shared_cfg->ccin;
+        p_resource_entry->nr_ioa_microcode = p_shared_cfg->nr_ioa_microcode;
+        p_shared_cfg->ioa_resource = *p_resource_entry;
+    }
+
+    if (device_changed)
+    {
+        p_resource_entry->dev_changed = 1;
+        if (p_resource_entry->rw_protected)
+            ipr_log_config_error(p_shared_cfg, 0, p_resource_entry);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Log a configuration error - unsupported attribute
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_log_config_error(struct ipr_shared_config *p_shared_cfg,
+                                    int is_ipl, struct ipr_resource_entry *p_resource)
+{
+    struct ipr_resource_entry *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll;
+    int found = 0;
+
+    if (is_ipl)
+    {
+        for (p_resource_dll = p_shared_cfg->rsteUsedH;
+             p_resource_dll != NULL;
+             p_resource_dll = p_resource_dll->next)
+        {
+            p_resource_entry = &p_resource_dll->data;
+
+            if (p_resource_entry->is_af &&
+                p_resource_entry->rw_protected)
+            {
+                if (found == 0)
+                {
+                    ipr_beg_err(KERN_ERR);
+                    ipr_log_err("Configuration Error. The following devices are"IPR_EOL);
+                    ipr_log_err("not supported in this hardware configuration"IPR_EOL);
+                    ipr_log_err("Refer to the appropriate service documents"IPR_EOL);
+                    ipr_log_err("%-45sSerial #"IPR_EOL, "Device");
+                }
+
+                found = 1;
+                ipr_print_dev(p_shared_cfg, p_resource_entry);
+            }
+        }
+
+        if (found)
+            ipr_end_err(KERN_ERR);
+    }
+    else
+    {
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err("Configuration Error. The following devices are"IPR_EOL);
+        ipr_log_err("not supported in this hardware configuration"IPR_EOL);
+        ipr_log_err("Refer to the appropriate service documents"IPR_EOL);
+        ipr_log_err("%-45sSerial #"IPR_EOL, "Device");
+
+        ipr_print_dev(p_shared_cfg, p_resource);
+        ipr_end_err(KERN_ERR);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print out a string describing a given device
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_print_dev(struct ipr_shared_config *p_shared_cfg,
+                             struct ipr_resource_entry *p_resource)
+{
+    char line[100];
+    u32 size, len;
+    char dev_loc_str[IPR_MAX_LOCATION_LEN];
+
+    ipr_dev_loc_str(p_shared_cfg, p_resource, dev_loc_str);
+
+    size = 0;
+
+    len = sprintf(line, "%-45s", dev_loc_str);
+    size += len;
+    len = sprintf(line + size, "%-11s", p_resource->serial_num);
+    size += len;
+
+    ipr_log_err("%s"IPR_EOL, line);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Prepares devices to run
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Op completed sucessfully
+ *          IPR_RC_FAILED            - Op failed
+ *          IPR_RC_TIMEOUT           - Op timed out
+ *          IPR_RC_XFER_FAILED       - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ              - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST         - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR           - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED     - IOA unit checked
+ *---------------------------------------------------------------------------*/
+static u32 ipr_init_devices(struct ipr_shared_config *p_shared_cfg)
+{
+    u32 rc = IPR_RC_SUCCESS;
+    struct ipr_resource_entry *p_resource_entry;
+    struct ipr_resource_dll *p_resource_dll;
+
+    /* Loop through all the devices */
+    for (p_resource_dll = p_shared_cfg->rsteUsedH;
+         p_resource_dll != NULL;
+         p_resource_dll = p_resource_dll->next)
+    {
+        p_resource_entry = &p_resource_dll->data;
+
+        rc = ipr_init_single_dev(p_shared_cfg, p_resource_entry);
+
+        /* If we get a completion other than success and other than
+         failed, there is a serious problem with the adapter and
+         we want to stop talking to it */
+        if ((rc != IPR_RC_SUCCESS) && (rc != IPR_RC_FAILED))
+        {
+            ipr_trace;
+            return rc;
+        }
+    }
+
+    return IPR_RC_SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Initialize the supported device structure to default values.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *--------------------------------------------------------------------------*/
+static void ipr_set_sup_dev_dflt(struct ipr_supported_device
+                                    *p_supported_device,
+                                    struct ipr_std_inq_vpids *vpids)
+{
+    memset(p_supported_device, 0,
+           sizeof(struct ipr_supported_device));
+    memcpy(&p_supported_device->vpids, vpids,
+           sizeof(struct ipr_std_inq_vpids));
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Initialize a single device
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Op completed sucessfully
+ *          IPR_RC_FAILED            - Op failed
+ *          IPR_RC_TIMEOUT           - Op timed out
+ *          IPR_RC_XFER_FAILED       - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ              - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST         - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR           - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED     - IOA unit checked
+ *---------------------------------------------------------------------------*/
+static u32 ipr_init_single_dev(struct ipr_shared_config *p_shared_cfg,
+                                  struct ipr_resource_entry *p_resource_entry)
+{
+    struct ipr_dasd_timeouts *p_dasd_timeouts;
+    ipr_dma_addr dasd_timeouts_dma;
+    struct ipr_mode_parm_hdr *p_mode_parm, *p_changeable_pages;
+    struct ipr_query_res_state *p_res_query;
+    ipr_dma_addr mode_pages_dma, changeable_pages_dma, page3_inq_dma, res_query_dma;
+    struct ipr_dasd_inquiry_page3 *p_page3_inq;
+    u32 rc = IPR_RC_SUCCESS;
+    u8 alloc_len;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_std_inq_data_long *p_std_inq;
+    struct ipr_ssd_header *p_ssd_header;
+    ipr_dma_addr ssd_header_dma, std_inq_dma;
+    u32 i, in_ssd_list;
+    struct ipr_supported_device *p_supported_device;
+
+    p_dasd_timeouts = &ipr_cfg->p_dasd_init_buf[0]->dasd_timeouts;
+    dasd_timeouts_dma = ipr_cfg->p_dasd_init_buf[0]->dasd_timeouts_dma;
+
+    memcpy(p_dasd_timeouts->record, ipr_dasd_timeout_list,
+           sizeof(ipr_dasd_timeout_list));
+    p_dasd_timeouts->length = htosis32(sizeof(ipr_dasd_timeout_list)
+                                       + sizeof(u32));
+    p_mode_parm = &ipr_cfg->p_dasd_init_buf[0]->mode_pages;
+    mode_pages_dma = ipr_cfg->p_dasd_init_buf[0]->mode_pages_dma;
+    p_changeable_pages = &ipr_cfg->p_dasd_init_buf[0]->changeable_parms;
+    changeable_pages_dma = ipr_cfg->p_dasd_init_buf[0]->changeable_parms_dma;
+    p_std_inq = &ipr_cfg->p_dasd_init_buf[0]->std_inq;
+    std_inq_dma = ipr_cfg->p_dasd_init_buf[0]->std_inq_dma;
+    p_ssd_header = &ipr_cfg->p_dasd_init_buf[0]->ssd_header;
+    ssd_header_dma = ipr_cfg->p_dasd_init_buf[0]->ssd_header_dma;
+    p_page3_inq = &ipr_cfg->p_dasd_init_buf[0]->page3_inq;
+    page3_inq_dma = ipr_cfg->p_dasd_init_buf[0]->page3_inq_dma;
+    p_res_query = &ipr_cfg->p_dasd_init_buf[0]->res_query;
+    res_query_dma = ipr_cfg->p_dasd_init_buf[0]->res_query_dma;
+
+    if (ipr_is_af_dasd_device(p_resource_entry))
+    { /* If this is a DASD */
+
+        memset(p_std_inq, 0, sizeof(struct ipr_std_inq_data_long));
+
+        /* Send Inquiry */
+        rc = ipr_blocking_dasd_cmd(p_shared_cfg, p_resource_entry,
+                                      std_inq_dma,
+                                      IPR_INQUIRY, 0xff,
+                                      sizeof(struct ipr_std_inq_data_long));
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+
+        if (p_std_inq->std_inq_data.version >= 4)
+            p_resource_entry->supports_qas = p_std_inq->qas;
+        else
+            p_resource_entry->supports_qas = 0;
+
+        /* Fill in additional VPD information */
+        memcpy(p_resource_entry->part_number, p_std_inq->part_number,
+               IPR_STD_INQ_PART_NUM_LEN);
+        p_resource_entry->part_number[IPR_STD_INQ_PART_NUM_LEN] = '\0';
+
+        memcpy(p_resource_entry->ec_level, p_std_inq->ec_level,
+               IPR_STD_INQ_EC_LEVEL_LEN);
+        p_resource_entry->ec_level[IPR_STD_INQ_EC_LEVEL_LEN] = '\0';
+
+        memcpy(p_resource_entry->fru_number, p_std_inq->fru_number,
+               IPR_STD_INQ_FRU_NUM_LEN);
+        p_resource_entry->fru_number[IPR_STD_INQ_FRU_NUM_LEN] = '\0';
+
+        memcpy(p_resource_entry->z1_term, p_std_inq->z1_term,
+               IPR_STD_INQ_Z1_TERM_LEN);
+        p_resource_entry->z1_term[IPR_STD_INQ_Z1_TERM_LEN] = '\0';
+
+        memcpy(p_resource_entry->z2_term, p_std_inq->z2_term,
+               IPR_STD_INQ_Z2_TERM_LEN);
+        p_resource_entry->z2_term[IPR_STD_INQ_Z2_TERM_LEN] = '\0';
+
+        memcpy(p_resource_entry->z3_term, p_std_inq->z3_term,
+               IPR_STD_INQ_Z3_TERM_LEN);
+        p_resource_entry->z3_term[IPR_STD_INQ_Z3_TERM_LEN] = '\0';
+
+        memcpy(p_resource_entry->z4_term, p_std_inq->z4_term,
+               IPR_STD_INQ_Z4_TERM_LEN);
+        p_resource_entry->z4_term[IPR_STD_INQ_Z4_TERM_LEN] = '\0';
+
+        memcpy(p_resource_entry->z5_term, p_std_inq->z5_term,
+               IPR_STD_INQ_Z5_TERM_LEN);
+        p_resource_entry->z5_term[IPR_STD_INQ_Z5_TERM_LEN] = '\0';
+
+        memcpy(p_resource_entry->z6_term, p_std_inq->z6_term,
+               IPR_STD_INQ_Z6_TERM_LEN);
+        p_resource_entry->z6_term[IPR_STD_INQ_Z6_TERM_LEN] = '\0';
+
+        /* Check if device in default ssd list */
+        for (i = 0,
+             in_ssd_list = 0;
+             i < sizeof(ipr_supported_dev_list)/
+                 sizeof(struct ipr_supported_device);
+             i++)
+        {
+            if (memcmp(&ipr_supported_dev_list_ptr[i].vpids,
+                              &p_std_inq->std_inq_data.vpids,
+                              sizeof(struct ipr_std_inq_vpids)) == 0)
+            {
+                in_ssd_list = 1;
+                break;
+            }
+        }
+
+        /* Send Set Supported Devices command only if device
+         is not in Set Supported Devices table. Sending it down all
+         the time would break the 15K blocking code. */
+        if (!in_ssd_list)
+        {
+            /* Send Set Supported Device */
+            p_ssd_header->num_records = 1;
+            p_ssd_header->data_length =
+                htosis16(sizeof(struct ipr_supported_device) +
+                         sizeof(struct ipr_ssd_header));
+            p_ssd_header->reserved = 0;
+
+            p_supported_device = &ipr_cfg->p_dasd_init_buf[0]->supported_device;
+
+            ipr_set_sup_dev_dflt(p_supported_device,
+                                    &p_std_inq->std_inq_data.vpids);
+
+            rc = ipr_send_blocking_cmd(p_shared_cfg,
+                                          IPR_SET_SUPPORTED_DEVICES,
+                                          IPR_SET_SUP_DEVICE_TIMEOUT,
+                                          0, p_ssd_header,
+                                          ssd_header_dma,
+                                          sistoh16(p_ssd_header->data_length));
+            if (rc != IPR_RC_SUCCESS)
+            {
+                ipr_trace;
+                goto leave;
+            }
+        }
+
+        /* Issue a Set DASD Timeouts */
+        rc = ipr_blocking_dasd_cmd(p_shared_cfg, p_resource_entry,
+                                      dasd_timeouts_dma,
+                                      IPR_SET_DASD_TIMEOUTS, 0,
+                                      sistoh32(p_dasd_timeouts->length));
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+
+        memset(p_page3_inq, 0, sizeof(struct ipr_dasd_inquiry_page3));
+
+        /* Issue a page 3 inquiry for software VPD */
+        rc = ipr_blocking_dasd_cmd(p_shared_cfg, p_resource_entry, page3_inq_dma,
+                                      IPR_INQUIRY, 3, sizeof(struct ipr_dasd_inquiry_page3));
+
+        if (rc == IPR_RC_SUCCESS)
+        {
+            /* Fill in the software load id and release level */
+            p_resource_entry->sw_load_id =
+                (p_page3_inq->load_id[0] << 24) |
+                (p_page3_inq->load_id[1] << 16) |
+                (p_page3_inq->load_id[2] << 8) |
+                (p_page3_inq->load_id[3]);
+
+            p_resource_entry->sw_release_level =
+                (p_page3_inq->release_level[0] << 24) |
+                (p_page3_inq->release_level[1] << 16) |
+                (p_page3_inq->release_level[2] << 8) |
+                (p_page3_inq->release_level[3]);
+        }
+
+        memset(p_mode_parm, 0, 255);
+
+        /* Issue a mode sense to get current mode pages */
+        rc = ipr_blocking_dasd_cmd(p_shared_cfg, p_resource_entry, mode_pages_dma,
+                                      IPR_MODE_SENSE, 0x3f, 255);
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+
+        memset(p_changeable_pages, 0, 255);
+
+        /* Issue mode sense to get the changeable parms */
+        rc = ipr_blocking_dasd_cmd(p_shared_cfg, p_resource_entry, changeable_pages_dma,
+                                      IPR_MODE_SENSE, 0x7f, 255);
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+
+        /* Modify mode pages */
+        alloc_len = ipr_set_mode_pages(p_shared_cfg, p_resource_entry,
+                                          p_mode_parm, p_changeable_pages);
+
+        /* Issue mode select */
+        rc = ipr_blocking_dasd_cmd(p_shared_cfg, p_resource_entry, mode_pages_dma,
+                                      IPR_MODE_SELECT, 0x11, alloc_len);
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+    }
+    else if (ipr_is_vset_device(p_resource_entry))
+    {
+        /* Issue start unit */
+        rc = ipr_blocking_vset_cmd(p_shared_cfg, p_resource_entry,
+                                      0, IPR_START_STOP,
+                                      IPR_START_STOP_START, 0);
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+
+        /* Issue query resource state */
+        rc = ipr_blocking_vset_cmd(p_shared_cfg, p_resource_entry,
+                                      res_query_dma, IPR_QUERY_RESOURCE_STATE,
+                                      0, sizeof(struct ipr_query_res_state));
+
+        if (rc != IPR_RC_SUCCESS)
+        {
+            ipr_trace;
+            goto leave;
+        }
+
+        p_resource_entry->model = IPR_VSET_MODEL_NUMBER +
+            simple_strtoul(p_res_query->protection_level_str, NULL, 10);
+    }
+
+    leave:
+        return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Initialize a single device - first job step
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Failure
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+static u32 ipr_init_single_dev_runtime(struct ipr_shared_config *p_shared_cfg,
+                                          struct ipr_resource_entry *p_resource_entry,
+                                          u32 is_ndn,
+                                          struct ipr_hostrcb *p_hostrcb)
+{
+    struct ipr_ccb *p_sis_ccb;
+    u32 rc = IPR_RC_SUCCESS;
+    struct ipr_dasd_init_bufs *p_dasd_init_buf;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    if (ipr_is_af_dasd_device(p_resource_entry) ||
+        ipr_is_vset_device(p_resource_entry))
+    { /* If this is a AF DASD or VSET */
+
+        if (p_resource_entry->in_init)
+        {
+            /* We got another config change for this device while we were in
+             our bringup job. This will simply force us to start over from the beginning */
+            p_resource_entry->redo_init = 1;
+            ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                             p_hostrcb);
+        }
+        else
+        {
+            p_sis_ccb = ipr_allocate_ccb(p_shared_cfg);
+
+            if (p_sis_ccb == NULL)
+            {
+                /* Requests must not be allowed right now - we are probably going through
+                 reset/reload right now */
+                ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                                 p_hostrcb);
+                return IPR_RC_FAILED;
+            }
+
+            p_dasd_init_buf = ipr_get_dasd_init_buffer(ipr_cfg);
+
+            if (p_dasd_init_buf == NULL)
+            {
+                /* This should be dead code - we should not be able to hit this */
+                ipr_log_err("Failed to allocate dasd init buffer"IPR_EOL);
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+                ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                                 p_hostrcb);
+                return IPR_RC_FAILED;
+            }
+
+            p_resource_entry->in_init = 1;
+            p_sis_ccb->p_resource = p_resource_entry;
+            p_sis_ccb->p_scratch = p_dasd_init_buf;
+            p_dasd_init_buf->p_hostrcb = p_hostrcb;
+            p_dasd_init_buf->p_dev_res = p_resource_entry;
+
+            if (ipr_is_af_dasd_device(p_resource_entry))
+            {
+                p_sis_ccb->job_step = IPR_DINIT_START;
+                ipr_dasd_init_job(p_shared_cfg, p_sis_ccb);
+            }
+            else
+            {
+                p_sis_ccb->job_step = IPR_VINIT_START;
+                ipr_vset_init_job(p_shared_cfg, p_sis_ccb);
+            }
+
+        }
+    }
+    else if
+        (IPR_IS_SES_DEVICE(p_resource_entry->std_inq_data) && is_ndn &&
+         (ipr_arch == IPR_ARCH_ISERIES))
+    {
+        rc = ipr_build_slot_map_runtime(p_shared_cfg, p_resource_entry,
+                                           p_hostrcb);
+    }
+    else
+    {
+        ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                         p_hostrcb);
+    }
+
+    return rc;
+}
+
+#ifdef IPR_DEBUG_MODE_PAGES
+/*---------------------------------------------------------------------------
+ * Purpose: Prints out a mode sense buffer for debug purposes
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_print_mode_sense_buffer(struct ipr_mode_parm_hdr *p_mode_parm)
+{
+    int i;
+    static u8 buffer[4096];
+    u8 *p_buf = (u8*)p_mode_parm;
+    u32 count = 0;
+
+    for (i = 0; i < p_mode_parm->length + 1; i++)
+        count += sprintf(buffer + count, " %02x", p_buf[i]);
+    printk("Mode sense buffer: %s"IPR_EOL, buffer);
+}
+#endif
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send an op to a DASD resource and sleep until its completion
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Op completed sucessfully
+ *          IPR_RC_FAILED            - Op failed
+ *          IPR_RC_TIMEOUT           - Op timed out
+ *          IPR_RC_XFER_FAILED       - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ              - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST         - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR           - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED     - IOA unit checked
+ *---------------------------------------------------------------------------*/
+static int ipr_blocking_dasd_cmd(struct ipr_shared_config *p_shared_cfg,
+                                    struct ipr_resource_entry *p_resource_entry,
+                                    ipr_dma_addr dma_buffer,
+                                    u8 cmd, u8 parm, u16 alloc_len)
+{
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_ioadl_desc *p_ioadl;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    int rc = IPR_RC_SUCCESS;
+    int timeout = IPR_INTERNAL_DEV_TIMEOUT;
+    char cmd_str[50];
+
+    p_host_ioarcb = ipr_get_free_host_ioarcb(p_shared_cfg);
+    p_ioarcb = &p_host_ioarcb->ioarcb; 
+    p_ioadl = p_host_ioarcb->p_ioadl;
+    p_ioarcb->ioarcb_cmd_pkt.cdb[0] = cmd;
+    p_ioarcb->ioa_res_handle = p_resource_entry->resource_handle;
+    p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_SCSICDB;
+
+    switch(cmd)
+    {
+        case IPR_MODE_SENSE:
+            p_ioarcb->ioarcb_cmd_pkt.cdb[2] = parm; 
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = alloc_len;
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | alloc_len);
+            p_ioadl->address = htosis32((u32)dma_buffer);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(alloc_len);
+            strcpy(cmd_str, "Mode Sense");
+            break;
+        case IPR_MODE_SELECT:
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[1] = parm;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = alloc_len;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_WR_LAST_DATA | alloc_len);
+            p_ioadl->address = htosis32((u32)dma_buffer);
+            p_ioarcb->write_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->write_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->write_data_transfer_length = htosis32(alloc_len);
+            strcpy(cmd_str, "Mode Select");
+            break;
+        case IPR_SET_DASD_TIMEOUTS:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_WR_LAST_DATA | alloc_len);
+            p_ioadl->address = htosis32((u32)dma_buffer);
+            p_ioarcb->write_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->write_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->write_data_transfer_length = htosis32(alloc_len);
+            p_ioarcb->ioarcb_cmd_pkt.cdb[7] = (alloc_len >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[8] = alloc_len & 0xff;
+            strcpy(cmd_str, "Set Dasd Timeouts");
+            break;
+        case IPR_INQUIRY:
+            if (parm != 0xff)
+            {
+                p_ioarcb->ioarcb_cmd_pkt.cdb[1] = 0x01;
+                p_ioarcb->ioarcb_cmd_pkt.cdb[2] = parm; 
+            }
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = alloc_len;
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | alloc_len);
+            p_ioadl->address = htosis32((u32)dma_buffer);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(alloc_len);
+            strcpy(cmd_str, "Inquiry");
+            break;
+        default:
+            panic(IPR_ERR": Invalid blocking dasd command 0x%02X"IPR_EOL, cmd);
+            break;
+    };
+
+    ipr_trc_hook(p_shared_cfg,
+                    cmd,
+                    IPR_TRACE_START,
+                    IPR_TRACE_DASD,
+                    p_host_ioarcb->host_ioarcb_index,
+                    alloc_len,
+                    IPR_GET_PHYSICAL_LOCATOR(p_resource_entry->resource_address));
+
+    /* Poke the IOARRIN with the PCI address of the IOARCB */
+    writel(sistoh32(p_ioarcb->ioarcb_host_pci_addr), ipr_cfg->regs.ioarrin_reg);
+
+    rc = ipr_poll_isr(p_shared_cfg, timeout);
+
+    ipr_trc_hook(p_shared_cfg,
+                    cmd,
+                    IPR_TRACE_FINISH,
+                    IPR_TRACE_DASD,
+                    p_host_ioarcb->host_ioarcb_index,
+                    alloc_len,
+                    sistoh32(p_host_ioarcb->p_ioasa->ioasc));
+
+    if (rc == IPR_RC_TIMEOUT)
+    {
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err("%s timed out!!"IPR_EOL, cmd_str);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_end_err(KERN_ERR);
+        return rc;
+    }
+    else if (sistoh32(p_host_ioarcb->p_ioasa->ioasc) != 0)
+    {
+        /* Don't log an error if page 3 inquiry fails */
+        if (ipr_debug && ((cmd != IPR_INQUIRY) || (parm != 3)))
+        {
+            ipr_beg_err(KERN_ERR);
+            ipr_log_err("%s failed with IOASC: 0x%08X"IPR_EOL,
+                           cmd_str, sistoh32(p_host_ioarcb->p_ioasa->ioasc));
+            ipr_log_err("Controlling IOA:"IPR_EOL);
+            ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+            ipr_log_err("Failing device:"IPR_EOL);
+            ipr_log_dev_physical_location(p_shared_cfg,
+                                             p_resource_entry->resource_address,
+                                             KERN_ERR);
+            ipr_end_err(KERN_ERR);
+        }
+
+        if (rc == IPR_RC_SUCCESS)
+            rc = IPR_RC_FAILED;
+    }
+
+    ipr_remove_host_ioarcb_from_pending(ipr_cfg, p_host_ioarcb);
+    ipr_put_host_ioarcb_to_free(ipr_cfg, p_host_ioarcb);
+
+    return rc;
+
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send an op to a VSET resource and sleep until its completion
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Op completed sucessfully
+ *          IPR_RC_FAILED            - Op failed
+ *          IPR_RC_TIMEOUT           - Op timed out
+ *          IPR_RC_XFER_FAILED       - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ              - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST         - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR           - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED     - IOA unit checked
+ *---------------------------------------------------------------------------*/
+static int ipr_blocking_vset_cmd(struct ipr_shared_config *p_shared_cfg,
+                                    struct ipr_resource_entry *p_resource_entry,
+                                    ipr_dma_addr dma_buffer,
+                                    u8 cmd, u8 parm, u16 alloc_len)
+{
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_ioadl_desc *p_ioadl;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    int rc = IPR_RC_SUCCESS;
+    int timeout = IPR_INTERNAL_DEV_TIMEOUT;
+    char cmd_str[50];
+
+    p_host_ioarcb = ipr_get_free_host_ioarcb(p_shared_cfg);
+    p_ioarcb = &p_host_ioarcb->ioarcb; 
+    p_ioadl = p_host_ioarcb->p_ioadl;
+    p_ioarcb->ioarcb_cmd_pkt.cdb[0] = cmd;
+    p_ioarcb->ioa_res_handle = p_resource_entry->resource_handle;
+    p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_SCSICDB;
+
+    switch(cmd)
+    {
+        case IPR_START_STOP:
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = parm;
+            strcpy(cmd_str, "Start/Stop unit");
+            break;
+        case IPR_QUERY_RESOURCE_STATE:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[7] = (alloc_len >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[8] = alloc_len & 0xff;
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | alloc_len);
+            p_ioadl->address = htosis32((u32)dma_buffer);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(alloc_len);
+            strcpy(cmd_str, "Query resource state");
+            break;
+        default:
+            panic(IPR_ERR": Invalid blocking vset command 0x%02X"IPR_EOL, cmd);
+            break;
+    };
+
+    ipr_trc_hook(p_shared_cfg,
+                    cmd,
+                    IPR_TRACE_START,
+                    IPR_TRACE_DASD,
+                    p_host_ioarcb->host_ioarcb_index,
+                    alloc_len,
+                    IPR_GET_PHYSICAL_LOCATOR(p_resource_entry->resource_address));
+
+    /* Poke the IOARRIN with the PCI address of the IOARCB */
+    writel(sistoh32(p_ioarcb->ioarcb_host_pci_addr), ipr_cfg->regs.ioarrin_reg);
+
+    rc = ipr_poll_isr(p_shared_cfg, timeout);
+
+    ipr_trc_hook(p_shared_cfg,
+                    cmd,
+                    IPR_TRACE_FINISH,
+                    IPR_TRACE_DASD,
+                    p_host_ioarcb->host_ioarcb_index,
+                    alloc_len,
+                    sistoh32(p_host_ioarcb->p_ioasa->ioasc));
+
+    if (rc == IPR_RC_TIMEOUT)
+    {
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err("%s timed out!!"IPR_EOL, cmd_str);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_end_err(KERN_ERR);
+        return rc;
+    }
+    else if (ipr_debug && (sistoh32(p_host_ioarcb->p_ioasa->ioasc) != 0))
+    {
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err("%s failed with IOASC: 0x%08X"IPR_EOL,
+                       cmd_str, sistoh32(p_host_ioarcb->p_ioasa->ioasc));
+        ipr_log_err("Controlling IOA:"IPR_EOL);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_log_err("Failing device:"IPR_EOL);
+        ipr_log_dev_physical_location(p_shared_cfg,
+                                         p_resource_entry->resource_address,
+                                         KERN_ERR);
+        ipr_end_err(KERN_ERR);
+
+        if (rc == IPR_RC_SUCCESS)
+            rc = IPR_RC_FAILED;
+    }
+
+    ipr_remove_host_ioarcb_from_pending(ipr_cfg, p_host_ioarcb);
+    ipr_put_host_ioarcb_to_free(ipr_cfg, p_host_ioarcb);
+
+    return rc;
+
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Job router for DASD initialization
+ * Lock State: io_request_lock assumed to be held
+ * Context: Interrupt level
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_dasd_init_job(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_ccb *p_sis_ccb)
+{
+    struct ipr_mode_parm_hdr *p_mode_parm, *p_changeable_pages;
+    struct ipr_dasd_inquiry_page3 *p_page3_inq;
+    struct ipr_dasd_timeouts *p_dasd_timeouts;
+    struct ipr_query_res_state *p_res_query;
+    u8 alloc_len;
+    struct ipr_resource_entry *p_resource_entry;
+    u32 rc = IPR_RC_SUCCESS;
+    int done = 0;
+    struct ipr_dasd_init_bufs *p_dasd_init_buf = p_sis_ccb->p_scratch;
+    struct ipr_hostrcb *p_hostrcb = p_dasd_init_buf->p_hostrcb;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_std_inq_data_long *p_std_inq;
+    struct ipr_ssd_header *p_ssd_header;
+    struct ipr_supported_device *p_supported_device;
+    int i, in_ssd_list;
+    bool continue_with_job = true;
+
+    rc = p_sis_ccb->completion;
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        p_resource_entry = p_sis_ccb->p_resource;
+
+        /* We have a valid sense buffer */
+        if (ipr_sense_valid(p_sis_ccb->sense_buffer[0]))
+        {
+            if ((p_sis_ccb->sense_buffer[2] & 0xf) != 0)
+            {
+                rc = IPR_RC_FAILED;
+                IPR_DBG_CMD(ipr_beg_err(KERN_ERR));
+                ipr_dbg_err("0x%02x failed with SK: 0x%X ASC: 0x%X ASCQ: 0x%X"IPR_EOL,
+                               p_sis_ccb->cdb[0], (p_sis_ccb->sense_buffer[2] & 0xf),
+                               p_sis_ccb->sense_buffer[12], p_sis_ccb->sense_buffer[13]);
+                ipr_dbg_err("Failing device"IPR_EOL);
+                IPR_DBG_CMD(ipr_log_dev_physical_location(p_shared_cfg,
+                                                                p_resource_entry->resource_address,
+                                                                KERN_ERR));
+                ipr_dbg_err("Controlling IOA"IPR_EOL);
+                IPR_DBG_CMD(ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR));
+                IPR_DBG_CMD(ipr_end_err(KERN_ERR));
+            }
+        }
+    }
+
+    p_resource_entry = p_dasd_init_buf->p_dev_res;
+
+    while (continue_with_job)
+    {
+        continue_with_job = false;
+
+        switch (p_sis_ccb->job_step)
+        {
+            case IPR_DINIT_START:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    /* Send standard inquiry */
+                    p_std_inq = &p_dasd_init_buf->std_inq;
+
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_std_inq,
+                                         p_dasd_init_buf->std_inq_dma,
+                                         IPR_INQUIRY, 0xff,
+                                         sizeof(struct ipr_std_inq_data_long),
+                                         IPR_DINIT_STD_INQUIRY);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    done = 1;
+                    ipr_trace;
+                }
+                break;
+            case IPR_DINIT_STD_INQUIRY:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_std_inq = &p_dasd_init_buf->std_inq;
+
+                    if (p_std_inq->std_inq_data.version >= 4)
+                        p_resource_entry->supports_qas = p_std_inq->qas;
+                    else
+                        p_resource_entry->supports_qas = 0;
+
+                    /* Fill in additional VPD information */
+                    memcpy(p_resource_entry->part_number, p_std_inq->part_number,
+                           IPR_STD_INQ_PART_NUM_LEN);
+                    p_resource_entry->part_number[IPR_STD_INQ_PART_NUM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->ec_level, p_std_inq->ec_level,
+                           IPR_STD_INQ_EC_LEVEL_LEN);
+                    p_resource_entry->ec_level[IPR_STD_INQ_EC_LEVEL_LEN] = '\0';
+
+                    memcpy(p_resource_entry->fru_number, p_std_inq->fru_number,
+                           IPR_STD_INQ_FRU_NUM_LEN);
+                    p_resource_entry->fru_number[IPR_STD_INQ_FRU_NUM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->z1_term, p_std_inq->z1_term,
+                           IPR_STD_INQ_Z1_TERM_LEN);
+                    p_resource_entry->z1_term[IPR_STD_INQ_Z1_TERM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->z2_term, p_std_inq->z2_term,
+                           IPR_STD_INQ_Z2_TERM_LEN);
+                    p_resource_entry->z2_term[IPR_STD_INQ_Z2_TERM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->z3_term, p_std_inq->z3_term,
+                           IPR_STD_INQ_Z3_TERM_LEN);
+                    p_resource_entry->z3_term[IPR_STD_INQ_Z3_TERM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->z4_term, p_std_inq->z4_term,
+                           IPR_STD_INQ_Z4_TERM_LEN);
+                    p_resource_entry->z4_term[IPR_STD_INQ_Z4_TERM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->z5_term, p_std_inq->z5_term,
+                           IPR_STD_INQ_Z5_TERM_LEN);
+                    p_resource_entry->z5_term[IPR_STD_INQ_Z5_TERM_LEN] = '\0';
+
+                    memcpy(p_resource_entry->z6_term, p_std_inq->z6_term,
+                           IPR_STD_INQ_Z6_TERM_LEN);
+                    p_resource_entry->z6_term[IPR_STD_INQ_Z6_TERM_LEN] = '\0';
+
+                    p_res_query = &p_dasd_init_buf->res_query;
+
+                    /* Issue a query resource state to determine the state of the device */
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_res_query,
+                                         p_dasd_init_buf->res_query_dma,
+                                         IPR_QUERY_RESOURCE_STATE, 0,
+                                         sizeof(struct ipr_query_res_state),
+                                         IPR_DINIT_QUERY_RESOURCE_STATE);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    done = 1;
+                    ipr_trace;
+                }
+                break;
+            case IPR_DINIT_QUERY_RESOURCE_STATE:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_res_query = &p_dasd_init_buf->res_query;
+
+                    /* If the DASD is not healthy, then lets not send the rest of these
+                     bringup commands. In order for the host to talk to the device it will
+                     need to issue a recovery command which we would end up getting a config
+                     change for which would force us through here again anyway. */
+                    if (p_res_query->not_oper || p_res_query->not_ready ||
+                        p_res_query->read_write_prot)
+                    {
+                        done = 1;
+                        ipr_trace;
+                    }
+                    else
+                    {
+                        /* Check if device on current ssd list */
+                        p_std_inq = &p_dasd_init_buf->std_inq;
+
+                        for (i = 0,
+                             in_ssd_list = 0;
+                             i < sizeof(ipr_supported_dev_list)/
+                                 sizeof(struct ipr_supported_device);
+                             i++)
+                        {
+                            if (memcmp(&ipr_supported_dev_list_ptr[i].vpids,
+                                              &p_std_inq->std_inq_data.vpids,
+                                              sizeof(struct ipr_std_inq_vpids)) == 0)
+                            {
+                                in_ssd_list = 1;
+                                break;
+                            }
+                        }
+
+                        /* Send Set Supported Devices command only if device
+                         is not in Set Supported Devices table. Sending it
+                         down all the time would break the 15K blocking code.*/
+                        if (!in_ssd_list)
+                        {
+                            p_ssd_header = &p_dasd_init_buf->ssd_header;
+                            p_ssd_header->num_records = 1;
+                            p_ssd_header->data_length =
+                                htosis16(sizeof(struct ipr_supported_device) +
+                                         sizeof(struct ipr_ssd_header));
+                            p_ssd_header->reserved = 0;
+
+                            p_supported_device = &p_dasd_init_buf->supported_device;
+
+                            ipr_set_sup_dev_dflt(p_supported_device,
+                                                    &p_std_inq->std_inq_data.vpids);
+
+                            rc = ipr_ioa_req(p_shared_cfg,
+                                                ipr_dasd_init_job,
+                                                p_dasd_init_buf,
+                                                p_ssd_header,
+                                                p_dasd_init_buf->ssd_header_dma,
+                                                IPR_SET_SUPPORTED_DEVICES, 0,
+                                                sistoh16(p_ssd_header->data_length),
+                                                IPR_DINIT_SET_SUPPORTED_DEVICE);
+
+                            if (rc != IPR_RC_SUCCESS)
+                                done = 1;
+                        }
+                        else
+                        {
+                            p_sis_ccb = ipr_allocate_ccb(p_shared_cfg);
+
+                            if (p_sis_ccb == NULL)
+                                done = 1;
+                            else
+                            {
+                                p_sis_ccb->job_step = IPR_DINIT_SET_SUPPORTED_DEVICE;
+                                continue_with_job = true;
+                            }
+                        }
+
+                        if (rc != IPR_RC_SUCCESS)
+                            done = 1;
+                    }
+                }
+                else
+                {
+                    done = 1;
+                    ipr_trace;
+                }
+                break;
+            case IPR_DINIT_SET_SUPPORTED_DEVICE:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_dasd_timeouts = &p_dasd_init_buf->dasd_timeouts;
+
+                    memcpy(p_dasd_timeouts->record, ipr_dasd_timeout_list,
+                           sizeof(ipr_dasd_timeout_list));
+                    p_dasd_timeouts->length = htosis32(sizeof(ipr_dasd_timeout_list) + sizeof(u32));
+
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_dasd_timeouts,
+                                         p_dasd_init_buf->dasd_timeouts_dma,
+                                         IPR_SET_DASD_TIMEOUTS, 0, sistoh32(p_dasd_timeouts->length),
+                                         IPR_DINIT_DASD_INIT_SET_DASD_TIMEOUTS);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    done = 1;
+                    ipr_trace;
+                }
+                break;
+            case IPR_DINIT_DASD_INIT_SET_DASD_TIMEOUTS:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_page3_inq = &p_dasd_init_buf->page3_inq;
+
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_page3_inq,
+                                         p_dasd_init_buf->page3_inq_dma,
+                                         IPR_INQUIRY, 3, sizeof(struct ipr_dasd_inquiry_page3),
+                                         IPR_DINIT_PAGE3_INQ);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    done = 1;
+                    ipr_trace;
+                }
+                break;
+            case IPR_DINIT_PAGE3_INQ:
+                p_page3_inq = &p_dasd_init_buf->page3_inq;
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    /* Fill in the software load id and release level */
+                    p_resource_entry->sw_load_id =
+                        (p_page3_inq->load_id[0] << 24) |
+                        (p_page3_inq->load_id[1] << 16) |
+                        (p_page3_inq->load_id[2] << 8) |
+                        (p_page3_inq->load_id[3]);
+
+                    p_resource_entry->sw_release_level =
+                        (p_page3_inq->release_level[0] << 24) |
+                        (p_page3_inq->release_level[1] << 16) |
+                        (p_page3_inq->release_level[2] << 8) |
+                        (p_page3_inq->release_level[3]);
+                }
+
+                /* Some xSeries DASD may not handle Page 3 inquiry, so
+                 we want to keep going if this is the case */
+                if ((rc != IPR_RC_DID_RESET) && !p_resource_entry->redo_init)
+                {
+                    p_mode_parm = &p_dasd_init_buf->mode_pages;
+
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_mode_parm,
+                                         p_dasd_init_buf->mode_pages_dma,
+                                         IPR_MODE_SENSE, 0x3f, 255,
+                                         IPR_DINIT_MODE_SENSE_CUR);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    ipr_trace;
+                    done = 1;
+                }
+                break;
+            case IPR_DINIT_MODE_SENSE_CUR:
+                p_mode_parm = &p_dasd_init_buf->mode_pages;
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_changeable_pages = &p_dasd_init_buf->changeable_parms;
+
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_changeable_pages,
+                                         p_dasd_init_buf->changeable_parms_dma,
+                                         IPR_MODE_SENSE, 0x7f, 255,
+                                         IPR_DINIT_MODE_SENSE_CHANGEABLE);
+
+                    if (rc != IPR_RC_SUCCESS)
+                    {
+                        ipr_trace;
+                        done = 1;
+                    }
+                }
+                else
+                {
+                    ipr_trace;
+                    done = 1;
+                }
+                break;
+            case IPR_DINIT_MODE_SENSE_CHANGEABLE:
+                p_mode_parm = &p_dasd_init_buf->mode_pages;
+                p_changeable_pages = &p_dasd_init_buf->changeable_parms;
+
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    /* Modify mode pages */
+                    alloc_len = ipr_set_mode_pages(p_shared_cfg, p_resource_entry,
+                                                      p_mode_parm, p_changeable_pages);
+
+                    rc = ipr_dasd_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_mode_parm,
+                                         p_dasd_init_buf->mode_pages_dma,
+                                         IPR_MODE_SELECT, 0x11, alloc_len,
+                                         IPR_DINIT_MODE_SELECT);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    ipr_trace;
+                    done = 1;
+                }
+                break;
+            case IPR_DINIT_MODE_SELECT:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+                done = 1;
+                break;
+            default:
+                break;
+        }
+    }
+
+    if (done)
+    {
+        p_resource_entry->in_init = 0;
+
+        ipr_put_dasd_init_buffer(ipr_cfg, p_dasd_init_buf);
+
+        if (p_resource_entry->redo_init)
+        {
+            p_resource_entry->redo_init = 0;
+            ipr_init_single_dev_runtime(p_shared_cfg, p_resource_entry, 0, p_hostrcb);
+        }
+        else
+        {
+            ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                             p_hostrcb);
+        }
+    }
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Job router for VSET initialization
+ * Lock State: io_request_lock assumed to be held
+ * Context: Interrupt level
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_vset_init_job(struct ipr_shared_config *p_shared_cfg,
+                                 struct ipr_ccb *p_sis_ccb)
+{
+    struct ipr_query_res_state *p_res_query;
+    struct ipr_resource_entry *p_resource_entry;
+    u32 rc = IPR_RC_SUCCESS;
+    int done = 0;
+    struct ipr_dasd_init_bufs *p_dasd_init_buf = p_sis_ccb->p_scratch;
+    struct ipr_hostrcb *p_hostrcb = p_dasd_init_buf->p_hostrcb;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    bool continue_with_job = true;
+
+    rc = p_sis_ccb->completion;
+
+    if (rc != IPR_RC_SUCCESS)
+    {
+        p_resource_entry = p_sis_ccb->p_resource;
+
+        /* We have a valid sense buffer */
+        if (ipr_sense_valid(p_sis_ccb->sense_buffer[0]))
+        {
+            if ((p_sis_ccb->sense_buffer[2] & 0xf) != 0)
+            {
+                rc = IPR_RC_FAILED;
+                IPR_DBG_CMD(ipr_beg_err(KERN_ERR));
+                ipr_dbg_err("0x%02x failed with SK: 0x%X ASC: 0x%X ASCQ: 0x%X"IPR_EOL,
+                               p_sis_ccb->cdb[0], (p_sis_ccb->sense_buffer[2] & 0xf),
+                               p_sis_ccb->sense_buffer[12], p_sis_ccb->sense_buffer[13]);
+                ipr_dbg_err("Failing device"IPR_EOL);
+                IPR_DBG_CMD(ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR));
+                IPR_DBG_CMD(ipr_end_err(KERN_ERR));
+            }
+        }
+    }
+
+    p_resource_entry = p_dasd_init_buf->p_dev_res;
+
+    while (continue_with_job)
+    {
+        continue_with_job = false;
+
+        switch (p_sis_ccb->job_step)
+        {
+            case IPR_VINIT_START:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_res_query = &p_dasd_init_buf->res_query;
+
+                    /* Issue a query resource state to determine the state of the device */
+                    rc = ipr_vset_req(p_shared_cfg, p_resource_entry,
+                                         p_dasd_init_buf,
+                                         p_res_query,
+                                         p_dasd_init_buf->res_query_dma,
+                                         IPR_QUERY_RESOURCE_STATE, 0,
+                                         sizeof(struct ipr_query_res_state),
+                                         IPR_VINIT_QUERY_RESOURCE_STATE);
+
+                    if (rc != IPR_RC_SUCCESS)
+                        done = 1;
+                }
+                else
+                {
+                    done = 1;
+                    ipr_trace;
+                }
+                break;
+            case IPR_VINIT_QUERY_RESOURCE_STATE:
+                ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+                done = 1;
+
+                if ((rc == IPR_RC_SUCCESS) && !p_resource_entry->redo_init)
+                {
+                    p_res_query = &p_dasd_init_buf->res_query;
+
+                    p_resource_entry->model = IPR_VSET_MODEL_NUMBER +
+                        simple_strtoul(p_res_query->protection_level_str, NULL, 10);
+                }
+                else
+                    ipr_trace;
+                break;
+            default:
+                break;
+        }
+    }
+
+    if (done)
+    {
+        p_resource_entry->in_init = 0;
+
+        ipr_put_dasd_init_buffer(ipr_cfg, p_dasd_init_buf);
+
+        if (p_resource_entry->redo_init)
+        {
+            p_resource_entry->redo_init = 0;
+            ipr_init_single_dev_runtime(p_shared_cfg, p_resource_entry, 0, p_hostrcb);
+        }
+        else
+        {
+            ipr_send_hcam(p_shared_cfg, IPR_HCAM_CDB_OP_CODE_CONFIG_CHANGE,
+                             p_hostrcb);
+        }
+    }
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send an op to a DASD resource.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Failure
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+static int ipr_dasd_req(struct ipr_shared_config *p_shared_cfg,
+                           struct ipr_resource_entry *p_resource_entry,
+                           struct ipr_dasd_init_bufs *p_dasd_init_buf,
+                           void *p_buffer,
+                           ipr_dma_addr dma_addr,
+                           u8 cmd, u8 parm, u16 alloc_len, u8 job_step)
+{
+    struct ipr_ccb *p_sis_ccb;
+    int rc = IPR_RC_SUCCESS;
+    int timeout = IPR_INTERNAL_DEV_TIMEOUT;
+
+    p_sis_ccb = ipr_allocate_ccb(p_shared_cfg);
+
+    if (p_sis_ccb == NULL)
+    {
+        /* Requests must not be allowed right now - we are probably going through
+         reset/reload right now */
+        return IPR_RC_FAILED;
+    }
+
+    p_sis_ccb->p_resource = p_resource_entry;
+    p_sis_ccb->p_scratch = p_dasd_init_buf;
+    p_sis_ccb->bufflen = alloc_len;
+    p_sis_ccb->buffer = p_buffer;
+    p_sis_ccb->buffer_dma = (u32)dma_addr;
+    p_sis_ccb->scsi_use_sg = 0;
+    p_sis_ccb->cdb[0] = cmd;
+    p_sis_ccb->cmd_len = 6;
+    p_sis_ccb->job_step = job_step;
+    p_sis_ccb->flags = IPR_BUFFER_MAPPED;
+
+    switch(cmd)
+    {
+        case IPR_MODE_SENSE:
+            p_sis_ccb->cdb[2] = parm; 
+            p_sis_ccb->cdb[4] = alloc_len & 0xff;
+            p_sis_ccb->data_direction = IPR_DATA_READ;
+            memset(p_buffer, 0, alloc_len);
+            break;
+        case IPR_MODE_SELECT:
+            p_sis_ccb->data_direction = IPR_DATA_WRITE;
+            p_sis_ccb->cdb[1] = parm;
+            p_sis_ccb->cdb[4] = alloc_len & 0xff;
+            break;
+        case IPR_SET_DASD_TIMEOUTS:
+            p_sis_ccb->flags |= IPR_IOA_CMD;
+            p_sis_ccb->data_direction = IPR_DATA_WRITE;
+            p_sis_ccb->cdb[7] = (alloc_len >> 8) & 0xff;
+            p_sis_ccb->cdb[8] = alloc_len & 0xff;
+            p_sis_ccb->cmd_len = 10;
+            break;
+        case IPR_INQUIRY:
+            p_sis_ccb->data_direction = IPR_DATA_READ;
+
+            if (parm != 0xff)
+            {
+                p_sis_ccb->cdb[1] = 0x01;
+                p_sis_ccb->cdb[2] = parm; 
+            }
+
+            p_sis_ccb->cdb[4] = alloc_len & 0xff;
+            memset(p_buffer, 0, alloc_len);
+            break;
+        case IPR_QUERY_RESOURCE_STATE:
+            p_sis_ccb->flags |= IPR_IOA_CMD;
+            p_sis_ccb->data_direction = IPR_DATA_READ;
+            p_sis_ccb->cdb[7] = (alloc_len >> 8) & 0xff;
+            p_sis_ccb->cdb[8] = alloc_len & 0xff;
+            p_sis_ccb->cmd_len = 10;
+            memset(p_buffer, 0, alloc_len);
+            break;
+        default:
+            rc = IPR_RC_FAILED;
+            goto leave;
+            break;
+    };
+
+    rc = ipr_do_req(p_shared_cfg, p_sis_ccb,
+                       ipr_dasd_init_job, timeout);
+
+    leave:
+        if (rc != IPR_RC_SUCCESS)
+            ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send an op to a VSET resource.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Failure
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+static int ipr_vset_req(struct ipr_shared_config *p_shared_cfg,
+                           struct ipr_resource_entry *p_resource_entry,
+                           struct ipr_dasd_init_bufs *p_dasd_init_buf,
+                           void *p_buffer,
+                           ipr_dma_addr dma_addr,
+                           u8 cmd, u8 parm, u16 alloc_len, u8 job_step)
+{
+    struct ipr_ccb *p_sis_ccb;
+    int rc = IPR_RC_SUCCESS;
+    int timeout = IPR_INTERNAL_DEV_TIMEOUT;
+
+    p_sis_ccb = ipr_allocate_ccb(p_shared_cfg);
+
+    if (p_sis_ccb == NULL)
+    {
+        /* Requests must not be allowed right now - we are probably going through
+         reset/reload right now */
+        return IPR_RC_FAILED;
+    }
+
+    p_sis_ccb->p_resource = p_resource_entry;
+    p_sis_ccb->p_scratch = p_dasd_init_buf;
+    p_sis_ccb->bufflen = alloc_len;
+    p_sis_ccb->buffer = p_buffer;
+    p_sis_ccb->buffer_dma = (u32)dma_addr;
+    p_sis_ccb->scsi_use_sg = 0;
+    p_sis_ccb->cdb[0] = cmd;
+    p_sis_ccb->cmd_len = 6;
+    p_sis_ccb->job_step = job_step;
+    p_sis_ccb->flags = IPR_BUFFER_MAPPED;
+
+    switch(cmd)
+    {
+        case IPR_QUERY_RESOURCE_STATE:
+            p_sis_ccb->flags |= IPR_IOA_CMD;
+            p_sis_ccb->data_direction = IPR_DATA_READ;
+            p_sis_ccb->cdb[7] = (alloc_len >> 8) & 0xff;
+            p_sis_ccb->cdb[8] = alloc_len & 0xff;
+            p_sis_ccb->cmd_len = 10;
+            memset(p_buffer, 0, alloc_len);
+            break;
+        default:
+            rc = IPR_RC_FAILED;
+            goto leave;
+            break;
+    };
+
+    rc = ipr_do_req(p_shared_cfg, p_sis_ccb,
+                       ipr_vset_init_job, timeout);
+
+    leave:
+        if (rc != IPR_RC_SUCCESS)
+            ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Send an op to the IOA resource.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS           - Success
+ *          IPR_RC_FAILED            - Failure
+ *          IPR_RC_OP_NOT_SENT       - Op was not sent to the device
+ *---------------------------------------------------------------------------*/
+static int ipr_ioa_req(struct ipr_shared_config *p_shared_cfg,
+                          void (*done) (struct ipr_shared_config *, struct ipr_ccb *),
+                          void *p_scratch,
+                          void *p_buffer,
+                          ipr_dma_addr dma_addr,
+                          u8 cmd, u8 parm, u16 alloc_len, u8 job_step)
+{
+    struct ipr_ccb *p_sis_ccb;
+    int rc = IPR_RC_SUCCESS;
+    int timeout = IPR_INTERNAL_TIMEOUT;
+
+    p_sis_ccb = ipr_allocate_ccb(p_shared_cfg);
+
+    if (p_sis_ccb == NULL)
+    {
+        /* Requests must not be allowed right now - we are probably going through
+         reset/reload right now */
+        return IPR_RC_FAILED;
+    }
+
+    p_sis_ccb->p_resource = &p_shared_cfg->ioa_resource;
+    p_sis_ccb->p_scratch = p_scratch;
+    p_sis_ccb->bufflen = alloc_len;
+    p_sis_ccb->buffer = p_buffer;
+    p_sis_ccb->buffer_dma = (u32)dma_addr;
+    p_sis_ccb->scsi_use_sg = 0;
+    p_sis_ccb->cdb[0] = cmd;
+    p_sis_ccb->cmd_len = 6;
+    p_sis_ccb->job_step = job_step;
+    p_sis_ccb->flags = IPR_BUFFER_MAPPED;
+
+    switch(cmd)
+    {
+        case IPR_MODE_SENSE:
+            p_sis_ccb->cdb[2] = parm; 
+            p_sis_ccb->cdb[4] = alloc_len;
+            p_sis_ccb->data_direction = IPR_DATA_READ;
+            break;
+        case IPR_MODE_SELECT:
+            p_sis_ccb->data_direction = IPR_DATA_WRITE;
+            p_sis_ccb->cdb[1] = parm;
+            p_sis_ccb->cdb[4] = alloc_len;
+            break;
+        case IPR_INQUIRY:
+            p_sis_ccb->data_direction = IPR_DATA_READ;
+
+            if (parm != 0xff)
+            {
+                p_sis_ccb->cdb[1] = 0x01;
+                p_sis_ccb->cdb[2] = parm; 
+            }
+            p_sis_ccb->cdb[4] = alloc_len;
+            break;
+        case IPR_SET_SUPPORTED_DEVICES:
+            p_sis_ccb->flags |= IPR_IOA_CMD;
+            p_sis_ccb->cmd_len = 10;
+            p_sis_ccb->data_direction = IPR_DATA_WRITE;
+            p_sis_ccb->cdb[7] = (alloc_len >> 8) & 0xff;
+            p_sis_ccb->cdb[8] = alloc_len & 0xff;
+            timeout = IPR_SET_SUP_DEVICE_TIMEOUT;
+            break;
+        default:
+            rc = IPR_RC_FAILED;
+            goto leave;
+            break;
+    };
+
+    rc = ipr_do_req(p_shared_cfg, p_sis_ccb,
+                       done, timeout);
+
+    leave:
+        if (rc != IPR_RC_SUCCESS)
+            ipr_release_ccb(p_shared_cfg, p_sis_ccb);
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get the specified mode page
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Pointer to mode page or NULL if mode page not found
+ *---------------------------------------------------------------------------*/
+static void *ipr_get_mode_page(struct ipr_mode_parm_hdr *p_mode_parm,
+                                  u32 page_code, u32 len)
+{
+    struct ipr_mode_page_hdr *p_mode_hdr;
+    u32 page_length;
+    u32 length;
+
+    if ((p_mode_parm == NULL) || (p_mode_parm->length == 0))
+        return NULL;
+
+    length = (p_mode_parm->length + 1) - 4 - p_mode_parm->block_desc_len;
+    p_mode_hdr = (struct ipr_mode_page_hdr*)((unsigned long)p_mode_parm +
+                                                4 + p_mode_parm->block_desc_len);
+
+    while(length)
+    {
+        if (p_mode_hdr->page_code == page_code)
+        {
+            if (p_mode_hdr->page_length >= (len - sizeof(struct ipr_mode_page_hdr)))
+                return p_mode_hdr;
+            break;
+        }
+        else
+        {
+            page_length = (sizeof(struct ipr_mode_page_hdr) + p_mode_hdr->page_length);
+            length -= page_length;
+            p_mode_hdr = (struct ipr_mode_page_hdr*)((unsigned long)p_mode_hdr + page_length);
+        }
+    }
+    return NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Convert EBCDIC string to ASCII string
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_ebcdic_to_ascii(const u8 *ebcdic, u32 length,  u8 *ascii)
+{
+    u8 ebcdic_char;
+    int i;
+
+    for (i = 0; i < length; i++, ebcdic++, ascii++ )
+    {
+        ebcdic_char = *ebcdic;
+        *ascii = ipr_etoa[ebcdic_char];
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Convert DASD Vendor/Product ID to CCIN
+ * Lock State: io_request_lock assumed to be held
+ * Returns: CCIN of DASD or default_ccin if not in supported device list
+ *---------------------------------------------------------------------------*/
+u16 ipr_dasd_vpids_to_ccin(struct ipr_std_inq_vpids *p_vpids,
+                              u16 default_ccin)
+{
+    int j;
+    char p_ccin[5];
+    u32 num_supported_devs = sizeof(ipr_supported_dev_list)/sizeof(struct ipr_supported_device);
+
+    for (j = 0; j < num_supported_devs; j++)
+    {
+        if (memcmp(&ipr_supported_dev_list_ptr[j].vpids, p_vpids,
+                          sizeof(struct ipr_std_inq_vpids)) == 0)
+        {
+            ipr_ebcdic_to_ascii((u8 *)&ipr_supported_dev_list_ptr[j].ebcdic_as400_device_type,
+                                   4, p_ccin);
+            p_ccin[4] = '\0';
+            return simple_strtoul(p_ccin, NULL, 16);
+        }
+    }
+
+    return default_ccin;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Convert DASD Vendor/Product ID to CCIN
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_dasd_vpids_to_ccin_str(struct ipr_std_inq_vpids *p_vpids,
+                                   char *p_ccin, char *p_default_ccin)
+{
+    u16 ccin = ipr_dasd_vpids_to_ccin(p_vpids, 0);
+
+    if (ccin)
+        sprintf(p_ccin, "%X", ccin);
+    else
+        sprintf(p_ccin, "%s", p_default_ccin);
+    return;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Print the command packet for debug purposes
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_print_cmd_pkt(struct ipr_cmd_pkt *p_cmd_pkt)
+{
+    u8 *p_byte = (u8 *)p_cmd_pkt;
+    char string[(sizeof(struct ipr_cmd_pkt) * 2) + 1];
+    int i, len;
+
+    for (i = 0, len = 0; i < sizeof(struct ipr_cmd_pkt); i++)
+        len += sprintf(&string[len], "%02X", p_byte[i]);
+
+    string[(sizeof(struct ipr_cmd_pkt) * 2)] = '\0';
+
+    ipr_log_err("Cmd pkt: %s"IPR_EOL, string);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Sends an internal request to the Focal Point
+ *          and polls isr until a response is received or is
+ *          timed out.
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS                   - Op completed successfully
+ *          IPR_RC_TIMEOUT                   - Op timed out
+ *          IPR_RC_XFER_FAILED               - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ                      - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST                 - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR                   - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED             - IOA unit checked
+ *          IPR_RC_FAILED                    - Op failed
+ *          IPR_IOASC_NR_IOA_MICROCODE       - IOA needs ucode download
+ *---------------------------------------------------------------------------*/
+static u32 ipr_send_blocking_cmd(struct ipr_shared_config *p_shared_cfg,
+                                    u8 sis_cmd,
+                                    u32 timeout,
+                                    u8 parm,
+                                    void *p_data,
+                                    ipr_dma_addr dma_addr,
+                                    u32 xfer_len)
+{
+    u32 pci_addr_ioarcb;
+    u32 ioasc;
+    u32 host_ioarcb_index;
+    u32 rc = IPR_RC_SUCCESS;
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    p_host_ioarcb = ipr_build_ioa_cmd(p_shared_cfg,
+                                         sis_cmd,
+                                         NULL,
+                                         parm,
+                                         p_data,
+                                         dma_addr,
+                                         xfer_len);
+
+    host_ioarcb_index = p_host_ioarcb->host_ioarcb_index;
+
+    ipr_trc_hook(p_shared_cfg,
+                    sis_cmd,
+                    IPR_TRACE_START,
+                    IPR_TRACE_IOA,
+                    host_ioarcb_index,
+                    xfer_len,
+                    IPR_IOA_RESOURCE_ADDRESS);
+
+    pci_addr_ioarcb = (u32)p_host_ioarcb->ioarcb_dma;
+
+    /* Poke the IOARRIN with the PCI address of the IOARCB */
+    writel(pci_addr_ioarcb, ipr_cfg->regs.ioarrin_reg);
+
+    rc = ipr_poll_isr(p_shared_cfg, timeout);
+
+    if (rc == IPR_RC_SUCCESS)
+    {
+        ioasc = sistoh32(p_host_ioarcb->p_ioasa->ioasc);
+
+        if ((ioasc != 0) && (ioasc != IPR_IOASC_NR_IOA_MICROCODE))
+        {
+            rc = IPR_RC_FAILED;
+
+            if ((IPR_IOASC_SENSE_KEY(ioasc) != 0x05) ||
+                (ipr_debug))
+            {
+                ipr_log_err("Op failed: op: 0x%x. IOASC: 0x%08x. Parm: %d"IPR_EOL,
+                               sis_cmd, ioasc, parm);
+                ipr_log_err("IOASA: 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x"IPR_EOL,
+                               ioasc, sistoh32(*((u32 *)&p_host_ioarcb->p_ioasa->ret_stat_len)),
+                               sistoh32(p_host_ioarcb->p_ioasa->residual_data_len),
+                               sistoh32(p_host_ioarcb->p_ioasa->ilid),
+                               sistoh32(p_host_ioarcb->p_ioasa->fd_ioasc),
+                               sistoh32(p_host_ioarcb->p_ioasa->fd_phys_locator),
+                               sistoh32(p_host_ioarcb->p_ioasa->fd_res_handle));
+
+                if (IPR_IOASC_SENSE_KEY(ioasc) == 0x05)
+                    ipr_print_cmd_pkt(&p_host_ioarcb->ioarcb.ioarcb_cmd_pkt);
+            }
+        }
+        else if (ioasc == IPR_IOASC_NR_IOA_MICROCODE)
+        {
+            p_shared_cfg->nr_ioa_microcode = 1;
+            rc = IPR_IOASC_NR_IOA_MICROCODE;
+        }
+
+        ipr_remove_host_ioarcb_from_pending(ipr_cfg, p_host_ioarcb);
+        ipr_put_host_ioarcb_to_free(ipr_cfg, p_host_ioarcb);
+    }
+    else
+        ipr_dbg_err("Blocking command failed: 0x%02x 0x%08x"IPR_EOL, sis_cmd, rc);
+
+    ipr_trc_hook(p_shared_cfg,
+                    sis_cmd,
+                    IPR_TRACE_FINISH,
+                    IPR_TRACE_IOA,
+                    host_ioarcb_index,
+                    xfer_len,
+                    rc);
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Builds up an IOARCB for a Focal Point command
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to a host ioarcb or NULL if command was invalid
+ *          If the command was invalid, sense data will have been filled in
+ *---------------------------------------------------------------------------*/
+static struct ipr_host_ioarcb* ipr_build_ioa_cmd(struct ipr_shared_config *p_shared_cfg,
+                                                       u8 sis_cmd,
+                                                       struct ipr_ccb *p_sis_cmd,
+                                                       u8 parm,
+                                                       void *p_data,
+                                                       ipr_dma_addr dma_addr,
+                                                       u32 xfer_len)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_host_ioarcb *p_host_ioarcb;
+    struct ipr_ioarcb *p_ioarcb;
+    struct ipr_ioadl_desc *p_ioadl;
+    unsigned char *p_sense_buffer;
+    struct ipr_discard_cache_data *p_discard_data;
+
+    p_host_ioarcb = ipr_get_free_host_ioarcb(p_shared_cfg);
+    p_ioarcb = &p_host_ioarcb->ioarcb; 
+    p_ioadl = p_host_ioarcb->p_ioadl;
+    p_host_ioarcb->p_sis_cmd = p_sis_cmd;
+
+    /* Setup IOARCB */
+    p_ioarcb->ioarcb_cmd_pkt.cdb[0] = sis_cmd;
+    p_ioarcb->ioa_res_handle = IPR_IOA_RESOURCE_HANDLE;
+
+    if (p_sis_cmd)
+        memcpy(p_ioarcb->ioarcb_cmd_pkt.cdb, p_sis_cmd->cdb, p_sis_cmd->cmd_len);
+
+    switch(sis_cmd)
+    {
+        case IPR_ID_HOST_RR_Q:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[2] = ((u32)ipr_cfg->host_rrq_dma >> 24) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[3] = ((u32)ipr_cfg->host_rrq_dma >> 16) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = ((u32)ipr_cfg->host_rrq_dma >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[5] = ((u32)ipr_cfg->host_rrq_dma) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[7] = ((sizeof(u32) * IPR_NUM_CMD_BLKS) >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[8] = (sizeof(u32) * IPR_NUM_CMD_BLKS) & 0xff;
+            break;
+        case IPR_QUERY_IOA_CONFIG:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            p_ioarcb->ioarcb_cmd_pkt.cdb[7] = (xfer_len >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[8] = xfer_len & 0xff;
+            break;
+        case IPR_INQUIRY:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_SCSICDB;
+
+            if ((p_sis_cmd == NULL) && (parm != 0xff))
+            {
+                p_ioarcb->ioarcb_cmd_pkt.cdb[1] = 1;
+                p_ioarcb->ioarcb_cmd_pkt.cdb[2] = parm;
+            }
+
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = xfer_len;
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            break;
+        case IPR_HOST_CONTROLLED_ASYNC:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_HCAM;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            break;
+        case IPR_SET_SUPPORTED_DEVICES:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_WR_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->write_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->write_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->write_data_transfer_length = htosis32(xfer_len);
+            p_ioarcb->ioarcb_cmd_pkt.cdb[7] = (xfer_len >> 8) & 0xff;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[8] = xfer_len & 0xff;
+            break;
+        case IPR_IOA_SHUTDOWN:
+        case IPR_EVALUATE_DEVICE:
+        case IPR_START_ARRAY_PROTECTION:
+        case IPR_STOP_ARRAY_PROTECTION:
+        case IPR_REBUILD_DEVICE_DATA:
+        case IPR_ADD_ARRAY_DEVICE:
+        case IPR_RESYNC_ARRAY_PROTECTION:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+        case IPR_WRITE_BUFFER:
+            ipr_build_ioadl(p_shared_cfg, p_host_ioarcb);
+            break;
+        case IPR_QUERY_ARRAY_CONFIG:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            break;
+        case IPR_RECLAIM_CACHE_STORE:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            break;
+        case IPR_QUERY_COMMAND_STATUS:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            break;
+        case IPR_SUSPEND_DEV_BUS:
+            p_ioarcb->ioarcb_cmd_pkt.cmd_timeout = htosis16(p_sis_cmd->timeout);
+        case IPR_RESUME_DEVICE_BUS:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            break;
+        case IPR_DISCARD_CACHE_DATA:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+            p_discard_data = p_sis_cmd->buffer;
+
+            p_ioarcb->add_cmd_parms_len = htosis32(p_discard_data->length);
+            memcpy(p_ioarcb->add_cmd_parms,
+                   p_discard_data->data.add_cmd_parms,
+                   p_discard_data->length);
+            break;
+        case IPR_MODE_SENSE:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_SCSICDB;
+            if (p_sis_cmd == NULL)
+                p_ioarcb->ioarcb_cmd_pkt.cdb[2] = parm;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = xfer_len;
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+            break;
+        case IPR_MODE_SELECT:
+            p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+            if (p_sis_cmd == NULL)
+                p_ioarcb->ioarcb_cmd_pkt.cdb[1] = parm;
+            p_ioarcb->ioarcb_cmd_pkt.cdb[4] = xfer_len;
+
+            p_ioadl->flags_and_data_len =
+                htosis32(IPR_IOADL_FLAGS_HOST_WR_LAST_DATA | xfer_len);
+            p_ioadl->address = htosis32((u32)dma_addr);
+            p_ioarcb->write_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+            p_ioarcb->write_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+            p_ioarcb->write_data_transfer_length = htosis32(xfer_len);
+            break;
+        case IPR_IOA_DEBUG:
+            p_ioarcb->ioarcb_cmd_pkt.request_type = IPR_RQTYPE_IOACMD;
+
+            if (p_sis_cmd->data_direction == IPR_DATA_READ)
+            {
+                p_ioadl->flags_and_data_len =
+                    htosis32(IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA | xfer_len);
+                p_ioadl->address = htosis32((u32)dma_addr);
+                p_ioarcb->read_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+                p_ioarcb->read_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+                p_ioarcb->read_data_transfer_length = htosis32(xfer_len);
+                break;
+            }
+            else if (p_sis_cmd->data_direction == IPR_DATA_WRITE)
+            {
+                p_ioarcb->ioarcb_cmd_pkt.write_not_read = 1;
+                p_ioadl->flags_and_data_len =
+                    htosis32(IPR_IOADL_FLAGS_HOST_WR_LAST_DATA | xfer_len);
+                p_ioadl->address = htosis32((u32)dma_addr);
+                p_ioarcb->write_ioadl_addr = htosis32((u32)p_host_ioarcb->ioadl_dma);
+                p_ioarcb->write_ioadl_len = htosis32(sizeof(struct ipr_ioadl_desc));
+                p_ioarcb->write_data_transfer_length = htosis32(xfer_len);
+                break;
+            }
+        default:
+            if (p_sis_cmd)
+            {
+                /* Generate sense data: Illegal Request, Invalid Command Op Code */
+                p_sense_buffer = p_sis_cmd->sense_buffer;
+                memset(p_sense_buffer, 0, IPR_SENSE_BUFFERSIZE);
+                p_sense_buffer[0] = 0x70;
+                p_sense_buffer[2] = 0x05;
+                p_sense_buffer[7] = 6;
+                p_sense_buffer[12] = 0x20;
+                p_sense_buffer[13] = 0x00;
+                p_sis_cmd->status = 0;
+            }
+            else
+                panic(IPR_ERR": Invalid blocking command issued: 0x%X"IPR_EOL,
+                             sis_cmd);
+
+            ipr_remove_host_ioarcb_from_pending(ipr_cfg, p_host_ioarcb);
+            ipr_put_host_ioarcb_to_free(ipr_cfg, p_host_ioarcb);
+            p_host_ioarcb = NULL;
+            break;
+    }
+
+    return p_host_ioarcb;
+
+}
+
+/*---------------------------------------------------------------------------
+ * Polls the interrupt register for op completion
+ * Returns: IPR_RC_SUCCESS           - Op completed sucessfully
+ *          IPR_RC_TIMEOUT           - Op timed out
+ *          IPR_RC_XFER_FAILED       - IOARCB xfer failed interrupt
+ *          IPR_NO_HRRQ              - No HRRQ interrupt
+ *          IPR_IOARRIN_LOST         - IOARRIN lost interrupt
+ *          IPR_MMIO_ERROR           - MMIO error interrupt
+ *          IPR_IOA_UNIT_CHECKED     - IOA unit checked
+ *          IPR_RC_FAILED            - Other error
+ * Notes: Timeout value is in seconds
+ *---------------------------------------------------------------------------*/
+static u32 ipr_poll_isr(struct ipr_shared_config *p_shared_cfg, u32 timeout)
+{
+    volatile u32 temp_pci_reg;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    int rc = IPR_RC_SUCCESS;
+
+    /* Convert unit to 10 msecs ticks */
+    timeout *= 100;
+
+    while (timeout)
+    {
+        temp_pci_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+
+        if (temp_pci_reg & IPR_PCII_HOST_RRQ_UPDATED)
+            break;
+        else if (temp_pci_reg & IPR_PCII_ERROR_INTERRUPTS)
+        {
+            if (temp_pci_reg & IPR_PCII_IOARCB_XFER_FAILED)
+                rc = IPR_RC_XFER_FAILED;
+            else if (temp_pci_reg & IPR_PCII_NO_HOST_RRQ)
+                rc = IPR_NO_HRRQ;
+            else if (temp_pci_reg & IPR_PCII_IOARRIN_LOST)
+                rc = IPR_IOARRIN_LOST;
+            else if (temp_pci_reg & IPR_PCII_MMIO_ERROR)
+                rc = IPR_MMIO_ERROR;
+            else if (temp_pci_reg & IPR_PCII_IOA_UNIT_CHECKED)
+                rc = IPR_IOA_UNIT_CHECKED;
+            else
+                rc = IPR_RC_FAILED;
+            break;
+        }
+        else
+        {
+            /* Sleep for 10 msecs */
+            ipr_sleep(10);
+            timeout--;
+        }
+    }
+
+    if (timeout)
+    {
+        if (rc == IPR_RC_SUCCESS)
+        {
+            if (ipr_cfg->host_rrq_curr_ptr < ipr_cfg->host_rrq_end_addr)
+            {
+                ipr_cfg->host_rrq_curr_ptr++;
+            }
+            else
+            {
+                ipr_cfg->host_rrq_curr_ptr = ipr_cfg->host_rrq_start_addr;
+                ipr_cfg->toggle_bit ^= 1u;
+            }
+
+            /* Clear the PCI interrupt */
+            writel (IPR_PCII_HOST_RRQ_UPDATED,
+                           ipr_cfg->regs.clr_interrupt_reg);
+
+            /* Re-read the PCI interrupt reg to force clear */
+            temp_pci_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+        }
+        else
+            ipr_dbg_err("Op failed due to interrupt=0x%08x"IPR_EOL, temp_pci_reg);
+    }
+    else
+    {
+        ipr_dbg_err("Op timed out. temp_pci_reg=0x%08x"IPR_EOL, temp_pci_reg);
+        rc = IPR_RC_TIMEOUT;
+    }
+
+    return rc;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Mask all interrupts on the adapter
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+void ipr_mask_interrupts(struct ipr_shared_config *p_shared_cfg)
+{
+    volatile u32 temp_pci_reg;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    /* Stop new interrupts */
+    p_shared_cfg->allow_interrupts = 0;
+
+    /* Set interrupt mask to stop all new interrupts */
+    writel(~0, ipr_cfg->regs.set_interrupt_mask_reg);
+
+    /* Re-read the PCI interrupt mask reg to force clear */
+    temp_pci_reg = readl(ipr_cfg->regs.sense_interrupt_mask_reg);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get pointer to device config for a device
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer
+ *---------------------------------------------------------------------------*/
+static const
+struct ipr_dev_config *ipr_get_dev_config(struct ipr_resource_entry *p_resource_entry)
+{
+    int i;
+
+    if (p_resource_entry)
+    {
+        for (i = 0;
+             i < sizeof(ipr_dev_cfg_table)/sizeof(struct ipr_dev_config);
+             i++)
+        {
+            if (memcmp(&ipr_dev_cfg_table[i].vpids,
+                              &p_resource_entry->std_inq_data.vpids,
+                              ipr_dev_cfg_table[i].vpd_len) == 0)
+            {
+                return &ipr_dev_cfg_table[i];
+            }
+        }
+    }
+    return NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x00 buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x00(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_vendor_unique_page *p_ch,
+                                struct ipr_vendor_unique_page *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_ch && p_buf)
+    {
+        if (p_dev_cfg && p_dev_cfg->set_page0x00)
+            p_dev_cfg->set_page0x00(p_resource_entry, p_ch, p_buf);
+        else
+            ipr_set_page0x00_defaults(p_resource_entry, p_ch, p_buf);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x00 to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x00_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_vendor_unique_page *p_ch,
+                                         struct ipr_vendor_unique_page *p_buf)
+{
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x00 to the default AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x00_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_vendor_unique_page *p_ch,
+                                      struct ipr_vendor_unique_page *p_buf)
+{
+    ipr_set_page0x00_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->qpe, p_buf->qpe, 1);
+    IPR_SET_MODE(p_ch->uqe, p_buf->uqe, 0);
+    IPR_SET_MODE(p_ch->dwd, p_buf->dwd, 0);
+    IPR_SET_MODE(p_ch->asdpe, p_buf->asdpe, 1);
+    IPR_SET_MODE(p_ch->cmdac, p_buf->cmdac, 1);
+    IPR_SET_MODE(p_ch->rpfae, p_buf->rpfae, 0);
+    IPR_SET_MODE(p_ch->dsn, p_buf->dsn, 1);
+    IPR_SET_MODE(p_ch->frdd, p_buf->frdd, 1);
+    IPR_SET_MODE(p_ch->dpsdp, p_buf->dpsdp, 0);
+    IPR_SET_MODE(p_ch->wpen, p_buf->wpen, 0);
+    IPR_SET_MODE(p_ch->drd, p_buf->drd, 0);
+    IPR_SET_MODE(p_ch->rrnde, p_buf->rrnde, 0);
+    IPR_SET_MODE(p_ch->led_mode, p_buf->led_mode, 0);
+
+    /* Completely clear byte 15 */
+    IPR_SET_MODE(p_ch->rtp, p_buf->rtp, 0);
+    IPR_SET_MODE(p_ch->rrc, p_buf->rrc, 0);
+    IPR_SET_MODE(p_ch->fcert, p_buf->fcert, 0);
+    IPR_SET_MODE(p_ch->reserved13, p_buf->reserved13, 0);
+    IPR_SET_MODE(p_ch->drpdv, p_buf->drpdv, 0);
+    IPR_SET_MODE(p_ch->dsf, p_buf->dsf, 0);
+    IPR_SET_MODE(p_ch->irt, p_buf->irt, 0);
+    IPR_SET_MODE(p_ch->ivr, p_buf->ivr, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x00 to the default AS/400 TCQ settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x00_TCQ(struct ipr_resource_entry *p_resource_entry,
+                                    struct ipr_vendor_unique_page *p_ch,
+                                    struct ipr_vendor_unique_page *p_buf)
+{
+    ipr_set_page0x00_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->qpe, p_buf->qpe, 1);
+    IPR_SET_MODE(p_ch->rrnde, p_buf->rrnde, 0);
+    IPR_SET_MODE(p_ch->irt, p_buf->irt, 0);
+    IPR_SET_MODE(p_ch->ivr, p_buf->ivr, 0);
+    IPR_SET_MODE(p_ch->asdpe, p_buf->asdpe, 1);
+    IPR_SET_MODE(p_ch->cmdac, p_buf->cmdac, 1);
+    IPR_SET_MODE(p_ch->frdd, p_buf->frdd, 1);
+    IPR_SET_MODE(p_ch->ffmt, p_buf->ffmt, 0);
+    IPR_SET_MODE(p_ch->led_mode, p_buf->led_mode, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_rw_err_mode_page *p_ch,
+                                struct ipr_rw_err_mode_page *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_ch && p_buf)
+    {
+        if (p_dev_cfg && p_dev_cfg->set_page0x01)
+            p_dev_cfg->set_page0x01(p_resource_entry, p_ch, p_buf);
+        else
+            ipr_set_page0x01_defaults(p_resource_entry, p_ch, p_buf);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_rw_err_mode_page *p_ch,
+                                         struct ipr_rw_err_mode_page *p_buf)
+{
+    IPR_SET_MODE(p_ch->awre, p_buf->awre, 1);
+    IPR_SET_MODE(p_ch->arre, p_buf->arre, 1);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 to the default AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_rw_err_mode_page *p_ch,
+                                      struct ipr_rw_err_mode_page *p_buf)
+{
+    ipr_set_page0x01_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->tb, p_buf->tb, 0);
+    IPR_SET_MODE(p_ch->rc, p_buf->rc, 0);
+    IPR_SET_MODE(p_ch->per, p_buf->per, 1);
+    IPR_SET_MODE(p_ch->dte, p_buf->dte, 0);
+    IPR_SET_MODE(p_ch->dcr, p_buf->dcr, 0);
+    IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, 1);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 to the default AS/400 TCQ settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_TCQ(struct ipr_resource_entry *p_resource_entry,
+                                    struct ipr_rw_err_mode_page *p_ch,
+                                    struct ipr_rw_err_mode_page *p_buf)
+{
+    ipr_set_page0x01_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->tb, p_buf->tb, 0);
+    IPR_SET_MODE(p_ch->rc, p_buf->rc, 0);
+    IPR_SET_MODE(p_ch->per, p_buf->per, 1);
+    IPR_SET_MODE(p_ch->dte, p_buf->dte, 0);
+    IPR_SET_MODE(p_ch->dcr, p_buf->dcr, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_thresher_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_rw_err_mode_page *p_ch,
+                                             struct ipr_rw_err_mode_page *p_buf)
+{
+    ipr_set_page0x01_defaults(p_resource_entry, p_ch, p_buf);
+
+    /* Is this a Seagate 10K 8 GB drive? */
+    if (p_resource_entry->sw_load_id == 0xA17002B4)
+        IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, 0x0B);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_hammerhead_18Gb(struct ipr_resource_entry *p_resource_entry,
+                                                struct ipr_rw_err_mode_page *p_ch,
+                                                struct ipr_rw_err_mode_page *p_buf)
+{
+    u8 retry_cnt = 0;
+
+    if ((p_resource_entry->sw_load_id == 0xA17002BA) ||
+        (p_resource_entry->sw_load_id == 0xA17002C0)) /* Seagate 10 17GB drive */
+    {
+        retry_cnt = p_buf->read_retry_count;
+    }
+
+    ipr_set_page0x01_as400(p_resource_entry, p_ch, p_buf);
+
+    if (p_resource_entry->sw_load_id == 0xA17002B5)  /* Seagate 17GB, Apollo, 10kRPM */
+    {
+        IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, 0x0B);
+    }
+    else if ((p_resource_entry->sw_load_id == 0xA17002BA) ||
+             (p_resource_entry->sw_load_id == 0xA17002C0)) /* Seagate 10 17GB drive */
+    {
+        IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, retry_cnt);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_discovery_36Gb(struct ipr_resource_entry *p_resource_entry,
+                                               struct ipr_rw_err_mode_page *p_ch,
+                                               struct ipr_rw_err_mode_page *p_buf)
+{
+    u8 retry_cnt = 0;
+
+    if ((p_resource_entry->sw_load_id == 0xA17002BB) || /* Seagate 35GB, Gemini, 10kRPM */
+        (p_resource_entry->sw_load_id == 0xA17002C1))   /* Seagate 35GB,  ?, 10kRPM */
+    {
+        retry_cnt = p_buf->read_retry_count;
+    }
+
+    ipr_set_page0x01_as400(p_resource_entry, p_ch, p_buf);
+
+    if (p_resource_entry->sw_load_id == 0xA17002B6)  /* Seagate 35GB, Apollo, 10kRPM */
+    {
+        IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, 0x0B);
+    }
+    else if ((p_resource_entry->sw_load_id == 0xA17002BB) || /* Seagate 35GB, Gemini, 10kRPM */
+             (p_resource_entry->sw_load_id == 0xA17002C1))   /* Seagate 35GB,  ?, 10kRPM */
+    {
+        IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, retry_cnt);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x01 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x01_daytona_70Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_rw_err_mode_page *p_ch,
+                                             struct ipr_rw_err_mode_page *p_buf)
+{
+    u8 retry_cnt = 0;
+
+    if ((p_resource_entry->sw_load_id == 0xA17002C2) || /* Seagate 70GB, Jupiter, 10kRPM */
+        (p_resource_entry->sw_load_id == 0xA17002C3))   /* Seagate 70GB, Gemini, 10kRPM */
+    {
+        retry_cnt = p_buf->read_retry_count;
+    }
+
+    ipr_set_page0x01_as400(p_resource_entry, p_ch, p_buf);
+
+    if ((p_resource_entry->sw_load_id == 0xA17002C2) || /* Seagate 70GB, Jupiter, 10kRPM */
+        (p_resource_entry->sw_load_id == 0xA17002C3))   /* Seagate 70GB, Gemini, 10kRPM */
+    {
+        IPR_SET_MODE(p_ch->read_retry_count, p_buf->read_retry_count, retry_cnt);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_disc_reconn_page *p_ch,
+                                struct ipr_disc_reconn_page *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_ch && p_buf)
+    {
+        if (p_dev_cfg && p_dev_cfg->set_page0x02)
+            p_dev_cfg->set_page0x02(p_resource_entry, p_ch, p_buf);
+        else
+            ipr_set_page0x02_defaults(p_resource_entry, p_ch, p_buf);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_disc_reconn_page *p_ch,
+                                         struct ipr_disc_reconn_page *p_buf)
+{
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 to the default AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_disc_reconn_page *p_ch,
+                                      struct ipr_disc_reconn_page *p_buf)
+{
+    ipr_set_page0x02_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->buffer_full_ratio, p_buf->buffer_full_ratio, 0x90);
+    IPR_SET_MODE(p_ch->buffer_empty_ratio, p_buf->buffer_empty_ratio, 0x80);
+    IPR_SET_MODE(p_ch->maximum_burst_size, p_buf->maximum_burst_size, htosis32(0x0030));
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Use the drive's default mode settings for mode page 0x02
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_noop(struct ipr_resource_entry *p_resource_entry,
+                                     struct ipr_disc_reconn_page *p_ch,
+                                     struct ipr_disc_reconn_page *p_buf)
+{
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_starfire_4Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_disc_reconn_page *p_ch,
+                                             struct ipr_disc_reconn_page *p_buf)
+{
+    ipr_set_page0x02_as400(p_resource_entry, p_ch, p_buf);
+
+    /* Is this a Sailfin or Marlin drive? */
+    if (p_resource_entry->sw_load_id == 0xA090061B)
+    {
+        IPR_SET_MODE(p_ch->dimm, p_buf->dimm, 1);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_scorpion_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_disc_reconn_page *p_ch,
+                                             struct ipr_disc_reconn_page *p_buf)
+{
+    ipr_set_page0x02_as400(p_resource_entry, p_ch, p_buf);
+
+    /* Is this a Sailfin or Marlin drive? */
+    if (p_resource_entry->sw_load_id == 0xA090061B)
+    {
+        IPR_SET_MODE(p_ch->dimm, p_buf->dimm, 1);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_marlin_17Gb(struct ipr_resource_entry *p_resource_entry,
+                                            struct ipr_disc_reconn_page *p_ch,
+                                            struct ipr_disc_reconn_page *p_buf)
+{
+    ipr_set_page0x02_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->dimm, p_buf->dimm, 1);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_thresher_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_disc_reconn_page *p_ch,
+                                             struct ipr_disc_reconn_page *p_buf)
+{
+    ipr_set_page0x02_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->maximum_burst_size, p_buf->maximum_burst_size, htosis32(0));
+    IPR_SET_MODE(p_ch->dimm, p_buf->dimm, 1);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x02 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x02_hammerhead_18Gb(struct ipr_resource_entry *p_resource_entry,
+                                                struct ipr_disc_reconn_page *p_ch,
+                                                struct ipr_disc_reconn_page *p_buf)
+{
+    ipr_set_page0x02_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->maximum_burst_size, p_buf->maximum_burst_size, htosis32(0));
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x07 buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x07(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_verify_err_rec_page *p_ch,
+                                struct ipr_verify_err_rec_page *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_ch && p_buf)
+    {
+        if (p_dev_cfg && p_dev_cfg->set_page0x07)
+            p_dev_cfg->set_page0x07(p_resource_entry, p_ch, p_buf);
+        else
+            ipr_set_page0x07_defaults(p_resource_entry, p_ch, p_buf);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x07 to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x07_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_verify_err_rec_page *p_ch,
+                                         struct ipr_verify_err_rec_page *p_buf)
+{
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x07 to the default AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x07_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_verify_err_rec_page *p_ch,
+                                      struct ipr_verify_err_rec_page *p_buf)
+{
+    ipr_set_page0x07_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->per, p_buf->per, 1);
+    IPR_SET_MODE(p_ch->dcr, p_buf->dcr, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_caching_page *p_ch,
+                                struct ipr_caching_page *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_ch && p_buf)
+    {
+        if (p_dev_cfg && p_dev_cfg->set_page0x08)
+            p_dev_cfg->set_page0x08(p_resource_entry, p_ch, p_buf);
+        else
+            ipr_set_page0x08_defaults(p_resource_entry, p_ch, p_buf);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_caching_page *p_ch,
+                                         struct ipr_caching_page *p_buf)
+{
+    IPR_SET_MODE(p_ch->wce, p_buf->wce, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 to the default AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_caching_page *p_ch,
+                                      struct ipr_caching_page *p_buf)
+{
+    ipr_set_page0x08_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->mf, p_buf->mf, 0);
+    IPR_SET_MODE(p_ch->rcd, p_buf->rcd, 0);
+    IPR_SET_MODE(p_ch->demand_read_retention_priority,
+                    p_buf->demand_read_retention_priority, 1);
+    IPR_SET_MODE(p_ch->write_retention_priority,
+                    p_buf->write_retention_priority, 1);
+    IPR_SET_MODE(p_ch->disable_pre_fetch_xfer_len,
+                    p_buf->disable_pre_fetch_xfer_len, htosis32(0xffff));
+    IPR_SET_MODE(p_ch->max_pre_fetch, p_buf->max_pre_fetch, htosis32(0xffff));
+    IPR_SET_MODE(p_ch->max_pre_fetch_ceiling,
+                    p_buf->max_pre_fetch_ceiling, htosis32(0xffff));
+    IPR_SET_MODE(p_ch->num_cache_segments,
+                    p_buf->num_cache_segments, 0x08);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 to the default AS/400 TCQ settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_TCQ(struct ipr_resource_entry *p_resource_entry,
+                                    struct ipr_caching_page *p_ch,
+                                    struct ipr_caching_page *p_buf)
+{
+    ipr_set_page0x08_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->rcd, p_buf->rcd, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_scorpion_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_caching_page *p_ch,
+                                             struct ipr_caching_page *p_buf)
+{
+    ipr_set_page0x08_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->num_cache_segments, p_buf->num_cache_segments, 0x10);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_marlin_17Gb(struct ipr_resource_entry *p_resource_entry,
+                                            struct ipr_caching_page *p_ch,
+                                            struct ipr_caching_page *p_buf)
+{
+    ipr_set_page0x08_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->num_cache_segments, p_buf->num_cache_segments, 0x10);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_thresher_8Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_caching_page *p_ch,
+                                             struct ipr_caching_page *p_buf)
+{
+    ipr_set_page0x08_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->num_cache_segments, p_buf->num_cache_segments, 0x18);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_hammerhead_18Gb(struct ipr_resource_entry *p_resource_entry,
+                                                struct ipr_caching_page *p_ch,
+                                                struct ipr_caching_page *p_buf)
+{
+    ipr_set_page0x08_as400(p_resource_entry, p_ch, p_buf);
+    IPR_SET_MODE(p_ch->num_cache_segments, p_buf->num_cache_segments, 0x18);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_discovery_36Gb(struct ipr_resource_entry *p_resource_entry,
+                                               struct ipr_caching_page *p_ch,
+                                               struct ipr_caching_page *p_buf)
+{
+    IPR_SET_MODE(p_ch->wce, p_buf->wce, 0);
+    IPR_SET_MODE(p_ch->mf, p_buf->mf, 0);
+    IPR_SET_MODE(p_ch->rcd, p_buf->rcd, 0);
+
+    IPR_SET_MODE(p_ch->demand_read_retention_priority,
+                    p_buf->demand_read_retention_priority, 1);
+    IPR_SET_MODE(p_ch->write_retention_priority,
+                    p_buf->write_retention_priority, 1);
+    IPR_SET_MODE(p_ch->disable_pre_fetch_xfer_len,
+                    p_buf->disable_pre_fetch_xfer_len, htosis32(0xffff));
+    IPR_SET_MODE(p_ch->max_pre_fetch, p_buf->max_pre_fetch, htosis32(0xffff));
+    IPR_SET_MODE(p_ch->max_pre_fetch_ceiling,
+                    p_buf->max_pre_fetch_ceiling, htosis32(0xffff));
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x08 for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x08_daytona_70Gb(struct ipr_resource_entry *p_resource_entry,
+                                             struct ipr_caching_page *p_ch,
+                                             struct ipr_caching_page *p_buf)
+{
+    IPR_SET_MODE(p_ch->wce, p_buf->wce, 0);
+    IPR_SET_MODE(p_ch->rcd, p_buf->rcd, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x0a buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x0a(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_control_mode_page *p_ch,
+                                struct ipr_control_mode_page *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_ch && p_buf)
+    {
+        if (p_dev_cfg && p_dev_cfg->set_page0x0a)
+            p_dev_cfg->set_page0x0a(p_resource_entry, p_ch, p_buf);
+        else
+            ipr_set_page0x0a_defaults(p_resource_entry, p_ch, p_buf);
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x0a to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x0a_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_control_mode_page *p_ch,
+                                         struct ipr_control_mode_page *p_buf)
+{
+    IPR_SET_MODE(p_ch->queue_algorithm_modifier,
+                    p_buf->queue_algorithm_modifier, 1);
+    IPR_SET_MODE(p_ch->qerr, p_buf->qerr, 1);
+    IPR_SET_MODE(p_ch->dque, p_buf->dque, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x0a to the default TCQ AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x0a_noTCQ(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_control_mode_page *p_ch,
+                                      struct ipr_control_mode_page *p_buf)
+{
+    ipr_set_page0x0a_defaults(p_resource_entry, p_ch, p_buf);
+
+    IPR_SET_MODE(p_ch->queue_algorithm_modifier,
+                    p_buf->queue_algorithm_modifier, 0);
+    IPR_SET_MODE(p_ch->qerr, p_buf->qerr, 0);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x0a to the default AS/400 settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x0a_as400(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_control_mode_page *p_ch,
+                                      struct ipr_control_mode_page *p_buf)
+{
+    ipr_set_page0x0a_defaults(p_resource_entry, p_ch, p_buf);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x20 to the default settings for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x20_defaults(struct ipr_resource_entry *p_resource_entry,
+                                         struct ipr_ioa_dasd_page_20 *p_buf)
+{
+    p_buf->max_TCQ_depth = 64;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x20 to the default settings for mode select
+ *          for Tagged Command Queuing
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x20_noTCQ(struct ipr_resource_entry *p_resource_entry,
+                                      struct ipr_ioa_dasd_page_20 *p_buf)
+{
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page 0x20 buffer for mode select
+ * Lock State: io_request_lock assumed to be held
+ * Returns: nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_set_page0x20(struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_ioa_dasd_page_20 *p_buf)
+{
+    const struct ipr_dev_config *p_dev_cfg = ipr_get_dev_config(p_resource_entry);
+
+    if (p_dev_cfg && p_dev_cfg->set_page0x20)
+        p_dev_cfg->set_page0x20(p_resource_entry, p_buf);
+    else
+        ipr_set_page0x20_defaults(p_resource_entry, p_buf);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Setup mode page buffer for a mode select to a DASD
+ * Lock State: io_request_lock assumed to be held
+ * Returns: mode page allocation length
+ *---------------------------------------------------------------------------*/
+static u8 ipr_set_mode_pages(struct ipr_shared_config *p_shared_cfg,
+                                struct ipr_resource_entry *p_resource_entry,
+                                struct ipr_mode_parm_hdr *p_mode_parm,
+                                struct ipr_mode_parm_hdr *p_changeable_pages)
+{
+    struct ipr_vendor_unique_page *p_vendor_unique_pg, *p_ch_vendor_unique;
+    struct ipr_rw_err_mode_page *p_rw_err_mode_pg, *p_ch_rw_err_mode_pg;
+    struct ipr_disc_reconn_page *p_disc_reconn_pg, *p_ch_disc_reconn_pg;
+    struct ipr_verify_err_rec_page *p_verify_err_rec_pg, *p_ch_verify_err_rec_pg;
+    struct ipr_caching_page *p_caching_pg, *p_ch_caching_pg;
+    struct ipr_control_mode_page *p_control_pg, *p_ch_control_pg;
+    struct ipr_ioa_dasd_page_20 *p_ioa_dasd_pg_20;
+    struct ipr_mode_page_hdr *p_mode_hdr;
+    int i;
+    u8 alloc_len;
+
+#ifdef IPR_DEBUG_MODE_PAGES
+    printk("Before modification: for 0x%04X"IPR_EOL, p_resource_entry->type);
+    ipr_print_mode_sense_buffer(p_mode_parm);
+
+    printk("Change mask: for 0x%04X"IPR_EOL, p_resource_entry->type);
+    ipr_print_mode_sense_buffer(p_changeable_pages);
+#endif
+
+    /* Get pages ready for mode select */
+    for (i = 0; i < 0x3f; i++)
+    {
+        p_mode_hdr = ipr_get_mode_page(p_mode_parm, i, sizeof(struct ipr_mode_page_hdr));
+
+        if (p_mode_hdr != NULL)
+            p_mode_hdr->parms_saveable = 0;
+    }
+
+    p_vendor_unique_pg = ipr_get_mode_page(p_mode_parm, 0x00,
+                                              sizeof(struct ipr_vendor_unique_page));
+    p_ch_vendor_unique = ipr_get_mode_page(p_changeable_pages, 0x00,
+                                              sizeof(struct ipr_vendor_unique_page));
+
+    ipr_set_page0x00(p_resource_entry, p_ch_vendor_unique, p_vendor_unique_pg);
+
+    p_rw_err_mode_pg = ipr_get_mode_page(p_mode_parm, 0x01,
+                                            sizeof(struct ipr_rw_err_mode_page));
+    p_ch_rw_err_mode_pg = ipr_get_mode_page(p_changeable_pages, 0x01,
+                                               sizeof(struct ipr_rw_err_mode_page));
+
+    ipr_set_page0x01(p_resource_entry, p_ch_rw_err_mode_pg, p_rw_err_mode_pg);
+
+    p_disc_reconn_pg = ipr_get_mode_page(p_mode_parm, 0x02, sizeof(struct ipr_disc_reconn_page));
+    p_ch_disc_reconn_pg = ipr_get_mode_page(p_changeable_pages, 0x02, sizeof(struct ipr_disc_reconn_page));
+
+    ipr_set_page0x02(p_resource_entry, p_ch_disc_reconn_pg, p_disc_reconn_pg);
+
+    p_verify_err_rec_pg = ipr_get_mode_page(p_mode_parm, 0x07,
+                                               sizeof(struct ipr_verify_err_rec_page));
+    p_ch_verify_err_rec_pg = ipr_get_mode_page(p_changeable_pages, 0x07,
+                                                  sizeof(struct ipr_verify_err_rec_page));
+
+    ipr_set_page0x07(p_resource_entry, p_ch_verify_err_rec_pg, p_verify_err_rec_pg);
+
+    p_caching_pg = ipr_get_mode_page(p_mode_parm, 0x08, sizeof(struct ipr_caching_page));
+    p_ch_caching_pg = ipr_get_mode_page(p_changeable_pages, 0x08, sizeof(struct ipr_caching_page));
+
+    ipr_set_page0x08(p_resource_entry, p_ch_caching_pg, p_caching_pg);
+
+    p_control_pg = ipr_get_mode_page(p_mode_parm, 0x0a,
+                                        sizeof(struct ipr_control_mode_page));
+    p_ch_control_pg = ipr_get_mode_page(p_changeable_pages, 0x0a,
+                                           sizeof(struct ipr_control_mode_page));
+
+    ipr_set_page0x0a(p_resource_entry, p_ch_control_pg, p_control_pg);
+
+    if (p_shared_cfg->set_mode_page_20)
+    {
+        p_ioa_dasd_pg_20 = ipr_get_mode_page(p_mode_parm, 0x20, sizeof(struct ipr_ioa_dasd_page_20));
+        ipr_set_page0x20(p_resource_entry, p_ioa_dasd_pg_20);
+    }
+
+#ifdef IPR_DEBUG_MODE_PAGES
+    printk("After modification: for 0x%04X"IPR_EOL, p_resource_entry->type);
+    ipr_print_mode_sense_buffer(p_mode_parm);
+#endif
+
+    alloc_len = p_mode_parm->length + 1;
+
+    p_mode_parm->length = 0;
+    p_mode_parm->medium_type = 0;
+    p_mode_parm->device_spec_parms = 0;
+
+    return alloc_len;
+}
+
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a buffer for use in the DASD init job
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to the buffer
+ *---------------------------------------------------------------------------*/
+static struct ipr_dasd_init_bufs
+*ipr_get_dasd_init_buffer(struct ipr_data *ipr_cfg)
+{
+    struct ipr_dasd_init_bufs *p_cur_buf = ipr_cfg->free_init_buf_head;
+
+    if (p_cur_buf == NULL)
+        return NULL;
+
+    ipr_cfg->free_init_buf_head = p_cur_buf->p_next;
+    p_cur_buf->p_next = NULL;
+    return p_cur_buf;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Frees a buffer for use in the DASD init job
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_put_dasd_init_buffer(struct ipr_data *ipr_cfg,
+                                        struct ipr_dasd_init_bufs *p_dasd_init_buffer)
+{
+    struct ipr_dasd_init_bufs *p_cur_buf = ipr_cfg->free_init_buf_head;
+
+    if (ipr_cfg->free_init_buf_head == NULL)
+        ipr_cfg->free_init_buf_head = p_dasd_init_buffer;
+    else
+    {
+        for (p_cur_buf = ipr_cfg->free_init_buf_head;
+             p_cur_buf->p_next != NULL;
+             p_cur_buf = p_cur_buf->p_next)
+        {
+        }
+        p_cur_buf->p_next = p_dasd_init_buffer;
+    }
+    p_dasd_init_buffer->p_next = NULL;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Wait for an IODEBUG ACK from the IOA
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS   - Success
+ *          IPR_RC_FAILED    - Failed
+ *---------------------------------------------------------------------------*/
+static int ipr_wait_iodebug_ack(struct ipr_data *ipr_cfg,
+                                   int max_delay)
+{
+    volatile u32 pcii_reg;
+    int delay = 1;
+    int rc = IPR_RC_FAILED;  /* initialize rc to failed in case of timeout */
+
+    /* Read interrupt reg until IOA signals IO Debug Acknowledge */
+    while (delay < max_delay)
+    {
+        pcii_reg = readl(ipr_cfg->regs.sense_interrupt_reg);
+
+        if (pcii_reg & IPR_PCII_IO_DEBUG_ACKNOWLEDGE)
+        {
+            rc = IPR_RC_SUCCESS;
+            break;
+        }
+
+        /* Delay and then double delay time for next iteration */
+        ipr_udelay(delay);
+        delay += delay;
+    }
+    return (rc);
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Internal routine for obtaining a continuous section of LDUMP data
+ * Lock State: io_request_lock assumed to be held
+ * Returns: IPR_RC_SUCCESS
+ *          IPR_RC_FAILED
+ *---------------------------------------------------------------------------*/
+int ipr_get_ldump_data_section(struct ipr_shared_config *p_shared_cfg,
+                                  u32 fmt2_start_addr,
+                                  u32 *p_dest,
+                                  u32 length_in_words)
+{
+    u32 temp_pcii_reg;
+    int i, delay = 0;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    /* Write IOA interrupt reg starting LDUMP state  */
+    writel((IPR_UPROCI_RESET_ALERT | IPR_UPROCI_IO_DEBUG_ALERT),
+           ipr_cfg->regs.set_uproc_interrupt_reg);
+
+    /* Wait for IO debug acknowledge */
+    if (IPR_RC_FAILED ==
+        ipr_wait_iodebug_ack(ipr_cfg,
+                             IPR_LDUMP_MAX_LONG_ACK_DELAY_IN_USEC))
+    {
+        ipr_log_err("IOA long data transfer timeout"IPR_EOL);
+        return IPR_RC_FAILED;
+    }
+
+    /* Signal LDUMP interlocked - clear IO debug ack */
+    writel(IPR_PCII_IO_DEBUG_ACKNOWLEDGE,
+           ipr_cfg->regs.clr_interrupt_reg);
+
+    /* Write Mailbox with starting address */
+    writel(fmt2_start_addr,
+           p_shared_cfg->ioa_mailbox);
+
+    /* Signal address valid - clear IOA Reset alert */
+    writel(IPR_UPROCI_RESET_ALERT,
+           ipr_cfg->regs.clr_uproc_interrupt_reg);
+
+    for (i=0; i<length_in_words; i++)
+    {
+        /* Wait for IO debug acknowledge*/
+        if (IPR_RC_FAILED ==
+            ipr_wait_iodebug_ack(ipr_cfg,
+                                 IPR_LDUMP_MAX_SHORT_ACK_DELAY_IN_USEC))
+        {
+            ipr_log_err("IOA short data transfer timeout"IPR_EOL);
+            return IPR_RC_FAILED;
+        }
+
+        /* Read data from mailbox and increment destination pointer*/
+        *p_dest = htosis32(readl(p_shared_cfg->ioa_mailbox));
+        p_dest++;
+
+        /* For all but the last word of data, signal data received */
+        if (i < (length_in_words-1))
+            /* Signal dump data received - Clear IO debug Ack */
+            writel(IPR_PCII_IO_DEBUG_ACKNOWLEDGE,
+                   ipr_cfg->regs.clr_interrupt_reg);
+    }
+
+    /* Signal end of block transfer. Set reset alert then clear IO debug ack */
+    writel(IPR_UPROCI_RESET_ALERT,
+           ipr_cfg->regs.set_uproc_interrupt_reg);
+
+    writel(IPR_UPROCI_IO_DEBUG_ALERT,
+           ipr_cfg->regs.clr_uproc_interrupt_reg);
+
+    /* Signal dump data received - Clear IO debug Ack */
+    writel(IPR_PCII_IO_DEBUG_ACKNOWLEDGE,
+           ipr_cfg->regs.clr_interrupt_reg);
+
+    /* Wait for IOA to signal LDUMP exit - IOA reset alert will be cleared */
+    while (delay < IPR_LDUMP_MAX_SHORT_ACK_DELAY_IN_USEC)
+    {
+        temp_pcii_reg = readl(ipr_cfg->regs.sense_uproc_interrupt_reg);
+
+        if (!(temp_pcii_reg & IPR_UPROCI_RESET_ALERT))
+            break;
+
+        /* Delay 10 usecs. */
+        ipr_udelay(10);
+        delay += (10);
+    }
+
+    return IPR_RC_SUCCESS;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Return a pointer to the internal trace and its length
+ * Lock State: io_request_lock assumed to be held
+ * Returns: pointer to internal trace, length
+ *---------------------------------------------------------------------------*/
+void ipr_get_internal_trace(struct ipr_shared_config *p_shared_cfg,
+                               u32 **trace_block_address,
+                               u32 *trace_block_length)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+
+    if (ipr_cfg->trace == NULL)
+        *trace_block_length = 0;
+    else
+        *trace_block_length = (sizeof(struct ipr_internal_trace_entry) *
+                               IPR_NUM_TRACE_ENTRIES);
+
+    *trace_block_address = (u32 *)ipr_cfg->trace;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Copy the internal trace to caller's buffer
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+void ipr_copy_internal_trace_for_dump(struct ipr_shared_config *p_shared_cfg,
+                                         u32 *p_buffer,
+                                         u32 buffer_len)
+{
+    int i;
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    struct ipr_internal_trace_entry *p_temp_trace_entry;
+
+    ENTER;
+
+    if (ipr_cfg->trace == NULL)
+        return;
+
+    p_temp_trace_entry = (struct ipr_internal_trace_entry *)p_buffer;
+
+    for (i = 0;
+         (i < IPR_NUM_TRACE_ENTRIES) && (buffer_len >= sizeof(struct ipr_internal_trace_entry));
+         i++, buffer_len -= sizeof(struct ipr_internal_trace_entry), p_temp_trace_entry++)
+    {
+        p_temp_trace_entry->time = htosis32(ipr_cfg->trace[i].time);
+        p_temp_trace_entry->op_code = ipr_cfg->trace[i].op_code;
+        p_temp_trace_entry->type = ipr_cfg->trace[i].type;
+        p_temp_trace_entry->device_type = ipr_cfg->trace[i].device_type;
+        p_temp_trace_entry->host_ioarcb_index = htosis16(ipr_cfg->trace[i].host_ioarcb_index);
+        p_temp_trace_entry->xfer_len = htosis32(ipr_cfg->trace[i].xfer_len);
+        p_temp_trace_entry->data.res_addr = htosis32(ipr_cfg->trace[i].data.res_addr);
+    }
+
+    LEAVE;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Check the backplane to see if 15K devices need to be blocked
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_check_backplane(struct ipr_shared_config *p_shared_cfg,
+                                   struct ipr_config_table_entry *cfgte)
+{
+    struct ipr_data *ipr_cfg = p_shared_cfg->p_data;
+    const struct ipr_backplane_table_entry *p_bte;
+    int bus_num, ii;
+
+    if (IPR_IS_SES_DEVICE(cfgte->std_inq_data))
+    {
+        bus_num = cfgte->resource_address.bus;
+
+        if (bus_num > IPR_MAX_NUM_BUSES)
+        {
+            ipr_log_err("Invalid resource address returned for SES"IPR_EOL);
+            ipr_log_err("Resource address: 0x%08x"IPR_EOL,
+                           IPR_GET_PHYSICAL_LOCATOR(cfgte->resource_address));
+            return;
+        }
+
+        for /*! Loop through entries of the backplane table */
+            (ii = 0,
+             p_bte = &ipr_backplane_table[0];
+             ii < (sizeof(ipr_backplane_table)/
+                   sizeof(struct ipr_backplane_table_entry));
+             ii++, p_bte++)
+        {
+            /* Does the Product ID for this SCSI device match this entry in
+             the backplane table */
+            if (memcmp(cfgte->std_inq_data.vpids.product_id,
+                              p_bte->product_id, IPR_PROD_ID_LEN) == 0)
+            {
+                if (p_bte->block_15k_devices)
+                {
+                    /* Set the bit corresponding to the bus number */
+                    ipr_cfg->non15k_ses |= 1 << bus_num;
+                    ipr_cfg->p_ssd_header->num_records = IPR_NUM_NON15K_DASD;
+                    ipr_cfg->p_ssd_header->data_length =
+                        htosis16(sizeof(ipr_supported_dev_list.dev_non15k) +
+                                 sizeof(struct ipr_ssd_header));
+                }
+            }
+        }
+    }
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Get a resource entry for use in the resource table
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Pointer to the resource entry
+ *---------------------------------------------------------------------------*/
+static struct ipr_resource_dll
+*ipr_get_resource_entry(struct ipr_shared_config *p_shared_cfg)
+{
+    struct ipr_resource_dll *p_resource_dll;
+
+    /* Grab an available resource entry */
+    p_resource_dll = p_shared_cfg->rsteFreeH;
+
+    if (p_resource_dll == NULL)
+    {
+        /* No resources left */
+        ipr_beg_err(KERN_ERR);
+        ipr_log_err("Max number of devices allowed for adapter exceeded"IPR_EOL);
+        ipr_log_ioa_physical_location(p_shared_cfg->p_location, KERN_ERR);
+        ipr_end_err(KERN_ERR);
+        return NULL;
+    }
+
+    p_shared_cfg->rsteFreeH  = p_resource_dll->next;
+
+    if (p_shared_cfg->rsteFreeH == NULL)
+        p_shared_cfg->rsteFreeT = NULL;
+
+    /* Now put that resource entry in allocated list */
+    if (p_shared_cfg->rsteUsedT == NULL)
+    {
+        /* if the tail is NULL, the head MUST be NULL as well
+         which allows the entry to be locked to the head */
+        p_shared_cfg->rsteUsedH = p_resource_dll;
+    }
+    else
+    {
+        p_shared_cfg->rsteUsedT->next = p_resource_dll;
+    }
+
+    p_resource_dll->prev = p_shared_cfg->rsteUsedT;
+    p_shared_cfg->rsteUsedT = p_resource_dll;
+    p_shared_cfg->rsteUsedT->next = NULL;
+
+    memset(&p_resource_dll->data, 0, sizeof(struct ipr_resource_entry));
+    return p_resource_dll;
+}
+
+/*---------------------------------------------------------------------------
+ * Purpose: Free a resource entry
+ * Lock State: io_request_lock assumed to be held
+ * Returns: Nothing
+ *---------------------------------------------------------------------------*/
+static void ipr_put_resource_entry(struct ipr_shared_config *p_shared_cfg,
+                                      struct ipr_resource_dll *p_resource_dll)
+{
+
+    /* Remove from allocated list */
+    if ((p_resource_dll == p_shared_cfg->rsteUsedH) &&
+        (p_resource_dll == p_shared_cfg->rsteUsedT))
+    {
+        p_shared_cfg->rsteUsedH = NULL;
+        p_shared_cfg->rsteUsedT = NULL;
+    }    
+    else if (p_resource_dll == p_shared_cfg->rsteUsedH)
+    {
+        p_shared_cfg->rsteUsedH = p_resource_dll->next;
+        p_shared_cfg->rsteUsedH->prev = NULL;
+    }
+    else if (p_resource_dll == p_shared_cfg->rsteUsedT)
+    {
+        p_shared_cfg->rsteUsedT = p_resource_dll->prev;
+        p_shared_cfg->rsteUsedT->next = NULL;
+    }
+    else
+    {
+        p_resource_dll->prev->next = p_resource_dll->next;  
+        p_resource_dll->next->prev = p_resource_dll->prev;
+    }
+
+    /* Now add this resource entry to available list */
+    if (p_shared_cfg->rsteFreeT == NULL)
+    {
+        /* if the tail is NULL, the head MUST be NULL as well
+         which allows the entry to be locked to the head */
+        p_shared_cfg->rsteFreeH = p_resource_dll;
+    }
+    else
+    {
+        p_shared_cfg->rsteFreeT->next = p_resource_dll;
+    }
+    p_resource_dll->prev = p_shared_cfg->rsteFreeT;
+    p_shared_cfg->rsteFreeT = p_resource_dll;
+    p_shared_cfg->rsteFreeT->next = NULL;
+}
diff -urNp linux-8230/drivers/addon/ipr/lib/iprliblits.h linux-8240/drivers/addon/ipr/lib/iprliblits.h
--- linux-8230/drivers/addon/ipr/lib/iprliblits.h
+++ linux-8240/drivers/addon/ipr/lib/iprliblits.h
@@ -0,0 +1,119 @@
+/*****************************************************************************/
+/* iprliblits.h -- driver for IBM Power Linux RAID adapters                  */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/lib/iprliblits.h,v 1.2.2.1 2003/10/29 14:04:26 bjking1 Exp $
+ */
+
+#ifndef iprliblits_h
+#define iprliblits_h
+
+#ifndef iprlits_h
+#include "iprlits.h"
+#endif
+
+#if IPR_DBG_TRACE
+#define ipr_trace printk(KERN_ERR IPR_NAME": %s: %s: Line: %d"\
+IPR_EOL, __FILE__, __FUNCTION__, __LINE__);
+#else
+#define ipr_trace
+#endif
+
+/******************************************************************/
+/* Literals                                                       */
+/******************************************************************/
+
+#define IPR_DOORBELL                         0x82800000
+
+#define IPR_PCII_IOA_TRANS_TO_OPER           (0x80000000 >> 0)
+#define IPR_PCII_IOARCB_XFER_FAILED          (0x80000000 >> 3)
+#define IPR_PCII_IOA_UNIT_CHECKED            (0x80000000 >> 4)
+#define IPR_PCII_NO_HOST_RRQ                 (0x80000000 >> 5)
+#define IPR_PCII_CRITICAL_OPERATION          (0x80000000 >> 6)
+#define IPR_PCII_IO_DEBUG_ACKNOWLEDGE        (0x80000000 >> 7)
+#define IPR_PCII_IOARRIN_LOST                (0x80000000 >> 27)
+#define IPR_PCII_MMIO_ERROR                  (0x80000000 >> 28)
+#define IPR_PCII_PROC_ERR_STATE              (0x80000000 >> 29)
+#define IPR_PCII_HOST_RRQ_UPDATED            (0x80000000 >> 30)
+#define IPR_PCII_CORE_ISSUED_RST_REQ         (0x80000000 >> 31)
+
+#define IPR_PCII_ERROR_INTERRUPTS            (IPR_PCII_IOARCB_XFER_FAILED | \
+                                                 IPR_PCII_IOA_UNIT_CHECKED | \
+                                                 IPR_PCII_NO_HOST_RRQ | \
+                                                 IPR_PCII_IOARRIN_LOST | \
+                                                 IPR_PCII_MMIO_ERROR)
+
+#define IPR_PCII_OPER_INTERRUPTS             (IPR_PCII_ERROR_INTERRUPTS | \
+                                                 IPR_PCII_HOST_RRQ_UPDATED)
+
+#define IPR_403I_RESET_ALERT                 (0x80000000 >> 7)
+#define IPR_UPROCI_RESET_ALERT               (0x80000000 >> 7)
+#define IPR_UPROCI_IO_DEBUG_ALERT            (0x80000000 >> 9)
+
+#define IPR_LDUMP_MAX_LONG_ACK_DELAY_IN_USEC       1000000   /* 1 second */
+#define IPR_LDUMP_MAX_SHORT_ACK_DELAY_IN_USEC       500000   /* 500 ms */
+
+#define IPR_SET_SUP_DEVICE_TIMEOUT           120             /* 120 seconds */
+#define IPR_SET_DASD_TIMEOUTS_TIMEOUT        120             /* 120 seconds */
+#define IPR_REQUEST_SENSE_TIMEOUT            30              /* 30 seconds  */
+#define IPR_OPERATIONAL_TIMEOUT              (12 * 60)       /* 12 minutes  */
+
+#define IPR_MAX_OP_SIZE                      (256 * 1024)
+#define IPR_NUM_IOADL_ENTRIES                IPR_MAX_SGLIST
+
+/**************************************************
+ *   DASD initialization job steps
+ **************************************************/
+#define IPR_DINIT_START                              1
+#define IPR_DINIT_STD_INQUIRY                        2
+#define IPR_DINIT_QUERY_RESOURCE_STATE               3
+#define IPR_DINIT_SET_SUPPORTED_DEVICE               4
+#define IPR_DINIT_DASD_INIT_SET_DASD_TIMEOUTS        5
+#define IPR_DINIT_PAGE3_INQ                          6
+#define IPR_DINIT_MODE_SENSE_CUR                     7
+#define IPR_DINIT_MODE_SENSE_CHANGEABLE              8
+#define IPR_DINIT_MODE_SELECT                        9
+
+#define IPR_VINIT_START                              1
+#define IPR_VINIT_QUERY_RESOURCE_STATE               2
+
+#define IPR_RETURN_FROM_JOB                          0
+#define IPR_CONTINUE_WITH_JOB                        1
+
+/**************************************************
+ *   SES initialization job steps
+ **************************************************/
+#define IPR_SINIT_START              1
+#define IPR_SINIT_MODE_SENSE         2
+#define IPR_SINIT_MODE_SELECT        3
+
+/**************************************************
+ *   SIS Commands
+ **************************************************/
+#define IPR_ID_HOST_RR_Q             0xC4u
+#define IPR_SKIP_READ                0xE8u
+#define IPR_SKIP_WRITE               0xEAu
+#define IPR_SET_DASD_TIMEOUTS        0xECu
+#define IPR_SET_SUPPORTED_DEVICES    0xFBu
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/lib/iprlibtypes.h linux-8240/drivers/addon/ipr/lib/iprlibtypes.h
--- linux-8230/drivers/addon/ipr/lib/iprlibtypes.h
+++ linux-8240/drivers/addon/ipr/lib/iprlibtypes.h
@@ -0,0 +1,292 @@
+/*****************************************************************************/
+/* iprlibtypes.h -- driver for IBM Power Linux RAID adapters                 */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/lib/iprlibtypes.h,v 1.2 2003/10/24 20:52:18 bjking1 Exp $
+ */
+
+#ifndef iprlibtypes_h
+#define iprlibtypes_h
+
+#if (defined(__KERNEL__) && defined(__LITTLE_ENDIAN)) || \
+(!defined(__KERNEL__) && (__BYTE_ORDER == __LITTLE_ENDIAN))
+#ifndef iprlibtypesle_h
+#include "iprlibtypesle.h"
+#endif
+#elif (defined(__KERNEL__) && defined(__BIG_ENDIAN)) || \
+(!defined(__KERNEL__) && (__BYTE_ORDER == __BIG_ENDIAN))
+#ifndef iprlibtypesbe_h
+#include "iprlibtypesbe.h"
+#endif
+#else
+#error "Neither __LITTLE_ENDIAN nor __BIG_ENDIAN defined"
+#endif
+
+struct ipr_error_int_decode_t {
+    u32 interrupt;
+    char *p_error;
+};
+
+struct ipr_error_rc_decode_t {
+    u32 rc;
+    char *p_error;
+};
+
+struct ipr_config_table{
+    u8 num_entries;
+    u8 reserved1;
+    u16 reserved2;
+    struct ipr_config_table_entry dev[IPR_MAX_PHYSICAL_DEVS];
+};
+
+struct ipr_hostrcb_cfg_ch_not_bin
+{
+    struct ipr_config_table_entry cfgte;
+    u8 reserved[936];
+};
+
+struct ipr_ssd_header
+{
+    u16 data_length;
+    u8 reserved;
+    u8 num_records;
+};
+
+struct ipr_supported_device
+{
+    struct ipr_std_inq_vpids vpids;
+    u8  ebcdic_as400_device_type[4];
+    u8  ebcdic_as400_rctt;
+    u8  ebcdic_space;
+    u8  modifier_flags[2];
+    u8  ebcdic_spaces[8];
+};
+
+struct ipr_dasd_timeout_record
+{
+    u8 op_code;
+    u8 reserved;
+    u16 timeout; /* Timeout in seconds */
+};
+
+/* IOA Request Control Block    128 bytes  */
+struct ipr_ioarcb
+{
+    u32 ioarcb_host_pci_addr;
+    u32 reserved;
+    u32 ioa_res_handle;
+    u32 host_response_handle;
+    u32 reserved1;
+    u32 reserved2;
+    u32 reserved3;
+
+    u32 write_data_transfer_length;
+    u32 read_data_transfer_length;
+    u32 write_ioadl_addr;
+    u32 write_ioadl_len;
+    u32 read_ioadl_addr;
+    u32 read_ioadl_len;
+
+    u32 ioasa_host_pci_addr;
+    u16 ioasa_len;   
+    u16 reserved4;
+
+    struct ipr_cmd_pkt ioarcb_cmd_pkt;
+
+    u32 add_cmd_parms_len;
+    u32 add_cmd_parms[10];
+};
+
+/* 8 bytes */
+struct ipr_ioadl_desc {
+    u32 flags_and_data_len;
+#define IPR_IOADL_FLAGS_MASK                         0xff000000
+#define IPR_IOADL_DATA_LEN_MASK                      0x00ffffff
+#define IPR_IOADL_FLAGS_HOST_READ_BUF                0x48000000
+#define IPR_IOADL_FLAGS_HOST_READ_BUF_LAST_DATA      0x49000000
+#define IPR_IOADL_FLAGS_HOST_WR_BUF                  0x68000000
+#define IPR_IOADL_FLAGS_HOST_WR_LAST_DATA            0x69000000
+
+    u32 address;
+};
+
+/* 128 bytes */
+struct ipr_ioasa
+{
+    u32 ioasc;
+#define IPR_IOASC_SENSE_KEY(ioasc) ((ioasc) >> 24)
+#define IPR_IOASC_SENSE_CODE(ioasc) (((ioasc) & 0x00ff0000) >> 16)
+#define IPR_IOASC_SENSE_QUAL(ioasc) (((ioasc) & 0x0000ff00) >> 8)
+#define IPR_IOASC_SENSE_STATUS(ioasc) ((ioasc) & 0x000000ff)
+
+    u16 ret_stat_len;           /* Length of the returned IOASA */
+
+    u16 avail_stat_len;         /* Total Length of status available. */
+
+    u32 residual_data_len;      /* number of bytes in the host data */
+    /* buffers that were not used by the IOARCB command. */
+
+    u32 ilid;
+#define IPR_NO_ILID             0x00000000u 
+
+    u32 fd_ioasc;
+
+    u32 fd_phys_locator;
+
+    u32 fd_res_handle;
+
+    u32 ioasc_specific;      /* status code specific field */
+#define IPR_IOASC_SPECIFIC_MASK  0x00ffffff
+#define IPR_FIELD_POINTER_VALID  (0x80000000 >> 8)
+#define IPR_FIELD_POINTER_MASK   0x0000ffff
+    u32 failing_lba_hi;
+    u32 failing_lba_lo;
+    u32 reserved[22];
+};
+
+/* Before changing this, make sure that the IOADL is 8 byte aligned */
+/* IOARCB and IOASA must be 4 byte aligned */
+struct ipr_host_ioarcb {                     /* 32 bit */            /* 64 bit */
+    struct ipr_ioarcb ioarcb;                /* 128 bytes */         /* 128 bytes */
+    struct ipr_ioadl_desc *p_ioadl;          /* 4 bytes */           /* 8 bytes */
+    struct ipr_ioasa *p_ioasa;               /* 4 bytes */           /* 8 bytes */
+    struct ipr_host_ioarcb *p_next;          /* 4 bytes */           /* 8 bytes */
+    struct ipr_host_ioarcb *p_prev;          /* 4 bytes */           /* 8 bytes */
+    struct ipr_ccb *p_sis_cmd;               /* 4 bytes */           /* 8 bytes */
+    void *reserved;                             /* 4 bytes */           /* 8 bytes */
+    u32 host_ioarcb_index;                      /* 4 bytes */           /* 4 bytes */
+    ipr_dma_addr ioarcb_dma;                 /* 4 bytes */           /* 4 bytes */
+    ipr_dma_addr ioadl_dma;                  /* 4 bytes */           /* 4 bytes */
+    ipr_dma_addr ioasa_dma;                  /* 4 bytes */           /* 4 bytes */
+};                                              /* 168 bytes */         /* 192 bytes */
+
+struct ipr_host_ioarcb_alloc {
+    struct ipr_host_ioarcb host_ioarcb;
+    struct ipr_ioadl_desc ioadl[IPR_NUM_IOADL_ENTRIES];
+    struct ipr_ioasa ioasa;
+};
+
+struct ipr_interrupts
+{
+    unsigned long set_interrupt_mask_reg;
+    unsigned long clr_interrupt_mask_reg;
+    unsigned long sense_interrupt_mask_reg;
+    unsigned long clr_interrupt_reg;
+
+    unsigned long sense_interrupt_reg;
+    unsigned long ioarrin_reg;
+    unsigned long sense_uproc_interrupt_reg;
+    unsigned long set_uproc_interrupt_reg;
+    unsigned long clr_uproc_interrupt_reg;
+};
+
+struct ipr_interrupt_table_t
+{
+    u16 vendor_id;
+    u16 device_id;
+    struct ipr_interrupts regs;
+};
+
+struct ipr_ioa_parms_t
+{
+    u16 vendor_id;
+    u16 device_id;
+    u16 subsystem_id;
+    u16 scsi_id_changeable:1;
+    u16 reserverd:15;
+    u32 max_bus_speed_limit; /* MB/sec limit for this IOA. Should be 0 if no limit */
+};
+
+struct ipr_data
+{
+    char eye_catcher[16];
+#define IPR_DATA_EYE_CATCHER         "sis_cfg"
+
+    char cfg_table_start[8];
+#define IPR_DATA_CFG_TBL_START       "cfg"
+    struct ipr_config_table *p_config_table;
+
+#define IPR_NUM_TRACE_INDEX_BITS     9
+#define IPR_NUM_TRACE_ENTRIES        (1 << IPR_NUM_TRACE_INDEX_BITS)
+    char trace_start[8];
+#define IPR_DATA_TRACE_START         "trace"
+    struct ipr_internal_trace_entry *trace;
+    u32 trace_index:IPR_NUM_TRACE_INDEX_BITS;
+    u32 reserved_index:(32-IPR_NUM_TRACE_INDEX_BITS);
+    ipr_dma_addr config_table_dma;
+
+    char free_start[8];
+#define IPR_FREEQ_START              "free"
+    struct ipr_host_ioarcb *qFreeH;
+    struct ipr_host_ioarcb *qFreeT;
+
+    char pendq_start[8];
+#define IPR_PENDQ_START              "pend"
+    struct ipr_host_ioarcb *qPendingH;
+    struct ipr_host_ioarcb *qPendingT;
+
+    volatile u32 *host_rrq_start_addr;
+    volatile u32 *host_rrq_end_addr;
+    volatile u32 *host_rrq_curr_ptr;
+    volatile u32 toggle_bit;
+    u32 reserved_pad;
+
+    char hrrq_label[8];
+#define IPR_HRRQ_LABEL               "hrrq"
+    u32 *host_rrq;
+    ipr_dma_addr host_rrq_dma;
+#define IPR_HRRQ_REQ_RESP_HANDLE_MASK 0xfffffffc
+#define IPR_HRRQ_RESP_BIT_SET         0x00000002
+#define IPR_HRRQ_TOGGLE_BIT           0x00000001
+#define IPR_HRRQ_REQ_RESP_HANDLE_SHIFT 2
+    u32 non15k_ses;
+
+    struct ipr_dasd_init_bufs *p_dasd_init_buf[IPR_NUM_CFG_CHG_HCAMS];
+    ipr_dma_addr dasd_init_buf_dma[IPR_NUM_CFG_CHG_HCAMS];
+
+    struct ipr_dasd_init_bufs *free_init_buf_head;
+
+    struct ipr_ssd_header *p_ssd_header;
+    ipr_dma_addr ssd_header_dma;
+    u32 reserved_pad2;
+
+    const struct ipr_ioa_parms_t *p_ioa_cfg;
+
+    struct ipr_interrupts regs;      /* 32 bytes */
+
+    char ioarcb_label[8];
+#define IPR_IOARCB_LABEL             "ioarcbs"
+    struct ipr_host_ioarcb *host_ioarcb_list[IPR_NUM_CMD_BLKS];
+    ipr_dma_addr host_ioarcb_list_dma[IPR_NUM_CMD_BLKS];
+};
+
+struct ipr_backplane_table_entry
+{
+    char product_id[17];
+    char compare_product_id_byte[16];
+    u32 max_bus_speed_limit; /* MB/sec limit for this backplane */
+    u32 block_15k_devices:1;
+    u32 reserved:31;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/lib/iprlibtypesbe.h linux-8240/drivers/addon/ipr/lib/iprlibtypesbe.h
--- linux-8230/drivers/addon/ipr/lib/iprlibtypesbe.h
+++ linux-8240/drivers/addon/ipr/lib/iprlibtypesbe.h
@@ -0,0 +1,296 @@
+/*****************************************************************************/
+/* iprlibtypesbe.h -- driver for IBM Power Linux RAID adapters               */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/lib/iprlibtypesbe.h,v 1.2 2003/10/24 20:52:18 bjking1 Exp $
+ */
+
+#ifndef iprlibtypesbe_h
+#define iprlibtypesbe_h
+
+/******************************************************************/
+/* Note: Any additions/changes here must be duplicated in         */
+/*       iprlibtypesle.h                                       */
+/******************************************************************/
+
+#ifndef iprlib_h
+#include "iprlib.h"
+#endif
+
+/**************************************************
+ *   Internal Data Structures
+ **************************************************/
+
+/* 64 bytes */
+struct ipr_config_table_entry{
+    u8 service_level;
+    u8 array_id;
+    u8 is_ioa_resource:1;
+    u8 is_compressed:1;
+    u8 is_array_member:1;
+    u8 is_hot_spare:1;
+    u8 reserved2:2;
+    u8 capacity_reduction_hi:2;
+    u8 capacity_reduction_lo:1;
+    u8 reserved3:3;
+    u8 subtype:4;
+
+#define IPRLIB_GET_CAP_REDUCTION(cfgte) \
+(((cfgte).capacity_reduction_hi << 1) | (cfgte).capacity_reduction_lo)
+
+    struct ipr_res_addr resource_address;
+    u32 resource_handle;
+    u32 reserved4;
+    u32 reserved5;
+    struct ipr_std_inq_data std_inq_data;
+};
+
+struct ipr_internal_trace_entry
+{
+    u32 time;
+
+    u8 op_code;
+    u8 type:4;
+#define IPR_TRACE_START      0x0
+#define IPR_TRACE_FINISH     0xf
+    u8 device_type:4;
+#define IPR_TRACE_DASD       0x0
+#define IPR_TRACE_GEN        0x1
+#define IPR_TRACE_IOA        0x2
+    u16 host_ioarcb_index;
+
+    u32 xfer_len;
+    union {
+        u32 ioasc;
+        u32 res_addr;
+    }data;
+};
+
+struct ipr_vendor_unique_page
+{
+    /* Page code 0x00 */
+    struct ipr_mode_page_hdr header;
+
+    u8 qpe:1;
+    u8 uqe:1;
+    u8 dwd:1;
+    u8 reserved1:4;
+    u8 arhes:1;
+
+    u8 asdpe:1;
+    u8 reserved2:1;
+    u8 cmdac:1;
+    u8 rpfae:1;
+    u8 dotf:1;
+    u8 reserved3:1;
+    u8 rrnde:1;
+    u8 cpe:1;
+
+    u8 reserved4:6;
+    u8 dwlro:1;
+    u8 dlro:1;
+
+    u8 reserved5:2;
+    u8 dsn:1;
+    u8 frdd:1;
+    u8 dpsdp:1;
+    u8 wpen:1;
+    u8 caen:1;
+    u8 ovple:1;
+
+    u8 reserved7[2];
+
+    u8 reserved8:1;
+    u8 adc:1;
+    u8 qemc:1;
+    u8 drd:1;
+    u8 led_mode:4;
+
+    u8 temp_threshold;
+
+    u8 cmd_aging_limit_hi;
+
+    u8 cmd_aging_limit_lo;
+
+    u8 qpe_read_threshold;
+
+    u8 reserved10;
+
+    u8 drrt:1;
+    u8 dnr:1;
+    u8 reserved11:1;
+    u8 rarr:1;
+    u8 ffmt:1;
+    u8 reserved12:3;
+
+    u8 rtp:1;
+    u8 rrc:1;
+    u8 fcert:1;
+    u8 reserved13:1;
+    u8 drpdv:1;
+    u8 dsf:1;
+    u8 irt:1;
+    u8 ivr:1;
+};
+
+struct ipr_rw_err_mode_page
+{
+    /* Page code 0x01 */
+    struct ipr_mode_page_hdr header;
+    u8 awre:1;
+    u8 arre:1;
+    u8 tb:1;
+    u8 rc:1;
+    u8 eer:1;
+    u8 per:1;
+    u8 dte:1;
+    u8 dcr:1;
+    u8 read_retry_count;
+    u8 correction_span;
+    u8 head_offset_count;
+    u8 data_strobe_offset_count;
+    u8 reserved1;
+    u8 write_retry_count;
+    u8 reserved2;
+    u16 recovery_time_limit;
+};
+
+struct ipr_disc_reconn_page
+{
+    /* Page code 0x02 */
+    struct ipr_mode_page_hdr header;
+    u8 buffer_full_ratio;
+    u8 buffer_empty_ratio;
+    u16 bus_inactivity_limit;
+    u16 disconnect_time_limit;
+    u16 connect_time_limit;
+    u16 maximum_burst_size;
+    u8 emdp:1;
+    u8 fair_arbitration:3;
+    u8 dimm:1;
+    u8 dtdc:3;
+    u8 reserved1;
+    u16 first_burst_size;
+};
+
+struct ipr_format_device_page
+{
+    /* Page code 0x03 */
+    struct ipr_mode_page_hdr header;
+    u16 tracks_per_zone;
+    u16 alt_sectors_per_zone;
+    u16 alt_tracks_per_zone;
+    u16 sectors_per_track;
+    u16 data_bytes_per_phys_sector;
+    u16 interleave;
+    u16 track_skew_factor;
+    u16 cylinder_skew_factor;
+    u8 ssec:1;
+    u8 hsec:1;
+    u8 rmb:1;
+    u8 surf:1;
+    u8 reserved:4;
+    u8 reserved2[3];
+};
+
+struct ipr_verify_err_rec_page
+{
+    /* Page code 0x07 */
+    struct ipr_mode_page_hdr header;
+    u8 reserved1:4;
+    u8 eer:1;
+    u8 per:1;
+    u8 dte:1;
+    u8 dcr:1;
+    u8 verify_retry_count;
+    u8 verify_correction_span;
+    u8 reserved2[5];
+    u16 verify_recovery_time;
+};
+
+struct ipr_caching_page
+{
+    /* Page code 0x08 */
+    struct ipr_mode_page_hdr header;
+    u8 ic:1;
+    u8 abpf:1;
+    u8 cap:1;
+    u8 disc:1;
+    u8 size:1;
+    u8 wce:1;
+    u8 mf:1;
+    u8 rcd:1;
+    u8 demand_read_retention_priority:4;
+    u8 write_retention_priority:4;
+    u16 disable_pre_fetch_xfer_len;
+    u16 min_pre_fetch;
+    u16 max_pre_fetch;
+    u16 max_pre_fetch_ceiling;
+    u8 fsw:1;
+    u8 lbcss:1;
+    u8 dra:1;
+    u8 vendor_spec:2;
+    u8 reserved1:3;
+    u8 num_cache_segments;
+    u16 cache_segment_size;
+    u8 reserved2;
+    u8 non_cache_segment_size_hi;
+    u8 non_cache_segment_size_mid;
+    u8 non_cache_segment_size_lo;
+};
+
+struct ipr_ioa_dasd_page_20
+{
+    /* Mode page 0x20 */
+    struct ipr_mode_page_hdr header;
+    u8 auto_alloc_on_write:1;
+    u8 disable_idle_time_diag:1;
+    u8 reserved:6;
+    u8 max_TCQ_depth;
+};
+
+/* SIS command packet structure */
+struct ipr_cmd_pkt
+{
+    u16 reserved;               /* Reserved by IOA */
+    u8 request_type;
+#define IPR_RQTYPE_SCSICDB     0x00
+#define IPR_RQTYPE_IOACMD      0x01
+#define IPR_RQTYPE_HCAM        0x02
+
+    u8 luntar_luntrn;
+
+    u8 write_not_read:1;
+    u8 reserved2:1;
+    u8 no_underlength_checking:1;
+    u8 cmd_sync_override:1;
+    u8 reserved3:4;
+
+    u8 reserved4;
+
+    u8 cdb[16];
+    u16 cmd_timeout;
+} ;
+
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/lib/iprlibtypesle.h linux-8240/drivers/addon/ipr/lib/iprlibtypesle.h
--- linux-8230/drivers/addon/ipr/lib/iprlibtypesle.h
+++ linux-8240/drivers/addon/ipr/lib/iprlibtypesle.h
@@ -0,0 +1,296 @@
+/*****************************************************************************/
+/* iprlibtypesle.h -- driver for IBM Power Linux RAID adapters               */
+/*                                                                           */
+/* Written By: Brian King, IBM Corporation                                   */
+/*                                                                           */
+/* Copyright (C) 2003 IBM Corporation                                        */
+/*                                                                           */
+/* This program is free software; you can redistribute it and/or modify      */
+/* it under the terms of the GNU General Public License as published by      */
+/* the Free Software Foundation; either version 2 of the License, or         */
+/* (at your option) any later version.                                       */
+/*                                                                           */
+/* This program is distributed in the hope that it will be useful,           */
+/* but WITHOUT ANY WARRANTY; without even the implied warranty of            */
+/* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the             */
+/* GNU General Public License for more details.                              */
+/*                                                                           */
+/* You should have received a copy of the GNU General Public License         */
+/* along with this program; if not, write to the Free Software               */
+/* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */
+/*                                                                           */
+/*****************************************************************************/
+
+/*
+ * $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/lib/iprlibtypesle.h,v 1.2 2003/10/24 20:52:18 bjking1 Exp $
+ */
+
+#ifndef iprlibtypesle_h
+#define iprlibtypesle_h
+
+/******************************************************************/
+/* Note: Any additions/changes here must be duplicated in         */
+/*       iprlibtypesbe.h                                       */
+/******************************************************************/
+
+#ifndef iprlib_h
+#include "iprlib.h"
+#endif
+
+/**************************************************
+ *   Internal Data Structures
+ **************************************************/
+
+/* 64 bytes */
+struct ipr_config_table_entry{
+    u8 service_level;
+    u8 array_id;
+    u8 capacity_reduction_hi:2;
+    u8 reserved2:2;
+    u8 is_hot_spare:1;
+    u8 is_array_member:1;
+    u8 is_compressed:1;
+    u8 is_ioa_resource:1;
+    u8 subtype:4;
+    u8 reserved3:3;
+    u8 capacity_reduction_lo:1;
+
+#define IPRLIB_GET_CAP_REDUCTION(cfgte) \
+(((cfgte).capacity_reduction_hi << 1) | (cfgte).capacity_reduction_lo)
+
+    struct ipr_res_addr resource_address;
+    u32 resource_handle;
+    u32 reserved4;
+    u32 reserved5;
+    struct ipr_std_inq_data std_inq_data;
+};
+
+struct ipr_internal_trace_entry
+{
+    u32 time;
+
+    u16 host_ioarcb_index;
+    u8 device_type:4;
+#define IPR_TRACE_DASD       0x0
+#define IPR_TRACE_GEN        0x1
+#define IPR_TRACE_IOA        0x2
+    u8 type:4;
+#define IPR_TRACE_START      0x0
+#define IPR_TRACE_FINISH     0xf
+    u8 op_code;
+
+    u32 xfer_len;
+
+    union {
+        u32 ioasc;
+        u32 res_addr;
+    }data;
+};
+
+struct ipr_vendor_unique_page
+{
+    /* Page code 0x00 */
+    struct ipr_mode_page_hdr header;
+
+    u8 arhes:1;
+    u8 reserved1:4;
+    u8 dwd:1;
+    u8 uqe:1;
+    u8 qpe:1;
+
+    u8 cpe:1;
+    u8 rrnde:1;
+    u8 reserved3:1;
+    u8 dotf:1;
+    u8 rpfae:1;
+    u8 cmdac:1;
+    u8 reserved2:1;
+    u8 asdpe:1;
+
+    u8 dlro:1;
+    u8 dwlro:1;
+    u8 reserved4:6;
+
+    u8 ovple:1;
+    u8 caen:1;
+    u8 wpen:1;
+    u8 dpsdp:1;
+    u8 frdd:1;
+    u8 dsn:1;
+    u8 reserved5:2;
+
+    u8 reserved7[2];
+
+    u8 led_mode:4;
+    u8 drd:1;
+    u8 qemc:1;
+    u8 adc:1;
+    u8 reserved8:1;
+
+    u8 temp_threshold;
+
+    u8 cmd_aging_limit_hi;
+
+    u8 cmd_aging_limit_lo;
+
+    u8 qpe_read_threshold;
+
+    u8 reserved10;
+
+    u8 reserved12:3;
+    u8 ffmt:1;
+    u8 rarr:1;
+    u8 reserved11:1;
+    u8 dnr:1;
+    u8 drrt:1;
+
+    u8 ivr:1;
+    u8 irt:1;
+    u8 dsf:1;
+    u8 drpdv:1;
+    u8 reserved13:1;
+    u8 fcert:1;
+    u8 rrc:1;
+    u8 rtp:1;
+};
+
+struct ipr_rw_err_mode_page
+{
+    /* Page code 0x01 */
+    struct ipr_mode_page_hdr header;
+    u8 dcr:1;
+    u8 dte:1;
+    u8 per:1;
+    u8 eer:1;
+    u8 rc:1;
+    u8 tb:1;
+    u8 arre:1;
+    u8 awre:1;
+    u8 read_retry_count;
+    u8 correction_span;
+    u8 head_offset_count;
+    u8 data_strobe_offset_count;
+    u8 reserved1;
+    u8 write_retry_count;
+    u8 reserved2;
+    u16 recovery_time_limit;
+};
+
+struct ipr_disc_reconn_page
+{
+    /* Page code 0x02 */
+    struct ipr_mode_page_hdr header;
+    u8 buffer_full_ratio;
+    u8 buffer_empty_ratio;
+    u16 bus_inactivity_limit;
+    u16 disconnect_time_limit;
+    u16 connect_time_limit;
+    u16 maximum_burst_size;
+    u8 reserved1;
+    u8 dtdc:3;
+    u8 dimm:1;
+    u8 fair_arbitration:3;
+    u8 emdp:1;
+    u16 first_burst_size;
+};
+
+struct ipr_format_device_page
+{
+    /* Page code 0x03 */
+    struct ipr_mode_page_hdr header;
+    u16 tracks_per_zone;
+    u16 alt_sectors_per_zone;
+    u16 alt_tracks_per_zone;
+    u16 sectors_per_track;
+    u16 data_bytes_per_phys_sector;
+    u16 interleave;
+    u16 track_skew_factor;
+    u16 cylinder_skew_factor;
+    u8 reserved:4;
+    u8 surf:1;
+    u8 rmb:1;
+    u8 hsec:1;
+    u8 ssec:1;
+    u8 reserved2[3];
+};
+
+struct ipr_verify_err_rec_page
+{
+    /* Page code 0x07 */
+    struct ipr_mode_page_hdr header;
+    u8 dcr:1;
+    u8 dte:1;
+    u8 per:1;
+    u8 eer:1;
+    u8 reserved1:4;
+    u8 verify_retry_count;
+    u8 verify_correction_span;
+    u8 reserved2[5];
+    u16 verify_recovery_time;
+};
+
+struct ipr_caching_page
+{
+    /* Page code 0x08 */
+    struct ipr_mode_page_hdr header;
+    u8 rcd:1;
+    u8 mf:1;
+    u8 wce:1;
+    u8 size:1;
+    u8 disc:1;
+    u8 cap:1;
+    u8 abpf:1;
+    u8 ic:1;
+    u8 write_retention_priority:4;
+    u8 demand_read_retention_priority:4;
+    u16 disable_pre_fetch_xfer_len;
+    u16 min_pre_fetch;
+    u16 max_pre_fetch;
+    u16 max_pre_fetch_ceiling;
+    u8 reserved1:3;
+    u8 vendor_spec:2;
+    u8 dra:1;
+    u8 lbcss:1;
+    u8 fsw:1;
+    u8 num_cache_segments;
+    u16 cache_segment_size;
+    u8 reserved2;
+    u8 non_cache_segment_size_hi;
+    u8 non_cache_segment_size_mid;
+    u8 non_cache_segment_size_lo;
+};
+
+struct ipr_ioa_dasd_page_20
+{
+    /* Mode page 0x20 */
+    struct ipr_mode_page_hdr header;
+    u8 reserved:6;
+    u8 disable_idle_time_diag:1;
+    u8 auto_alloc_on_write:1;
+    u8 max_TCQ_depth;
+};
+
+/* SIS command packet structure */
+struct ipr_cmd_pkt
+{
+    u16 reserved;               /* Reserved by IOA */
+    u8 request_type;
+#define IPR_RQTYPE_SCSICDB     0x00
+#define IPR_RQTYPE_IOACMD      0x01
+#define IPR_RQTYPE_HCAM        0x02
+
+    u8 luntar_luntrn;
+
+    u8 reserved3:4;
+    u8 cmd_sync_override:1;
+    u8 no_underlength_checking:1;
+    u8 reserved2:1;
+    u8 write_not_read:1;
+
+    u8 reserved4;
+
+    u8 cdb[16];
+    u16 cmd_timeout;
+};
+
+#endif
diff -urNp linux-8230/drivers/addon/ipr/version.mk linux-8240/drivers/addon/ipr/version.mk
--- linux-8230/drivers/addon/ipr/version.mk
+++ linux-8240/drivers/addon/ipr/version.mk
@@ -0,0 +1,14 @@
+# $Header: /afs/rchland.ibm.com/usr8/ibmsis/devel/ipr/ipr/src/version.mk,v 1.2.2.3 2003/11/10 19:19:51 bjking1 Exp $
+
+IPR_MAJOR_RELEASE=1
+IPR_MINOR_RELEASE=0
+IPR_FIX_LEVEL=4
+IPR_FIX_DATE=(April 15, 2004)
+
+IPR_VERSION_STR=Ver. $(IPR_MAJOR_RELEASE) Rev. $(IPR_MINOR_RELEASE).$(IPR_FIX_LEVEL)
+
+IPR_DEFINES = -DIPR_MAJOR_RELEASE=$(IPR_MAJOR_RELEASE) \
+		 -DIPR_MINOR_RELEASE=$(IPR_MINOR_RELEASE) \
+		 -DIPR_FIX_LEVEL=$(IPR_FIX_LEVEL) \
+		 -DIPR_FIX_DATE='"$(IPR_FIX_DATE)"' \
+		 -DIPR_VERSION_STR='"$(IPR_VERSION_STR)"'
