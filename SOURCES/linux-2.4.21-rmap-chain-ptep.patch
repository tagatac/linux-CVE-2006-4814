diff -urNp linux-1020/include/asm-generic/rmap.h linux-1025/include/asm-generic/rmap.h
--- linux-1020/include/asm-generic/rmap.h
+++ linux-1025/include/asm-generic/rmap.h
@@ -26,6 +26,29 @@
  */
 #include <linux/mm.h>
 
+/*
+ * The pte_addr_t is the type of the pte.direct field of the page
+ * structure, whereas the chain_ptep_t is the type of the ptes[]
+ * array elements in the pte_chain structure.  The PTE_ADDR_C2D()
+ * macro converts from a chain_ptep_t to a pte_addr_t, and the
+ * PTE_ADDR_D2C() macro converts from a pte_addr_t to a chain_ptep_t.
+ *
+ * Typically, these mappings are no-ops.  But for certain x86
+ * configurations, the pte_addr_t is 64 bits and the chain_ptep_t
+ * is 32 bits, thus more than doubling the number of pte addresses
+ * that can be stored in a pte_chain structure.  In this case, the
+ * definitions for CHAIN_PTEP_T, PTE_ADDR_C2D(), and PTE_ADDR_D2C()
+ * must occur in an architecture-dependent header file before this
+ * header file is included.
+ */
+#ifdef CHAIN_PTEP_T
+typedef CHAIN_PTEP_T	chain_ptep_t;
+#else
+typedef pte_addr_t	chain_ptep_t;
+#define PTE_ADDR_C2D(x) ((pte_addr_t)(x))
+#define PTE_ADDR_D2C(x) ((chain_ptep_t)(x))
+#endif
+
 static inline void pgtable_add_rmap(struct page * page, struct mm_struct * mm, unsigned long address)
 {
 #ifdef BROKEN_PPC_PTE_ALLOC_ONE
@@ -62,16 +85,16 @@ static inline unsigned long ptep_to_addr
 }
 
 #if CONFIG_HIGHPTE
-static inline pte_addr_t ptep_to_paddr(pte_t *ptep)
+static inline chain_ptep_t ptep_to_paddr(pte_t *ptep)
 {
-	pte_addr_t paddr;
-	paddr = ((pte_addr_t)page_to_pfn(kmap_atomic_to_page(ptep))) << PAGE_SHIFT;
-	return paddr + (pte_addr_t)((unsigned long)ptep & ~PAGE_MASK);
+	u64 paddr;
+	paddr = (u64)page_to_pfn(kmap_atomic_to_page(ptep)) << PAGE_SHIFT;
+	return PTE_ADDR_D2C(paddr + ((u64)(unsigned long)ptep & ~PAGE_MASK));
 }
 #else
-static inline pte_addr_t ptep_to_paddr(pte_t *ptep)
+static inline chain_ptep_t ptep_to_paddr(pte_t *ptep)
 {
-	return (pte_addr_t)ptep;
+	return (chain_ptep_t)ptep;
 }
 #endif
 
diff -urNp linux-1020/include/asm-i386/pgtable.h linux-1025/include/asm-i386/pgtable.h
--- linux-1020/include/asm-i386/pgtable.h
+++ linux-1025/include/asm-i386/pgtable.h
@@ -367,6 +367,11 @@ typedef u32 pte_addr_t;
 
 #if defined(CONFIG_HIGHPTE) && defined(CONFIG_HIGHMEM64G)
 typedef u64 pte_addr_t;
+#if !defined(CONFIG_X86_4G)
+#define CHAIN_PTEP_T	u32
+#define PTE_ADDR_D2C(x)	((u32)((x) >> 3))
+#define PTE_ADDR_C2D(x)	((pte_addr_t)(x) << 3)
+#endif
 #endif
 
 #if !defined(CONFIG_HIGHPTE)
diff -urNp linux-1020/mm/rmap.c linux-1025/mm/rmap.c
--- linux-1020/mm/rmap.c
+++ linux-1025/mm/rmap.c
@@ -42,7 +42,7 @@
  * We use an array of pte pointers in this structure to minimise cache misses
  * while traversing reverse maps.
  */
-#define NRPTE ((L1_CACHE_BYTES - sizeof(unsigned long))/sizeof(pte_addr_t))
+#define NRPTE ((L1_CACHE_BYTES - sizeof(unsigned long))/sizeof(chain_ptep_t))
 
 /*
  * next_and_idx encodes both the address of the next pte_chain and the
@@ -50,7 +50,7 @@
  */
 struct pte_chain {
 	unsigned long next_and_idx;
-	pte_addr_t ptes[NRPTE];
+	chain_ptep_t ptes[NRPTE];
 } ____cacheline_aligned;
 
 static kmem_cache_t	*pte_chain_cache;
@@ -173,12 +173,12 @@ int page_referenced(struct page * page, 
 			int i;
 
 			for (i = NRPTE-1; i >= 0; i--) {
-				pte_addr_t pte_paddr = pc->ptes[i];
+				chain_ptep_t pte_paddr = pc->ptes[i];
 				pte_t *pte;
 
 				if (!pte_paddr)
 					break;
-				pte = rmap_ptep_map(pte_paddr);
+				pte = rmap_ptep_map(PTE_ADDR_C2D(pte_paddr));
 				if (ptep_test_and_clear_young(pte))
 					referenced++;
 				mm = ptep_to_mm(pte);
@@ -190,7 +190,7 @@ int page_referenced(struct page * page, 
 		}
 		if (nr_chains == 1) {
 			pc = page->pte.chain;
-			page->pte.direct = pc->ptes[NRPTE-1];
+			page->pte.direct = PTE_ADDR_C2D(pc->ptes[NRPTE-1]);
 			SetPageDirect(page);
 			pc->ptes[NRPTE-1] = 0;
 			__pte_chain_free(pc);
@@ -217,7 +217,7 @@ int page_referenced(struct page * page, 
 struct pte_chain *
 page_add_rmap(struct page * page, pte_t * ptep, struct pte_chain * pte_chain)
 {
-	pte_addr_t pte_paddr = ptep_to_paddr(ptep);
+	chain_ptep_t pte_paddr = ptep_to_paddr(ptep);
 	struct pte_chain * cur_pte_chain;
 
 #ifdef DEBUG_RMAP
@@ -242,12 +242,12 @@ page_add_rmap(struct page * page, pte_t 
 		struct pte_chain * pc;
 		int i;
 		if (PageDirect(page)) {
-			if (page->pte.direct == pte_paddr)
+			if (page->pte.direct == PTE_ADDR_C2D(pte_paddr))
 				BUG();
 		} else {
 			for (pc = page->pte.chain; pc; pc = pc->next) {
 				for (i = 0; i < NRPTE; i++) {
-					pte_addr_t pte = pc->ptes[i];
+					chain_ptep_t pte = pc->ptes[i];
 
 					if (pte && pte == pte_paddr)
 						BUG();
@@ -258,7 +258,7 @@ page_add_rmap(struct page * page, pte_t 
 #endif
 
 	if (page->pte.direct == 0) {
-		page->pte.direct = pte_paddr;
+		page->pte.direct = PTE_ADDR_C2D(pte_paddr);
 		SetPageDirect(page);
 		goto out;
 	}
@@ -266,7 +266,7 @@ page_add_rmap(struct page * page, pte_t 
 	if (PageDirect(page)) {
 		/* Convert a direct pointer into a pte_chain */
 		ClearPageDirect(page);
-		pte_chain->ptes[NRPTE-1] = page->pte.direct;
+		pte_chain->ptes[NRPTE-1] = PTE_ADDR_D2C(page->pte.direct);
 		pte_chain->ptes[NRPTE-2] = pte_paddr;
 		pte_chain->next_and_idx = pte_chain_encode(NULL, NRPTE-2);
 		page->pte.direct = 0;
@@ -303,7 +303,7 @@ out:
  */
 void page_remove_rmap(struct page * page, pte_t * ptep)
 {
-	pte_addr_t pte_paddr = ptep_to_paddr(ptep);
+	chain_ptep_t pte_paddr = ptep_to_paddr(ptep);
 	struct pte_chain *pc;
 
 	if (!page || !ptep)
@@ -320,7 +320,7 @@ void page_remove_rmap(struct page * page
 		printk("page_remove_rmap: reserved page with rmap...\n");
 
 	if (PageDirect(page)) {
-		if (page->pte.direct == pte_paddr) {
+		if (page->pte.direct == PTE_ADDR_C2D(pte_paddr)) {
 			page->pte.direct = 0;
 			ClearPageDirect(page);
 			goto out;
@@ -337,7 +337,7 @@ void page_remove_rmap(struct page * page
 			if (next)
 				prefetch(next);
 			for (i = pte_chain_idx(pc); i < NRPTE; i++) {
-				pte_addr_t pa = pc->ptes[i];
+				chain_ptep_t pa = pc->ptes[i];
 
 				if (victim_i == -1)
 					victim_i = i;
@@ -499,14 +499,15 @@ int try_to_unmap(struct page * page)
 		if (next_pc)
 			prefetch(next_pc);
 		for (i = pte_chain_idx(pc); i < NRPTE; i++) {
-			pte_addr_t pte_paddr = pc->ptes[i];
+			chain_ptep_t pte_paddr = pc->ptes[i];
 
 			if (!pte_paddr)
 				continue;
 			if (victim_i == -1) 
 				victim_i = i;
 
-			switch (try_to_unmap_one(page, pte_paddr)) {
+			switch (try_to_unmap_one(page,
+				PTE_ADDR_C2D(pte_paddr))) {
 			case SWAP_SUCCESS:
 				/*
 				 * Release a slot.  If we're releasing the
