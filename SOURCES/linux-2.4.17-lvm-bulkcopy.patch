diff -urNp linux-1120/drivers/md/lvm-internal.h linux-1121/drivers/md/lvm-internal.h
--- linux-1120/drivers/md/lvm-internal.h	
+++ linux-1121/drivers/md/lvm-internal.h	
@@ -96,6 +96,8 @@ int lvm_write_COW_table_block(vg_t *, lv
 void lvm_hash_link(lv_block_exception_t *, kdev_t, ulong, lv_t *);
 int lvm_snapshot_alloc_hash_table(lv_t *);
 void lvm_drop_snapshot(vg_t *vg, lv_t *, const char *);
+int lvm_snapshot_alloc_iobuf_pages(struct kiobuf *, int);
+int lvm_do_bulk_copy(kdev_t, kdev_t, uint, uint, uint);
 
 
 /* lvm_fs.c */
diff -urNp linux-1120/drivers/md/lvm-snap.c linux-1121/drivers/md/lvm-snap.c
--- linux-1120/drivers/md/lvm-snap.c	
+++ linux-1121/drivers/md/lvm-snap.c	
@@ -241,7 +241,7 @@ static inline int lvm_snapshot_prepare_b
 	return 1;
 }
 
-inline int lvm_get_blksize(kdev_t dev)
+extern int lvm_get_blksize(kdev_t dev)
 {
 	int correct_size = BLOCK_SIZE, i, major;
 
@@ -278,6 +278,90 @@ static inline void invalidate_snap_cache
 #endif
 
 
+static int lvm_do_bulk_copy_iobuf(struct kiobuf *iobuf,
+				  kdev_t old_dev, kdev_t new_dev, 
+				  uint old_start, uint new_start, 
+				  uint total_sectors)
+{
+	int err, ret;
+	int old_blksize, new_blksize, io_sectors;
+	int min_blksize, max_blksize;
+	
+	old_blksize = get_hardsect_size(old_dev);
+	new_blksize = get_hardsect_size(new_dev);
+
+	max_blksize = max(old_blksize, new_blksize);
+	min_blksize = min(old_blksize, new_blksize);
+
+	err = -EINVAL;
+	if (total_sectors % (max_blksize>>9))
+		goto out;
+	
+	while (total_sectors)
+	{
+		io_sectors = min(total_sectors, (uint) KIO_MAX_SECTORS);
+		total_sectors -= io_sectors;
+
+		iobuf->length = io_sectors << 9;
+
+		if(!lvm_snapshot_prepare_blocks(iobuf->blocks, old_start,
+						io_sectors, old_blksize))
+			goto out;
+
+		ret = brw_kiovec(READ, 1, &iobuf, old_dev,
+				 iobuf->blocks, old_blksize) ;
+		if (ret != (io_sectors<<9))
+			goto fail_io;
+
+		if(!lvm_snapshot_prepare_blocks(iobuf->blocks, new_start,
+						io_sectors, new_blksize))
+			goto out;
+
+		ret = brw_kiovec(WRITE, 1, &iobuf, new_dev,
+				 iobuf->blocks, new_blksize);
+		if (ret != (io_sectors<<9))
+			goto fail_io;
+
+		old_start += io_sectors;
+		new_start += io_sectors;
+	}
+	err = 0;
+out:
+	return err;
+
+fail_io:
+	if (ret < 0)
+		err = ret;
+	else
+		err = -EIO;
+	goto out;
+}
+
+
+extern int lvm_do_bulk_copy(kdev_t old_dev, kdev_t new_dev, 
+			    uint old_start, uint new_start, 
+			    uint total_sectors)
+{
+	struct kiobuf *iobuf;
+	int err;
+	
+	err = alloc_kiovec(1, &iobuf);
+	if (err)
+		return err;
+	
+	err = lvm_snapshot_alloc_iobuf_pages(iobuf, KIO_MAX_SECTORS);
+	if (err)
+		goto out;
+
+	err = lvm_do_bulk_copy_iobuf(iobuf, old_dev, new_dev,
+				     old_start, new_start, total_sectors);
+	unmap_kiobuf(iobuf);
+out:
+	free_kiovec(1, &iobuf);
+	return err;
+}
+
+
 int lvm_snapshot_fill_COW_page(vg_t * vg, lv_t * lv_snap)
 {
 	int id = 0, is = lv_snap->lv_remap_ptr;
@@ -355,7 +439,6 @@ int lvm_snapshot_COW(kdev_t org_phys_dev
 {
 	const char * reason;
 	unsigned long org_start, snap_start, snap_phys_dev, virt_start, pe_off;
-	unsigned long phys_start;
 	int idx = lv_snap->lv_remap_ptr, chunk_size = lv_snap->lv_chunk_size;
 	struct kiobuf * iobuf = lv_snap->lv_iobuf;
 	unsigned long *blocks = iobuf->blocks;
@@ -388,44 +471,9 @@ int lvm_snapshot_COW(kdev_t org_phys_dev
 	       org_virt_sector);
 #endif
 
-	blksize_org = lvm_sectsize(org_phys_dev);
-	blksize_snap = lvm_sectsize(snap_phys_dev);
-	max_blksize = max(blksize_org, blksize_snap);
-	min_blksize = min(blksize_org, blksize_snap);
-	max_sectors = KIO_MAX_SECTORS * (min_blksize>>9);
-
-	if (chunk_size % (max_blksize>>9))
-		goto fail_blksize;
-
-	/* Don't change org_start, we need it to fill in the exception table */
-	phys_start = org_start;
-
-	while (chunk_size)
-	{
-		nr_sectors = min(chunk_size, max_sectors);
-		chunk_size -= nr_sectors;
-
-		iobuf->length = nr_sectors << 9;
-
-		if (!lvm_snapshot_prepare_blocks(blocks, phys_start,
-						 nr_sectors, blksize_org))
-			goto fail_prepare;
-
-		if (__brw_kiovec(READ, 1, &iobuf, org_phys_dev, blocks,
-				 blksize_org, lv_snap) != (nr_sectors<<9))
-			goto fail_raw_read;
-
-		if (!lvm_snapshot_prepare_blocks(blocks, snap_start,
-						 nr_sectors, blksize_snap))
-			goto fail_prepare;
-
-		if (__brw_kiovec(WRITE, 1, &iobuf, snap_phys_dev, blocks,
-				 blksize_snap, lv_snap) != (nr_sectors<<9))
-			goto fail_raw_write;
-
-		phys_start += nr_sectors;
-		snap_start += nr_sectors;
-	}
+	if (lvm_do_bulk_copy_iobuf(iobuf, org_phys_dev, snap_phys_dev,
+				   org_start, snap_start, chunk_size))
+		goto fail_io;
 
 #ifdef DEBUG_SNAPSHOT
 	/* invalidate the logical snapshot buffer cache */
@@ -455,19 +503,8 @@ out:
 fail_out_of_space:
 	reason = "out of space";
 	goto out;
-fail_raw_read:
-	reason = "read error";
-	goto out;
-fail_raw_write:
-	reason = "write error";
-	goto out;
-fail_blksize:
-	reason = "blocksize error";
-	goto out;
-
-fail_prepare:
-	reason = "couldn't prepare kiovec blocks "
-		"(start probably isn't block aligned)";
+fail_io:
+	reason = "IO error";
 	goto out;
 }
 
