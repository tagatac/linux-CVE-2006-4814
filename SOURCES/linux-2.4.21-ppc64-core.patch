diff -urNp linux-463/arch/ppc/boot/lib/zlib.c linux-340/arch/ppc/boot/lib/zlib.c
--- linux-463/arch/ppc/boot/lib/zlib.c
+++ linux-340/arch/ppc/boot/lib/zlib.c
@@ -1322,6 +1322,7 @@ z_stream *zs;           /* for zalloc fu
     if ((j = *p++) != 0)
       v[x[j]++] = i;
   } while (++i < n);
+  n = x[g];			/* set n to length of v */
 
 
   /* Generate the Huffman codes and for each, make the table entries */
diff -urNp linux-463/arch/ppc64/boot/ppc32-types.h linux-340/arch/ppc64/boot/ppc32-types.h
--- linux-463/arch/ppc64/boot/ppc32-types.h
+++ linux-340/arch/ppc64/boot/ppc32-types.h
@@ -25,6 +25,9 @@ typedef unsigned int u32;
 typedef signed long long s64;
 typedef unsigned long long u64;
 
+typedef unsigned int umode_t;
+typedef unsigned int size_t;
+
 #define BITS_PER_LONG 32
 
 #endif /* _PPC64_TYPES_H */
diff -urNp linux-463/arch/ppc64/boot/zImage.c linux-340/arch/ppc64/boot/zImage.c
--- linux-463/arch/ppc64/boot/zImage.c
+++ linux-340/arch/ppc64/boot/zImage.c
@@ -11,7 +11,7 @@
 #define __KERNEL__
 #include "ppc32-types.h"
 #include "zlib.h"
-#include <linux/elf.h>
+#include <elf.h>
 #include <linux/version.h>
 #include <asm/processor.h>
 #include <asm/page.h>
diff -urNp linux-463/arch/ppc64/boot/zlib.c linux-340/arch/ppc64/boot/zlib.c
--- linux-463/arch/ppc64/boot/zlib.c
+++ linux-340/arch/ppc64/boot/zlib.c
@@ -735,7 +735,7 @@ local uInt border[] = { /* Order of the 
       end-of-block.  Note however that the static length tree defines
       288 codes just to fill out the Huffman codes.  Codes 286 and 287
       cannot be used though, since there is no length base or extra bits
-      defined for them.  Similarily, there are up to 30 distance codes.
+      defined for them.  Similarly, there are up to 30 distance codes.
       However, static trees define 32 codes (all 5 bits) to fill out the
       Huffman codes, but the last two had better not show up in the data.
    7. Unzip can check dynamic Huffman blocks for complete code sets.
@@ -1338,6 +1338,7 @@ z_stream *zs;           /* for zalloc fu
     if ((j = *p++) != 0)
       v[x[j]++] = i;
   } while (++i < n);
+  n = x[g];			/* set n to length of v */
 
 
   /* Generate the Huffman codes and for each, make the table entries */
diff -urNp linux-463/arch/ppc64/config.in linux-340/arch/ppc64/config.in
--- linux-463/arch/ppc64/config.in
+++ linux-340/arch/ppc64/config.in
@@ -39,9 +39,25 @@ else
 bool 'MsChunks Physical to Absolute address translation support' CONFIG_MSCHUNKS
 tristate 'Firmware flash interface' CONFIG_RTAS_FLASH
 tristate 'Scanlog Dump interface' CONFIG_SCANLOG
+bool 'Support for RTAS (RunTime Abstraction Services) in /proc' CONFIG_PPC_RTAS
+     if [ "$CONFIG_PPC_RTAS" = "y" ]; then
+	bool 'RTAS Error Inject' CONFIG_RTAS_ERRINJCT
+     fi
+fi
+
+bool 'Shared kernel/user space addressing' CONFIG_SHARED_MEMORY_ADDRESSING
+
+if [ "$CONFIG_PPC_ISERIES" = "y" -a "$CONFIG_SMP" = "y" ]; then
+   choice 'HMT Support' \
+       "off           CONFIG_NR_SIBLINGS_0 \
+        2-siblings    CONFIG_NR_SIBLINGS_2" off
+fi 
+   
+if [ "$CONFIG_NR_SIBLINGS_2" = "y" ]; then
+   define_bool CONFIG_SHARE_RUNQUEUE y
+   define_int CONFIG_MAX_NR_SIBLINGS 2
 fi
 
-
 endmenu
 
 mainmenu_option next_comment
@@ -238,6 +254,7 @@ bool 'Magic SysRq key' CONFIG_MAGIC_SYSR
 bool 'Include kgdb kernel debugger' CONFIG_KGDB
 bool 'Include xmon kernel debugger' CONFIG_XMON
 bool 'Include kdb kernel debugger' CONFIG_KDB
+bool 'Debug memory allocations' CONFIG_DEBUG_SLAB
 if [ "$CONFIG_KDB" = "y" ]; then
   bool '  KDB off by default' CONFIG_KDB_OFF
   define_bool CONFIG_KALLSYMS y
diff -urNp linux-463/arch/ppc64/kernel/HvCall.c linux-340/arch/ppc64/kernel/HvCall.c
--- linux-463/arch/ppc64/kernel/HvCall.c
+++ linux-340/arch/ppc64/kernel/HvCall.c
@@ -105,11 +105,10 @@ void HvCall_writeLogBuffer(const void *b
 			bytesLeft -= leftThisPage;
 		}
 
+		HvCall2(HvCallBaseWriteLogBuffer,
+			virt_to_absolute((unsigned long)&bufList), 
+			bufList.len);
+
 		curPtr = (curPtr & PAGE_MASK) + PAGE_SIZE;
 	}
-
-
-	HvCall2(HvCallBaseWriteLogBuffer,
-		virt_to_absolute((unsigned long)&bufList), bufLen);
-
 }
diff -urNp linux-463/arch/ppc64/kernel/LparData.c linux-340/arch/ppc64/kernel/LparData.c
--- linux-463/arch/ppc64/kernel/LparData.c
+++ linux-340/arch/ppc64/kernel/LparData.c
@@ -71,7 +71,7 @@ struct HvReleaseData hvReleaseData = {
 	6,		/* TEMP: This allows non-GA driver */
 	4,		/* We are v5r2m0               */
 	3,		/* Min supported PLIC = v5r1m0 */
-	3,		/* Min usuable PLIC   = v5r1m0 */
+	3,		/* Min usable PLIC   = v5r1m0 */
 	{ 0xd3, 0x89, 0x95, 0xa4, /* "Linux 2.4   "*/
 	  0xa7, 0x40, 0xf2, 0x4b,
 	  0xf4, 0x4b, 0xf6, 0xf4 },
diff -urNp linux-463/arch/ppc64/kernel/Makefile linux-340/arch/ppc64/kernel/Makefile
--- linux-463/arch/ppc64/kernel/Makefile
+++ linux-340/arch/ppc64/kernel/Makefile
@@ -27,7 +27,7 @@ obj-y               :=	ppc_ksyms.o setup
 			pmc.o mf_proc.o proc_pmc.o proc_pcifr.o iSeries_setup.o \
 			ItLpQueue.o hvCall.o mf.o HvLpEvent.o ras.o \
 			iSeries_proc.o HvCall.o flight_recorder.o HvLpConfig.o \
-			rtc.o perfmon.o
+			rtc.o perfmon.o cputable.o
 
 obj-$(CONFIG_PCI) +=  pci.o pci_dn.o pci_dma.o pSeries_lpar.o pSeries_hvCall.o
 
@@ -58,6 +58,16 @@ include $(TOPDIR)/Rules.make
 
 head.o: head.S ppc_defs.h
 
+sys32.o: sys32.S ppc_defs.h
+
+misc.o: misc.S ppc_defs.h
+
+entry.o: entry.S ppc_defs.h
+
+pSeries_hvCall.o: pSeries_hvCall.S ppc_defs.h
+
+hvCall.o: hvCall.S ppc_defs.h
+
 ppc_defs.h: mk_defs.c ppc_defs.head \
 		$(TOPDIR)/include/asm/mmu.h \
 		$(TOPDIR)/include/asm/processor.h \
diff -urNp linux-463/arch/ppc64/kernel/XmPciLpEvent.c linux-340/arch/ppc64/kernel/XmPciLpEvent.c
--- linux-463/arch/ppc64/kernel/XmPciLpEvent.c
+++ linux-340/arch/ppc64/kernel/XmPciLpEvent.c
@@ -34,7 +34,7 @@ long Pci_Event_Count     = 0;
 enum XmPciLpEvent_Subtype {
 	XmPciLpEvent_BusCreated	   = 0,		// PHB has been created
 	XmPciLpEvent_BusError	   = 1,		// PHB has failed
-	XmPciLpEvent_BusFailed	   = 2,		// Msg to Seconday, Primary failed bus
+	XmPciLpEvent_BusFailed	   = 2,		// Msg to Secondary, Primary failed bus
 	XmPciLpEvent_NodeFailed	   = 4,		// Multi-adapter bridge has failed
 	XmPciLpEvent_NodeRecovered = 5,		// Multi-adapter bridge has recovered
 	XmPciLpEvent_BusRecovered  = 12,	// PHB has been recovered
@@ -99,7 +99,7 @@ static void XmPciLpEvent_handler( struct
 			break;
 		}
 	}
-	else if (event) {
+	else if (eventParm) {
 		printk(KERN_ERR "XmPciLpEvent.c: Unrecognized PCI event type 0x%x\n",(int)eventParm->xType);
 	}
 	else {
diff -urNp linux-463/arch/ppc64/kernel/align.c linux-340/arch/ppc64/kernel/align.c
--- linux-463/arch/ppc64/kernel/align.c
+++ linux-340/arch/ppc64/kernel/align.c
@@ -21,6 +21,7 @@
 #include <asm/uaccess.h>
 #include <asm/system.h>
 #include <asm/cache.h>
+#include <asm/cputable.h>
 
 struct aligninfo {
 	unsigned char len;
@@ -238,7 +239,7 @@ fix_alignment(struct pt_regs *regs)
 	dsisr = regs->dsisr;
 
 	/* Power4 doesn't set DSISR for an alignment interrupt */
-	if (__is_processor(PV_POWER4) || __is_processor(PV_POWER4p))
+	if (cur_cpu_spec->cpu_features & CPU_FTR_NODSISRALIGN)
 		dsisr = make_dsisr( *((unsigned *)regs->nip) );
 
 	/* extract the operation and registers from the dsisr */
@@ -306,6 +307,7 @@ fix_alignment(struct pt_regs *regs)
 				/* Doing stfs, have to convert to single */
 				enable_kernel_fp();
 				cvt_df(&current->thread.fpr[reg], (float *)&data.v[4], &current->thread.fpscr);
+				disable_kernel_fp();
 			}
 			else
 				data.dd = current->thread.fpr[reg];
@@ -339,6 +341,7 @@ fix_alignment(struct pt_regs *regs)
 				/* Doing lfs, have to convert to double */
 				enable_kernel_fp();
 				cvt_fd((float *)&data.v[4], &current->thread.fpr[reg], &current->thread.fpscr);
+				disable_kernel_fp();
 			}
 			else
 				current->thread.fpr[reg] = data.dd;
diff -urNp linux-463/arch/ppc64/kernel/chrp_setup.c linux-340/arch/ppc64/kernel/chrp_setup.c
--- linux-463/arch/ppc64/kernel/chrp_setup.c
+++ linux-340/arch/ppc64/kernel/chrp_setup.c
@@ -65,6 +65,7 @@
 #include "open_pic.h"
 #include "xics.h"
 #include <asm/ppcdebug.h>
+#include <asm/cputable.h>
 
 extern volatile unsigned char *chrp_int_ack_special;
 
@@ -302,9 +303,37 @@ chrp_init(unsigned long r3, unsigned lon
 	ppc_md.kbd_init_hw       = pckbd_init_hw;
 #ifdef CONFIG_MAGIC_SYSRQ
 	ppc_md.ppc_kbd_sysrq_xlate = pckbd_sysrq_xlate;
-	SYSRQ_KEY = 0x63;	/* Print Screen */
 #endif
 #endif
+
+        /* Build the firmware_features bitmask field
+         * using contents of device-tree/ibm,hypertas-functions.
+         * Ultimately this functionality may be moved into prom.c prom_init().
+         */
+	struct device_node * dn;
+	char * hypertas;
+	unsigned int len;
+	dn = find_path_device("/rtas");
+	cur_cpu_spec->firmware_features=0;
+	hypertas = get_property(dn, "ibm,hypertas-functions", &len);
+	if (hypertas) {
+	    while (len > 0){
+		int i;
+	    /* check value against table of strings */
+		for(i=0; i < FIRMWARE_MAX_FEATURES ;i++) {
+		    if ((firmware_features_table[i].name) && (strcmp(firmware_features_table[i].name,hypertas))==0) {
+		    /* we have a match */
+			cur_cpu_spec->firmware_features |= (1UL << firmware_features_table[i].val );
+			break;
+		    } 
+		}
+		int hypertas_len = strlen(hypertas);
+		len -= hypertas_len +1;
+		hypertas+= hypertas_len +1;
+	    }
+	}
+	udbg_printf("firmware_features bitmask: 0x%x \n",cur_cpu_spec->firmware_features);
+
 }
 
 void __chrp
diff -urNp linux-463/arch/ppc64/kernel/cputable.c linux-340/arch/ppc64/kernel/cputable.c
--- linux-463/arch/ppc64/kernel/cputable.c
+++ linux-340/arch/ppc64/kernel/cputable.c
@@ -0,0 +1,127 @@
+/*
+ *  arch/ppc/kernel/cputable.c
+ *
+ *  Copyright (C) 2001 Ben. Herrenschmidt (benh@kernel.crashing.org)
+ *
+ *  Modifications for ppc64:
+ *      Copyright (C) 2003 Dave Engebretsen <engebret@us.ibm.com>
+ * 
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/config.h>
+#include <linux/string.h>
+#include <linux/sched.h>
+#include <linux/threads.h>
+#include <linux/init.h>
+#include <asm/cputable.h>
+
+struct cpu_spec* cur_cpu_spec = NULL;
+
+extern void __setup_cpu_power3(unsigned long offset, int cpu_nr, struct cpu_spec* spec);
+extern void __setup_cpu_power4(unsigned long offset, int cpu_nr, struct cpu_spec* spec);
+
+
+/* We only set the altivec features if the kernel was compiled with altivec
+ * support
+ */
+#ifdef CONFIG_ALTIVEC
+#define CPU_FTR_ALTIVEC_COMP	CPU_FTR_ALTIVEC
+#else
+#define CPU_FTR_ALTIVEC_COMP	0
+#endif
+
+struct cpu_spec	cpu_specs[] = {
+    {	/* Power3 */
+	    0xffff0000, 0x00400000, "Power3 (630)",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power3,
+	    COMMON_PPC64_FW
+    },
+    {	/* Power3+ */
+	    0xffff0000, 0x00410000, "Power3 (630+)",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power3,
+	    COMMON_PPC64_FW
+    },
+    {	/* Northstar */
+	    0xffff0000, 0x00330000, "Northstar",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power3,
+	    COMMON_PPC64_FW
+    },
+    {	/* Pulsar */
+	    0xffff0000, 0x00340000, "Pulsar",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power3,
+	    COMMON_PPC64_FW
+    },
+    {	/* I-star */
+	    0xffff0000, 0x00360000, "I-star",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power3,
+	    COMMON_PPC64_FW
+    },
+    {	/* S-star */
+	    0xffff0000, 0x00370000, "S-star",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power3,
+	    COMMON_PPC64_FW
+    },
+    {	/* Power4 */
+	    0xffff0000, 0x00350000, "Power4",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	    CPU_FTR_PPCAS_ARCH_V2,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    },
+    {	/* Power4+ */
+	    0xffff0000, 0x00380000, "Power4+",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	    CPU_FTR_PPCAS_ARCH_V2,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    },
+    {	/* default match */
+	    0x00000000, 0x00000000, "(Power4-Compatible)",
+  	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	    CPU_FTR_PPCAS_ARCH_V2,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    }
+};
+
+firmware_feature_t firmware_features_table[FIRMWARE_MAX_FEATURES] = {
+    {FW_FEATURE_PFT,		"hcall-pft"},
+    {FW_FEATURE_TCE,		"hcall-tce"},
+    {FW_FEATURE_SPRG0,		"hcall-sprg0"},
+    {FW_FEATURE_DABR,		"hcall-dabr"},
+    {FW_FEATURE_COPY,		"hcall-copy"},
+    {FW_FEATURE_ASR,		"hcall-asr"},
+    {FW_FEATURE_DEBUG,		"hcall-debug"},
+    {FW_FEATURE_PERF,		"hcall-perf"},
+    {FW_FEATURE_DUMP,		"hcall-dump"},
+    {FW_FEATURE_INTERRUPT,	"hcall-interrupt"},
+    {FW_FEATURE_MIGRATE,	"hcall-migrate"},
+};
diff -urNp linux-463/arch/ppc64/kernel/entry.S linux-340/arch/ppc64/kernel/entry.S
--- linux-463/arch/ppc64/kernel/entry.S
+++ linux-340/arch/ppc64/kernel/entry.S
@@ -437,7 +437,7 @@ _GLOBAL(enter_rtas)
 	mfsrr1	r10
 	std	r10,_SRR1(r1)
 
-	/* Unfortunatly, the stack pointer and the MSR are also clobbered,
+	/* Unfortunately, the stack pointer and the MSR are also clobbered,
 	 * so they are saved in the PACA (SPRG3) which allows us to restore
 	 * our original state after RTAS returns.
          */
@@ -548,7 +548,7 @@ _GLOBAL(enter_prom)
 	mfmsr	r11
 	std	r11,_MSR(r1)
 
-	/* Unfortunatly, the stack pointer is also clobbered, so it is saved
+	/* Unfortunately, the stack pointer is also clobbered, so it is saved
 	 * in the SPRG2 which allows us to restore our original state after
 	 * PROM returns.
          */
diff -urNp linux-463/arch/ppc64/kernel/head.S linux-340/arch/ppc64/kernel/head.S
--- linux-463/arch/ppc64/kernel/head.S
+++ linux-340/arch/ppc64/kernel/head.S
@@ -32,6 +32,7 @@
 #include <linux/config.h>
 #include <asm/mmu.h>
 #include <asm/perfmon.h>
+#include <asm/cputable.h>
 
 #ifdef CONFIG_PPC_ISERIES
 #define DO_SOFT_DISABLE
@@ -582,14 +583,17 @@ fast_exception_return:
  */
 	.globl DataAccess_common
 DataAccess_common:
-	mfspr   r22,DAR
-	srdi    r22,r22,60
-	cmpi    0,r22,0xc
+	mfspr   r22,DSISR
+	andis.  r22,r22,0x0020
+	beq	1f
+	mfspr   r22,DAR			/* if it's a segment table miss, */
+	srdi    r22,r22,60		/* check if it is in kernel region */
+	cmpi    0,r22,0xc		/* and call do_stab_bolted if so */
 	beq     .do_stab_bolted
 	cmpi    0,r22,0xb
 	beq     .do_stab_bolted
 
-stab_bolted_user_return:
+1:
 	EXCEPTION_PROLOG_COMMON
 	ld      r3,_DSISR(r1)
 	andis.	r0,r3,0xa450		/* weird error? */
@@ -641,6 +645,7 @@ DataAccessSLB_common:
 	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
 #endif
 	li	r6,0x380
+	li	r5,0
 	bl      .save_remaining_regs
 	bl      .do_page_fault
 	b       .ret_from_except
@@ -662,7 +667,7 @@ InstructionAccess_common:
 	bl	.do_hash_page_ISI	/* Try to handle as hpte fault */
 1:
 	mr	r4,r22
-	mr	r5,r23
+	rlwinm	r5,r23,0,4,4		/* We only care about PR in error_code */
 	addi	r3,r1,STACK_FRAME_OVERHEAD
 #ifdef DO_SOFT_DISABLE
 	ld	r20,SOFTE(r1)
@@ -690,6 +695,7 @@ InstructionAccessSLB_common:
 	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
 #endif
 	li	r6,0x480
+	li	r5,0
 	bl      .save_remaining_regs
 	bl      .do_page_fault
 	b       .ret_from_except
@@ -781,11 +787,16 @@ ProgramCheck_common:
 FPUnavailable_common:
 	EXCEPTION_PROLOG_COMMON
 	bne	.load_up_fpu		/* if from user, just load it up */
-	li	r20,0
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+#ifdef DO_SOFT_DISABLE
+	ld	r20,SOFTE(r1)
+#else
+	rldicl	r20,r23,49,63   	/* copy EE bit from saved MSR */
+#endif
 	li	r6,0x800
-	bl      .save_remaining_regs    /* if from kernel, take a trap */
-	bl      .KernelFP
-	b       .ret_from_except
+	bl      .save_remaining_regs
+	bl      .KernelFPUnavailableException
+	BUG_OPCODE
 
 	.globl SystemCall_common
 SystemCall_common:
@@ -1030,25 +1041,6 @@ _GLOBAL(do_hash_page_DSI)
 _GLOBAL(do_stab_bolted)
 	stw	r23,EX_CCR(r21)	/* save CR in exc. frame */
 
-	mfspr   r22,DSISR
-	andis.  r22,r22,0x0020
-	bne+    2f
-	ld	r22,8(r21)	/* get SRR1 */
-	andi.	r22,r22,MSR_PR	/* check if from user */
-	bne+	stab_bolted_user_return  /* from user, send the error on up */
-	li	r3,0
-#ifdef CONFIG_XMON
-	bl	.xmon
-#endif
-#ifdef CONFIG_KDB
-	/*	    kdb(KDB_REASON_FAULT,regs->trap,regs); */
-	li      r3,1   /* reason_call, regs considered invalid*/
-	li      r4,0x200  /* trap */
-	li      r5,0      /* pointers to regs.*/
-	bl	.kdb
-#endif
-1:	b	1b
-2:
 	/* (((ea >> 28) & 0x1fff) << 15) | (ea >> 60) */
 	mfspr	r21,DAR
 	rldicl  r20,r21,36,32   /* Permits a full 32b of ESID */
@@ -1185,7 +1177,7 @@ _GLOBAL(do_slb_bolted)
 	slbmfee	r23,r22
 	rldicl  r23,r23,37,63
 	cmpwi   r23,0
-	beq     3f              /* Found an invalid entry              */
+	beq     4f              /* Found an invalid entry              */
 
 	addi	r22,r22,1
 	cmpldi	r22,64
@@ -1194,16 +1186,36 @@ _GLOBAL(do_slb_bolted)
 	/* No free entry - just take the next entry, round-robin */
 	/* XXX we should get the number of SLB entries from the naca */
 SLB_NUM_ENTRIES = 64
-	mfspr	r21,SPRG3
+2:	mfspr	r21,SPRG3
 	ld	r22,PACASTABRR(r21)
 	addi	r23,r22,1
 	cmpdi	r23,SLB_NUM_ENTRIES
-	blt	2f
+	blt	3f
 	li	r23,1
-2:	std	r23,PACASTABRR(r21)
+3:	std	r23,PACASTABRR(r21)
 
 	/* r20 = vsid, r22 = entry */
-3:
+
+	/*
+	 * Never cast out the segment for our kernel stack. Since we
+	 * dont invalidate the ERAT we could have a valid translation
+	 * for the kernel stack during the first part of exception exit
+	 * which gets invalidated due to a tlbie from another cpu at a
+	 * non recoverable point (after setting srr0/1) - Anton
+	 */
+	slbmfee	r23,r22
+	srdi	r23,r23,28
+	/*
+	 * This is incorrect (r1 is not the kernel stack) if we entered
+	 * from userspace but there is no critical window from userspace
+	 * so this should be OK. Also if we cast out the userspace stack
+	 * segment while in userspace we will fault it straight back in.
+	 */
+	srdi	r21,r1,28
+	cmpd	r21,r23
+	beq-	2b
+	
+4:
 	/* Put together the vsid portion of the entry. */
 	li      r21,0
 	rldimi  r21,r20,12,0
@@ -1390,6 +1402,11 @@ _GLOBAL(__start_initialization_iSeries)
 	li	r0,0
 	stdu	r0,-STACK_FRAME_OVERHEAD(r1)
 
+	LOADADDR(r3,cpu_specs)
+	LOADADDR(r4,cur_cpu_spec)
+	li	r5,0
+	bl	.identify_cpu
+
 	LOADADDR(r2,__toc_start)
 	addi	r2,r2,0x4000
 	addi	r2,r2,0x4000
@@ -1619,21 +1636,19 @@ _STATIC(load_up_fpu)
 	/* restore registers and return */
 	b	fast_exception_return
 
+
 /*
- * FP unavailable trap from kernel - print a message, but let
- * the task use FP in the kernel until it returns to user mode.
+ * disable_kernel_fp()
+ * Disable the FPU.
  */
-_GLOBAL(KernelFP)
-	ld	r3,_MSR(r1)
-	ori	r3,r3,MSR_FP
-	std	r3,_MSR(r1)		/* enable use of FP after return */
-	LOADADDR(r3,86f)
-	mfspr	r4,SPRG3		/* Get PACA */
-	ld	r4,PACACURRENT(r4)	/* current */
-	ld	r5,_NIP(r1)
-	b	.ret_from_except
-86:	.string	"floating point used in kernel (task=%p, pc=%x)\n"
-	.align	4
+_GLOBAL(disable_kernel_fp)
+	mfmsr   r3
+	rldicl  r0,r3,(63-MSR_FP_LG),1
+	rldicl  r3,r0,(MSR_FP_LG+1),0
+	mtmsrd  r3			/* disable use of fpu now */
+	isync
+	blr
+
 
 /*
  * giveup_fpu(tsk)
@@ -1861,6 +1876,13 @@ _STATIC(start_here_pSeries)
 	li	r0,0
 	stdu	r0,-STACK_FRAME_OVERHEAD(r1)
 
+	LOADADDR(r3,cpu_specs)
+	sub	r3,r3,r26
+	LOADADDR(r4,cur_cpu_spec)
+	sub	r4,r4,r26
+	mr	r5,r26
+	bl	.identify_cpu
+
 	/* set up the TOC (physical address) */
 	LOADADDR(r2,__toc_start)
 	addi    r2,r2,0x4000
@@ -1949,6 +1971,9 @@ _STATIC(start_here_common)
 	addi    r2,r2,0x4000
 	addi    r2,r2,0x4000
 
+	li	r3,0
+	bl	.do_cpu_ftr_fixups
+
 	/* setup the systemcfg pointer                                       */
 	LOADADDR(r9,systemcfg)
 	SET_REG_TO_CONST(r8, KERNELBASE+0x5000)
@@ -2006,6 +2031,11 @@ _STATIC(start_here_common)
 
 	bl .start_kernel
 
+_GLOBAL(__setup_cpu_power3)
+	blr
+_GLOBAL(__setup_cpu_power4)
+	blr
+
 _GLOBAL(hmt_init)
 #ifdef CONFIG_HMT
 	LOADADDR(r5, hmt_thread_data)
diff -urNp linux-463/arch/ppc64/kernel/htab.c linux-340/arch/ppc64/kernel/htab.c
--- linux-463/arch/ppc64/kernel/htab.c
+++ linux-340/arch/ppc64/kernel/htab.c
@@ -46,6 +46,7 @@
 #include <asm/hvcall.h>
 #include <asm/iSeries/LparData.h>
 #include <asm/iSeries/HvCallHpt.h>
+#include <asm/cputable.h>
 
 /*
  * Note:  pte   --> Linux PTE
@@ -183,7 +184,9 @@ htab_initialize(void)
 
 	/* XXX we currently map kernel text rw, should fix this */
 	if ((systemcfg->platform & PLATFORM_PSERIES) &&
-	   cpu_has_largepage() && (systemcfg->physicalMemorySize > 256*MB)) {
+	    (cur_cpu_spec->cpu_features & 
+	     CPU_FTR_16M_PAGE) &&
+	    (systemcfg->physicalMemorySize > 256*MB)) {
 		create_pte_mapping((unsigned long)KERNELBASE, 
 				   KERNELBASE + 256*MB, mode_rw, mask, 0);
 		create_pte_mapping((unsigned long)KERNELBASE + 256*MB, 
@@ -334,11 +337,23 @@ int __hash_page(unsigned long ea, unsign
 	 * Check the user's access rights to the page.  If access should be
 	 * prevented then send the problem up to do_page_fault.
 	 */
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+	access |= _PAGE_PRESENT;
+	if (unlikely(access & ~(pte_val(*ptep)))) {
+		if(!(((ea >> SMALLOC_EA_SHIFT) == 
+		      (SMALLOC_START >> SMALLOC_EA_SHIFT)) &&
+		     ((current->thread.flags) & PPC_FLAG_SHARED))) {
+			spin_unlock(&hash_table_lock[lock_slot].lock);
+			return 1;
+		}
+	}
+#else
 	access |= _PAGE_PRESENT;
 	if (unlikely(access & ~(pte_val(*ptep)))) {
 		spin_unlock(&hash_table_lock[lock_slot].lock);
 		return 1;
 	}
+#endif
 
 	/* 
 	 * We have found a pte (which was present).
@@ -446,6 +461,19 @@ int hash_page(unsigned long ea, unsigned
 	case VMALLOC_REGION_ID:
 		mm = &init_mm;
 		vsid = get_kernel_vsid(ea);
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+                /*
+                 * Check if this is a user task with shared access to kernel
+                 * data & we got a protection fault.  If it is, the kernel
+                 * must have faulted in the segment and the protection flags
+                 * on the segment are kernel access only.  Just flush the
+                 * segment table & fault in the segment with the right flags.
+                 */
+                if(((current->thread.flags) & PPC_FLAG_SHARED) &&
+                   (access & _PAGE_USER)) {
+                        flush_stab();
+                }
+#endif
 		break;
 	case EEH_REGION_ID:
 		/*
diff -urNp linux-463/arch/ppc64/kernel/i8259.c linux-340/arch/ppc64/kernel/i8259.c
--- linux-463/arch/ppc64/kernel/i8259.c
+++ linux-340/arch/ppc64/kernel/i8259.c
@@ -146,7 +146,7 @@ void __init i8259_init(void)
         /* init master interrupt controller */
         outb(0x11, 0x20); /* Start init sequence */
         outb(0x00, 0x21); /* Vector base */
-        outb(0x04, 0x21); /* edge tiggered, Cascade (slave) on IRQ2 */
+        outb(0x04, 0x21); /* edge triggered, Cascade (slave) on IRQ2 */
         outb(0x01, 0x21); /* Select 8086 mode */
         outb(0xFF, 0x21); /* Mask all */
         /* init slave interrupt controller */
diff -urNp linux-463/arch/ppc64/kernel/iSeries_IoMmTable.h linux-340/arch/ppc64/kernel/iSeries_IoMmTable.h
--- linux-463/arch/ppc64/kernel/iSeries_IoMmTable.h
+++ linux-340/arch/ppc64/kernel/iSeries_IoMmTable.h
@@ -71,7 +71,7 @@ extern  void iSeries_allocateDeviceBars(
 /* iSeries_xlateIoMmAddress                                             */
 /************************************************************************/
 /* - Translates an I/O Memory address to Device Node that has been the  */
-/*   allocated the psuedo I/O Address.                                  */
+/*   allocated the pseudo I/O Address.                                  */
 /*                                                                      */
 /* Parameters:                                                          */
 /* IoAddress = I/O Memory Address.                                      */
diff -urNp linux-463/arch/ppc64/kernel/iSeries_setup.c linux-340/arch/ppc64/kernel/iSeries_setup.c
--- linux-463/arch/ppc64/kernel/iSeries_setup.c
+++ linux-340/arch/ppc64/kernel/iSeries_setup.c
@@ -49,6 +49,9 @@
 #include <asm/proc_pmc.h>
 #include <asm/perfmon.h>
 #include <asm/iSeries/mf.h>
+#include <asm/cputable.h>
+
+extern int boot_cpuid;
 
 /* Function Prototypes */
 
@@ -249,7 +252,7 @@ unsigned long iSeries_process_mainstore_
 {
 	unsigned long i;
 	unsigned long mem_blocks = 0;
-	if (__is_processor(PV_POWER4) || __is_processor(PV_POWER4p))
+	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB)
 		mem_blocks = iSeries_process_Regatta_mainstore_vpd( mb_array, max_entries );
 	else
 		mem_blocks = iSeries_process_Condor_mainstore_vpd( mb_array, max_entries );
@@ -620,6 +623,8 @@ static void __init iSeries_bolt_kernel(u
 		if (hpte.dw0.dw0.v) {
 			/* HPTE exists, so just bolt it */
 			HvCallHpt_setSwBits(slot, 0x10, 0);
+			/* And make sure the pp bits are correct */
+			HvCallHpt_setPp(slot, PP_RWXX);
 		} else {
 			/* No HPTE exists, so create a new bolted one */
 			make_pte(NULL, va, (unsigned long)__v2a(ea), 
@@ -698,6 +703,9 @@ iSeries_setup_arch(void)
 	systemcfg->processor = xIoHriProcessorVpd[procIx].xPVR;
 	printk("Processor version = %x\n", systemcfg->processor);
 
+#if defined(CONFIG_IRQ_ALL_CPUS)
+	do_spread_lpevents(MAX_PACAS);
+#endif
 }
 
 /*
diff -urNp linux-463/arch/ppc64/kernel/idle.c linux-340/arch/ppc64/kernel/idle.c
--- linux-463/arch/ppc64/kernel/idle.c
+++ linux-340/arch/ppc64/kernel/idle.c
@@ -38,22 +38,27 @@
 static void yield_shared_processor(void)
 {
 	struct paca_struct *lpaca = get_paca();
-	unsigned long tb;
-
-	HvCall_setEnabledInterrupts( HvCall_MaskIPI |
-				     HvCall_MaskLpEvent |
-				     HvCall_MaskLpProd |
-				     HvCall_MaskTimeout );
-
-	if ( ! ItLpQueue_isLpIntPending( paca->lpQueuePtr ) ) {
-	  tb = get_tb();
-	  /* Compute future tb value when yield should expire */
-	  HvCall_yieldProcessor( HvCall_YieldTimed, tb+tb_ticks_per_jiffy );
-	  
-	  /* The decrementer stops during the yield.  Force a fake decrementer
-	   * here and let the timer_interrupt code sort out the actual time.
-	   */
-	  lpaca->xLpPaca.xIntDword.xFields.xDecrInt = 1;
+	
+	HvCall_setEnabledInterrupts(HvCall_MaskIPI |
+				    HvCall_MaskLpEvent |
+				    HvCall_MaskLpProd |
+				    HvCall_MaskTimeout);
+
+	if (!ItLpQueue_isLpIntPending(paca->lpQueuePtr)) {
+		/* 
+		 * Compute future tb value when yield should expire.
+		 * We want to be woken up when the next decrementer is
+		 * to fire.  
+		 */
+		HvCall_yieldProcessor(HvCall_YieldTimed, 
+				      lpaca->next_jiffy_update_tb);	  
+
+		/* 
+		 * The decrementer stops during the yield.  Force a fake 
+		 * decrementer here and let the timer_interrupt code sort 
+		 * out the actual time.
+		 */
+		lpaca->xLpPaca.xIntDword.xFields.xDecrInt = 1;
 	}
 	  
 	process_iSeries_events();
@@ -75,8 +80,6 @@ int idled(void)
 	CTRL &= ~RUNLATCH;
 	mtspr(CTRLT, CTRL);
 #endif
-	/* endless loop with no priority at all */
-	init_idle();	
 
 	lpaca = get_paca();
 
diff -urNp linux-463/arch/ppc64/kernel/ioctl32.c linux-340/arch/ppc64/kernel/ioctl32.c
--- linux-463/arch/ppc64/kernel/ioctl32.c
+++ linux-340/arch/ppc64/kernel/ioctl32.c
@@ -552,62 +552,121 @@ static int ethtool_ioctl(unsigned int fd
 	mm_segment_t old_fs;
 	int err, len;
 	u32 data, ethcmd;
-	
+	struct ethtool_drvinfo drvinfo;
+
 	if (copy_from_user(&ifr, (struct ifreq32 *)arg, sizeof(struct ifreq32)))
 		return -EFAULT;
-	ifr.ifr_data = (__kernel_caddr_t)get_free_page(GFP_KERNEL);
-	if (!ifr.ifr_data)
-		return -EAGAIN;
 
 	__get_user(data, &(((struct ifreq32 *)arg)->ifr_ifru.ifru_data));
 
-	if (get_user(ethcmd, (u32 *)A(data))) {
-		err = -EFAULT;
-		goto out;
-	}
+	if (get_user(ethcmd, (u32 *)A(data)))
+		return -EFAULT;
+
 	switch (ethcmd) {
-	case ETHTOOL_GDRVINFO:	len = sizeof(struct ethtool_drvinfo); break;
+	case ETHTOOL_GDRVINFO:
+		len = sizeof(struct ethtool_drvinfo);
+		break;
 	case ETHTOOL_GMSGLVL:
 	case ETHTOOL_SMSGLVL:
 	case ETHTOOL_GLINK:
-	case ETHTOOL_NWAY_RST:	len = sizeof(struct ethtool_value); break;
-	case ETHTOOL_GREGS: {
-		struct ethtool_regs *regaddr = (struct ethtool_regs *)A(data);
-		/* darned variable size arguments */
-		if (get_user(len, (u32 *)&regaddr->len)) {
-			err = -EFAULT;
-			goto out;
+	case ETHTOOL_NWAY_RST:
+		len = sizeof(struct ethtool_value);
+		break;
+	case ETHTOOL_GREGS:
+	case ETHTOOL_GEEPROM:
+	case ETHTOOL_SEEPROM:
+		/*
+		 * These commands permit the specification of variable
+		 * sized requests so obtain the maximum size from the driver
+		 * via ETHTOOL_GETDRVINFO and guarantee that the kernel
+		 * buffer allocated does not exceed this value.
+		 */
+		drvinfo.cmd = ETHTOOL_GDRVINFO;
+		drvinfo.regdump_len = 0;
+		drvinfo.eedump_len = 0;
+		ifr.ifr_data = (__kernel_caddr_t)&drvinfo;
+		old_fs = get_fs();
+		set_fs(KERNEL_DS);
+		err = sys_ioctl(fd, cmd, (unsigned long)&ifr);	
+		set_fs(old_fs);
+		if (!err) {
+			if (ethcmd == ETHTOOL_GREGS)
+				len = drvinfo.regdump_len;
+			else
+				len = drvinfo.eedump_len;
+		}
+		if (err)
+			return err;
+		if (len == 0)
+			return -EOPNOTSUPP;
+		if (ethcmd == ETHTOOL_GREGS) {
+			struct ethtool_regs *regaddr = (struct ethtool_regs *)A(data);
+			int ulen;
+
+			if (get_user(ulen, (u32 *)&regaddr->len))
+				return -EFAULT;
+			if (len == 0)
+				return 0;
+			if (ulen < len)
+				len = ulen;
+			len += sizeof(struct ethtool_regs);
+		} else if (ethcmd == ETHTOOL_GEEPROM ||
+			   ethcmd == ETHTOOL_SEEPROM) {
+			struct ethtool_eeprom *promaddr = (struct ethtool_eeprom *)A(data); 
+			int ulen;
+
+			if (get_user(ulen, (u32 *)&promaddr->len))
+				return -EFAULT; 
+			if (len == 0)
+				return 0;
+			if (ulen < len)
+				len = ulen;
+			len += sizeof(struct ethtool_eeprom); 
 		}
-		len += sizeof(struct ethtool_regs);
 		break;
-	}
 	case ETHTOOL_GSET:
-	case ETHTOOL_SSET:	len = sizeof(struct ethtool_cmd); break;
+	case ETHTOOL_SSET:
+		len = sizeof(struct ethtool_cmd);
+		break;
 	default:
-		err = -EOPNOTSUPP;
-		goto out;
+		return -EOPNOTSUPP;
 	}
 
+	ifr.ifr_data = kmalloc(len, GFP_KERNEL);
+	if (!ifr.ifr_data)
+		return -EAGAIN;
+
 	if (copy_from_user(ifr.ifr_data, (char *)A(data), len)) {
 		err = -EFAULT;
 		goto out;
 	}
 
+	if (ethcmd == ETHTOOL_GREGS) {
+		struct ethtool_regs *p;
+
+		p = (struct ethtool_regs *)ifr.ifr_data;
+		p->len = len - sizeof(struct ethtool_regs);
+	} else if (ethcmd == ETHTOOL_GEEPROM ||
+		   ethcmd == ETHTOOL_SEEPROM) {
+		struct ethtool_eeprom *p;
+
+		p = (struct ethtool_eeprom *)ifr.ifr_data;
+		p->len = len - sizeof(struct ethtool_eeprom);
+	}
+
 	old_fs = get_fs();
 	set_fs (KERNEL_DS);
 	err = sys_ioctl (fd, cmd, (unsigned long)&ifr);
 	set_fs (old_fs);
-	if (!err) {
-		u32 data;
 
-		__get_user(data, &(((struct ifreq32 *)arg)->ifr_ifru.ifru_data));
+	if (!err) {
 		len = copy_to_user((char *)A(data), ifr.ifr_data, len);
 		if (len)
 			err = -EFAULT;
 	}
 
 out:
-	free_page((unsigned long)ifr.ifr_data);
+	kfree(ifr.ifr_data);
 	return err;
 }
 
@@ -1227,12 +1286,16 @@ typedef struct sg_iovec32 {
 	u32 iov_len;
 } sg_iovec32_t;
 
+#define EMU_SG_MAX 128
+
 static int alloc_sg_iovec(sg_io_hdr_t *sgp, u32 uptr32)
 {
 	sg_iovec32_t *uiov = (sg_iovec32_t *) A(uptr32);
 	sg_iovec_t *kiov;
 	int i;
 
+	if (sgp->iovec_count > EMU_SG_MAX)
+		return -EINVAL;
 	sgp->dxferp = kmalloc(sgp->iovec_count *
 			      sizeof(sg_iovec_t), GFP_KERNEL);
 	if (!sgp->dxferp)
@@ -1246,39 +1309,9 @@ static int alloc_sg_iovec(sg_io_hdr_t *s
 		if (__get_user(iov_base32, &uiov->iov_base) ||
 		    __get_user(kiov->iov_len, &uiov->iov_len))
 			return -EFAULT;
-
-		kiov->iov_base = kmalloc(kiov->iov_len, GFP_KERNEL);
-		if (!kiov->iov_base)
-			return -ENOMEM;
-		if (copy_from_user(kiov->iov_base,
-				   (void *) A(iov_base32),
-				   kiov->iov_len))
-			return -EFAULT;
-
-		uiov++;
-		kiov++;
-	}
-
-	return 0;
-}
-
-static int copy_back_sg_iovec(sg_io_hdr_t *sgp, u32 uptr32)
-{
-	sg_iovec32_t *uiov = (sg_iovec32_t *) A(uptr32);
-	sg_iovec_t *kiov = (sg_iovec_t *) sgp->dxferp;
-	int i;
-
-	for (i = 0; i < sgp->iovec_count; i++) {
-		u32 iov_base32;
-
-		if (__get_user(iov_base32, &uiov->iov_base))
-			return -EFAULT;
-
-		if (copy_to_user((void *) A(iov_base32),
-				 kiov->iov_base,
-				 kiov->iov_len))
+		if (verify_area(VERIFY_WRITE, (void *)A(iov_base32), kiov->iov_len))
 			return -EFAULT;
-
+		kiov->iov_base = (void *)A(iov_base32);
 		uiov++;
 		kiov++;
 	}
@@ -1288,16 +1321,6 @@ static int copy_back_sg_iovec(sg_io_hdr_
 
 static void free_sg_iovec(sg_io_hdr_t *sgp)
 {
-	sg_iovec_t *kiov = (sg_iovec_t *) sgp->dxferp;
-	int i;
-
-	for (i = 0; i < sgp->iovec_count; i++) {
-		if (kiov->iov_base) {
-			kfree(kiov->iov_base);
-			kiov->iov_base = NULL;
-		}
-		kiov++;
-	}
 	kfree(sgp->dxferp);
 	sgp->dxferp = NULL;
 }
@@ -1326,6 +1349,10 @@ static int sg_ioctl_trans(unsigned int f
 	sg_io64.sbp = NULL;
 
 	err |= __get_user(cmdp32, &sg_io32->cmdp);
+	if (sg_io64.cmd_len > 4*PAGE_SIZE || sg_io64.mx_sb_len > 4*PAGE_SIZE) {
+		err = -EINVAL;
+		goto out;
+	}
 	sg_io64.cmdp = kmalloc(sg_io64.cmd_len, GFP_KERNEL);
 	if (!sg_io64.cmdp) {
 		err = -ENOMEM;
@@ -1360,6 +1387,10 @@ static int sg_ioctl_trans(unsigned int f
 			goto out;
 		}
 	} else {
+		if (sg_io64.dxfer_len > 8*PAGE_SIZE) {
+			err = -EINVAL;
+			goto out;
+		}
 		sg_io64.dxferp = kmalloc(sg_io64.dxfer_len, GFP_KERNEL);
 		if (!sg_io64.dxferp) {
 			err = -ENOMEM;
@@ -1400,7 +1431,7 @@ static int sg_ioctl_trans(unsigned int f
 	err |= copy_to_user((void *)A(sbp32), sg_io64.sbp, sg_io64.mx_sb_len);
 	if (sg_io64.dxferp) {
 		if (sg_io64.iovec_count)
-			err |= copy_back_sg_iovec(&sg_io64, dxferp32);
+			;
 		else
 			err |= copy_to_user((void *)A(dxferp32),
 					    sg_io64.dxferp,
@@ -1456,6 +1487,8 @@ static int ppp_ioctl_trans(unsigned int 
 	case PPPIOCSCOMPRESS32:
 		if (copy_from_user(&data32, (struct ppp_option_data32 *)arg, sizeof(struct ppp_option_data32)))
 			return -EFAULT;
+		if (data32.length > PAGE_SIZE) 
+			return -EINVAL;
 		data.ptr = kmalloc (data32.length, GFP_KERNEL);
 		if (!data.ptr)
 			return -ENOMEM;
@@ -1658,10 +1691,11 @@ static int cdrom_ioctl_trans(unsigned in
 		err |= __get_user(addr, &((struct cdrom_read_audio32 *)arg)->buf);
 		if (err)
 			return -EFAULT;
-		data = kmalloc(cdreadaudio.nframes * 2352, GFP_KERNEL);
-		if (!data)
-			return -ENOMEM;
-		cdreadaudio.buf = data;
+
+
+		if (verify_area(VERIFY_WRITE, (void *)A(addr), cdreadaudio.nframes*2352))
+			return -EFAULT;
+		cdreadaudio.buf = (void *)A(addr);
 		break;
 	case CDROM_SEND_PACKET:
 		karg = &cgc;
@@ -1670,9 +1704,9 @@ static int cdrom_ioctl_trans(unsigned in
 		err |= __get_user(cgc.buflen, &((struct cdrom_generic_command32 *)arg)->buflen);
 		if (err)
 			return -EFAULT;
-		if ((data = kmalloc(cgc.buflen, GFP_KERNEL)) == NULL)
-			return -ENOMEM;
-		cgc.buffer = data;
+		if (verify_area(VERIFY_WRITE, (void *)A(addr), cgc.buflen))
+			return -EFAULT;
+		cgc.buffer = (void *)A(addr);
 		break;
 	default:
 		do {
@@ -1731,6 +1765,7 @@ static int loop_status(unsigned int fd, 
 		err |= __get_user(l.lo_device, &((struct loop_info32 *)arg)->lo_device);
 		err |= __get_user(l.lo_inode, &((struct loop_info32 *)arg)->lo_inode);
 		err |= __get_user(l.lo_rdevice, &((struct loop_info32 *)arg)->lo_rdevice);
+
 		err |= __copy_from_user((char *)&l.lo_offset, (char *)&((struct loop_info32 *)arg)->lo_offset,
 					   8 + (unsigned long)l.lo_init - (unsigned long)&l.lo_offset);
 		if (err) {
@@ -2115,37 +2150,16 @@ static int do_atm_iobuf(unsigned int fd,
 	if (iobuf32.buffer == (__kernel_caddr_t32) NULL || iobuf32.length == 0) {
 		iobuf.buffer = (void*)(unsigned long)iobuf32.buffer;
 	} else {
-		iobuf.buffer = kmalloc(iobuf.length, GFP_KERNEL);
-		if (iobuf.buffer == NULL) {
-			err = -ENOMEM;
-			goto out;
-		}
-
-		err = copy_from_user(iobuf.buffer, (void *)A(iobuf32.buffer), iobuf.length);
-		if (err) {
-			err = -EFAULT;
-			goto out;
-		}
+		iobuf.buffer = A(iobuf32.buffer);
+		if (verify_area(VERIFY_WRITE, iobuf.buffer, iobuf.length))
+			return -EINVAL;
 	}
 
 	old_fs = get_fs(); set_fs (KERNEL_DS);
 	err = sys_ioctl (fd, cmd, (unsigned long)&iobuf);      
 	set_fs (old_fs);
-        if (err)
-		goto out;
-
-        if (iobuf.buffer && iobuf.length > 0) {
-		err = copy_to_user((void *)A(iobuf32.buffer), iobuf.buffer, iobuf.length);
-		if (err) {
-			err = -EFAULT;
-			goto out;
-		}
-	}
-	err = __put_user(iobuf.length, &(((struct atm_iobuf32*)arg)->length));
-
- out:
-        if (iobuf32.buffer && iobuf32.length > 0)
-		kfree(iobuf.buffer);
+        if(!err)
+		err = __put_user(iobuf.length, &(((struct atm_iobuf32*)arg)->length));
 
 	return err;
 }
@@ -2169,39 +2183,16 @@ static int do_atmif_sioc(unsigned int fd
 	if (sioc32.arg == (__kernel_caddr_t32) NULL || sioc32.length == 0) {
 		sioc.arg = (void*)(unsigned long)sioc32.arg;
         } else {
-                sioc.arg = kmalloc(sioc.length, GFP_KERNEL);
-                if (sioc.arg == NULL) {
-                        err = -ENOMEM;
-			goto out;
-		}
-                
-                err = copy_from_user(sioc.arg, (void *)A(sioc32.arg), sioc32.length);
-                if (err) {
-                        err = -EFAULT;
-                        goto out;
-                }
+		sioc.arg = A(sioc32.arg);
+		if (verify_area(VERIFY_WRITE, sioc.arg, sioc32.length))
+			return -EFAULT;
         }
         
         old_fs = get_fs(); set_fs (KERNEL_DS);
         err = sys_ioctl (fd, cmd, (unsigned long)&sioc);	
         set_fs (old_fs);
-        if (err) {
-                goto out;
-	}
-        
-        if (sioc.arg && sioc.length > 0) {
-                err = copy_to_user((void *)A(sioc32.arg), sioc.arg, sioc.length);
-                if (err) {
-                        err = -EFAULT;
-                        goto out;
-                }
-        }
-        err = __put_user(sioc.length, &(((struct atmif_sioc32*)arg)->length));
-        
- out:
-        if (sioc32.arg && sioc32.length > 0)
-		kfree(sioc.arg);
-        
+	if (!err)
+		err = __put_user(sioc.length, &(((struct atmif_sioc32*)arg)->length));
 	return err;
 }
 
@@ -2417,12 +2408,24 @@ static lv_t *get_lv_t(u32 p, int *errp)
 		return NULL;
 	}
 	if (ptr1) {
+		if (l->lv_allocated_le > 2*PAGE_SIZE/sizeof(pe_t)) { 
+			kfree(l);
+			*errp = -EINVAL;
+			return NULL;
+		}
 		size = l->lv_allocated_le * sizeof(pe_t);
 		l->lv_current_pe = vmalloc(size);
 		if (l->lv_current_pe)
 			err = copy_from_user(l->lv_current_pe, (void *)A(ptr1), size);
 	}
 	if (!err && ptr2) {
+		/* small limit */
+		/* just verify area it? */
+		if (l->lv_remap_end > 256*PAGE_SIZE/sizeof(lv_block_exception_t)) { 
+			put_lv_t(l);
+			*errp = -EINVAL;
+			return NULL;
+		}
 		size = l->lv_remap_end * sizeof(lv_block_exception_t);
 		l->lv_block_exception = lbe = vmalloc(size);
 		if (l->lv_block_exception) {
@@ -3070,7 +3073,7 @@ typedef struct drm32_dma {
 #define DRM32_IOCTL_DMA	     DRM_IOWR(0x29, drm32_dma_t)
 
 /* RED PEN	The DRM layer blindly dereferences the send/request
- * 		indice/size arrays even though they are userland
+ * 		index/size arrays even though they are userland
  * 		pointers.  -DaveM
  */
 static int drm32_dma(unsigned int fd, unsigned int cmd, unsigned long arg)
@@ -3586,17 +3589,11 @@ static int do_usbdevfs_urb(unsigned int 
 		goto out;
 	uptr = (void *) A(udata);
 
-	err = -ENOMEM;
 	buflen = kurb->buffer_length;
-	kptr = kmalloc(buflen, GFP_KERNEL);
-	if (!kptr)
+	err = verify_area(VERIFY_WRITE, uptr, buflen);
+	if (err) 
 		goto out;
 
-	kurb->buffer = kptr;
-
-	err = -EFAULT;
-	if (copy_from_user(kptr, uptr, buflen))
-		goto out_kptr;
 
 	old_fs = get_fs();
 	set_fs(KERNEL_DS);
@@ -3607,15 +3604,9 @@ static int do_usbdevfs_urb(unsigned int 
 		/* XXX Shit, this doesn't work for async URBs :-( XXX */
 		if (put_urb32(kurb, uurb)) {
 			err = -EFAULT;
-		} else if ((kurb->endpoint & USB_DIR_IN) != 0) {
-			if (copy_to_user(uptr, kptr, buflen))
-				err = -EFAULT;
 		}
 	}
 
-out_kptr:
-	kfree(kptr);
-
 out:
 	kfree(kurb);
 	return err;
@@ -3694,7 +3685,6 @@ mtd_rw_oob(unsigned int fd, unsigned int
 	struct mtd_oob_buf32	*uarg 	= (struct mtd_oob_buf32 *)arg;
 	struct mtd_oob_buf		karg;
 	u32 tmp;
-	char *ptr;
 	int ret;
 
 	if (get_user(karg.start, &uarg->start) 		||
@@ -3702,18 +3692,9 @@ mtd_rw_oob(unsigned int fd, unsigned int
 	    get_user(tmp, &uarg->ptr))
 		return -EFAULT;
 
-	ptr = (char *)A(tmp);
-	if (0 >= karg.length) 
-		return -EINVAL;
-
-	karg.ptr = kmalloc(karg.length, GFP_KERNEL);
-	if (NULL == karg.ptr)
-		return -ENOMEM;
-
-	if (copy_from_user(karg.ptr, ptr, karg.length)) {
-		kfree(karg.ptr);
+	karg.ptr = A(tmp); 
+	if (verify_area(VERIFY_WRITE, karg.ptr, karg.length))
 		return -EFAULT;
-	}
 
 	set_fs(KERNEL_DS);
 	if (MEMREADOOB32 == cmd) 
@@ -3725,13 +3706,11 @@ mtd_rw_oob(unsigned int fd, unsigned int
 	set_fs(old_fs);
 
 	if (0 == ret && cmd == MEMREADOOB32) {
-		ret = copy_to_user(ptr, karg.ptr, karg.length);
-		ret |= put_user(karg.start, &uarg->start);
+		ret = put_user(karg.start, &uarg->start);
 		ret |= put_user(karg.length, &uarg->length);
 	}
 
-	kfree(karg.ptr);
-	return ((0 == ret) ? 0 : -EFAULT);
+	return ret;
 }	
 
 /* Fix sizeof(sizeof()) breakage */
@@ -4679,13 +4658,15 @@ int unregister_ioctl32_conversion(unsign
 	    (unsigned long)t < ((unsigned long)additional_ioctls) + PAGE_SIZE) {
 		ioctl32_hash_table[hash] = t->next;
 		t->cmd = 0;
+		t->next = 0;
 		return 0;
 	} else while (t->next) {
 		t1 = (struct ioctl_trans *)t->next;
 		if (t1->cmd == cmd && t1 >= additional_ioctls &&
 		    (unsigned long)t1 < ((unsigned long)additional_ioctls) + PAGE_SIZE) {
-			t1->cmd = 0;
 			t->next = t1->next;
+			t1->cmd = 0;
+			t1->next = 0;
 			return 0;
 		}
 		t = t1;
@@ -4716,15 +4697,8 @@ asmlinkage int sys32_ioctl(unsigned int 
 	if (t) {
 		handler = (void *)t->handler;
 		error = handler(fd, cmd, arg, filp);
-	} else {
-		static int count = 0;
-		if (++count <= 20)
-			printk("sys32_ioctl(%s:%d): Unknown cmd fd(%d) "
-			       "cmd(%08x) arg(%08x)\n",
-			       current->comm, current->pid,
-			       (int)fd, (unsigned int)cmd, (unsigned int)arg);
-		error = -EINVAL;
-	}
+	} else
+		error = -ENOTSUPP;
 out:
 	fput(filp);
 out2:
diff -urNp linux-463/arch/ppc64/kernel/irq.c linux-340/arch/ppc64/kernel/irq.c
--- linux-463/arch/ppc64/kernel/irq.c
+++ linux-340/arch/ppc64/kernel/irq.c
@@ -924,7 +924,7 @@ static void register_irq_proc (unsigned 
 	struct proc_dir_entry *entry;
 	char name [MAX_NAMELEN];
 
-	if (!root_irq_dir || (irq_desc[irq].handler == NULL))
+	if (!root_irq_dir || (irq_desc[irq].handler == NULL) || irq_dir[irq])
 		return;
 
 	memset(name, 0, MAX_NAMELEN);
@@ -961,15 +961,6 @@ void init_irq_proc (void)
 	entry->data = (void *)&prof_cpu_mask;
 	entry->read_proc = prof_cpu_mask_read_proc;
 	entry->write_proc = prof_cpu_mask_write_proc;
-
-	/*
-	 * Create entries for all existing IRQs.
-	 */
-	for (i = 0; i < NR_IRQS; i++) {
-		if (irq_desc[i].handler == NULL)
-			continue;
-		register_irq_proc(i);
-	}
 }
 
 void no_action(int irq, void *dev, struct pt_regs *regs)
diff -urNp linux-463/arch/ppc64/kernel/mf.c linux-340/arch/ppc64/kernel/mf.c
--- linux-463/arch/ppc64/kernel/mf.c
+++ linux-340/arch/ppc64/kernel/mf.c
@@ -44,7 +44,7 @@
 extern struct pci_dev * iSeries_vio_dev;
 
 /*
- * This is the structure layout for the Machine Facilites LPAR event
+ * This is the structure layout for the Machine Facilities LPAR event
  * flows.
  */
 struct VspCmdData;
@@ -402,7 +402,8 @@ static int dmaAndSignalCEMsg( char * ceM
  */
 static int shutdown( void )
 {
-	int rc = kill_proc(1,SIGINT,1);
+	extern int cad_pid; /* from kernel/sys.c */
+	int rc = kill_proc(cad_pid,SIGINT,1);
 
 	if ( rc )
 	{
@@ -760,9 +761,8 @@ void mf_init( void )
 	iSeries_proc_callback(&mf_proc_init);
 }
 
-void mf_setSide(char side)
+int mf_setSide(char side)
 {
-	int rc = 0;
 	u64 newSide = 0;
 	struct VspCmdData myVspCmd;
 
@@ -779,7 +779,7 @@ void mf_setSide(char side)
 	myVspCmd.xSubData.xFunction02SelectIplTypeIn.xIplType = newSide;
 	myVspCmd.xCmd = 10;
 
-	rc = signalVspInstruction(&myVspCmd);
+	return signalVspInstruction(&myVspCmd);
 }
 
 char mf_getSide(void)
@@ -870,7 +870,7 @@ void mf_getSrcHistory(char *buffer, int 
      kfree(pages[3]);*/
 }
 
-void mf_setCmdLine(const char *cmdline, int size, u64 side)
+int mf_setCmdLine(const char *cmdline, int size, u64 side)
 {
 	struct VspCmdData myVspCmd;
 	int rc = 0;
@@ -878,11 +878,14 @@ void mf_setCmdLine(const char *cmdline, 
 	char *page = pci_alloc_consistent(iSeries_vio_dev, size, &dma_addr);
 
 	if (page == NULL) {
-		printk(KERN_ERR "mf.c: couldn't allocate memory to set command line\n");
-		return;
+		printk(KERN_INFO "mf_setCmdLine: memory allocation failed\n");
+		return -ENOMEM;
 	}
 
-	copy_from_user(page, cmdline, size);
+	if (copy_from_user(page, cmdline, size)) {
+		pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
+		return -EFAULT;
+	}
 
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
 	myVspCmd.xCmd = 31;
@@ -894,6 +897,8 @@ void mf_setCmdLine(const char *cmdline, 
 	rc = signalVspInstruction(&myVspCmd);
 
 	pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
+
+	return rc;
 }
 
 int mf_getCmdLine(char *cmdline, int *size, u64 side)
@@ -942,11 +947,15 @@ int mf_setVmlinuxChunk(const char *buffe
 	char *page = pci_alloc_consistent(iSeries_vio_dev, size, &dma_addr);
 
 	if (page == NULL) {
-		printk(KERN_ERR "mf.c: couldn't allocate memory to set vmlinux chunk\n");
+		printk(KERN_INFO "mf_setVmlinuxChunk: memory allocation failed\n");
 		return -ENOMEM;
 	}
 
-	copy_from_user(page, buffer, size);
+	if (copy_from_user(page, buffer, size)) {
+		pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
+		return -EFAULT;
+	}
+
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
 
 	myVspCmd.xCmd = 30;
diff -urNp linux-463/arch/ppc64/kernel/mf_proc.c linux-340/arch/ppc64/kernel/mf_proc.c
--- linux-463/arch/ppc64/kernel/mf_proc.c
+++ linux-340/arch/ppc64/kernel/mf_proc.c
@@ -43,8 +43,6 @@ int proc_mf_dump_side
 int proc_mf_change_side
 (struct file *file, const char *buffer, unsigned long count, void *data);
 
-int proc_mf_dump_src
-(char *page, char **start, off_t off, int count, int *eof, void *data);
 int proc_mf_change_src (struct file *file, const char *buffer, unsigned long count, void *data);
 int proc_mf_change_cmdline(struct file *file, const char *buffer, unsigned long count, void *data);
 int proc_mf_change_vmlinux(struct file *file, const char *buffer, unsigned long count, void *data);
@@ -141,7 +139,7 @@ void mf_proc_init(struct proc_dir_entry 
 	if (!ent) return;
 	ent->nlink = 1;
 	ent->data = (void *)0;
-	ent->read_proc = proc_mf_dump_src;
+	ent->read_proc = NULL;
 	ent->write_proc = proc_mf_change_src;
 }
 
@@ -220,78 +218,69 @@ int proc_mf_dump_side
 
 int proc_mf_change_side(struct file *file, const char *buffer, unsigned long count, void *data)
 {
+	char side;
+	int rc;
+
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
-
-	if ((*buffer != 'A') &&
-	    (*buffer != 'B') &&
-	    (*buffer != 'C') &&
-	    (*buffer != 'D'))
-	{
-		printk(KERN_ERR "mf_proc.c: proc_mf_change_side: invalid side\n");
+	if ((count != 1) && (count != 2)) 
 		return -EINVAL;
+	if (copy_from_user (&side, buffer, 1)) {
+		return -EFAULT;
 	}
-
-	mf_setSide(*buffer);
-
-	return count;			
-}
-
-int proc_mf_dump_src
-(char *page, char **start, off_t off, int count, int *eof, void *data)
-{
-	int		len = 0;
-	mf_getSrcHistory(page, count);
-	len = count;
-	len -= off;			
-	if (len < count) {		
-		*eof = 1;		
-		if (len <= 0)		
-			return 0;	
-	} else				
-		len = count;		
-	*start = page + off;		
-	return len;			
+	if ((side < 'A') || (side > 'D')) {
+		printk(KERN_INFO "proc_mf_change_side: invalid side\n");
+		return -EINVAL;
+	}
+	rc = mf_setSide(side);
+	return rc ? rc : count;			
 }
 
 int proc_mf_change_src(struct file *file, const char *buffer, unsigned long count, void *data)
 {
+	char source[4];
+
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
-
-	if ((count < 4) && (count != 1))
-	{
-		printk(KERN_ERR "mf_proc: invalid src\n");
+	if ((count < 4) && (count != 1)) {
+		printk(KERN_INFO "proc_mf_change_src: invalid src\n");
 		return -EINVAL;
 	}
-
-	if ((count == 1) && ((*buffer) == '\0'))
-	{
+	if (count > 4) count = 4;
+	if (copy_from_user (source, buffer, count)) {
+		return -EFAULT;
+	}
+	if ((count == 1) && ((*source) == '\0')) {
 		mf_clearSrc();
 	} else {
-		mf_displaySrc(*(u32 *)buffer);
+		mf_displaySrc(*(u32 *)source);
 	}
-
 	return count;			
 }
 
 int proc_mf_change_cmdline(struct file *file, const char *buffer, unsigned long count, void *data)
 {
+	int rc;
+
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
 
-	mf_setCmdLine(buffer, count, (u64)data);
+	rc = mf_setCmdLine(buffer, count, (u64)data);
 
-	return count;			
+	return rc ? rc : count;			
 }
 
 int proc_mf_change_vmlinux(struct file *file, const char *buffer, unsigned long count, void *data)
 {
+	int rc;
+
 	if (!capable(CAP_SYS_ADMIN))
 		return -EACCES;
 
-	mf_setVmlinuxChunk(buffer, count, file->f_pos, (u64)data);
-	file->f_pos += count;
+	rc = mf_setVmlinuxChunk(buffer, count, file->f_pos, (u64)data);
+	if (rc)
+		return rc;
 
+	file->f_pos += count;
 	return count;			
 }
diff -urNp linux-463/arch/ppc64/kernel/misc.S linux-340/arch/ppc64/kernel/misc.S
--- linux-463/arch/ppc64/kernel/misc.S
+++ linux-340/arch/ppc64/kernel/misc.S
@@ -1,5 +1,5 @@
 /*
- *  arch/ppc/kernel/misc.S
+ *  arch/ppc64/kernel/misc.S
  *
  *  
  *
@@ -25,6 +25,7 @@
 #include <asm/processor.h>
 #include <asm/page.h>
 #include <asm/cache.h>
+#include <asm/cputable.h>
 #include "ppc_asm.h"
 
 	.text
@@ -68,16 +69,14 @@ _GLOBAL(get_sp)
 _GLOBAL(__no_use_save_flags)
 	mfspr	r4,SPRG3
 	lbz	r3,PACAPROCENABLED(r4)
+ 	/* shift into position of MSR.EE */
+ 	sldi	r3,r3,15
 	blr
 
 /* void __no_use_restore_flags(unsigned long flags) */	
 _GLOBAL(__no_use_restore_flags)
-/*
- * Just set/clear the MSR_EE bit through restore/flags but do not
- * change anything else.  This is needed by the RT system and makes
- * sense anyway.
- *    -- Cort
- */
+ 	/* shift from position of MSR.EE */
+ 	srdi	r3,r3,15
 	mfspr	r6,SPRG3
 	lbz	r5,PACAPROCENABLED(r6)
 	 /* Check if things are setup the way we want _already_. */
@@ -103,6 +102,8 @@ _GLOBAL(__no_use_cli)
 	lbz	r3,PACAPROCENABLED(r5)
 	li	r4,0
 	stb	r4,PACAPROCENABLED(r5)
+ 	/* shift into position of MSR.EE */
+ 	sldi	r3,r3,15
 	blr			/* Done */
 
 _GLOBAL(__no_use_sti)
@@ -480,6 +481,93 @@ _GLOBAL(cvt_df)
 	blr
 
 /*
+ * identify_cpu,
+ * In:	 r3 = base of the cpu_specs array
+ *       r4 = address of cur_cpu_spec
+ *       r5 = relocation offset
+ */
+_GLOBAL(identify_cpu)
+	mfpvr	r7
+1:
+	lwz	r8,CPU_SPEC_PVR_MASK(r3)
+	and	r8,r8,r7
+	lwz	r9,CPU_SPEC_PVR_VALUE(r3)
+	cmplw	0,r9,r8
+	beq	1f
+	addi	r3,r3,CPU_SPEC_ENTRY_SIZE
+	b	1b
+1:
+	add	r3,r3,r5
+	std	r3,0(r4)
+	blr
+
+/*
+ * do_cpu_ftr_fixups - goes through the list of CPU feature fixups
+ * and writes nop's over sections of code that don't apply for this cpu.
+ * r3 = data offset (not changed)
+ */
+_GLOBAL(do_cpu_ftr_fixups)
+	/* Get CPU 0 features */
+	LOADADDR(r6,cur_cpu_spec)
+	sub	r6,r6,r3
+	ld	r4,0(r6)
+	sub	r4,r4,r3
+	ld	r4,CPU_SPEC_FEATURES(r4)
+	/* Get the fixup table */
+	LOADADDR(r6,__start___ftr_fixup)
+	sub	r6,r6,r3
+	LOADADDR(r7,__stop___ftr_fixup)
+	sub	r7,r7,r3
+	/* Do the fixup */
+1:	cmpld	r6,r7
+	bgelr
+	addi	r6,r6,32
+	ld	r8,-32(r6)	/* mask */
+	and	r8,r8,r4
+	ld	r9,-24(r6)	/* value */
+	cmpld	r8,r9
+	beq	1b
+	ld	r8,-16(r6)	/* section begin */
+	ld	r9,-8(r6)	/* section end */
+	subf.	r9,r8,r9
+	beq	1b
+	/* write nops over the section of code */
+	/* todo: if large section, add a branch at the start of it */
+	srwi	r9,r9,2
+	mtctr	r9
+	sub	r8,r8,r3
+	lis	r0,0x60000000@h	/* nop */
+3:	stw	r0,0(r8)
+	andi.	r10,r4,CPU_FTR_SPLIT_ID_CACHE@l
+	beq	2f
+	dcbst	0,r8		/* suboptimal, but simpler */
+	sync
+	icbi	0,r8
+2:	addi	r8,r8,4
+	bdnz	3b
+	sync			/* additional sync needed on g4 */
+	isync
+	b	1b
+
+/*
+ * call_setup_cpu - call the setup_cpu function for this cpu
+ * r3 = data offset
+ *
+ * Setup function is called with:
+ *   r3 = data offset
+ *   r4 = ptr to CPU spec (relocated)
+ */
+_GLOBAL(call_setup_cpu)
+	LOADADDR(r4, cur_cpu_spec)
+	sub	r4,r4,r3
+	lwz	r4,0(r4)		# load pointer to cpu_spec
+	sub	r4,r4,r3		# relocate
+	lwz	r6,CPU_SPEC_SETUP(r4)	# load function pointer
+	sub	r6,r6,r3	
+	mtctr	r6
+	bctr
+
+/*
  * Create a kernel thread
  *   arch_kernel_thread(fn, arg, flags)
  */
diff -urNp linux-463/arch/ppc64/kernel/mk_defs.c linux-340/arch/ppc64/kernel/mk_defs.c
--- linux-463/arch/ppc64/kernel/mk_defs.c
+++ linux-340/arch/ppc64/kernel/mk_defs.c
@@ -37,6 +37,7 @@
 #include <asm/iSeries/HvLpEvent.h>
 #include <asm/prom.h>
 #include <asm/rtas.h>
+#include <asm/cputable.h>
 
 #define DEFINE(sym, val) \
 	asm volatile("\n#define\t" #sym "\t%0" : : "i" (val))
@@ -188,5 +189,12 @@ main(void)
 
 	DEFINE(CLONE_VM, CLONE_VM);
 
+	/* About the CPU features table */
+	DEFINE(CPU_SPEC_ENTRY_SIZE, sizeof(struct cpu_spec));
+	DEFINE(CPU_SPEC_PVR_MASK, offsetof(struct cpu_spec, pvr_mask));
+	DEFINE(CPU_SPEC_PVR_VALUE, offsetof(struct cpu_spec, pvr_value));
+	DEFINE(CPU_SPEC_FEATURES, offsetof(struct cpu_spec, cpu_features));
+	DEFINE(CPU_SPEC_SETUP, offsetof(struct cpu_spec, cpu_setup));
+
 	return 0;
 }
diff -urNp linux-463/arch/ppc64/kernel/pSeries_lpar.c linux-340/arch/ppc64/kernel/pSeries_lpar.c
--- linux-463/arch/ppc64/kernel/pSeries_lpar.c
+++ linux-340/arch/ppc64/kernel/pSeries_lpar.c
@@ -276,7 +276,6 @@ static unsigned char udbg_getcLP(void)
 
 
 
-/* Code for hvc_console.  Should move it back eventually. */
 
 int hvc_get_chars(int index, char *buf, int count)
 {
diff -urNp linux-463/arch/ppc64/kernel/pci.c linux-340/arch/ppc64/kernel/pci.c
--- linux-463/arch/ppc64/kernel/pci.c
+++ linux-340/arch/ppc64/kernel/pci.c
@@ -137,7 +137,7 @@ struct pci_dev *pci_find_dev_by_addr(uns
 	ioaddr = (addr > _IO_BASE) ? addr - _IO_BASE : 0;
 
 	pci_for_each_dev(dev) {
-		if ((dev->class >> 8) == PCI_BASE_CLASS_BRIDGE)
+		if ((dev->class >> 16) == PCI_BASE_CLASS_BRIDGE)
 			continue;
 		for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
 			unsigned long start = pci_resource_start(dev,i);
diff -urNp linux-463/arch/ppc64/kernel/pci.h linux-340/arch/ppc64/kernel/pci.h
--- linux-463/arch/ppc64/kernel/pci.h
+++ linux-340/arch/ppc64/kernel/pci.h
@@ -71,7 +71,7 @@ void pSeries_pcibios_init(void);
 static inline struct device_node *pci_device_to_OF_node(struct pci_dev *dev)
 {
 	struct device_node *dn = (struct device_node *)(dev->sysdata);
-	if (dn->devfn == dev->devfn && dn->busno == dev->bus->number)
+	if (dn->devfn == dev->devfn && dn->busno == (dev->bus->number&0xff))
 		return dn;	/* fast path.  sysdata is good */
 	else
 		return fetch_dev_dn(dev);
diff -urNp linux-463/arch/ppc64/kernel/pci_dma.c linux-340/arch/ppc64/kernel/pci_dma.c
--- linux-463/arch/ppc64/kernel/pci_dma.c
+++ linux-340/arch/ppc64/kernel/pci_dma.c
@@ -555,7 +555,8 @@ static inline dma_addr_t get_tces( struc
 		__asm__ __volatile__ ("sync" : : : "memory");
 	}
 	else {
-		panic("PCI_DMA: Tce Allocation failure in get_tces. 0x%p\n",tbl);
+		panic("get_tces: TCE allocation failed. 0x%p 0x%lx\n", 
+		      tbl, order);
 	}
 
 	return retTce; 
@@ -726,8 +727,8 @@ void create_tce_tables_for_busesLP(struc
 			 */
 			busdn->busno = bus->number;
 			create_pci_bus_tce_table((unsigned long)busdn);
-		} else
-			create_tce_tables_for_busesLP(&bus->children);
+		}
+		create_tce_tables_for_busesLP(&bus->children);
 	}
 }
 
@@ -1015,8 +1016,9 @@ void *pci_alloc_consistent(struct pci_de
  	/* Client asked for way to much space.  This is checked later anyway */
 	/* It is easier to debug here for the drivers than in the tce tables.*/
  	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_alloc_consistent size to large: 0x%lx \n",size);
- 		return (void *)NO_TCE;
+ 		printk("PCI_DMA: pci_alloc_consistent size too large: 0x%lx\n",
+		       size);
+ 		return (void *)NULL;
  	}
 
 	tbl = get_tce_table(hwdev); 
@@ -1033,15 +1035,15 @@ void *pci_alloc_consistent(struct pci_de
 				PPCDBG(PPCDBG_TCE, "pci_alloc_consistent: get_tces failed\n" );
 				free_pages( (unsigned long)ret, order );
 				ret = NULL;
-			}
-			else
-			{
+			} else {
 				*dma_handle = tce;
 			}
+		} else {
+			printk("pci_alloc_consistent: __get_free_pages failed for order = %d\n", order);
 		}
-		else PPCDBG(PPCDBG_TCE, "pci_alloc_consistent: __get_free_pages failed for order = %d\n", order);
+	} else {
+		panic("pci_alloc_consistent: unable to find TCE table\n");
 	}
-	else PPCDBG(PPCDBG_TCE, "pci_alloc_consistent: get_tce_table failed for 0x%016lx\n", hwdev);
 
 	PPCDBG(PPCDBG_TCE, "\tpci_alloc_consistent: dma_handle = 0x%16.16lx\n", *dma_handle);	
 	PPCDBG(PPCDBG_TCE, "\tpci_alloc_consistent: return     = 0x%16.16lx\n", ret);	
@@ -1103,8 +1105,8 @@ dma_addr_t pci_map_single(struct pci_dev
  	/* Client asked for way to much space.  This is checked later anyway */
 	/* It is easier to debug here for the drivers than in the tce tables.*/
  	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_map_single size to large: 0x%lx \n",size);
- 		return NO_TCE;
+ 		panic("PCI_DMA: pci_map_single size too large: 0x%lx \n", size);
+ 		return dma_handle;
  	}
 
 	tbl = get_tce_table(hwdev); 
@@ -1112,6 +1114,8 @@ dma_addr_t pci_map_single(struct pci_dev
 	if ( tbl ) {
 		dma_handle = get_tces( tbl, order, vaddr, nPages, direction );
 		dma_handle |= ( uaddr & ~PAGE_MASK );
+	} else {
+		panic("PCI_DMA: Unable to find TCE table.\n");
 	}
 
 	return dma_handle;
@@ -1156,6 +1160,7 @@ static unsigned long num_tces_sg( struct
 {
 	unsigned long nTces, numPages, startPage, endPage, prevEndPage;
 	unsigned i;
+	void *address;
 
 	prevEndPage = 0;
 	nTces = 0;
@@ -1164,8 +1169,10 @@ static unsigned long num_tces_sg( struct
 		/* Compute the starting page number and
 		 * the ending page number for this entry
 		 */
-		startPage = (unsigned long)sg->address >> PAGE_SHIFT;
-		endPage = ((unsigned long)sg->address + sg->length - 1) >> PAGE_SHIFT;
+		address = sg->address ? sg->address :
+			  (page_address(sg->page) + sg->offset);
+		startPage = (unsigned long)address >> PAGE_SHIFT;
+		endPage = ((unsigned long)address + sg->length - 1) >> PAGE_SHIFT;
 		numPages = endPage - startPage + 1;
 		/* Simple optimization: if the previous entry ended
 		 * in the same page in which this entry starts
@@ -1192,17 +1199,20 @@ static unsigned fill_scatterlist_sg( str
 	u32 cur_start_dma;
 	unsigned long cur_len_dma, cur_end_virt, uaddr;
 	unsigned num_dma_ents;
+	void *address;
 
 	dma_sg = sg;
 	num_dma_ents = 1;
 
 	/* Process the first sg entry */
-	cur_start_dma = dma_addr + ((unsigned long)sg->address & (~PAGE_MASK));
+	address = sg->address ? sg->address : 
+		  (page_address(sg->page) + sg->offset);
+	cur_start_dma = dma_addr + ((unsigned long)address & (~PAGE_MASK));
 	cur_len_dma = sg->length;
 	/* cur_end_virt holds the address of the byte immediately after the
 	 * end of the current buffer.
 	 */
-	cur_end_virt = (unsigned long)sg->address + cur_len_dma;
+	cur_end_virt = (unsigned long)address + cur_len_dma;
 	/* Later code assumes that unused sg->dma_address and sg->dma_length
 	 * fields will be zero.  Other archs seem to assume that the user
 	 * (device driver) guarantees that...I don't want to depend on that
@@ -1227,7 +1237,9 @@ static unsigned fill_scatterlist_sg( str
 		 * or if the previous entry ends at a page boundary
 		 * and the current entry starts at a page boundary.
 		 */
-		uaddr = (unsigned long)sg->address;
+		address = sg->address ? sg->address :
+			  (page_address(sg->page) + sg->offset);
+		uaddr = (unsigned long)address;
 		if ( ( uaddr != cur_end_virt ) &&
 		     ( ( ( uaddr | cur_end_virt ) & (~PAGE_MASK) ) ||
 		       ( ( uaddr & PAGE_MASK ) == ( ( cur_end_virt-1 ) & PAGE_MASK ) ) ) ) {
@@ -1285,6 +1297,7 @@ static dma_addr_t create_tces_sg( struct
 	unsigned long startPage, endPage, prevEndPage, numPages, uaddr;
 	long tcenum, starttcenum;
 	dma_addr_t dmaAddr;
+	void *address;
 
 	dmaAddr = NO_TCE;
 
@@ -1304,11 +1317,13 @@ static dma_addr_t create_tces_sg( struct
 		dmaAddr = tcenum << PAGE_SHIFT;
 		prevEndPage = 0;
 		for (j=0; j<nents; ++j) {
-			startPage = (unsigned long)sg->address >> PAGE_SHIFT;
-			endPage = ((unsigned long)sg->address + sg->length - 1) >> PAGE_SHIFT;
+			address = sg->address ? sg->address :
+				  (page_address(sg->page) + sg->offset);
+			startPage = (unsigned long)address >> PAGE_SHIFT;
+			endPage = ((unsigned long)address + sg->length - 1) >> PAGE_SHIFT;
 			numPages = endPage - startPage + 1;
 			
-			uaddr = (unsigned long)sg->address;
+			uaddr = (unsigned long)address;
 
 			/* If the previous entry ended in the same page that
 			 * the current page starts then they share that
@@ -1340,6 +1355,9 @@ static dma_addr_t create_tces_sg( struct
 	    		PPCDBG(PPCDBG_TCE, "create_tces_sg: numTces %d, tces used %d\n",
 		   		numTces, (unsigned)(tcenum - starttcenum));
 
+	} else {
+		panic("PCI_DMA: TCE allocation failure in create_tces_sg. 0x%p 0x%lx\n",
+		      tbl, order);
 	}
 
 	return dmaAddr;
@@ -1349,14 +1367,17 @@ int pci_map_sg( struct pci_dev *hwdev, s
 {
 	struct TceTable * tbl;
 	unsigned numTces;
-	int num_dma;
+	int num_dma = 0;
 	dma_addr_t dma_handle;
+	void *address;
 
 	PPCDBG(PPCDBG_TCE, "pci_map_sg:\n");
 	PPCDBG(PPCDBG_TCE, "\thwdev = 0x%16.16lx, sg = 0x%16.16lx, direction = 0x%16.16lx, nents = 0x%16.16lx\n", hwdev, sg, direction, nents);	
 	/* Fast path for a single entry scatterlist */
 	if ( nents == 1 ) {
-		sg->dma_address = pci_map_single( hwdev, sg->address, 
+		address = sg->address ? sg->address :
+			  (page_address(sg->page) + sg->offset);
+		sg->dma_address = pci_map_single( hwdev, address, 
 					sg->length, direction );
 		sg->dma_length = sg->length;
 		return 1;
@@ -1373,8 +1394,12 @@ int pci_map_sg( struct pci_dev *hwdev, s
 		/* Create the tces and get the dma address */ 
 		dma_handle = create_tces_sg( tbl, sg, nents, numTces, direction );
 
+		if (dma_handle == NO_TCE) return 0;
+
 		/* Fill in the dma scatterlist */
 		num_dma = fill_scatterlist_sg( sg, nents, dma_handle, numTces );
+	} else {
+		panic("pci_map_sg: unable to find TCE table\n");
 	}
 
 	return num_dma;
diff -urNp linux-463/arch/ppc64/kernel/perfmon.c linux-340/arch/ppc64/kernel/perfmon.c
--- linux-463/arch/ppc64/kernel/perfmon.c
+++ linux-340/arch/ppc64/kernel/perfmon.c
@@ -22,6 +22,7 @@
 #include <asm/perfmon.h>
 #include <asm/iSeries/HvCall.h>
 #include <asm/hvcall.h>
+#include <asm/cputable.h>
 
 extern char _stext[], _etext[], _end[];
 struct perfmon_base_struct perfmon_base = {0, 0, 0, 0, 0, 0, 0, PMC_STATE_INITIAL};
@@ -450,7 +451,7 @@ int pmc_profile(struct perfmon_struct *p
 	}
 	perfmon_base.state = PMC_STATE_PROFILE_KERN; 
 
-	if (__is_processor(PV_POWER4) || __is_processor(PV_POWER4p)) {
+	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB) {
 		for(i = 0; i < 8; i++) 
 			pdata->pmc[i] = 0x0;
 		pdata->pmc[1] = 0x7f000000;
@@ -794,7 +795,7 @@ void pmc_configure_hardware() {
 	 * Flood enabled is required on GP for PMC cycle profile mode
 	 *   iSeries SP sets this by default.  pSeries requires the OS to enable.
 	 */
-	if (__is_processor(PV_POWER4) || __is_processor(PV_POWER4p)) {
+	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB) {
 		/* Set up the debug bus to pmc mode - a feature of GP */
 		switch(systemcfg->platform) {
 		case PLATFORM_ISERIES_LPAR:
diff -urNp linux-463/arch/ppc64/kernel/pmc.c linux-340/arch/ppc64/kernel/pmc.c
--- linux-463/arch/ppc64/kernel/pmc.c
+++ linux-340/arch/ppc64/kernel/pmc.c
@@ -241,7 +241,7 @@ void* btmalloc (unsigned long size) {
 		lock_slot = get_lock_slot(vpn); 
 		rpn = pa >> PAGE_SHIFT;
 
-		spin_lock(&hash_table_lock[lock_slot].lock);
+		spin_lock(&hash_table_lock[lock_slot]);
 		/* Get a pointer to the linux page table entry for this page
 		 * allocating pmd or pte pages along the way as needed.  Note
 		 * that the pmd & pte pages are not themselfs bolted.
@@ -266,7 +266,7 @@ void* btmalloc (unsigned long size) {
 
 		*ptep = pte;
 
-		spin_unlock(&hash_table_lock[lock_slot].lock);
+		spin_unlock(&hash_table_lock[lock_slot]);
 	}
 
 	spin_unlock(&btmalloc_mm.page_table_lock);
diff -urNp linux-463/arch/ppc64/kernel/ppc_ksyms.c linux-340/arch/ppc64/kernel/ppc_ksyms.c
--- linux-463/arch/ppc64/kernel/ppc_ksyms.c
+++ linux-340/arch/ppc64/kernel/ppc_ksyms.c
@@ -78,6 +78,13 @@ int abs(int);
 extern struct pci_dev * iSeries_veth_dev;
 extern struct pci_dev * iSeries_vio_dev;
 
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+extern void shared_malloc(unsigned long);
+extern void shared_free(void *);
+extern int shared_task_mark();
+extern int shared_task_unmark();
+#endif
+
 EXPORT_SYMBOL(do_signal);
 EXPORT_SYMBOL(syscall_trace);
 EXPORT_SYMBOL(do_IRQ);
@@ -95,6 +102,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
 EXPORT_SYMBOL(kernel_flag);
 EXPORT_SYMBOL(synchronize_irq);
 EXPORT_SYMBOL(smp_num_cpus);
+EXPORT_SYMBOL(cpu_online_map);
 #endif /* CONFIG_SMP */
 
 EXPORT_SYMBOL(register_ioctl32_conversion);
@@ -121,6 +129,7 @@ EXPORT_SYMBOL(strlen);
 EXPORT_SYMBOL(strnlen);
 EXPORT_SYMBOL(strcmp);
 EXPORT_SYMBOL(strncmp);
+EXPORT_SYMBOL(memchr);
 
 EXPORT_SYMBOL(__down_interruptible);
 EXPORT_SYMBOL(__up);
@@ -309,3 +318,10 @@ EXPORT_SYMBOL(tb_ticks_per_usec);
 extern void dump_send_ipi(int (*dump_ipi_callback)(struct pt_regs *));
 EXPORT_SYMBOL(dump_send_ipi);
 #endif
+
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+EXPORT_SYMBOL(shared_malloc);
+EXPORT_SYMBOL(shared_free);
+EXPORT_SYMBOL(shared_task_mark);
+EXPORT_SYMBOL(shared_task_unmark);
+#endif
diff -urNp linux-463/arch/ppc64/kernel/proc_pcifr.c linux-340/arch/ppc64/kernel/proc_pcifr.c
--- linux-463/arch/ppc64/kernel/proc_pcifr.c
+++ linux-340/arch/ppc64/kernel/proc_pcifr.c
@@ -53,11 +53,8 @@ extern long Pci_Error_Count;
 /************************************************************************/
 static struct proc_dir_entry *pciFr_proc_root = NULL;
 int proc_pciFr_read_proc(char *page, char **start, off_t off, int count, int *eof, void *data);
-int proc_pciFr_write_proc(struct file *file, const char *buffer, unsigned long count, void *data);
-
 static struct proc_dir_entry *pciDev_proc_root = NULL;
 int proc_pciDev_read_proc(char *page, char **start, off_t off, int count, int *eof, void *data);
-int proc_pciDev_write_proc(struct file *file, const char *buffer, unsigned long count, void *data);
 
 /************************************************************************/
 /* Create entry ../proc/ppc64/pcifr                                     */
@@ -77,7 +74,7 @@ void proc_pciFr_init(struct proc_dir_ent
 	pciFr_proc_root->nlink = 1;
 	pciFr_proc_root->data = (void *)0;
 	pciFr_proc_root->read_proc  = proc_pciFr_read_proc;
-	pciFr_proc_root->write_proc = proc_pciFr_write_proc;
+	pciFr_proc_root->write_proc = NULL;
 
 	PciFr = alloc_Flight_Recorder(NULL,"PciFr", 4096);
 
@@ -91,79 +88,56 @@ void proc_pciFr_init(struct proc_dir_ent
 	pciDev_proc_root->nlink = 1;
 	pciDev_proc_root->data = (void *)0;
 	pciDev_proc_root->read_proc  = proc_pciDev_read_proc;
-	pciDev_proc_root->write_proc = proc_pciDev_write_proc;
+	pciDev_proc_root->write_proc = NULL;
 }
 
-static	char* PciFrBuffer = NULL;
-static  int   PciFrBufLen = 0;
-static  char* PciFrBufPtr = NULL;
-static  int   PciFileSize = 0;
-
 /*******************************************************************************/
 /* Read function for ../proc/ppc64/pcifr.                                      */
 /*  -> Function grabs a copy of the pcifr(could change) and writes the data to */
-/*     the caller.  Note, it may not all fit in the buffer.  The function      */
-/*     handles the repeated calls until all the data has been read.            */
+/*     the caller.  Note, it may not all fit in the buffer.                   */
 /* Tip:                                                                        */
 /* ./fs/proc/generic.c::proc_file_read is the caller of this routine.          */
 /*******************************************************************************/
 int proc_pciFr_read_proc(char *page, char **start, off_t off, int count, int *eof, void *data)
 {
-	/* First call will have offset 0, get snapshot the pcifr          */
-	if( off == 0) {
-		spin_lock(&proc_pcifr_lock);
-		PciFrBuffer = (char*)kmalloc(PciFr->Size, GFP_KERNEL);
-		PciFrBufLen = fr_Dump(PciFr,PciFrBuffer, PciFr->Size);
-		PciFrBufPtr = PciFrBuffer;
-		PciFileSize = 0;
-	}
-	/* For the persistant folks, set eof and return zero length.      */
-	else if( PciFrBuffer == NULL) {
-		*eof = 1;
-		return 0;
-	}
-	/* - If there is more data than will fit, move what will fit.     */
-	/* - The rest will get moved on the next call.                    */
-	int MoveSize = PciFrBufLen;
-	if( MoveSize > count) MoveSize = count;
-
-	/* Move the data info the FileSystem buffer.                      */
-	memcpy(page+off,PciFrBufPtr,MoveSize);
-	PciFrBufPtr += MoveSize;
-	PciFileSize += MoveSize;
-	PciFrBufLen -= MoveSize;
-
-	/* If all the data has been moved, free the buffer and set EOF.   */
-	if( PciFrBufLen == 0) {
-		kfree(PciFrBuffer);
-		PciFrBuffer = NULL;
-		spin_unlock(&proc_pcifr_lock);
-		*eof = 1;
-	}
-	return PciFileSize;
-}
-/*******************************************************************************/
-/* Gets called when client writes to ../proc/ppc64/pcifr                       */
-/*******************************************************************************/
-int proc_pciFr_write_proc(struct file *file, const char *buffer, unsigned long count, void *data)
-{
-	return count;
+	char *PciFrBuffer;
+	int PciFrBufLen;
+
+	PciFrBuffer = (char*)kmalloc(PciFr->Size, GFP_KERNEL);
+	if (PciFrBuffer == NULL)
+		return -ENOMEM;
+
+	/* Snapshot the pci flight recorder */
+	PciFrBufLen = fr_Dump(PciFr, PciFrBuffer, PciFr->Size);
+
+        if (off >= PciFrBufLen) {
+                *eof = 1;
+                kfree(PciFrBuffer);
+                return 0;
+        }
+        if (off)
+                PciFrBufLen -= off;
+        if (PciFrBufLen > count)
+                PciFrBufLen = count;
+        else
+                *eof = 1;
+
+        memcpy (page, PciFrBuffer + off, PciFrBufLen);
+        *start = page;
+        kfree(PciFrBuffer);
+        return PciFrBufLen;
 }
-static  spinlock_t ProcBufferLock;
-static	char* ProcBuffer   = NULL;
-static  int   ProcBufSize  = 0;
-static  char* ProcBufPtr   = NULL;
-static  int   ProcFileSize = 0;
 
 /*******************************************************************************/
 /* Build Device Buffer for /proc/ppc64/pci                                     */
 /*******************************************************************************/
-static int build_PciDev_Buffer(int BufferSize) 
+static int build_PciDev_Buffer(char *ProcBuffer, int BufferSize) 
 {
-	ProcBuffer  = (char*)kmalloc(BufferSize, GFP_KERNEL);
-	ProcBufPtr  = ProcBuffer;
-
 	int BufLen  = 0;
+	struct pci_dev*    PciDev;		    /* Device pointer              */
+	struct net_device* dev;		            /* net_device pointer          */
+	int    DeviceCount  = 0;
+	int j;
 
 	BufLen += sprintf(ProcBuffer+BufLen,"Pci I/O Reads. %8ld  ",Pci_Io_Read_Count);
 	BufLen += sprintf(ProcBuffer+BufLen,"Pci I/O Writes %8ld\n",Pci_Io_Write_Count);
@@ -177,9 +151,6 @@ static int build_PciDev_Buffer(int Buffe
 	/***************************************************************************/
 	/* List the devices                                                        */
 	/***************************************************************************/
-	struct pci_dev*    PciDev;		    /* Device pointer              */
-	struct net_device* dev;		            /* net_device pointer          */
-	int    DeviceCount  = 0;
 	pci_for_each_dev(PciDev) {
 		if ( BufLen > BufferSize-128) {    /* Room for another line?       */
 			BufLen +=sprintf(ProcBuffer+BufLen,"Buffer Full\n");
@@ -198,54 +169,49 @@ static int build_PciDev_Buffer(int Buffe
 
 			/* look for the net devices out */
 			for (dev = dev_base; dev != NULL; dev = dev->next) 	{
-				if (dev->base_addr == PciDev->resource[0].start ) {
-					BufLen += sprintf(ProcBuffer+BufLen, "     - Net device: %s\n", dev->name);
+                               
+				if (!dev->base_addr) /* virtual device, no base address */
 					break;
-				} /* if */
+				
+				for (j=0;j<6;j++) { /* PCI has 6 base addresses */
+					if (dev->base_addr == PciDev->resource[j].start ) {
+						BufLen += sprintf(ProcBuffer+BufLen, "     - Net device: %s\n", dev->name);
+						break;
+					} /* if */
+				}
+				if (j!=6) break; /* found one */
 			} /* for */
 		} /* if(PCI_SLOT(PciDev->devfn) != 0)  */
 	}
 	return BufLen;
 }
 /*******************************************************************************/
-/* Get called when client reads the ../proc/ppc64/pcifr.                       */
+/* Get called when client reads the ../proc/ppc64/pci.                         */
 /*******************************************************************************/
 int proc_pciDev_read_proc(char *page, char **start, off_t off, int count, int *eof, void *data)
 {
-	/* First call will have offset 0                                  */
-	if( off == 0) {
-		spin_lock(&ProcBufferLock);
-		ProcBufSize  = build_PciDev_Buffer(4096);
-		ProcFileSize = 0;
-	}
-	/* For the persistant folks, set eof and return zero length.      */
-	else if( ProcBuffer == NULL) {
+	char *ProcBuffer;
+	int ProcBufSize;
+
+	ProcBuffer = (char*)kmalloc(4096, GFP_KERNEL);
+	if (ProcBuffer == NULL)
+		return -ENOMEM;
+	ProcBufSize = build_PciDev_Buffer(ProcBuffer, 4096);
+
+	if (off >= ProcBufSize) {
 		*eof = 1;
+		kfree(ProcBuffer);
 		return 0;
 	}
-	/* How much data can be moved                                     */
-	int MoveSize = ProcBufSize;
-	if( MoveSize > count) MoveSize = count;
-
-	/* Move the data info the FileSystem buffer.                      */
-	memcpy(page+off,ProcBufPtr,MoveSize);
-	ProcBufPtr   += MoveSize;
-	ProcBufSize  -= MoveSize;
-	ProcFileSize += MoveSize;
-
-	/* If all the data has been moved, free the buffer and set EOF.   */
-	if( ProcBufSize == 0) {
-		kfree(ProcBuffer );
-		ProcBuffer  = NULL;
-		spin_unlock(&ProcBufferLock);
+	if (off)
+		ProcBufSize -= off;
+	if (ProcBufSize > count)
+		ProcBufSize = count;
+	else
 		*eof = 1;
-	}
-	return ProcFileSize;
-}
-/*******************************************************************************/
-/* Gets called when client writes to ../proc/ppc64/pcifr                       */
-/*******************************************************************************/
-int proc_pciDev_write_proc(struct file *file, const char *buffer, unsigned long count, void *data)
-{
-	return count;
+
+	memcpy (page, ProcBuffer + off, ProcBufSize);
+	*start = page;
+	kfree(ProcBuffer);
+	return ProcBufSize;
 }
diff -urNp linux-463/arch/ppc64/kernel/proc_pmc.c linux-340/arch/ppc64/kernel/proc_pmc.c
--- linux-463/arch/ppc64/kernel/proc_pmc.c
+++ linux-340/arch/ppc64/kernel/proc_pmc.c
@@ -49,12 +49,12 @@ extern void proc_pciFr_init(struct proc_
 
 static int proc_pmc_control_mode = 0;
 
-static struct proc_dir_entry *proc_ppc64_root = NULL;
+struct proc_dir_entry *proc_ppc64_root = NULL;
 static struct proc_dir_entry *proc_ppc64_pmc_root = NULL;
 static struct proc_dir_entry *proc_ppc64_pmc_system_root = NULL;
 static struct proc_dir_entry *proc_ppc64_pmc_cpu_root[NR_CPUS] = {NULL, };
 
-static spinlock_t proc_ppc64_lock;
+spinlock_t proc_ppc64_lock;
 static int proc_ppc64_page_read(char *page, char **start, off_t off,
 				int count, int *eof, void *data);
 static void proc_ppc64_create_paca(int num, struct proc_dir_entry *paca_dir);
@@ -145,8 +145,13 @@ void proc_ppc64_init(void)
 	 *   /proc/ppc64/pmc/cpu0 
 	 */
 	spin_lock(&proc_ppc64_lock);
-	proc_ppc64_root = proc_mkdir("ppc64", 0);
-	if (!proc_ppc64_root) return;
+	if (proc_ppc64_root == NULL) {
+		proc_ppc64_root = proc_mkdir("ppc64", 0);
+		if (!proc_ppc64_root) {
+			spin_unlock(&proc_ppc64_lock);
+			return;
+		}
+	}
 	spin_unlock(&proc_ppc64_lock);
 
 	ent = create_proc_entry("naca", S_IFREG|S_IRUGO, proc_ppc64_root);
@@ -173,7 +178,9 @@ void proc_ppc64_init(void)
 	}
 
 	/* Placeholder for rtas interfaces. */
-	rtas_proc_dir = proc_mkdir("rtas", proc_ppc64_root);
+	if (rtas_proc_dir == NULL) {
+		rtas_proc_dir = proc_mkdir("rtas", proc_ppc64_root);
+	}
 
 	/* Create the /proc/ppc64/pcifr for the Pci Flight Recorder.	 */
 	proc_pciFr_init(proc_ppc64_root);
@@ -195,7 +202,7 @@ void proc_ppc64_init(void)
 			ent->nlink = 1;
 			ent->data = (void *)proc_ppc64_pmc_cpu_root[i];
 			ent->read_proc = (void *)proc_ppc64_pmc_stab_read;
-			ent->write_proc = (void *)proc_ppc64_pmc_stab_read;
+			ent->write_proc = NULL;
 		}
 
 		ent = create_proc_entry("htab", S_IRUGO | S_IWUSR, 
@@ -204,7 +211,7 @@ void proc_ppc64_init(void)
 			ent->nlink = 1;
 			ent->data = (void *)proc_ppc64_pmc_cpu_root[i];
 			ent->read_proc = (void *)proc_ppc64_pmc_htab_read;
-			ent->write_proc = (void *)proc_ppc64_pmc_htab_read;
+			ent->write_proc = NULL;
 		}
 	}
 
@@ -214,7 +221,7 @@ void proc_ppc64_init(void)
 		ent->nlink = 1;
 		ent->data = (void *)proc_ppc64_pmc_system_root;
 		ent->read_proc = (void *)proc_ppc64_pmc_stab_read;
-		ent->write_proc = (void *)proc_ppc64_pmc_stab_read;
+		ent->write_proc = NULL;
 	}
 
 	ent = create_proc_entry("htab", S_IRUGO | S_IWUSR, 
@@ -223,7 +230,7 @@ void proc_ppc64_init(void)
 		ent->nlink = 1;
 		ent->data = (void *)proc_ppc64_pmc_system_root;
 		ent->read_proc = (void *)proc_ppc64_pmc_htab_read;
-		ent->write_proc = (void *)proc_ppc64_pmc_htab_read;
+		ent->write_proc = NULL;
 	}
 
 	ent = create_proc_entry("profile", S_IWUSR | S_IRUGO, proc_ppc64_pmc_system_root);
@@ -254,7 +261,7 @@ void proc_ppc64_init(void)
 			ent->nlink = 1;
 			ent->data = (void *)proc_ppc64_pmc_cpu_root[i];
 			ent->read_proc = (void *)proc_ppc64_pmc_hw_read;
-			ent->write_proc = (void *)proc_ppc64_pmc_hw_read;
+			ent->write_proc = NULL;
 		}
 	}
 
@@ -264,7 +271,7 @@ void proc_ppc64_init(void)
 		ent->nlink = 1;
 		ent->data = (void *)proc_ppc64_pmc_system_root;
 		ent->read_proc = (void *)proc_ppc64_pmc_hw_read;
-		ent->write_proc = (void *)proc_ppc64_pmc_hw_read;
+		ent->write_proc = NULL;
 	}
 }
 
@@ -875,18 +882,26 @@ static inline void proc_pmc_tlb(void)
 
 int proc_pmc_set_control( struct file *file, const char *buffer, unsigned long count, void *data )
 {
-	if      ( ! strncmp( buffer, "stop", 4 ) )
+	char control[10];
+	if (count > 9) count = 9;
+	if (copy_from_user (control, buffer, count)) {
+		return -EFAULT;
+	}
+	control[count] = '\0';
+
+	if      ( ! strncmp( control, "stop", 4 ) )
 		proc_pmc_stop();
-	else if ( ! strncmp( buffer, "start", 5 ) )
+	else if ( ! strncmp( control, "start", 5 ) )
 		proc_pmc_start();
-	else if ( ! strncmp( buffer, "reset", 5 ) )
+	else if ( ! strncmp( control, "reset", 5 ) )
 		proc_pmc_reset();
-	else if ( ! strncmp( buffer, "cpi", 3 ) )
+	else if ( ! strncmp( control, "cpi", 3 ) )
 		proc_pmc_cpi();
-	else if ( ! strncmp( buffer, "tlb", 3 ) )
+	else if ( ! strncmp( control, "tlb", 3 ) )
 		proc_pmc_tlb();
+	else 
+		return -EINVAL;
 	
-	/* IMPLEMENT ME */
 	return count;
 }
 
diff -urNp linux-463/arch/ppc64/kernel/process.c linux-340/arch/ppc64/kernel/process.c
--- linux-463/arch/ppc64/kernel/process.c
+++ linux-340/arch/ppc64/kernel/process.c
@@ -42,6 +42,7 @@
 #include <asm/ppcdebug.h>
 #include <asm/machdep.h>
 #include <asm/iSeries/HvCallHpt.h>
+#include <asm/cputable.h>
 
 int dump_fpu(struct pt_regs *regs, elf_fpregset_t *fpregs);
 
@@ -390,7 +391,7 @@ void initialize_paca_hardware_interrupt_
 	 * __get_free_pages() might give us a page > KERNBASE+256M which
 	 * is mapped with large ptes so we can't set up the guard page.
 	 */
-	if (__is_processor(PV_POWER4) || __is_processor(PV_POWER4p))
+	if (cur_cpu_spec->cpu_features & CPU_FTR_16M_PAGE)
 		return;
 
 	for (i=0; i < systemcfg->processorCount; i++) {
diff -urNp linux-463/arch/ppc64/kernel/prom.c linux-340/arch/ppc64/kernel/prom.c
--- linux-463/arch/ppc64/kernel/prom.c
+++ linux-340/arch/ppc64/kernel/prom.c
@@ -180,6 +180,8 @@ struct _of_tce_table of_tce_table[MAX_PH
 char *bootpath = 0;
 char *bootdevice = 0;
 
+int boot_cpuid = 0;
+
 struct device_node *allnodes = 0;
 
 #define UNDEFINED_IRQ 0xffff
@@ -1199,7 +1201,7 @@ prom_hold_cpus(unsigned long mem)
 		for (i=0; i < _systemcfg->processorCount ;i++) {
 			unsigned long threadid = _systemcfg->processorCount*2-1-i;
 			
-			if (i == 0) {
+			if (i == boot_cpuid) {
 				unsigned long pir = _get_PIR();
 				if (__is_processor(PV_PULSAR)) {
 					RELOC(hmt_thread_data)[i].pir = 
@@ -1498,6 +1500,8 @@ prom_init(unsigned long r3, unsigned lon
 	_prom->cpu = (int)(unsigned long)getprop_rval;
 	_xPaca[0].xHwProcNum = _prom->cpu;
 
+	RELOC(boot_cpuid) = _prom->cpu;
+
 #ifdef DEBUG_PROM
   	prom_print(RELOC("Booting CPU hw index = 0x"));
   	prom_print_hex(_prom->cpu);
@@ -1534,8 +1538,7 @@ prom_init(unsigned long r3, unsigned lon
          * following, regardless of whether we have an SMP
          * kernel or not.
          */
-        if (_systemcfg->processorCount > 1)
-	        prom_hold_cpus(mem);
+	prom_hold_cpus(mem);
 
 #ifdef DEBUG_PROM
 	prom_print(RELOC("copying OF device tree...\n"));
@@ -1559,7 +1562,7 @@ prom_init(unsigned long r3, unsigned lon
 	}
 
 	/* We assume the phys. address size is 3 cells */
-	RELOC(prom_mmu) = (ihandle)(unsigned long)getprop_rval;
+	prom_mmu = (ihandle)(unsigned long)getprop_rval;
 
 	if ((long)call_prom(RELOC("call-method"), 4, 4,
 				RELOC("translate"),
diff -urNp linux-463/arch/ppc64/kernel/rtas-proc.c linux-340/arch/ppc64/kernel/rtas-proc.c
--- linux-463/arch/ppc64/kernel/rtas-proc.c
+++ linux-340/arch/ppc64/kernel/rtas-proc.c
@@ -115,14 +115,18 @@
 
 
 /* Globals */
-static struct proc_dir_entry *proc_rtas;
 static struct rtas_sensors sensors;
-static struct device_node *rtas_node;
+static struct device_node *rtas_node = NULL;
 static unsigned long power_on_time = 0; /* Save the time the user set */
 static char progress_led[MAX_LINELENGTH];
 
 static unsigned long rtas_tone_frequency = 1000;
 static unsigned long rtas_tone_volume = 0;
+static unsigned int open_token = 0;
+
+extern struct proc_dir_entry *proc_ppc64_root;
+extern struct proc_dir_entry *rtas_proc_dir;
+extern spinlock_t proc_ppc64_lock;
 
 /* ****************STRUCTS******************************************* */
 struct individual_sensor {
@@ -160,6 +164,12 @@ static ssize_t ppc_rtas_tone_volume_writ
 		size_t count, loff_t *ppos);
 static ssize_t ppc_rtas_tone_volume_read(struct file * file, char * buf,
 		size_t count, loff_t *ppos);
+static int ppc_rtas_errinjct_open(struct inode *inode, struct file *file);
+static int ppc_rtas_errinjct_release(struct inode *inode, struct file *file);
+static ssize_t ppc_rtas_errinjct_write(struct file * file, const char * buf,
+				   size_t count, loff_t *ppos);
+static ssize_t ppc_rtas_errinjct_read(struct file *file, char *buf,
+				      size_t count, loff_t *ppos);
 
 struct file_operations ppc_rtas_poweron_operations = {
 	.read =		ppc_rtas_poweron_read,
@@ -184,6 +194,13 @@ struct file_operations ppc_rtas_tone_vol
 	.write =	ppc_rtas_tone_volume_write
 };
 
+struct file_operations ppc_rtas_errinjct_operations = {
+    .open =		ppc_rtas_errinjct_open,
+    .read = 		ppc_rtas_errinjct_read,
+    .write = 		ppc_rtas_errinjct_write,
+    .release = 		ppc_rtas_errinjct_release
+};
+
 int ppc_rtas_find_all_sensors (void);
 int ppc_rtas_process_sensor(struct individual_sensor s, int state, 
 		int error, char * buf);
@@ -200,33 +217,54 @@ void proc_rtas_init(void)
 	struct proc_dir_entry *entry;
 
 	rtas_node = find_devices("rtas");
-	if ((rtas_node == 0) || (systemcfg->platform == PLATFORM_ISERIES_LPAR)) {
+	if ((rtas_node == NULL) || (systemcfg->platform == PLATFORM_ISERIES_LPAR)) {
 		return;
 	}
 	
-	proc_rtas = proc_mkdir("rtas", 0);
-	if (proc_rtas == 0)
+	spin_lock(&proc_ppc64_lock);
+	if (proc_ppc64_root == NULL) {
+		proc_ppc64_root = proc_mkdir("ppc64", 0);
+		if (!proc_ppc64_root) {
+			spin_unlock(&proc_ppc64_lock);
+			return;
+		}		
+	}
+	spin_unlock(&proc_ppc64_lock);
+	
+	if (rtas_proc_dir == NULL) {
+		rtas_proc_dir = proc_mkdir("rtas", proc_ppc64_root);
+	}
+
+	if (rtas_proc_dir == NULL) {
+		printk(KERN_ERR "Failed to create /proc/ppc64/rtas in rtas_init\n");
 		return;
+	}
 
 	/* /proc/rtas entries */
 
-	entry = create_proc_entry("progress", S_IRUGO|S_IWUSR, proc_rtas);
+	entry = create_proc_entry("progress", S_IRUGO|S_IWUSR, rtas_proc_dir);
 	if (entry) entry->proc_fops = &ppc_rtas_progress_operations;
 
-	entry = create_proc_entry("clock", S_IRUGO|S_IWUSR, proc_rtas); 
+	entry = create_proc_entry("clock", S_IRUGO|S_IWUSR, rtas_proc_dir); 
 	if (entry) entry->proc_fops = &ppc_rtas_clock_operations;
 
-	entry = create_proc_entry("poweron", S_IWUSR|S_IRUGO, proc_rtas); 
+	entry = create_proc_entry("poweron", S_IWUSR|S_IRUGO, rtas_proc_dir); 
 	if (entry) entry->proc_fops = &ppc_rtas_poweron_operations;
 
-	create_proc_read_entry("sensors", S_IRUGO, proc_rtas, 
+	create_proc_read_entry("sensors", S_IRUGO, rtas_proc_dir, 
 			ppc_rtas_sensor_read, NULL);
 	
-	entry = create_proc_entry("frequency", S_IWUSR|S_IRUGO, proc_rtas); 
+	entry = create_proc_entry("frequency", S_IWUSR|S_IRUGO, rtas_proc_dir); 
 	if (entry) entry->proc_fops = &ppc_rtas_tone_freq_operations;
 
-	entry = create_proc_entry("volume", S_IWUSR|S_IRUGO, proc_rtas); 
+	entry = create_proc_entry("volume", S_IWUSR|S_IRUGO, rtas_proc_dir); 
 	if (entry) entry->proc_fops = &ppc_rtas_tone_volume_operations;
+
+#ifdef CONFIG_RTAS_ERRINJCT
+	entry = create_proc_entry("errinjct", S_IWUSR|S_IRUGO, rtas_proc_dir);
+	if (entry) entry->proc_fops = &ppc_rtas_errinjct_operations;
+#endif
+
 }
 
 /* ****************************************************************** */
@@ -393,8 +431,8 @@ static int ppc_rtas_sensor_read(char * b
 	memset(buffer, 0, MAX_LINELENGTH*MAX_SENSORS);
 
 	n  = sprintf ( buffer  , "RTAS (RunTime Abstraction Services) Sensor Information\n");
-	n += sprintf ( buffer+n, "Sensor\t\tValue\t\tCondition\tLocation\n");
-	n += sprintf ( buffer+n, "********************************************************\n");
+	n += sprintf ( buffer+n, "%-17s\t%-15s\t%-15s\tLocation\n", "Sensor", "Value", "Condition");
+	n += sprintf ( buffer+n, "***************************************************************************\n");
 
 	if (ppc_rtas_find_all_sensors() != 0) {
 		n += sprintf ( buffer+n, "\nNo sensors are available\n");
@@ -436,10 +474,10 @@ return_string:
 
 int ppc_rtas_find_all_sensors (void)
 {
-	unsigned long *utmp;
-	int len, i, j;
+	unsigned int *utmp;
+	int len, i;
 
-	utmp = (unsigned long *) get_property(rtas_node, "rtas-sensors", &len);
+	utmp = (unsigned int *) get_property(rtas_node, "rtas-sensors", &len);
 	if (utmp == NULL) {
 		printk (KERN_ERR "error: could not get rtas-sensors\n");
 		return 1;
@@ -447,9 +485,9 @@ int ppc_rtas_find_all_sensors (void)
 
 	sensors.quant = len / 8;      /* int + int */
 
-	for (i=0, j=0; j<sensors.quant; i+=2, j++) {
-		sensors.sensor[j].token = utmp[i];
-		sensors.sensor[j].quant = utmp[i+1];
+	for (i=0; i<sensors.quant; i++) {
+		sensors.sensor[i].token = *utmp++;
+		sensors.sensor[i].quant = *utmp++;
 	}
 	return 0;
 }
@@ -495,10 +533,10 @@ int ppc_rtas_process_sensor(struct indiv
 		int error, char * buf) 
 {
 	/* Defined return vales */
-	const char * key_switch[]        = { "Off\t", "Normal\t", "Secure\t", "Mainenance" };
+	const char * key_switch[]        = { "Off", "Normal", "Secure", "Maintenance" };
 	const char * enclosure_switch[]  = { "Closed", "Open" };
 	const char * lid_status[]        = { " ", "Open", "Closed" };
-	const char * power_source[]      = { "AC\t", "Battery", "AC & Battery" };
+	const char * power_source[]      = { "AC", "Battery", "AC & Battery" };
 	const char * battery_remaining[] = { "Very Low", "Low", "Mid", "High" };
 	const char * epow_sensor[]       = { 
 		"EPOW Reset", "Cooling warning", "Power warning",
@@ -509,100 +547,109 @@ int ppc_rtas_process_sensor(struct indiv
 	const char * ibm_drconnector[]     = { "Empty", "Present" };
 	const char * ibm_intqueue[]        = { "Disabled", "Enabled" };
 
-	int have_strings = 0;
 	int temperature = 0;
 	int unknown = 0;
 	int n = 0;
+	char *label_string = NULL;
+	const char **value_arr = NULL;
+	int value_arrsize = 0;
+
 
 	/* What kind of sensor do we have here? */
 	switch (s.token) {
 		case KEY_SWITCH:
-			n += sprintf(buf+n, "Key switch:\t");
-			n += sprintf(buf+n, "%s\t", key_switch[state]);
-			have_strings = 1;
+			label_string = "Key switch:";
+			value_arrsize = sizeof(key_switch)/sizeof(char *);
+			value_arr = key_switch;
 			break;
 		case ENCLOSURE_SWITCH:
-			n += sprintf(buf+n, "Enclosure switch:\t");
-			n += sprintf(buf+n, "%s\t", enclosure_switch[state]);
-			have_strings = 1;
+			label_string = "Enclosure switch:";
+			value_arrsize = sizeof(enclosure_switch)/sizeof(char *);
+			value_arr = enclosure_switch;
 			break;
 		case THERMAL_SENSOR:
-			n += sprintf(buf+n, "Temp. (C/F):\t");
+			label_string = "Temp. (?C/?F):";
 			temperature = 1;
 			break;
 		case LID_STATUS:
-			n += sprintf(buf+n, "Lid status:\t");
-			n += sprintf(buf+n, "%s\t", lid_status[state]);
-			have_strings = 1;
+			label_string = "Lid status:";
+			value_arrsize = sizeof(lid_status)/sizeof(char *);
+			value_arr = lid_status;
 			break;
 		case POWER_SOURCE:
-			n += sprintf(buf+n, "Power source:\t");
-			n += sprintf(buf+n, "%s\t", power_source[state]);
-			have_strings = 1;
+			label_string = "Power source:";
+			value_arrsize = sizeof(power_source)/sizeof(char *);
+			value_arr = power_source;
 			break;
 		case BATTERY_VOLTAGE:
-			n += sprintf(buf+n, "Battery voltage:\t");
+			label_string = "Battery voltage:";
 			break;
 		case BATTERY_REMAINING:
-			n += sprintf(buf+n, "Battery remaining:\t");
-			n += sprintf(buf+n, "%s\t", battery_remaining[state]);
-			have_strings = 1;
+			label_string = "Battery remaining:";
+			value_arrsize = sizeof(battery_remaining)/sizeof(char *);
+			value_arr = battery_remaining;
 			break;
 		case BATTERY_PERCENTAGE:
-			n += sprintf(buf+n, "Battery percentage:\t");
+			label_string = "Battery percentage:";
 			break;
 		case EPOW_SENSOR:
-			n += sprintf(buf+n, "EPOW Sensor:\t");
-			n += sprintf(buf+n, "%s\t", epow_sensor[state]);
-			have_strings = 1;
+			label_string = "EPOW Sensor:";
+			value_arrsize = sizeof(epow_sensor)/sizeof(char *);
+			value_arr = epow_sensor;
 			break;
 		case BATTERY_CYCLESTATE:
-			n += sprintf(buf+n, "Battery cyclestate:\t");
-			n += sprintf(buf+n, "%s\t", battery_cyclestate[state]);
-			have_strings = 1;
+			label_string = "Battery cyclestate:";
+			value_arrsize = sizeof(battery_cyclestate)/sizeof(char *);
+			value_arr = battery_cyclestate;
 			break;
 		case BATTERY_CHARGING:
-			n += sprintf(buf+n, "Battery Charging:\t");
-			n += sprintf(buf+n, "%s\t", battery_charging[state]);
-			have_strings = 1;
+			label_string = "Battery Charging:";
+			value_arrsize = sizeof(battery_charging)/sizeof(char *);
+			value_arr = battery_charging;
 			break;
 		case IBM_SURVEILLANCE:
-			n += sprintf(buf+n, "Surveillance:\t");
+			label_string = "Surveillance:";
 			break;
 		case IBM_FANRPM:
-			n += sprintf(buf+n, "Fan (rpm):\t");
+			label_string = "Fan (rpm):";
 			break;
 		case IBM_VOLTAGE:
-			n += sprintf(buf+n, "Voltage (mv):\t");
+			label_string = "Voltage (mv):";
 			break;
 		case IBM_DRCONNECTOR:
-			n += sprintf(buf+n, "DR connector:\t");
-			n += sprintf(buf+n, "%s\t", ibm_drconnector[state]);
-			have_strings = 1;
+			label_string = "DR connector:";
+			value_arrsize = sizeof(ibm_drconnector)/sizeof(char *);
+			value_arr = ibm_drconnector;
 			break;
 		case IBM_POWERSUPPLY:
-			n += sprintf(buf+n, "Powersupply:\t");
+			label_string = "Powersupply:";
 			break;
 		case IBM_INTQUEUE:
-			n += sprintf(buf+n, "Interrupt queue:\t");
-			n += sprintf(buf+n, "%s\t", ibm_intqueue[state]);
-			have_strings = 1;
+			label_string = "Interrupt queue:";
+			value_arrsize = sizeof(ibm_intqueue)/sizeof(char *);
+			value_arr = ibm_intqueue;
 			break;
 		default:
 			n += sprintf(buf+n,  "Unkown sensor (type %d), ignoring it\n",
 					s.token);
 			unknown = 1;
-			have_strings = 1;
 			break;
 	}
-	if (have_strings == 0) {
+
+	if (label_string)
+		n += sprintf(buf+n, "%-17s\t", label_string);
+
+	if (value_arr && state >= 0 && state < value_arrsize) {
+		n += sprintf(buf+n, "%-15s\t", value_arr[state]);
+	} else {
 		if (temperature) {
-			n += sprintf(buf+n, "%4d /%4d\t", state, cel_to_fahr(state));
+			n += sprintf(buf+n, "%2d / %2d  \t", state, 
+				     cel_to_fahr(state));
 		} else
-			n += sprintf(buf+n, "%10d\t", state);
+			n += sprintf(buf+n, "%-10d\t", state);
 	}
 	if (unknown == 0) {
-		n += sprintf ( buf+n, "%s\t", ppc_rtas_process_error(error));
+		n += sprintf ( buf+n, "%-15s\t", ppc_rtas_process_error(error));
 		n += get_location_code(s, buf+n);
 	}
 	return n;
@@ -698,9 +745,9 @@ int get_location_code(struct individual_
 	ret = (char *) get_property(rtas_node, rstr, &llen);
 
 	n=0;
-	if (ret[0] == '\0')
+	if (ret == NULL || ret[0] == '\0') {
 		n += sprintf ( buffer+n, "--- ");/* does not have a location */
-	else {
+	} else {
 		char t[50];
 		ret += pos;
 
@@ -794,3 +841,137 @@ static ssize_t ppc_rtas_tone_volume_read
 	*ppos += n;
 	return n;
 }
+
+/* ****************************************************************** */
+/* ERRINJCT			                                      */
+/* ****************************************************************** */
+static int ppc_rtas_errinjct_open(struct inode *inode, struct file *file)
+{
+	int rc;
+
+	/* We will only allow one process to use error inject at a
+	   time.  Since errinjct is usually only used for testing,
+	   this shouldn't be an issue */
+	if (open_token) {
+		return -EAGAIN;
+	}
+	rc = rtas_errinjct_open();
+	if (rc < 0) {
+		return -EIO;
+	}
+	open_token = rc;
+
+	return 0;
+}
+
+static ssize_t ppc_rtas_errinjct_write(struct file * file, const char * buf,
+				       size_t count, loff_t *ppos)
+{
+ 
+	char * ei_token;
+	char * workspace = NULL;
+	size_t max_len;
+	int token_len;
+	int rc;
+
+	/* Verify the errinjct token length */
+	if (count < ERRINJCT_TOKEN_LEN) {
+		max_len = count;
+	} else {
+		max_len = ERRINJCT_TOKEN_LEN;
+	}
+
+	token_len = strnlen(buf, max_len);
+	token_len++; /* Add one for the null termination */
+    
+	ei_token = (char *)kmalloc(token_len, GFP_KERNEL);
+	if (!ei_token) {
+		printk(KERN_WARNING "error: kmalloc failed\n");
+		return -ENOMEM;
+	}
+
+	strncpy(ei_token, buf, token_len);
+    
+	if (count > token_len + WORKSPACE_SIZE) {
+		count = token_len + WORKSPACE_SIZE;
+	}
+    
+	buf += token_len;
+
+	/* check if there is a workspace */
+	if (count > token_len) {
+		/* Verify the workspace size */
+		if ((count - token_len) > WORKSPACE_SIZE) {
+			max_len = WORKSPACE_SIZE;
+		} else {
+			max_len = count - token_len;
+		}
+
+		workspace = (char *)kmalloc(max_len, GFP_KERNEL);
+		if (!workspace) {
+			printk(KERN_WARNING "error: failed kmalloc\n");
+			kfree(ei_token);
+			return -ENOMEM;
+		}
+	
+		memcpy(workspace, buf, max_len);
+	}
+
+	rc = rtas_errinjct(open_token, ei_token, workspace);
+
+	if (count > token_len) {
+		kfree(workspace);
+	}
+	kfree(ei_token);
+
+	return rc < 0 ? rc : count;
+}
+
+static int ppc_rtas_errinjct_release(struct inode *inode, struct file *file)
+{
+	int rc;
+    
+	rc = rtas_errinjct_close(open_token);
+	if (rc) {
+		return rc;
+	}
+	open_token = 0;
+	return 0;
+}
+
+static ssize_t ppc_rtas_errinjct_read(struct file *file, char *buf,
+				      size_t count, loff_t *ppos) 
+{
+	char * buffer;
+	int i;
+	int n = 0;
+
+	buffer = (char *)kmalloc(MAX_ERRINJCT_TOKENS * (ERRINJCT_TOKEN_LEN+1),
+				 GFP_KERNEL);
+	if (!buffer) {
+		printk(KERN_ERR "error: kmalloc failed\n");
+		return -ENOMEM;
+	}
+
+	for (i = 0; i < MAX_ERRINJCT_TOKENS && ei_token_list[i].value; i++) {
+		n += sprintf(buffer+n, ei_token_list[i].name);
+		n += sprintf(buffer+n, "\n");
+	}
+
+	if (*ppos >= strlen(buffer)) {
+		kfree(buffer);
+		return 0;
+	}
+	if (n > strlen(buffer) - *ppos)
+		n = strlen(buffer) - *ppos;
+
+	if (n > count)
+		n = count;
+
+	memcpy(buf, buffer + *ppos, n);
+
+	*ppos += n;
+
+	kfree(buffer);
+	return n;
+}
diff -urNp linux-463/arch/ppc64/kernel/rtas.c linux-340/arch/ppc64/kernel/rtas.c
--- linux-463/arch/ppc64/kernel/rtas.c
+++ linux-340/arch/ppc64/kernel/rtas.c
@@ -16,6 +16,7 @@
 #include <linux/types.h>
 #include <linux/spinlock.h>
 #include <linux/fs.h>
+#include <linux/slab.h>
 
 #include <asm/init.h>
 #include <asm/prom.h>
@@ -27,9 +28,11 @@
 #include <asm/system.h>
 #include <asm/abs_addr.h>
 #include <asm/udbg.h>
+#include <asm/uaccess.h>
 
 struct proc_dir_entry *rtas_proc_dir;	/* /proc/ppc64/rtas dir */
 struct flash_block_list_header rtas_firmware_flash_list = {0, 0};
+struct errinjct_token ei_token_list[MAX_ERRINJCT_TOKENS];
 
 /*
  * prom_init() is called very early on, before the kernel text
@@ -59,7 +62,7 @@ struct rtas_t rtas = { 
 extern unsigned long reloc_offset(void);
 
 spinlock_t rtas_data_buf_lock = SPIN_LOCK_UNLOCKED;
-char rtas_data_buf[RTAS_DATA_BUF_SIZE];
+char rtas_data_buf[RTAS_DATA_BUF_SIZE]__page_aligned;
 
 void
 phys_call_rtas(int token, int nargs, int nret, ...)
@@ -219,7 +222,10 @@ rtas_flash_firmware(void)
 			image_size += f->blocks[i].length;
 		}
 		next = f->next;
-		f->next = (struct flash_block_list *)virt_to_absolute((unsigned long)f->next);
+		/* Don't translate final NULL pointer */
+		if (next)
+			f->next = (struct flash_block_list *)virt_to_absolute((unsigned long)next);
+
 		/* make num_blocks into the version/length field */
 		f->num_blocks = (FLASH_BLOCK_LIST_VERSION << 56) | ((f->num_blocks+1)*16);
 	}
@@ -285,3 +291,108 @@ rtas_halt(void)
 		rtas_flash_bypass_warning();
         rtas_power_off();
 }
+
+int
+rtas_errinjct_open(void)
+{
+	u32 ret[2];
+	int open_token;
+	int rc;
+
+	/* The rc and open_token values are backwards due to a misprint in
+	 * the RPA */ 
+	open_token = rtas_call(rtas_token("ibm,open-errinjct"), 0, 2, (void *) &ret);
+	rc = ret[0];
+
+	if (rc < 0) {
+		printk(KERN_WARNING "error: ibm,open-errinjct failed (%d)\n", rc);
+		return rc;
+	}
+
+	return open_token;
+}
+
+int
+rtas_errinjct(unsigned int open_token, char * ei_token, char * in_workspace)
+{
+	struct errinjct_token * ei;
+	int rtas_ei_token = -1;
+	int rc;
+	int i;
+
+	ei = ei_token_list;
+	for (i = 0; i < MAX_ERRINJCT_TOKENS && ei->name; i++) {
+		if (strcmp(ei_token, ei->name) == 0) {
+			rtas_ei_token = ei->value;
+			break;
+		}
+		ei++;
+	}
+	if (rtas_ei_token == -1) {
+		return -EINVAL;
+	}
+
+	spin_lock(&rtas_data_buf_lock);
+
+	if (in_workspace) 
+		memcpy(rtas_data_buf, in_workspace, RTAS_DATA_BUF_SIZE);
+
+	rc = rtas_call(rtas_token("ibm,errinjct"), 3, 1, NULL, rtas_ei_token,
+		       open_token, __pa(rtas_data_buf));   
+
+	spin_unlock(&rtas_data_buf_lock);
+
+	return rc;
+}
+
+int
+rtas_errinjct_close(unsigned int open_token)
+{
+	int rc;
+
+	rc = rtas_call(rtas_token("ibm,close-errinjct"), 1, 1, NULL, open_token);
+	if (rc != 0) {
+		printk(KERN_WARNING "error: ibm,close-errinjct failed (%d)\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_PPC_PSERIES
+static int __init rtas_errinjct_init(void)
+{
+	char * token_array;
+	char * end_array;
+	int array_len = 0;
+	int len;
+	int i, j;
+
+	token_array = (char *) get_property(rtas.dev, "ibm,errinjct-tokens",
+					    &array_len);    
+	/* if token is not found, then we fall through loop */
+	end_array = token_array + array_len;
+	for (i = 0, j = 0; i < MAX_ERRINJCT_TOKENS && token_array < end_array; i++) {
+
+		len = strnlen(token_array, ERRINJCT_TOKEN_LEN) + 1;
+		ei_token_list[i].name = (char *) kmalloc(len, GFP_KERNEL);
+		if (!ei_token_list[i].name) {
+			printk(KERN_WARNING "error: kmalloc failed\n");
+			return -ENOMEM;
+		}
+
+		strcpy(ei_token_list[i].name, token_array);
+		token_array += len;
+
+		ei_token_list[i].value = *(int *)token_array;
+		token_array += sizeof(int);
+	}
+	for (; i < MAX_ERRINJCT_TOKENS; i++) {
+		ei_token_list[i].name = 0;
+		ei_token_list[i].value = 0;
+	}
+	return 0;
+}
+
+__initcall(rtas_errinjct_init);
+#endif
diff -urNp linux-463/arch/ppc64/kernel/rtasd.c linux-340/arch/ppc64/kernel/rtasd.c
--- linux-463/arch/ppc64/kernel/rtasd.c
+++ linux-340/arch/ppc64/kernel/rtasd.c
@@ -49,6 +49,9 @@ static unsigned int rtas_error_log_max;
 #define SURVEILLANCE_TIMEOUT	1
 #define SURVEILLANCE_SCANRATE	1
 
+extern struct proc_dir_entry *proc_ppc64_root;
+extern struct proc_dir_entry *rtas_proc_dir;
+extern spinlock_t proc_ppc64_lock;
 /*
  * Since we use 32 bit RTAS, the physical address of this must be below
  * 4G or else bad things happen. Allocate this in the kernel data and
@@ -780,7 +783,6 @@ static int rtasd(void *unused)
 
 	/* Rusty unreal time task */
 	current->policy = SCHED_FIFO;
-	current->nice = sys_sched_get_priority_max(SCHED_FIFO) + 1;
 
 	cpu = 0;
 	current->cpus_allowed = 1UL << cpu_logical_map(cpu);
@@ -821,12 +823,8 @@ static int rtasd(void *unused)
 		current->cpus_allowed = 1UL << cpu_logical_map(cpu);
 
 		/* Check all cpus for pending events before sleeping*/
-		if (first_pass) {
-			schedule();
-		} else {
-			set_current_state(TASK_INTERRUPTIBLE);
-			schedule_timeout((HZ*60/rtas_event_scan_rate) / 2);
-		}
+                set_current_state(TASK_INTERRUPTIBLE);
+                schedule_timeout(first_pass ? HZ : (HZ*60/rtas_event_scan_rate) / 2);
 	}
 
 error_vfree:
@@ -836,25 +834,45 @@ error:
 	return -EINVAL;
 }
 
-static void __init rtas_init(void)
+static int __init rtas_init(void)
 {
-	struct proc_dir_entry *rtas_dir, *entry;
+	int ret = 0;
+	struct proc_dir_entry *entry;
 
-	rtas_dir = proc_mkdir("rtas", 0);
-	if (!rtas_dir) {
-		printk(KERN_ERR "Failed to create rtas proc directory\n");
+	spin_lock(&proc_ppc64_lock);
+	if (proc_ppc64_root == NULL) {
+		proc_ppc64_root = proc_mkdir("ppc64", 0);
+		if (!proc_ppc64_root) {
+			spin_unlock(&proc_ppc64_lock);
+			return -EINVAL;
+		}		
+	}
+	spin_unlock(&proc_ppc64_lock);
+	
+	if (rtas_proc_dir == NULL) {
+		rtas_proc_dir = proc_mkdir("rtas", proc_ppc64_root);
+	}
+
+	if (rtas_proc_dir == NULL) {
+		printk(KERN_ERR "Failed to create /proc/ppc64/rtas in rtas_init\n");
+		ret = -EINVAL;
 	} else {
-		entry = create_proc_entry("error_log", S_IRUSR, rtas_dir);
+		entry = create_proc_entry("error_log", S_IRUSR, rtas_proc_dir);
 		if (entry)
 			entry->proc_fops = &proc_rtas_log_operations;
-		else
+		else {
 			printk(KERN_ERR "Failed to create rtas/error_log proc entry\n");
+			ret = -EINVAL;
+		}
 	}
 
-	if (kernel_thread(rtasd, 0, CLONE_FS) < 0)
+	if (kernel_thread(rtasd, 0, CLONE_FS) < 0) {
 		printk(KERN_ERR "Failed to start RTAS daemon\n");
+		ret = -EINVAL;
+	}
 
 	printk(KERN_ERR "RTAS daemon started\n");
+	return ret;
 }
 
 static int __init surveillance_setup(char *str)
diff -urNp linux-463/arch/ppc64/kernel/scanlog.c linux-340/arch/ppc64/kernel/scanlog.c
--- linux-463/arch/ppc64/kernel/scanlog.c
+++ linux-340/arch/ppc64/kernel/scanlog.c
@@ -129,21 +129,32 @@ static ssize_t scanlog_read(struct file 
 static ssize_t scanlog_write(struct file * file, const char * buf,
 			     size_t count, loff_t *ppos)
 {
+	char cmdbuf[10];
 	unsigned long status;
 
-	if (buf) {
-		if (strncmp(buf, "reset", 5) == 0) {
-			DEBUG("reset scanlog\n");
-			status = rtas_call(ibm_scan_log_dump, 2, 1, NULL, NULL, 0);
-			DEBUG("rtas returns %ld\n", status);
-		} else if (strncmp(buf, "debugon", 7) == 0) {
-			printk(KERN_ERR "scanlog: debug on\n");
-			scanlog_debug = 1;
-		} else if (strncmp(buf, "debugoff", 8) == 0) {
-			printk(KERN_ERR "scanlog: debug off\n");
-			scanlog_debug = 0;
+	if (count > 9) count = 9;
+	if (copy_from_user (cmdbuf, buf, count)) 
+		return -EFAULT;
+	cmdbuf[count] = '\0';
+
+	if (strncmp(cmdbuf, "reset", 5) == 0) {
+		printk(KERN_INFO "scanlog: reset\n");
+		status = rtas_call(ibm_scan_log_dump, 2, 1, NULL, NULL, 0);
+		if (status) {
+			printk(KERN_INFO "scanlog: reset failed with code %ld\n", 
+				status);
+			return -EIO;
 		}
+	} else if (strncmp(cmdbuf, "debugon", 7) == 0) {
+		printk(KERN_INFO "scanlog: debug on\n");
+		scanlog_debug = 1;
+	} else if (strncmp(cmdbuf, "debugoff", 8) == 0) {
+		printk(KERN_INFO "scanlog: debug off\n");
+		scanlog_debug = 0;
 	}
+	else 
+		return -EINVAL;
+
 	return count;
 }
 
diff -urNp linux-463/arch/ppc64/kernel/semaphore.c linux-340/arch/ppc64/kernel/semaphore.c
--- linux-463/arch/ppc64/kernel/semaphore.c
+++ linux-340/arch/ppc64/kernel/semaphore.c
@@ -75,9 +75,8 @@ void __down(struct semaphore *sem)
 	struct task_struct *tsk = current;
 	DECLARE_WAITQUEUE(wait, tsk);
 
-	tsk->state = TASK_UNINTERRUPTIBLE;
+	__set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 	add_wait_queue_exclusive(&sem->wait, &wait);
-	smp_wmb();
 
 	/*
 	 * Try to get the semaphore.  If the count is > 0, then we've
@@ -87,10 +86,10 @@ void __down(struct semaphore *sem)
 	 */
 	while (__sem_update_count(sem, -1) <= 0) {
 		schedule();
-		tsk->state = TASK_UNINTERRUPTIBLE;
+		set_task_state(tsk, TASK_UNINTERRUPTIBLE);
 	}
 	remove_wait_queue(&sem->wait, &wait);
-	tsk->state = TASK_RUNNING;
+	__set_task_state(tsk, TASK_RUNNING);
 
 	/*
 	 * If there are any more sleepers, wake one of them up so
@@ -106,9 +105,8 @@ int __down_interruptible(struct semaphor
 	struct task_struct *tsk = current;
 	DECLARE_WAITQUEUE(wait, tsk);
 
-	tsk->state = TASK_INTERRUPTIBLE;
+	__set_task_state(tsk, TASK_INTERRUPTIBLE);
 	add_wait_queue_exclusive(&sem->wait, &wait);
-	smp_wmb();
 
 	while (__sem_update_count(sem, -1) <= 0) {
 		if (signal_pending(current)) {
@@ -122,10 +120,11 @@ int __down_interruptible(struct semaphor
 			break;
 		}
 		schedule();
-		tsk->state = TASK_INTERRUPTIBLE;
+		set_task_state(tsk, TASK_INTERRUPTIBLE);
 	}
-	tsk->state = TASK_RUNNING;
 	remove_wait_queue(&sem->wait, &wait);
+	__set_task_state(tsk, TASK_RUNNING);
+
 	wake_up(&sem->wait);
 	return retval;
 }
diff -urNp linux-463/arch/ppc64/kernel/setup.c linux-340/arch/ppc64/kernel/setup.c
--- linux-463/arch/ppc64/kernel/setup.c
+++ linux-340/arch/ppc64/kernel/setup.c
@@ -85,10 +85,6 @@ void parse_cmd_line(unsigned long r3, un
 		    unsigned long r6, unsigned long r7);
 int parse_bootinfo(void);
 
-#ifdef CONFIG_MAGIC_SYSRQ
-unsigned long SYSRQ_KEY;
-#endif /* CONFIG_MAGIC_SYSRQ */
-
 struct machdep_calls ppc_md;
 
 /*
@@ -107,7 +103,7 @@ struct console udbg_console = {
 };
 
 /*
- * Do some initial setup of the system.  The paramters are those which 
+ * Do some initial setup of the system.  The parameters are those which 
  * were passed in from the bootloader.
  */
 void setup_system(unsigned long r3, unsigned long r4, unsigned long r5,
@@ -333,6 +329,7 @@ void parse_cmd_line(unsigned long r3, un
 		initrd_end = initrd_start + r4;
 		ROOT_DEV = MKDEV(RAMDISK_MAJOR, 0);
 		initrd_below_start_ok = 1;
+		lmb_reserve(__pa(initrd_start),r4);
 	}
 #endif
 
@@ -605,18 +602,31 @@ void exception_trace(unsigned long trap)
 	udbg_puts("   "); udbg_puthex(srr1); udbg_puts("\n");
 }
 
-int set_spread_lpevents( char * str )
+void do_spread_lpevents(unsigned long n)
 {
-	/* The parameter is the number of processors to share in processing lp events */
 	unsigned long i;
+
+	for (i=1; i < n; i++)
+		paca[i].lpQueuePtr = paca[0].lpQueuePtr;
+	for (i=n; i < MAX_PACAS; i++)
+		paca[i].lpQueuePtr = NULL;
+}
+
+/* 
+ * The parameter is the number of processors to share in 
+ * processing lp events 
+ */
+int set_spread_lpevents(char * str)
+{
 	unsigned long val = simple_strtoul( str, NULL, 0 );
-	if ( ( val > 0 ) && ( val <= MAX_PACAS ) ) {
-		for ( i=1; i<val; ++i )
-			paca[i].lpQueuePtr = paca[0].lpQueuePtr;
-		printk("lpevent processing spread over %ld processors\n", val);
-	}
-	else
-		printk("invalid spreaqd_lpevents %ld\n", val);
+
+	if ((val > 0) && (val <= MAX_PACAS)) {
+		do_spread_lpevents(val);
+		printk("lpevent processing spread over %ld processor(s)\n", 
+			val);
+	} else
+		printk("invalid spread_lpevents %ld\n", val);
+
 	return 1;
 }	
 
diff -urNp linux-463/arch/ppc64/kernel/signal.c linux-340/arch/ppc64/kernel/signal.c
--- linux-463/arch/ppc64/kernel/signal.c
+++ linux-340/arch/ppc64/kernel/signal.c
@@ -101,6 +101,7 @@ copy_siginfo_to_user(siginfo_t *to, sigi
 		err |= __put_user(from->si_pid, &to->si_pid);
 		switch (from->si_code >> 16) {
 		case __SI_FAULT >> 16:
+			err |= __put_user(from->si_addr, &to->si_addr);
 			break;
 		case __SI_CHLD >> 16:
 			err |= __put_user(from->si_utime, &to->si_utime);
@@ -295,7 +296,7 @@ get_sigframe(struct k_sigaction *ka, str
 			newsp = (current->sas_ss_sp + current->sas_ss_size);
 	}
 
-        return (void *)((newsp - frame_size) & -8ul);
+        return (void *)((newsp - frame_size) & -16ul);
 }
 
 static int
diff -urNp linux-463/arch/ppc64/kernel/smp.c linux-340/arch/ppc64/kernel/smp.c
--- linux-463/arch/ppc64/kernel/smp.c
+++ linux-340/arch/ppc64/kernel/smp.c
@@ -69,6 +69,7 @@ extern atomic_t ipi_recv;
 extern atomic_t ipi_sent;
 spinlock_t kernel_flag __cacheline_aligned = SPIN_LOCK_UNLOCKED;
 cycles_t cacheflush_time;
+unsigned long cache_decay_ticks = HZ/100;
 static int max_cpus __initdata = NR_CPUS;
 
 unsigned long cpu_online_map;
@@ -611,9 +612,7 @@ void __init smp_boot_cpus(void)
 	 * cpu 0, the master -- Cort
 	 */
 	cpu_callin_map[0] = 1;
-	current->processor = 0;
-
-	init_idle();
+	current->cpu = 0;
 
 	for (i = 0; i < NR_CPUS; i++) {
 		paca[i].prof_counter = 1;
@@ -684,12 +683,11 @@ void __init smp_boot_cpus(void)
 
 		PPCDBG(PPCDBG_SMP,"\tProcessor %d, task = 0x%lx\n", i, p);
 
-		del_from_runqueue(p);
+		init_idle(p, i);
+
 		unhash_process(p);
-		init_tasks[i] = p;
 
-		p->processor = i;
-		p->cpus_runnable = 1 << i; /* we schedule the first task manually */
+		p->cpu = i;
 		current_set[i].task = p;
 		sp = ((unsigned long)p) + sizeof(union task_union)
 			- STACK_FRAME_OVERHEAD;
@@ -726,6 +724,26 @@ void __init smp_boot_cpus(void)
 	        tb_last_stamp = get_tb();
 		smp_tb_synchronized = 1;
 	}
+
+#if CONFIG_SHARE_RUNQUEUE
+#if CONFIG_PPC_ISERIES
+	/* 
+	* Set up the scheduler for HMT on iSeries.  We can always assume that
+	* even and odd processors (and pacas) are paired threads, if threading
+	* is enabled on the platform.
+	* Except for that special case where we've given a maxcpus=X directive
+	* to the kernel.  i.e. maxcpus=1 on install.  So be sure to check for (i+1<cpu_nr).
+	*/
+	for (i = 0; (i < cpu_nr) && (i+1 < cpu_nr); i+=2) {
+		struct ItLpPaca * lpPaca;
+		lpPaca = paca[i].xLpPacaPtr;
+		if(lpPaca->xSecondaryThreadCnt) {
+			/* Merge runqueues, resulting in one runqueue per chip */
+			sched_map_runqueue(i, i+1);
+		}
+	}
+#endif /* CONFIG_PPC_ISERIES */
+#endif /* CONFIG_SHARED_RUNQUEUE */
 }
 
 void __init smp_commence(void)
@@ -740,7 +758,7 @@ void __init smp_commence(void)
 
 void __init smp_callin(void)
 {
-	int cpu = current->processor;
+	int cpu = current->cpu;
 	
         smp_store_cpu_info(cpu);
 	set_dec(paca[cpu].default_decr);
@@ -748,8 +766,6 @@ void __init smp_callin(void)
 
 	ppc_md.smp_setup_cpu(cpu);
 
-	init_idle();
-
 	set_bit(smp_processor_id(), &cpu_online_map);
 	
 	while(!smp_commenced) {
@@ -768,7 +784,7 @@ int start_secondary(void *unused)
 {
 	int cpu; 
 
-	cpu = current->processor;
+	cpu = current->cpu;
 	atomic_inc(&init_mm.mm_count);
 	current->active_mm = &init_mm;
 	smp_callin();
diff -urNp linux-463/arch/ppc64/kernel/stab.c linux-340/arch/ppc64/kernel/stab.c
--- linux-463/arch/ppc64/kernel/stab.c
+++ linux-340/arch/ppc64/kernel/stab.c
@@ -17,6 +17,9 @@
 #include <asm/paca.h>
 #include <asm/naca.h>
 #include <asm/pmc.h>
+#include <asm/cputable.h>
+
+extern int boot_cpuid;
 
 inline int make_ste(unsigned long stab, 
 		    unsigned long esid, unsigned long vsid);
@@ -35,10 +38,7 @@ void stab_initialize(unsigned long stab)
 	esid = GET_ESID(KERNELBASE);
 	vsid = get_kernel_vsid(esid << SID_SHIFT); 
 
-	if (!__is_processor(PV_POWER4) && !__is_processor(PV_POWER4p)) {
-                __asm__ __volatile__("isync; slbia; isync":::"memory");
-		make_ste(stab, esid, vsid);
-	} else {
+	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB) {
                 /* Invalidate the entire SLB & all the ERATS */
                 __asm__ __volatile__("isync" : : : "memory");
 #ifndef CONFIG_PPC_ISERIES
@@ -49,7 +49,10 @@ void stab_initialize(unsigned long stab)
 #else
                 __asm__ __volatile__("isync; slbia; isync":::"memory");
 #endif
-        }
+	} else {
+                __asm__ __volatile__("isync; slbia; isync":::"memory");
+		make_ste(stab, esid, vsid);
+	}
 }
 
 /*
@@ -61,6 +64,15 @@ make_ste(unsigned long stab, unsigned lo
 	unsigned long entry, group, old_esid, castout_entry, i;
 	unsigned int global_entry;
 	STE *ste, *castout_ste;
+	unsigned char kp = 1;
+	
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+	if(((esid >> SMALLOC_ESID_SHIFT) == 
+	    (SMALLOC_START >> SMALLOC_EA_SHIFT)) && 
+	   (current->thread.flags & PPC_FLAG_SHARED)) {
+		kp = 0;
+	}
+#endif
 
 	/* Search the primary group first. */
 	global_entry = (esid & 0x1f) << 3;
@@ -77,7 +89,7 @@ make_ste(unsigned long stab, unsigned lo
 				__asm__ __volatile__ ("eieio" : : : "memory");
 				ste->dw0.dw0.esid = esid;
 				ste->dw0.dw0.v  = 1;
-				ste->dw0.dw0.kp = 1;
+				ste->dw0.dw0.kp = kp;
 				/* Order update     */
 				__asm__ __volatile__ ("sync" : : : "memory"); 
 
@@ -135,7 +147,7 @@ make_ste(unsigned long stab, unsigned lo
 	old_esid = castout_ste->dw0.dw0.esid;
 	castout_ste->dw0.dw0.esid = esid;
 	castout_ste->dw0.dw0.v  = 1;
-	castout_ste->dw0.dw0.kp = 1;
+	castout_ste->dw0.dw0.kp = kp;
 	__asm__ __volatile__ ("slbie  %0" : : "r" (old_esid << SID_SHIFT)); 
 	/* Ensure completion of slbie */
 	__asm__ __volatile__ ("sync" : : : "memory" );  
@@ -149,7 +161,6 @@ make_ste(unsigned long stab, unsigned lo
 inline void make_slbe(unsigned long esid, unsigned long vsid, int large)
 {
 	unsigned long entry, castout_entry;
-	slb_dword0 castout_esid_data;
 	union {
 		unsigned long word0;
 		slb_dword0    data;
@@ -158,6 +169,15 @@ inline void make_slbe(unsigned long esid
 		unsigned long word0;
 		slb_dword1    data;
 	} vsid_data;
+	unsigned char kp = 1;
+ 	
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+	if(((esid >> SMALLOC_ESID_SHIFT) == 
+	    (SMALLOC_START >> SMALLOC_EA_SHIFT)) && 
+	   (current->thread.flags & PPC_FLAG_SHARED)) {
+		kp = 0;
+	}
+#endif
 	
 	/*
 	 * Find an empty entry, if one exists.
@@ -171,7 +191,7 @@ inline void make_slbe(unsigned long esid
 			 */
 			vsid_data.word0 = 0;
 			vsid_data.data.vsid = vsid;
-			vsid_data.data.kp = 1;
+			vsid_data.data.kp = kp;
 			if (large)
 				vsid_data.data.l = 1;
 
@@ -198,29 +218,45 @@ inline void make_slbe(unsigned long esid
 
 	PMC_SW_PROCESSOR(stab_capacity_castouts); 
 
+	/*
+	 * Never cast out the segment for our own stack. Since we
+	 * dont invalidate the ERAT we could have a valid translation
+	 * for our stack during the first part of exception exit
+	 * which gets invalidated due to a tlbie from another cpu at a
+	 * non recoverable point (after setting srr0/1) - Anton
+	 */
+
 	castout_entry = get_paca()->xStab_data.next_round_robin;
-	__asm__ __volatile__("slbmfee  %0,%1" 
-			     : "=r" (castout_esid_data) 
-			     : "r" (castout_entry)); 
-
-	entry = castout_entry; 
-	castout_entry++; 
-	if(castout_entry >= naca->slb_size) {
-		castout_entry = 1; 
-	}
+	do {
+		entry = castout_entry;
+		castout_entry++;
+		if (castout_entry >= naca->slb_size)
+			castout_entry = 1;
+		asm volatile("slbmfee  %0,%1" : "=r" (esid_data) : "r" (entry));
+	} while (esid_data.data.esid == GET_ESID((unsigned long)_get_SP()));
+	
 	get_paca()->xStab_data.next_round_robin = castout_entry;
 
-	/* Invalidate the old entry. */
-	castout_esid_data.v = 0; /* Set the class to 0 */
-	/* slbie not needed as the previous mapping is still valid. */
-	__asm__ __volatile__("slbie  %0" : : "r" (castout_esid_data)); 
-	
+	/* We're executing this code on the interrupt stack, so the
+	 * above code might pick the kernel stack segment as the victim.
+	 *
+	 * Because of this, we need to invalidate the old entry. We need
+	 * to do this since it'll otherwise be in the ERAT and might come
+	 * back and haunt us if it gets thrown out of there at the wrong
+	 * time (i.e. similar to throwing out our own stack above).
+	 */
+
+	esid_data.data.v = 0;
+	__asm__ __volatile__("slbie  %0" : : "r" (esid_data));
+	/* Second slbie for Power5 DD2.0 errata */
+	__asm__ __volatile__("slbie  %0" : : "r" (esid_data));
+
 	/* 
 	 * Write the new SLB entry.
 	 */
 	vsid_data.word0 = 0;
 	vsid_data.data.vsid = vsid;
-	vsid_data.data.kp = 1;
+	vsid_data.data.kp = kp;
 	if (large)
 		vsid_data.data.l = 1;
 	
@@ -264,6 +300,15 @@ int ste_allocate ( unsigned long ea, 
 		}
 	}
 
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+	/* Shared segments might be mapped into a user task space,
+	 * so we need to add them to the list of entries to flush
+	 */
+	if ((ea >> SMALLOC_EA_SHIFT) == (SMALLOC_START >> SMALLOC_EA_SHIFT)) {
+		kernel_segment = 0;
+	}
+#endif
+
 	esid = GET_ESID(ea);
 	if (trap == 0x380 || trap == 0x480) {
 #ifndef CONFIG_PPC_ISERIES
@@ -305,7 +350,15 @@ void flush_stab(void)
 	unsigned char *segments = get_paca()->xSegments;
 	unsigned long flags, i;
 
-	if (!__is_processor(PV_POWER4) && !__is_processor(PV_POWER4p)) {
+	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB) {
+		unsigned long flags;
+
+		PMC_SW_PROCESSOR(stab_invalidations); 
+
+		__save_and_cli(flags);
+		__asm__ __volatile__("isync; slbia; isync":::"memory");
+		__restore_flags(flags);
+	} else {
 		unsigned long entry;
 		STE *ste;
 
@@ -330,7 +383,8 @@ void flush_stab(void)
 			    entry++, ste++) {
 				unsigned long ea;
 				ea = ste->dw0.dw0.esid << SID_SHIFT;
-				if (STAB_PRESSURE || (!REGION_ID(ea))) {
+				if (STAB_PRESSURE || (!REGION_ID(ea)) ||
+				    (REGION_ID(ea) == VMALLOC_REGION_ID)) {
 					ste->dw0.dw0.v = 0;
 					PMC_SW_PROCESSOR(stab_invalidations); 
 				}
@@ -347,13 +401,5 @@ void flush_stab(void)
 		__asm__ __volatile__ ("slbia" : : : "memory"); 
 		/* Force flush to complete.  */
 		__asm__ __volatile__ ("sync" : : : "memory");  
-	} else {
-		unsigned long flags;
-
-		PMC_SW_PROCESSOR(stab_invalidations); 
-
-		__save_and_cli(flags);
-		__asm__ __volatile__("isync; slbia; isync":::"memory");
-		__restore_flags(flags);
 	}
 }
diff -urNp linux-463/arch/ppc64/kernel/sys_ppc32.c linux-340/arch/ppc64/kernel/sys_ppc32.c
--- linux-463/arch/ppc64/kernel/sys_ppc32.c
+++ linux-340/arch/ppc64/kernel/sys_ppc32.c
@@ -103,7 +103,33 @@ asmlinkage long sys32_utime(char * filen
 	return ret;
 }
 
+asmlinkage int sys32_ustat(__kernel_dev_t32 dev, struct ustat32 * ubuf)
+{
+
+	struct super_block *s;
+	struct ustat32 tmp;
+	struct statfs sbuf;
+	struct ustat *tmp_ubuf;
+	int err = -EINVAL;
+
+	s = get_super(to_kdev_t(dev));
+	if (s == NULL)
+		goto out;
+	err = vfs_statfs(s, &sbuf);
+	drop_super(s);
+	if (err)
+		goto out;
+
+	memset(&tmp,0,sizeof(struct ustat));
+	tmp.f_tfree = sbuf.f_bfree;
+	tmp.f_tinode = sbuf.f_ffree;
+
+	err = copy_to_user(ubuf, &tmp, sizeof(struct ustat32)) ? -EFAULT : 0;
 
+out:
+        return err;
+
+}
 
 struct iovec32 { u32 iov_base; __kernel_size_t32 iov_len; };
 
@@ -143,7 +169,11 @@ static long do_readv_writev32(int type, 
 
 		__get_user(len, &vector->iov_len);
 		__get_user(buf, &vector->iov_base);
-		tot_len += len;
+		if ((int)len < 0 || (tot_len += len) >= 0x7fffffff) {
+			if (iov != iovstack)
+				kfree(iov);
+			return -EINVAL;
+		}
 		ivp->iov_base = (void *)A(buf);
 		ivp->iov_len = (__kernel_size_t) len;
 		vector++;
@@ -479,7 +509,7 @@ asmlinkage long sys32_quotactl(u32 cmd_p
   int id  = (int)id_parm;
 	int cmds = cmd >> SUBCMDSHIFT;
 	int err;
-	struct dqblk d;
+	struct mem_dqblk d;
 	mm_segment_t old_fs;
 	char *spec;
 	
@@ -490,14 +520,6 @@ asmlinkage long sys32_quotactl(u32 cmd_p
 	case Q_GETQUOTA:
 		break;
 	case Q_SETQUOTA:
-	case Q_SETUSE:
-	case Q_SETQLIM:
-		if (copy_from_user (&d, (struct dqblk32 *)addr,
-				    sizeof (struct dqblk32)))
-			return -EFAULT;
-		d.dqb_itime = ((struct dqblk32 *)&d)->dqb_itime;
-		d.dqb_btime = ((struct dqblk32 *)&d)->dqb_btime;
-		break;
 	default:
 		return sys_quotactl(cmd, special,
 				    id, (caddr_t)addr);
@@ -2045,7 +2067,7 @@ asmlinkage long sys32_pause(void)
 	
 	PPCDBG(PPCDBG_SYS32, "sys32_pause - running - pid=%ld, comm=%s \n", current->pid, current->comm);
 
-	current->state = TASK_INTERRUPTIBLE;
+	set_current_state(TASK_INTERRUPTIBLE);
 	schedule();
 	
 	return -ERESTARTNOHAND;
@@ -3168,7 +3190,6 @@ asmlinkage long sys32_setsockopt(int fd,
 			__u32 filter;
 		} *fprog32 = (struct sock_fprog32 *)optval;
 		struct sock_fprog kfprog;
-		struct sock_filter *kfilter;
 		unsigned int fsize;
 		mm_segment_t old_fs;
 		__u32 uptr;
@@ -3178,21 +3199,13 @@ asmlinkage long sys32_setsockopt(int fd,
 		    __get_user(uptr, &fprog32->filter))
 			return -EFAULT;
 		kfprog.filter = (struct sock_filter *)A(uptr);
-		fsize = kfprog.len * sizeof(struct sock_filter);
-		kfilter = (struct sock_filter *)kmalloc(fsize, GFP_KERNEL);
-		if (kfilter == NULL)
-			return -ENOMEM;
-		if (copy_from_user(kfilter, kfprog.filter, fsize)) {
-			kfree(kfilter);
+		if (verify_area(VERIFY_WRITE, kfprog.filter, kfprog.len*sizeof(struct sock_filter)))
 			return -EFAULT;
-		}
-		kfprog.filter = kfilter;
 		old_fs = get_fs();
 		set_fs(KERNEL_DS);
 		ret = sys_setsockopt(fd, level, optname,
 				     (char *)&kfprog, sizeof(kfprog));
 		set_fs(old_fs);
-		kfree(kfilter);
 		return ret;
 	}
 	return sys_setsockopt(fd, level, optname, optval, optlen);
@@ -3352,6 +3365,8 @@ static int verify_iovec32(struct msghdr 
 		kern_msg->msg_name = NULL;
 
 	if(kern_msg->msg_iovlen > UIO_FASTIOV) {
+		if (kern_msg->msg_iovlen > (2*PAGE_SIZE)/ sizeof(struct iovec))
+			return -EINVAL;
 		kern_iov = kmalloc(kern_msg->msg_iovlen * sizeof(struct iovec),
 				   GFP_KERNEL);
 		if(!kern_iov)
@@ -3395,6 +3410,8 @@ static int cmsghdr_from_user32_to_kern(s
 		if((unsigned long)(((char *)ucmsg - (char *)kmsg->msg_control)
 				   + ucmlen) > kmsg->msg_controllen)
 			return -EINVAL;
+		if (kmsg->msg_controllen > 65536)
+			return -EINVAL;
 
 		tmp = ((ucmlen - CMSG32_ALIGN(sizeof(*ucmsg))) +
 		       CMSG_ALIGN(sizeof(struct cmsghdr)));
@@ -3462,7 +3479,7 @@ asmlinkage long sys32_sendmsg(int fd, st
 	if(msghdr_from_user32_to_kern(&kern_msg, user_msg))
 		return -EFAULT;
 	if(kern_msg.msg_iovlen > UIO_MAXIOV)
-		return -EINVAL;
+		return -EMSGSIZE;
 	err = verify_iovec32(&kern_msg, iov, address, VERIFY_READ);
 	if (err < 0)
 		goto out;
@@ -3700,7 +3717,7 @@ asmlinkage long sys32_recvmsg(int fd, st
 	if(msghdr_from_user32_to_kern(&kern_msg, user_msg))
 		return -EFAULT;
 	if(kern_msg.msg_iovlen > UIO_MAXIOV)
-		return -EINVAL;
+		return -EMSGSIZE;
 
 	uaddr = kern_msg.msg_name;
 	uaddr_len = &user_msg->msg_namelen;
@@ -3890,7 +3907,7 @@ static int do_execve32(char * filename, 
 	if ((bprm.envc = count32(envp, bprm.p / sizeof(u32))) < 0) {
 		allow_write_access(file);
 		fput(file);
-		return bprm.argc;
+		return bprm.envc;
 	}
   
 	retval = prepare_binprm(&bprm);
diff -urNp linux-463/arch/ppc64/kernel/time.c linux-340/arch/ppc64/kernel/time.c
--- linux-463/arch/ppc64/kernel/time.c
+++ linux-340/arch/ppc64/kernel/time.c
@@ -415,8 +415,8 @@ void do_settimeofday(struct timeval *tv)
 	time_esterror = NTP_PHASE_LIMIT;
 
 	delta_xsec = mulhdu( (tb_last_stamp-systemcfg->tb_orig_stamp), systemcfg->tb_to_xs );
-	new_xsec = (new_usec * XSEC_PER_SEC) / USEC_PER_SEC;
-	new_xsec += new_sec * XSEC_PER_SEC;
+	new_xsec = (tv->tv_usec * XSEC_PER_SEC) / USEC_PER_SEC;
+	new_xsec += tv->tv_sec * XSEC_PER_SEC;
 	if ( new_xsec > delta_xsec ) {
 		systemcfg->stamp_xsec = new_xsec - delta_xsec;
 	}
diff -urNp linux-463/arch/ppc64/kernel/traps.c linux-340/arch/ppc64/kernel/traps.c
--- linux-463/arch/ppc64/kernel/traps.c
+++ linux-340/arch/ppc64/kernel/traps.c
@@ -42,6 +42,7 @@
 #include <asm/io.h>
 #include <asm/processor.h>
 #include <asm/ppcdebug.h>
+#include <asm/machdep.h> /* for ppc_attention_msg */
 
 extern int fix_alignment(struct pt_regs *);
 extern void bad_page_fault(struct pt_regs *, unsigned long);
@@ -164,7 +165,8 @@ SystemResetException(struct pt_regs *reg
 	}
 #if defined(CONFIG_XMON)
 	xmon(regs);
-	udbg_printf("leaving xmon...\n");
+	if (smp_processor_id() == 0)
+		udbg_printf("leaving xmon...\n");
 #endif
 #if defined(CONFIG_KDB)
 	{
@@ -195,8 +197,6 @@ SystemResetException(struct pt_regs *reg
 void
 MachineCheckException(struct pt_regs *regs)
 {
-	siginfo_t info;
-
 	if (fwnmi_active) {
 		struct rtas_error_log *errhdr = FWNMI_get_errinfo(regs);
 		if (errhdr) {
@@ -205,37 +205,24 @@ MachineCheckException(struct pt_regs *re
 		FWNMI_release_errinfo();
 	}
 
-	if ( !user_mode(regs) ) {
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
-		if (debugger_fault_handler) {
-			debugger_fault_handler(regs);
-			return;
-		}
+	if (debugger_fault_handler) {
+		debugger_fault_handler(regs);
+		return;
+	}
 #endif
-		printk("Machine check in kernel mode.\n");
-		printk("Caused by (from SRR1=%lx): ", regs->msr);
-		show_regs(regs);
+	printk(KERN_EMERG "Unrecoverable Machine check.\n");
+	printk(KERN_EMERG "Caused by (from SRR1=%lx): ", regs->msr);
+	show_regs(regs);
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
-		debugger(regs);
+	debugger(regs);
 #endif
 #ifdef CONFIG_KDB
-		if (kdb(KDB_REASON_FAULT, 0, regs))
-			return ;
+	if (kdb(KDB_REASON_FAULT, 0, regs))
+		return;
 #endif
-		print_backtrace((unsigned long *)regs->gpr[1]);
-		panic("machine check");
-	}
-	
-	/*
-	 * XXX we should check RI bit on exception exit and kill the
-	 * task if it was cleared
-	 */
-	info.si_signo = SIGBUS;
-	info.si_errno = 0;
-	info.si_code = BUS_ADRERR;
-	info.si_addr = (void *)regs->nip;
-	_exception(SIGSEGV, &info, regs);
-
+	print_backtrace((unsigned long *)regs->gpr[1]);
+	panic("machine check");
 }
 
 void
@@ -377,6 +364,14 @@ ProgramCheckException(struct pt_regs *re
 	}
 }
 
+ void
+KernelFPUnavailableException(struct pt_regs *regs)
+{
+	printk("Illegal floating point used in kernel (task=0x%016lx, pc=0x%016lx, trap=0x%08x)\n",
+		current, regs->nip, regs->trap);
+	panic("Unrecoverable FP Unavailable Exception in Kernel");
+}
+
 void
 SingleStepException(struct pt_regs *regs)
 {
diff -urNp linux-463/arch/ppc64/kernel/udbg.c linux-340/arch/ppc64/kernel/udbg.c
--- linux-463/arch/ppc64/kernel/udbg.c
+++ linux-340/arch/ppc64/kernel/udbg.c
@@ -107,7 +107,7 @@ udbg_getc(void)
 			/* wait for char */;
 		return udbg_comport->rbr;
 	}
-	return 0;
+	return -1;
 }
 
 void
@@ -150,6 +150,8 @@ udbg_read(char *buf, int buflen) {
 		do {
 			c = ppc_md.udbg_getc();
 		} while (c == 0x11 || c == 0x13);
+		if (c == -1)	/* error occurred or no getc possible*/
+			break;
 		*p++ = c;
 	}
 	return i;
diff -urNp linux-463/arch/ppc64/kernel/xics.c linux-340/arch/ppc64/kernel/xics.c
--- linux-463/arch/ppc64/kernel/xics.c
+++ linux-340/arch/ppc64/kernel/xics.c
@@ -85,6 +85,9 @@ int xics_irq_8259_cascade_real = 0;
 unsigned int default_server = 0xFF;
 unsigned int default_distrib_server = 0;
 
+static inline u32 physmask(u32);
+extern unsigned int irq_affinity[];
+
 /* RTAS service tokens */
 int ibm_get_xive;
 int ibm_set_xive;
@@ -143,18 +146,25 @@ xics_enable_irq(
 	u_int		irq;
 	unsigned long	status;
 	long	        call_status;
+	unsigned int    interrupt_server = default_server;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(virq - XICS_IRQ_OFFSET);
 	if (irq == XICS_IPI)
 		return;
+
 #ifdef CONFIG_IRQ_ALL_CPUS
-	call_status = rtas_call(ibm_set_xive, 3, 1, (unsigned long*)&status,
-				irq, smp_threads_ready ? default_distrib_server : default_server, DEFAULT_PRIORITY);
-#else
-	call_status = rtas_call(ibm_set_xive, 3, 1, (unsigned long*)&status,
-				irq, default_server, DEFAULT_PRIORITY);
+	if((smp_num_cpus == systemcfg->processorCount) &&
+	   (smp_threads_ready)) {
+		/* Retain the affinity setting specified */
+		if (irq_affinity[virq] == 0xffffffff)
+			interrupt_server = default_distrib_server;
+		else
+			interrupt_server = physmask(irq_affinity[virq]);
+	}
 #endif
+	call_status = rtas_call(ibm_set_xive, 3, 1, (unsigned long*)&status,
+				irq, interrupt_server, DEFAULT_PRIORITY);
+
 	if( call_status != 0 ) {
 		printk("xics_enable_irq: irq=%x: rtas_call failed; retn=%lx, status=%lx\n",
 		       irq, call_status, status);
diff -urNp linux-463/arch/ppc64/lib/copyuser.S linux-340/arch/ppc64/lib/copyuser.S
--- linux-463/arch/ppc64/lib/copyuser.S
+++ linux-340/arch/ppc64/lib/copyuser.S
@@ -130,7 +130,7 @@ _GLOBAL(__copy_tofrom_user)
 6:	cmpwi	cr1,r5,8
 	addi	r3,r3,32
 	sld	r9,r9,r10
-	blt	cr1,.Ldo_tail
+	ble	cr1,.Ldo_tail
 34:	ld	r0,8(r4)
 	srd	r7,r0,r11
 	or	r9,r7,r9
@@ -483,8 +483,20 @@ _GLOBAL(__copy_tofrom_user)
  * on an exception, reset to the beginning and jump back into the
  * standard __copy_tofrom_user
  */
-100:	ld	r3,-24(r1)
-	ld	r4,-24(r1)
+100:	ld	r20,-120(1)
+	ld	r21,-112(1)
+	ld	r22,-104(1)
+	ld	r23,-96(1)
+	ld	r24,-88(1)
+	ld	r25,-80(1)
+	ld	r26,-72(1)
+	ld	r27,-64(1)
+	ld	r28,-56(1)
+	ld	r29,-48(1)
+	ld	r30,-40(1)
+	ld	r31,-32(1)
+	ld	r3,-24(r1)
+	ld	r4,-16(r1)
 	li	r5,4096
 	b	.Ldst_aligned
 
diff -urNp linux-463/arch/ppc64/mm/fault.c linux-340/arch/ppc64/mm/fault.c
--- linux-463/arch/ppc64/mm/fault.c
+++ linux-340/arch/ppc64/mm/fault.c
@@ -65,7 +65,7 @@ extern unsigned long get_srr1(void);
 void do_page_fault(struct pt_regs *regs, unsigned long address,
 		   unsigned long error_code)
 {
-	struct vm_area_struct * vma;
+	struct vm_area_struct * vma, * prev_vma;
 	struct mm_struct *mm = current->mm;
 	siginfo_t info;
 	unsigned long code = SEGV_MAPERR;
@@ -90,8 +90,8 @@ void do_page_fault(struct pt_regs *regs,
 	}
 #endif /* CONFIG_XMON || CONFIG_KGDB */
 
-	/* On an SLB miss we can only check for a valid exception entry */
-	if (regs->trap == 0x380) {
+	/* On a kernel SLB miss we can only check for a valid exception entry */
+	if (!user_mode(regs) && (regs->trap == 0x380)) {
 		bad_page_fault(regs, address);
 		return;
 	}
@@ -128,6 +128,7 @@ void do_page_fault(struct pt_regs *regs,
 		PPCDBG(PPCDBG_MM, "\tdo_page_fault: vma->vm_flags = %lx, %lx\n", vma->vm_flags, VM_GROWSDOWN);
 		goto bad_area;
 	}
+	vma = find_vma_prev(mm, address, &prev_vma);
 	if (expand_stack(vma, address)) {
 		PPCDBG(PPCDBG_MM, "\tdo_page_fault: expand_stack\n");
 		goto bad_area;
diff -urNp linux-463/arch/ppc64/mm/init.c linux-340/arch/ppc64/mm/init.c
--- linux-463/arch/ppc64/mm/init.c
+++ linux-340/arch/ppc64/mm/init.c
@@ -29,7 +29,7 @@
 #include <linux/types.h>
 #include <linux/ptrace.h>
 #include <linux/mman.h>
-#include <linux/mm.h>
+#include <linux/mm_inline.h>
 #include <linux/swap.h>
 #include <linux/stddef.h>
 #include <linux/vmalloc.h>
@@ -37,6 +37,7 @@
 #include <linux/delay.h>
 #include <linux/bootmem.h>
 #include <linux/highmem.h>
+#include <linux/slab.h>
 #ifdef CONFIG_BLK_DEV_INITRD
 #include <linux/blk.h>		/* for initrd_* */
 #endif
@@ -279,7 +280,11 @@ local_flush_tlb_all(void)
 	/* Implemented to just flush the vmalloc area.
 	 * vmalloc is the only user of flush_tlb_all.
 	 */
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+	local_flush_tlb_range( NULL, VMALLOC_START, SMALLOC_END );
+#else
 	local_flush_tlb_range( NULL, VMALLOC_START, VMALLOC_END );
+#endif
 }
 
 void
@@ -292,11 +297,6 @@ local_flush_tlb_mm(struct mm_struct *mm)
 		for ( mp = mm->mmap; mp != NULL; mp = mp->vm_next )
 			local_flush_tlb_range( mm, mp->vm_start, mp->vm_end );
 	}
-	else	/* MIKEC: It is not clear why this is needed */
-		/* paulus: it is needed to clear out stale HPTEs
-		 * when an address space (represented by an mm_struct)
-		 * is being destroyed. */
-		local_flush_tlb_range( mm, USER_START, USER_END );
 
 	spin_unlock(&mm->page_table_lock);
 }
@@ -644,3 +644,131 @@ void flush_icache_user_range(struct vm_a
 	maddr = (unsigned long)page_address(page) + (addr & ~PAGE_MASK);
 	flush_icache_range(maddr, maddr + len);
 }
+
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+static spinlock_t shared_malloc_lock = SPIN_LOCK_UNLOCKED;
+struct vm_struct *shared_list = NULL;
+static struct vm_struct *get_shared_area(unsigned long size, 
+					 unsigned long flags);
+
+void *shared_malloc(unsigned long size) {
+	pgprot_t prot;
+	struct vm_struct *area;
+	unsigned long ea;
+
+	spin_lock(&shared_malloc_lock);
+
+	printk("shared_malloc1 (no _PAGE_USER): addr = 0x%lx, size = 0x%lx\n", 
+	       SMALLOC_START, size); 
+
+	area = get_shared_area(size, 0);
+	if (!area) {
+	spin_unlock(&shared_malloc_lock);
+		return NULL;
+	}
+
+	ea = (unsigned long) area->addr;
+
+	prot = __pgprot(pgprot_val(PAGE_KERNEL));
+	if (vmalloc_area_pages(VMALLOC_VMADDR(ea), size, GFP_KERNEL, prot)) { 
+	spin_unlock(&shared_malloc_lock);
+		return NULL;
+	} 
+
+	printk("shared_malloc: addr = 0x%lx, size = 0x%lx\n", ea, size); 
+
+	spin_unlock(&shared_malloc_lock);
+	return(ea); 
+}
+
+void shared_free(void *addr) {
+	struct vm_struct **p, *tmp;
+	unsigned long size = 0;
+
+	if (!addr)
+		return;
+	if ((PAGE_SIZE-1) & (unsigned long) addr) {
+		printk(KERN_ERR "Trying to shared_free() bad address (%p)\n", 
+		       addr);
+		return;
+	}
+	spin_lock(&shared_malloc_lock);
+
+	printk("shared_free: addr = 0x%lx\n", addr); 
+
+	/* Scan the memory list for an entry matching
+	 * the address to be freed, get the size (in bytes)
+	 * and free the entry.  The list lock is not dropped
+	 * until the page table entries are removed.
+	 */
+	for(p = &shared_list; (tmp = *p); p = &tmp->next ) {
+		if (tmp->addr == addr) {
+			*p = tmp->next;
+			vmfree_area_pages(VMALLOC_VMADDR(tmp->addr),tmp->size);
+			spin_unlock(&shared_malloc_lock);
+			kfree(tmp);
+			return;
+		}
+	}
+
+	spin_unlock(&shared_malloc_lock);
+	printk("shared_free: error\n"); 
+}
+
+static struct vm_struct *get_shared_area(unsigned long size, 
+					 unsigned long flags) {
+	unsigned long addr;
+	struct vm_struct **p, *tmp, *area;
+  
+	area = (struct vm_struct *) kmalloc(sizeof(*area), GFP_KERNEL);
+	if (!area) return NULL;
+
+	size += PAGE_SIZE;
+	if (!size) {
+		kfree (area);
+		return NULL;
+	}
+
+	addr = SMALLOC_START;
+	for (p = &shared_list; (tmp = *p) ; p = &tmp->next) {
+		if ((size + addr) < addr) {
+			kfree(area);
+			return NULL;
+		}
+		if (size + addr <= (unsigned long) tmp->addr)
+			break;
+		addr = tmp->size + (unsigned long) tmp->addr;
+		if (addr > SMALLOC_END-size) {
+			kfree(area);
+			return NULL;
+		}
+	}
+
+	if (addr + size > SMALLOC_END) {
+		kfree(area);
+		return NULL;
+	}
+	area->flags = flags;
+	area->addr = (void *)addr;
+	area->size = size;
+	area->next = *p;
+	*p = area;
+	return area;
+}
+
+int shared_task_mark() {
+	current->thread.flags |= PPC_FLAG_SHARED;
+	printk("current->thread.flags = 0x%lx\n", current->thread.flags);
+
+	return 0;
+}
+
+int shared_task_unmark() {
+	if(current->thread.flags & PPC_FLAG_SHARED) {
+		current->thread.flags &= (~PPC_FLAG_SHARED);
+		return 0;
+	} else {
+		return -1;
+	}
+}
+#endif
diff -urNp linux-463/arch/ppc64/vmlinux.lds linux-340/arch/ppc64/vmlinux.lds
--- linux-463/arch/ppc64/vmlinux.lds
+++ linux-340/arch/ppc64/vmlinux.lds
@@ -73,6 +73,9 @@ SECTIONS
   __kallsyms : { *(__kallsyms) }
   __stop___kallsyms = .;
 
+  __start___ftr_fixup = .;
+  __ftr_fixup : { *(__ftr_fixup) }
+  __stop___ftr_fixup = .;
 
   . = ALIGN(4096);
   .data.page_aligned : { *(.data.page_aligned) }
diff -urNp linux-463/arch/ppc64/xmon/start.c linux-340/arch/ppc64/xmon/start.c
--- linux-463/arch/ppc64/xmon/start.c
+++ linux-340/arch/ppc64/xmon/start.c
@@ -226,6 +226,7 @@ xmon_readchar(void)
 			return ch;
 		case -1:
 			xmon_printf("read(stdin) returned -1\r\n", 0, 0);
+		case 0:
 			return -1;
 		}
 	}
diff -urNp linux-463/arch/ppc64/xmon/xmon.c linux-340/arch/ppc64/xmon/xmon.c
--- linux-463/arch/ppc64/xmon/xmon.c
+++ linux-340/arch/ppc64/xmon/xmon.c
@@ -33,9 +33,11 @@
 #define skipbl	xmon_skipbl
 
 #ifdef CONFIG_SMP
-static unsigned long cpus_in_xmon = 0;
-static unsigned long got_xmon = 0;
+static volatile unsigned long cpus_in_xmon = 0;
+static volatile unsigned long got_xmon = 0;
 static volatile int take_xmon = -1;
+static volatile int leaving_xmon = 0;
+
 #endif /* CONFIG_SMP */
 
 static unsigned long adrs;
@@ -190,7 +192,7 @@ extern inline void sync(void)
 	asm volatile("sync; isync");
 }
 
-/* (Ref: 64-bit PowerPC ELF ABI Spplement; Ian Lance Taylor, Zembu Labs).
+/* (Ref: 64-bit PowerPC ELF ABI Supplement; Ian Lance Taylor, Zembu Labs).
  A PPC stack frame looks like this:
 
  High Address
@@ -210,52 +212,16 @@ extern inline void sync(void)
  no functions have been called from the current function.
  */
 
-/*
- A traceback table typically follows each function.
- The find_tb_table() func will fill in this struct.  Note that the struct
- is not an exact match with the encoded table defined by the ABI.  It is
- defined here more for programming convenience.
- */
-struct tbtable {
-	unsigned long	flags;		/* flags: */
-#define TBTAB_FLAGSGLOBALLINK	(1L<<47)
-#define TBTAB_FLAGSISEPROL	(1L<<46)
-#define TBTAB_FLAGSHASTBOFF	(1L<<45)
-#define TBTAB_FLAGSINTPROC	(1L<<44)
-#define TBTAB_FLAGSHASCTL	(1L<<43)
-#define TBTAB_FLAGSTOCLESS	(1L<<42)
-#define TBTAB_FLAGSFPPRESENT	(1L<<41)
-#define TBTAB_FLAGSNAMEPRESENT	(1L<<38)
-#define TBTAB_FLAGSUSESALLOCA	(1L<<37)
-#define TBTAB_FLAGSSAVESCR	(1L<<33)
-#define TBTAB_FLAGSSAVESLR	(1L<<32)
-#define TBTAB_FLAGSSTORESBC	(1L<<31)
-#define TBTAB_FLAGSFIXUP	(1L<<30)
-#define TBTAB_FLAGSPARMSONSTK	(1L<<0)
-	unsigned char	fp_saved;	/* num fp regs saved f(32-n)..f31 */
-	unsigned char	gpr_saved;	/* num gpr's saved */
-	unsigned char	fixedparms;	/* num fixed point parms */
-	unsigned char	floatparms;	/* num float parms */
-	unsigned char	parminfo[32];	/* types of args.  null terminated */
-#define TBTAB_PARMFIXED 1
-#define TBTAB_PARMSFLOAT 2
-#define TBTAB_PARMDFLOAT 3
-	unsigned int	tb_offset;	/* offset from start of func */
-	unsigned long	funcstart;	/* addr of start of function */
-	char		name[64];	/* name of function (null terminated)*/
-};
-static int find_tb_table(unsigned long codeaddr, struct tbtable *tab);
-
 void
 xmon(struct pt_regs *excp)
 {
 	struct pt_regs regs;
-	int cmd;
+	int cmd = 0;
 	unsigned long msr;
 
 	if (excp == NULL) {
 		/* Ok, grab regs as they are now.
-		 This won't do a particularily good job because the
+		 This won't do a particularly good job because the
 		 prologue has already been executed.
 		 ToDo: We could reach back into the callers save
 		 area to do a better job of representing the
@@ -309,9 +275,15 @@ xmon(struct pt_regs *excp)
 	xmon_regs[smp_processor_id()] = excp;
 	excprint(excp);
 #ifdef CONFIG_SMP
-	if (test_and_set_bit(smp_processor_id(), &cpus_in_xmon))
+	/* possible race condition here if a CPU is held up and gets
+	 * here while we are exiting */
+	leaving_xmon = 0;
+	if (test_and_set_bit(smp_processor_id(), &cpus_in_xmon)) {
+		/* xmon probably caused an exception itself */
+		printf("We are already in xmon\n");
 		for (;;)
 			;
+	}
 	while (test_and_set_bit(0, &got_xmon)) {
 		if (take_xmon == smp_processor_id()) {
 			take_xmon = -1;
@@ -327,6 +299,9 @@ xmon(struct pt_regs *excp)
 	if (cmd == 's') {
 		xmon_trace[smp_processor_id()] = SSTEP;
 		excp->msr |= MSR_SE;
+#ifdef CONFIG_SMP		
+		take_xmon = smp_processor_id();
+#endif		
 	} else if (at_breakpoint(excp->nip)) {
 		xmon_trace[smp_processor_id()] = BRSTEP;
 		excp->msr |= MSR_SE;
@@ -336,7 +311,9 @@ xmon(struct pt_regs *excp)
 	}
 	xmon_regs[smp_processor_id()] = 0;
 #ifdef CONFIG_SMP
-	clear_bit(0, &got_xmon);
+	leaving_xmon = 1;
+	if (cmd != 's')
+		clear_bit(0, &got_xmon);
 	clear_bit(smp_processor_id(), &cpus_in_xmon);
 #endif /* CONFIG_SMP */
 	set_msrd(msr);		/* restore interrupt enable */
@@ -442,7 +419,7 @@ insert_bpts()
 	int i;
 	struct bpt *bp;
 
-	if (systemcfg->platform != PLATFORM_PSERIES)
+	if (!(systemcfg->platform & PLATFORM_PSERIES))
 		return;
 	bp = bpts;
 	for (i = 0; i < NBPTS; ++i, ++bp) {
@@ -473,11 +450,13 @@ remove_bpts()
 	struct bpt *bp;
 	unsigned instr;
 
-	if (systemcfg->platform != PLATFORM_PSERIES)
+	if (!(systemcfg->platform & PLATFORM_PSERIES))
 		return;
 	if (!__is_processor(PV_POWER4) && !__is_processor(PV_POWER4p)) {
-		set_dabr(0);
-		set_iabr(0);
+		if (dabr.enabled)
+			set_dabr(0);
+		if (iabr.enabled)
+			set_iabr(0);
 	}
 
 	bp = bpts;
@@ -500,11 +479,15 @@ static char *last_cmd;
 static int
 cmds(struct pt_regs *excp)
 {
-	int cmd;
+	int cmd = 0;
 
 	last_cmd = NULL;
 	for(;;) {
 #ifdef CONFIG_SMP
+		/* Need to check if we should take any commands on
+		   this CPU. */
+		if (leaving_xmon)
+			return cmd;
 		printf("%d:", smp_processor_id());
 #endif /* CONFIG_SMP */
 		printf("mon> ");
@@ -762,7 +745,6 @@ bpt_cmds(void)
 	unsigned long a;
 	int mode, i;
 	struct bpt *bp;
-	struct tbtable tab;
 
 	cmd = inchar();
 	switch (cmd) {
@@ -771,6 +753,7 @@ bpt_cmds(void)
 			printf("Not implemented on POWER4\n");
 			break;
 		}
+			
 		mode = 7;
 		cmd = inchar();
 		if (cmd == 'r')
@@ -872,11 +855,7 @@ bpt_cmds(void)
 		scanhex(&bp->count);
 		/* Find the function name just once. */
 		bp->funcname[0] = '\0';
-		if (find_tb_table(bp->address, &tab) && tab.name[0]) {
-			/* Got a nice name for it. */
-			int delta = bp->address - tab.funcstart;
-			sprintf(bp->funcname, "%s+0x%x", tab.name, delta);
-		}
+		lookup_symbol(bp->address, bp->funcname, sizeof(bp->funcname));
 		printf("Set breakpoint %2x trap   %.16lx %8x  %s\n", (bp-bpts)+1, bp->address, bp->count, bp->funcname);
 		break;
 	}
@@ -914,7 +893,6 @@ backtrace(struct pt_regs *excp)
 	unsigned long lr;
 	unsigned long stack[3];
 	struct pt_regs regs;
-	struct tbtable tab;
 	int framecount;
 	char *funcname;
 	/* declare these as raw ptrs so we don't get func descriptors */
@@ -960,13 +938,10 @@ backtrace(struct pt_regs *excp)
 				break;
 			printf("exception: %lx %s regs %lx\n", regs.trap, getvecname(regs.trap), sp+112);
 			printf("                  %.16lx", regs.nip);
-			if ((regs.nip & 0xffffffff00000000UL) &&
-			    find_tb_table(regs.nip, &tab)) {
-				int delta = regs.nip-tab.funcstart;
-				if (delta < 0)
-					printf("  <unknown code>");
-				else
-					printf("  %s+0x%x", tab.name, delta);
+			if ((regs.nip & 0xffffffff00000000UL)) {
+				char buffer[512];
+				lookup_symbol(regs.nip, buffer, 512);
+				printf("  %s", buffer);
 			}
 			printf("\n");
                         if (regs.gpr[1] < sp) {
@@ -978,12 +953,10 @@ backtrace(struct pt_regs *excp)
 			if (mread(sp, stack, sizeof(stack)) != sizeof(stack))
 				break;
 		} else {
-			if (stack[2] && find_tb_table(stack[2], &tab)) {
-				int delta = stack[2]-tab.funcstart;
-				if (delta < 0)
-					printf("  <unknown code>");
-				else
-					printf("  %s+0x%x", tab.name, delta);
+			if (stack[2]) {
+				char buffer[512];
+				lookup_symbol(stack[2], buffer, 512);
+				printf("  %s", buffer);
 			}
 			printf("\n");
 		}
@@ -1014,8 +987,8 @@ void
 excprint(struct pt_regs *fp)
 {
 	struct task_struct *c;
-	struct tbtable tab;
 	unsigned long flags;
+	char buffer[512];
 
 	spin_lock_irqsave(&exception_print_lock, flags);
 
@@ -1025,18 +998,12 @@ excprint(struct pt_regs *fp)
 
 	printf("Vector: %lx %s at  [%lx]\n", fp->trap, getvecname(fp->trap), fp);
 	printf("    pc: %lx", fp->nip);
-	if (find_tb_table(fp->nip, &tab) && tab.name[0]) {
-		/* Got a nice name for it */
-		int delta = fp->nip - tab.funcstart;
-		printf(" (%s+0x%x)", tab.name, delta);
-	}
+	lookup_symbol(fp->nip, buffer, sizeof(buffer));
+	printf(" (%s)", buffer);
 	printf("\n");
 	printf("    lr: %lx", fp->link);
-	if (find_tb_table(fp->link, &tab) && tab.name[0]) {
-		/* Got a nice name for it */
-		int delta = fp->link - tab.funcstart;
-		printf(" (%s+0x%x)", tab.name, delta);
-	}
+	lookup_symbol(fp->link, buffer, sizeof(buffer));
+	printf(" (%s)", buffer);
 	printf("\n");
 	printf("    sp: %lx\n", fp->gpr[1]);
 	printf("   msr: %lx\n", fp->msr);
@@ -2048,109 +2015,6 @@ char *str;
 	lineptr = str;
 }
 
-
-/* Starting at codeaddr scan forward for a tbtable and fill in the
- given table.  Return non-zero if successful at doing something.
- */
-static int
-find_tb_table(unsigned long codeaddr, struct tbtable *tab)
-{
-	unsigned long codeaddr_max;
-	unsigned long tbtab_start;
-	int nr;
-	int instr;
-	int num_parms;
-
-	if (tab == NULL)
-		return 0;
-	memset(tab, 0, sizeof(tab));
-
-	/* Scan instructions starting at codeaddr for 128k max */
-	for (codeaddr_max = codeaddr + 128*1024*4;
-	     codeaddr < codeaddr_max;
-	     codeaddr += 4) {
-		nr = mread(codeaddr, &instr, 4);
-		if (nr != 4)
-			return 0;	/* Bad read.  Give up promptly. */
-		if (instr == 0) {
-			/* table should follow. */
-			int version;
-			unsigned long flags;
-			tbtab_start = codeaddr;	/* save it to compute func start addr */
-			codeaddr += 4;
-			nr = mread(codeaddr, &flags, 8);
-			if (nr != 8)
-				return 0;	/* Bad read or no tb table. */
-			tab->flags = flags;
-			version = (flags >> 56) & 0xff;
-			if (version != 0)
-				continue;	/* No tb table here. */
-			/* Now, like the version, some of the flags are values
-			 that are more conveniently extracted... */
-			tab->fp_saved = (flags >> 24) & 0x3f;
-			tab->gpr_saved = (flags >> 16) & 0x3f;
-			tab->fixedparms = (flags >> 8) & 0xff;
-			tab->floatparms = (flags >> 1) & 0x7f;
-			codeaddr += 8;
-			num_parms = tab->fixedparms + tab->floatparms;
-			if (num_parms) {
-				unsigned int parminfo;
-				int parm;
-				if (num_parms > 32)
-					return 1;	/* incomplete */
-				nr = mread(codeaddr, &parminfo, 4);
-				if (nr != 4)
-					return 1;	/* incomplete */
-				/* decode parminfo...32 bits.
-				 A zero means fixed.  A one means float and the
-				 following bit determines single (0) or double (1).
-				 */
-				for (parm = 0; parm < num_parms; parm++) {
-					if (parminfo & 0x80000000) {
-						parminfo <<= 1;
-						if (parminfo & 0x80000000)
-							tab->parminfo[parm] = TBTAB_PARMDFLOAT;
-						else
-							tab->parminfo[parm] = TBTAB_PARMSFLOAT;
-					} else {
-						tab->parminfo[parm] = TBTAB_PARMFIXED;
-					}
-					parminfo <<= 1;
-				}
-				codeaddr += 4;
-			}
-			if (flags & TBTAB_FLAGSHASTBOFF) {
-				nr = mread(codeaddr, &tab->tb_offset, 4);
-				if (nr != 4)
-					return 1;	/* incomplete */
-				if (tab->tb_offset > 0) {
-					tab->funcstart = tbtab_start - tab->tb_offset;
-				}
-				codeaddr += 4;
-			}
-			/* hand_mask appears to be always be omitted. */
-			if (flags & TBTAB_FLAGSHASCTL) {
-				/* Assume this will never happen for C or asm */
-				return 1;	/* incomplete */
-			}
-			if (flags & TBTAB_FLAGSNAMEPRESENT) {
-				short namlen;
-				nr = mread(codeaddr, &namlen, 2);
-				if (nr != 2)
-					return 1;	/* incomplete */
-				if (namlen >= sizeof(tab->name))
-					namlen = sizeof(tab->name)-1;
-				codeaddr += 2;
-				nr = mread(codeaddr, tab->name, namlen);
-				tab->name[namlen] = '\0';
-				codeaddr += namlen;
-			}
-			return 1;
-		}
-	}
-	return 0;	/* hit max...sorry. */
-}
-
 void
 mem_translate()
 {
diff -urNp linux-463/drivers/char/tty_io.c linux-340/drivers/char/tty_io.c
--- linux-463/drivers/char/tty_io.c
+++ linux-340/drivers/char/tty_io.c
@@ -2287,6 +2287,9 @@ void __init console_init(void)
 #ifdef CONFIG_TN3215
 	con3215_init();
 #endif
+#ifdef CONFIG_HVC_CONSOLE
+        hvc_console_init();
+#endif
 #ifdef CONFIG_SCLP_CONSOLE
         sclp_console_init();
 #endif
diff -urNp linux-463/include/asm-ppc/termbits.h linux-340/include/asm-ppc/termbits.h
--- linux-463/include/asm-ppc/termbits.h
+++ linux-340/include/asm-ppc/termbits.h
@@ -80,6 +80,7 @@ struct termios {
 #define   TAB1	00002000
 #define   TAB2	00004000
 #define   TAB3	00006000
+#define   XTABS	00006000	/* required by POSIX to == TAB3 */
 #define CRDLY	00030000
 #define   CR0	00000000
 #define   CR1	00010000
@@ -94,7 +95,6 @@ struct termios {
 #define VTDLY	00200000
 #define   VT0	00000000
 #define   VT1	00200000
-#define XTABS	01000000 /* Hmm.. Linux/i386 considers this part of TABDLY.. */
 
 /* c_cflag bit meaning */
 #define CBAUD	0000377
diff -urNp linux-463/include/asm-ppc64/cache.h linux-340/include/asm-ppc64/cache.h
--- linux-463/include/asm-ppc64/cache.h
+++ linux-340/include/asm-ppc64/cache.h
@@ -8,6 +8,7 @@
 #define __ARCH_PPC64_CACHE_H
 
 /* bytes per L1 cache line */
-#define L1_CACHE_BYTES	128
-
+#define L1_CACHE_SHIFT        7
+#define L1_CACHE_BYTES        (1 << L1_CACHE_SHIFT)
+#define L1_CACHE_SHIFT_MAX 7  /* largest L1 which this arch supports */
 #endif
diff -urNp linux-463/include/asm-ppc64/cputable.h linux-340/include/asm-ppc64/cputable.h
--- linux-463/include/asm-ppc64/cputable.h
+++ linux-340/include/asm-ppc64/cputable.h
@@ -0,0 +1,152 @@
+/*
+ *  include/asm-ppc/cputable.h
+ *
+ *  Copyright (C) 2001 Ben. Herrenschmidt (benh@kernel.crashing.org)
+ *
+ *  Modifications for ppc64:
+ *      Copyright (C) 2003 Dave Engebretsen <engebret@us.ibm.com>
+ * 
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ */
+
+#ifndef __ASM_PPC_CPUTABLE_H
+#define __ASM_PPC_CPUTABLE_H
+
+/* Exposed to userland CPU features - Must match ppc32 definitions */
+#define PPC_FEATURE_32			0x80000000
+#define PPC_FEATURE_64			0x40000000
+#define PPC_FEATURE_601_INSTR		0x20000000
+#define PPC_FEATURE_HAS_ALTIVEC		0x10000000
+#define PPC_FEATURE_HAS_FPU		0x08000000
+#define PPC_FEATURE_HAS_MMU		0x04000000
+#define PPC_FEATURE_HAS_4xxMAC		0x02000000
+#define PPC_FEATURE_UNIFIED_CACHE	0x01000000
+
+#ifdef __KERNEL__
+
+#ifndef __ASSEMBLY__
+
+/* This structure can grow, it's real size is used by head.S code
+ * via the mkdefs mecanism.
+ */
+struct cpu_spec;
+
+typedef	void (*cpu_setup_t)(unsigned long offset, int cpu_nr, struct cpu_spec* spec);
+
+struct cpu_spec {
+	/* CPU is matched via (PVR & pvr_mask) == pvr_value */
+	unsigned int	pvr_mask;
+	unsigned int	pvr_value;
+
+	char		*cpu_name;
+	unsigned long	cpu_features;		/* Kernel features */
+	unsigned int	cpu_user_features;	/* Userland features */
+
+	/* cache line sizes */
+	unsigned int	icache_bsize;
+	unsigned int	dcache_bsize;
+
+	/* this is called to initialize various CPU bits like L1 cache,
+	 * BHT, SPD, etc... from head.S before branching to identify_machine
+	 */
+	cpu_setup_t	cpu_setup;
+
+	/* This is used to identify firmware features which are available
+	 * to the kernel.
+	 */
+	unsigned long   firmware_features;
+};
+
+extern struct cpu_spec		cpu_specs[];
+extern struct cpu_spec		*cur_cpu_spec;
+
+
+/* firmware feature bitmask values */
+#define FIRMWARE_MAX_FEATURES 63
+
+#define FW_FEATURE_PFT		(1UL<<0)
+#define FW_FEATURE_TCE		(1UL<<1)	
+#define FW_FEATURE_SPRG0	(1UL<<2)	
+#define FW_FEATURE_DABR		(1UL<<3)	
+#define FW_FEATURE_COPY		(1UL<<4)	
+#define FW_FEATURE_ASR		(1UL<<5)	
+#define FW_FEATURE_DEBUG	(1UL<<6)	
+#define FW_FEATURE_PERF		(1UL<<7)	
+#define FW_FEATURE_DUMP		(1UL<<8)	
+#define FW_FEATURE_INTERRUPT	(1UL<<9)	
+#define FW_FEATURE_MIGRATE	(1UL<<10)	
+
+typedef struct {
+    unsigned long val;
+    char * name;
+} firmware_feature_t;
+
+extern firmware_feature_t firmware_features_table[];
+
+#endif /* __ASSEMBLY__ */
+
+/* CPU kernel features */
+
+/* Retain the 32b definitions for the time being - use bottom half of word */
+#define CPU_FTR_SPLIT_ID_CACHE		0x0000000000000001
+#define CPU_FTR_L2CR			0x0000000000000002
+#define CPU_FTR_SPEC7450		0x0000000000000004
+#define CPU_FTR_ALTIVEC			0x0000000000000008
+#define CPU_FTR_TAU			0x0000000000000010
+#define CPU_FTR_CAN_DOZE		0x0000000000000020
+#define CPU_FTR_USE_TB			0x0000000000000040
+#define CPU_FTR_604_PERF_MON		0x0000000000000080
+#define CPU_FTR_601			0x0000000000000100
+#define CPU_FTR_HPTE_TABLE		0x0000000000000200
+#define CPU_FTR_CAN_NAP			0x0000000000000400
+#define CPU_FTR_L3CR			0x0000000000000800
+#define CPU_FTR_L3_DISABLE_NAP		0x0000000000001000
+#define CPU_FTR_NAP_DISABLE_L2_PR	0x0000000000002000
+#define CPU_FTR_DUAL_PLL_750FX		0x0000000000004000
+
+/* Add the 64b processor unique features in the top half of the word */
+#define CPU_FTR_SLB           		0x0000000100000000
+#define CPU_FTR_16M_PAGE      		0x0000000200000000
+#define CPU_FTR_TLBIEL         		0x0000000400000000
+#define CPU_FTR_NOEXECUTE     		0x0000000800000000
+#define CPU_FTR_NODSISRALIGN  		0x0000001000000000
+
+/* Platform firmware features */
+#define FW_FTR_                         0x0000000000000001
+
+#ifndef __ASSEMBLY__
+#define COMMON_USER_PPC64	(PPC_FEATURE_32 | PPC_FEATURE_64 | \
+			         PPC_FEATURE_HAS_FPU | PPC_FEATURE_HAS_MMU)
+
+#define CPU_FTR_PPCAS_ARCH_V2   (CPU_FTR_SLB | CPU_FTR_16M_PAGE | \
+                                 CPU_FTR_TLBIEL | CPU_FTR_NOEXECUTE | \
+                                 CPU_FTR_NODSISRALIGN)
+
+#define COMMON_PPC64_FW	(0)
+#endif
+
+#ifdef __ASSEMBLY__
+
+#define BEGIN_FTR_SECTION		98:
+
+#define END_FTR_SECTION(msk, val)		\
+99:						\
+	.section __ftr_fixup,"a";		\
+	.align 3;				\
+	.llong msk;			        \
+	.llong val;			        \
+	.llong 98b;			        \
+	.llong 99b;	 		        \
+	.previous
+
+#define END_FTR_SECTION_IFSET(msk)	END_FTR_SECTION((msk), (msk))
+#define END_FTR_SECTION_IFCLR(msk)	END_FTR_SECTION((msk), 0)
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* __ASM_PPC_CPUTABLE_H */
+#endif /* __KERNEL__ */
+
diff -urNp linux-463/include/asm-ppc64/delay.h linux-340/include/asm-ppc64/delay.h
--- linux-463/include/asm-ppc64/delay.h
+++ linux-340/include/asm-ppc64/delay.h
@@ -52,6 +52,9 @@ static inline void ndelay(unsigned long 
 
 	__delay(loops);
 }
+
+#define ndelay(x)       udelay(((x)+999)/1000)
+
 #endif /* !__ASSEMBLY__ */
 
 #endif /* _PPC64_DELAY_H */
diff -urNp linux-463/include/asm-ppc64/fcntl.h linux-340/include/asm-ppc64/fcntl.h
--- linux-463/include/asm-ppc64/fcntl.h
+++ linux-340/include/asm-ppc64/fcntl.h
@@ -27,6 +27,7 @@
 #define O_NOFOLLOW      0100000	/* don't follow links */
 #define O_LARGEFILE     0200000
 #define O_DIRECT	0400000	/* direct disk access hint */
+#define O_ATOMICLOOKUP 01000000 /* do atomic file lookup */
 
 #define F_DUPFD		0	/* dup */
 #define F_GETFD		1	/* get close_on_exec */
diff -urNp linux-463/include/asm-ppc64/floppy.h linux-340/include/asm-ppc64/floppy.h
--- linux-463/include/asm-ppc64/floppy.h
+++ linux-340/include/asm-ppc64/floppy.h
@@ -82,7 +82,7 @@ static int FDC2 = -1;
 /*
  * Again, the CMOS information not available
  */
-#define FLOPPY0_TYPE 6
+#define FLOPPY0_TYPE 4
 #define FLOPPY1_TYPE 0
 
 #define N_FDC 2			/* Don't change this! */
diff -urNp linux-463/include/asm-ppc64/iSeries/HvLpEvent.h linux-340/include/asm-ppc64/iSeries/HvLpEvent.h
--- linux-463/include/asm-ppc64/iSeries/HvLpEvent.h
+++ linux-340/include/asm-ppc64/iSeries/HvLpEvent.h
@@ -91,7 +91,7 @@ extern int HvLpEvent_openPath( HvLpEvent
 
 
 // Close an Lp Event Path for a type and partition
-//  returns 0 on sucess
+//  returns 0 on success
 extern int HvLpEvent_closePath( HvLpEvent_Type eventType, HvLpIndex lpIndex );
 
 #define HvLpEvent_Type_Hypervisor 0
diff -urNp linux-463/include/asm-ppc64/iSeries/iSeries_VpdInfo.h linux-340/include/asm-ppc64/iSeries/iSeries_VpdInfo.h
--- linux-463/include/asm-ppc64/iSeries/iSeries_VpdInfo.h
+++ linux-340/include/asm-ppc64/iSeries/iSeries_VpdInfo.h
@@ -24,7 +24,7 @@
 /************************************************************************/
 /* Change Activity:                                                     */
 /*   Created, Feg  8, 2001                                              */
-/*   Reformated for Card, March 8, 2001                                 */
+/*   Reformatted for Card, March 8, 2001                                 */
 /* End Change Activity                                                  */
 /************************************************************************/
 
diff -urNp linux-463/include/asm-ppc64/iSeries/mf.h linux-340/include/asm-ppc64/iSeries/mf.h
--- linux-463/include/asm-ppc64/iSeries/mf.h
+++ linux-340/include/asm-ppc64/iSeries/mf.h
@@ -58,11 +58,11 @@ extern void mf_clearSrc( void );
 
 extern void mf_init( void );
 
-extern void mf_setSide(char side);
+extern int  mf_setSide(char side);
 
 extern char mf_getSide(void);
 
-extern void mf_setCmdLine(const char *cmdline, int size, u64 side);
+extern int  mf_setCmdLine(const char *cmdline, int size, u64 side);
 
 extern int  mf_getCmdLine(char *cmdline, int *size, u64 side);
 
diff -urNp linux-463/include/asm-ppc64/ide.h linux-340/include/asm-ppc64/ide.h
--- linux-463/include/asm-ppc64/ide.h
+++ linux-340/include/asm-ppc64/ide.h
@@ -48,7 +48,10 @@ static __inline__ void ide_init_default_
 {
 }
 
-#include <asm-generic/ide_iops.h>
+#define __ide_mm_insw(p, a, c)  _insw_ns((volatile u16 *)(p), (a), (c))
+#define __ide_mm_insl(p, a, c)  _insl_ns((volatile u32 *)(p), (a), (c))
+#define __ide_mm_outsw(p, a, c) _outsw_ns((volatile u16 *)(p), (a), (c))
+#define __ide_mm_outsl(p, a, c) _outsl_ns((volatile u32 *)(p), (a), (c))
 
 #endif /* __KERNEL__ */
 
diff -urNp linux-463/include/asm-ppc64/io.h linux-340/include/asm-ppc64/io.h
--- linux-463/include/asm-ppc64/io.h
+++ linux-340/include/asm-ppc64/io.h
@@ -99,7 +99,7 @@ extern void _outsl_ns(volatile u32 *port
 #define inw_p(port)             inw(port)
 #define outw_p(val, port)       (udelay(1), outw((val), (port)))
 #define inl_p(port)             inl(port)
-#define outl_p(val, port)       (udelay(1), outl((val, (port)))
+#define outl_p(val, port)       (udelay(1), outl((val), (port)))
 
 /*
  * The *_ns versions below don't do byte-swapping.
@@ -141,6 +141,8 @@ static inline unsigned long virt_to_phys
 	return __pa((unsigned long)address);
 }
 
+#define	virt_to_bus	virt_to_phys
+
 static inline void * phys_to_virt(unsigned long address)
 {
 #ifdef __IO_DEBUG
@@ -149,6 +151,8 @@ static inline void * phys_to_virt(unsign
 	return (void *) __va(address);
 }
 
+#define bus_to_virt	phys_to_virt
+
 /*
  * Change "struct page" to physical address.
  */
diff -urNp linux-463/include/asm-ppc64/keyboard.h linux-340/include/asm-ppc64/keyboard.h
--- linux-463/include/asm-ppc64/keyboard.h
+++ linux-340/include/asm-ppc64/keyboard.h
@@ -79,7 +79,7 @@ static inline void kbd_init_hw(void)
 
 #define kbd_sysrq_xlate	(ppc_md.ppc_kbd_sysrq_xlate)
 
-extern unsigned long SYSRQ_KEY;
+#define SYSRQ_KEY	0x63
 #define E1_PAUSE	119		/* PAUSE key */
 
 /* resource allocation */
diff -urNp linux-463/include/asm-ppc64/mmu_context.h linux-340/include/asm-ppc64/mmu_context.h
--- linux-463/include/asm-ppc64/mmu_context.h
+++ linux-340/include/asm-ppc64/mmu_context.h
@@ -16,6 +16,22 @@
  * 2 of the License, or (at your option) any later version.
  */
 
+/*
+ * Every architecture must define this function. It's the fastest
+ * way of searching a 140-bit bitmap where the first 100 bits are
+ * unlikely to be set. It's guaranteed that at least one of the 140
+ * bits is cleared.
+ */
+static inline int sched_find_first_bit(unsigned long *b)
+{
+        if (unlikely(b[0]))
+                return __ffs(b[0]);
+        if (unlikely(b[1]))
+                return __ffs(b[1]) + 64;
+        return __ffs(b[2]) + 128;
+}
+
+
 #define NO_CONTEXT		0
 #define FIRST_USER_CONTEXT	0x10    /* First 16 reserved for kernel */
 #define LAST_USER_CONTEXT	0x8000  /* Same as PID_MAX for now... */
diff -urNp linux-463/include/asm-ppc64/pgtable.h linux-340/include/asm-ppc64/pgtable.h
--- linux-463/include/asm-ppc64/pgtable.h
+++ linux-340/include/asm-ppc64/pgtable.h
@@ -51,7 +51,16 @@
  */
 #define VMALLOC_START (0xD000000000000000)
 #define VMALLOC_VMADDR(x) ((unsigned long)(x))
+
+#ifndef CONFIG_SHARED_MEMORY_ADDRESSING
 #define VMALLOC_END   (VMALLOC_START + VALID_EA_BITS)
+#else
+#define VMALLOC_END   (VMALLOC_START + (VALID_EA_BITS >> 1))
+#define SMALLOC_START (VMALLOC_START + (VALID_EA_BITS >> 1) + 1)
+#define SMALLOC_END   (VMALLOC_START + VALID_EA_BITS)
+#define SMALLOC_EA_SHIFT 40
+#define SMALLOC_ESID_SHIFT 12
+#endif
 
 /*
  * Define the address range of the imalloc VM area.
@@ -189,14 +198,17 @@ extern unsigned long empty_zero_page[PAG
 /* pte_clear moved to later in this file */
 
 #define pte_pagenr(x)		((unsigned long)((pte_val(x) >> PTE_SHIFT)))
-#define pte_page(x)		(mem_map+pte_pagenr(x))
+#define pte_pfn(x)		pte_pagenr(x)
+#define pte_page(x)		pfn_to_page(pte_pfn(x))
 
 #define pmd_set(pmdp, ptep) 	(pmd_val(*(pmdp)) = (__ba_to_bpn(ptep)))
 #define pmd_none(pmd)		(!pmd_val(pmd))
 #define	pmd_bad(pmd)		((pmd_val(pmd)) == 0)
 #define	pmd_present(pmd)	((pmd_val(pmd)) != 0)
 #define	pmd_clear(pmdp)		(pmd_val(*(pmdp)) = 0)
-#define pmd_page(pmd)		(__bpn_to_ba(pmd_val(pmd)))
+#define pmd_large(pmd)		(0)
+#define pmd_page_kernel(pmd)    (__bpn_to_ba(pmd_val(pmd)))
+#define pmd_page(pmd)		virt_to_page(pmd_page_kernel(pmd))
 #define pgd_set(pgdp, pmdp)	(pgd_val(*(pgdp)) = (__ba_to_bpn(pmdp)))
 #define pgd_none(pgd)		(!pgd_val(pgd))
 #define pgd_bad(pgd)		((pgd_val(pgd)) == 0)
@@ -217,8 +229,13 @@ extern unsigned long empty_zero_page[PAG
   ((pmd_t *) pgd_page(*(dir)) + (((addr) >> PMD_SHIFT) & (PTRS_PER_PMD - 1)))
 
 /* Find an entry in the third-level page table.. */
-#define pte_offset(dir,addr) \
-  ((pte_t *) pmd_page(*(dir)) + (((addr) >> PAGE_SHIFT) & (PTRS_PER_PTE - 1)))
+#define pte_offset_kernel(dir,addr) \
+  ((pte_t *) pmd_page_kernel(*(dir)) + (((addr) >> PAGE_SHIFT) & (PTRS_PER_PTE - 1)))
+
+#define pte_offset_map(dir,addr)        pte_offset_kernel((dir), (addr))
+#define pte_offset_map_nested(dir,addr) pte_offset_kernel((dir), (addr))
+#define pte_unmap(pte)                  do { } while(0)
+#define pte_unmap_nested(pte)           do { } while(0)
 
 /* to find an entry in a kernel page-table-directory */
 /* This now only contains the vmalloc pages */
@@ -400,6 +417,8 @@ extern void build_valid_hpte(unsigned lo
 			     unsigned long pa, pte_t * ptep, 
 			     unsigned hpteflags, unsigned bolted );
 
+typedef pte_t *pte_addr_t;
+
 /* Encode and de-code a swap entry */
 #define SWP_TYPE(entry)			(((entry).val >> 1) & 0x3f)
 #define SWP_OFFSET(entry)		((entry).val >> 8)
diff -urNp linux-463/include/asm-ppc64/ppc32.h linux-340/include/asm-ppc64/ppc32.h
--- linux-463/include/asm-ppc64/ppc32.h
+++ linux-340/include/asm-ppc64/ppc32.h
@@ -76,6 +76,13 @@ struct statfs32 {
 	int f_spare[6];
 };
 
+struct ustat32 {
+	__kernel_daddr_t32      f_tfree;
+	__kernel_ino_t32        f_tinode;
+	char                    f_fname[6];
+	char                    f_fpack[6];
+};
+
 typedef union sigval32 {
 	int sival_int;
 	unsigned int sival_ptr;
diff -urNp linux-463/include/asm-ppc64/processor.h linux-340/include/asm-ppc64/processor.h
--- linux-463/include/asm-ppc64/processor.h
+++ linux-340/include/asm-ppc64/processor.h
@@ -137,7 +137,7 @@
 #define	SPRN_DBAT2U	0x21C	/* Data BAT 2 Upper Register */
 #define	SPRN_DBAT3L	0x21F	/* Data BAT 3 Lower Register */
 #define	SPRN_DBAT3U	0x21E	/* Data BAT 3 Upper Register */
-#define	SPRN_DBCR	0x3F2	/* Debug Control Regsiter */
+#define	SPRN_DBCR	0x3F2	/* Debug Control Register */
 #define	  DBCR_EDM	0x80000000
 #define	  DBCR_IDM	0x40000000
 #define	  DBCR_RST(x)	(((x) & 0x3) << 28)
@@ -191,13 +191,13 @@
 #define	  ESR_IMCB	0x20000000	/* Instr. Machine Check - Bus error */
 #define	  ESR_IMCT	0x10000000	/* Instr. Machine Check - Timeout */
 #define	  ESR_PIL	0x08000000	/* Program Exception - Illegal */
-#define	  ESR_PPR	0x04000000	/* Program Exception - Priveleged */
+#define	  ESR_PPR	0x04000000	/* Program Exception - Privileged */
 #define	  ESR_PTR	0x02000000	/* Program Exception - Trap */
 #define	  ESR_DST	0x00800000	/* Storage Exception - Data miss */
 #define	  ESR_DIZ	0x00400000	/* Storage Exception - Zone fault */
 #define	SPRN_EVPR	0x3D6	/* Exception Vector Prefix Register */
 #define	SPRN_HASH1	0x3D2	/* Primary Hash Address Register */
-#define	SPRN_HASH2	0x3D3	/* Secondary Hash Address Resgister */
+#define	SPRN_HASH2	0x3D3	/* Secondary Hash Address Register */
 #define	SPRN_HID0	0x3F0	/* Hardware Implementation Register 0 */
 #define	  HID0_EMCP	(1<<31)		/* Enable Machine Check pin */
 #define	  HID0_EBA	(1<<29)		/* Enable Bus Address Parity */
@@ -246,7 +246,7 @@
 #define	SPRN_ICTC	0x3FB	/* Instruction Cache Throttling Control Reg */
 #define	SPRN_IMISS	0x3D4	/* Instruction TLB Miss Register */
 #define	SPRN_IMMR	0x27E  	/* Internal Memory Map Register */
-#define	SPRN_L2CR	0x3F9	/* Level 2 Cache Control Regsiter */
+#define	SPRN_L2CR	0x3F9	/* Level 2 Cache Control Register */
 #define	SPRN_LR		0x008	/* Link Register */
 #define	SPRN_PBL1	0x3FC	/* Protection Bound Lower 1 */
 #define	SPRN_PBL2	0x3FE	/* Protection Bound Lower 2 */
@@ -504,7 +504,7 @@
 #define GLUE(a,b) XGLUE(a,b)
 
 /*
- * Begining of traceback info work for asm functions.
+ * Beginning of traceback info work for asm functions.
  */
 #define TB_ASM		0x000C000000000000
 #define TB_GLOBALLINK	0x0000800000000000
@@ -662,6 +662,10 @@ struct thread_struct {
 #define PPC_FLAG_32BIT		0x01
 #define PPC_FLAG_RUN_LIGHT	RUN_FLAG
 
+#ifdef CONFIG_SHARED_MEMORY_ADDRESSING
+#define PPC_FLAG_SHARED        0x4UL
+#endif
+
 #define INIT_SP		(sizeof(init_stack) + (unsigned long) &init_stack)
 
 #define INIT_THREAD  { \
@@ -754,18 +758,6 @@ static inline void prefetchw(const void 
 
 #define spin_lock_prefetch(x)	prefetchw(x)
 
-#define cpu_has_largepage()	(__is_processor(PV_POWER4) || \
-				 __is_processor(PV_POWER4p))
-
-#define cpu_has_slb()		(__is_processor(PV_POWER4) || \
-				 __is_processor(PV_POWER4p))
-
-#define cpu_has_tlbiel()	(__is_processor(PV_POWER4) || \
-				 __is_processor(PV_POWER4p))
-
-#define cpu_has_noexecute()	(__is_processor(PV_POWER4) || \
-				 __is_processor(PV_POWER4p))
-
 #endif /* ASSEMBLY */
 
 #endif /* __ASM_PPC64_PROCESSOR_H */
diff -urNp linux-463/include/asm-ppc64/rtas.h linux-340/include/asm-ppc64/rtas.h
--- linux-463/include/asm-ppc64/rtas.h
+++ linux-340/include/asm-ppc64/rtas.h
@@ -19,6 +19,11 @@
 #define RTAS_UNKNOWN_SERVICE (-1)
 #define RTAS_INSTANTIATE_MAX (1UL<<30) /* Don't instantiate rtas at/above this value */
 
+/* Error inject defines */
+#define ERRINJCT_TOKEN_LEN 24 /* Max length of an error inject token */
+#define MAX_ERRINJCT_TOKENS 8 /* Max # tokens. */
+#define WORKSPACE_SIZE 1024 
+
 /*
  * In general to call RTAS use rtas_token("string") to lookup
  * an RTAS token for the given string (e.g. "event-scan").
@@ -131,6 +136,11 @@ struct rtas_error_log {
 	unsigned char buffer[1];		/* allocated by klimit bump */
 };
 
+struct errinjct_token {
+    	char * name;
+	int value;
+};
+
 struct flash_block {
 	char *data;
 	unsigned long length;
@@ -165,15 +175,19 @@ extern void call_rtas_display_status(cha
 extern void rtas_restart(char *cmd);
 extern void rtas_power_off(void);
 extern void rtas_halt(void);
+extern int rtas_errinjct_open(void);
+extern int rtas_errinjct(unsigned int, char *, char *);
+extern int rtas_errinjct_close(unsigned int);
 
 extern struct proc_dir_entry *rtas_proc_dir;
+extern struct errinjct_token ei_token_list[MAX_ERRINJCT_TOKENS];
 
 /* Some RTAS ops require a data buffer and that buffer must be < 4G.
  * Rather than having a memory allocator, just use this buffer
  * (get the lock first), make the RTAS call.  Copy the data instead
  * of holding the buffer for long.
  */
-#define RTAS_DATA_BUF_SIZE 1024
+#define RTAS_DATA_BUF_SIZE 4096
 extern spinlock_t rtas_data_buf_lock;
 extern char rtas_data_buf[RTAS_DATA_BUF_SIZE];
 
diff -urNp linux-463/include/asm-ppc64/semaphore.h linux-340/include/asm-ppc64/semaphore.h
--- linux-463/include/asm-ppc64/semaphore.h
+++ linux-340/include/asm-ppc64/semaphore.h
@@ -81,9 +81,8 @@ static inline void down(struct semaphore
 	/*
 	 * Try to get the semaphore, take the slow path if we fail.
 	 */
-	if (atomic_dec_return(&sem->count) < 0)
+	if (unlikely(atomic_dec_return(&sem->count) < 0))
 		__down(sem);
-	smp_wmb();
 }
 
 static inline int down_interruptible(struct semaphore * sem)
@@ -94,23 +93,18 @@ static inline int down_interruptible(str
 	CHECK_MAGIC(sem->__magic);
 #endif
 
-	if (atomic_dec_return(&sem->count) < 0)
+	if (unlikely(atomic_dec_return(&sem->count) < 0))
 		ret = __down_interruptible(sem);
-	smp_wmb();
 	return ret;
 }
 
 static inline int down_trylock(struct semaphore * sem)
 {
-	int ret;
-
 #if WAITQUEUE_DEBUG
 	CHECK_MAGIC(sem->__magic);
 #endif
 
-	ret = atomic_dec_if_positive(&sem->count) < 0;
-	smp_wmb();
-	return ret;
+	return atomic_dec_if_positive(&sem->count) < 0;
 }
 
 static inline void up(struct semaphore * sem)
@@ -119,8 +113,7 @@ static inline void up(struct semaphore *
 	CHECK_MAGIC(sem->__magic);
 #endif
 
-	smp_wmb();
-	if (atomic_inc_return(&sem->count) <= 0)
+	if (unlikely(atomic_inc_return(&sem->count) <= 0))
 		__up(sem);
 }
 
diff -urNp linux-463/include/asm-ppc64/termbits.h linux-340/include/asm-ppc64/termbits.h
--- linux-463/include/asm-ppc64/termbits.h
+++ linux-340/include/asm-ppc64/termbits.h
@@ -88,6 +88,7 @@ struct termios {
 #define   TAB1	00002000
 #define   TAB2	00004000
 #define   TAB3	00006000
+#define   XTABS	00006000	/* required by POSIX to == TAB3 */
 #define CRDLY	00030000
 #define   CR0	00000000
 #define   CR1	00010000
@@ -102,7 +103,6 @@ struct termios {
 #define VTDLY	00200000
 #define   VT0	00000000
 #define   VT1	00200000
-#define XTABS	01000000 /* Hmm.. Linux/i386 considers this part of TABDLY.. */
 
 /* c_cflag bit meaning */
 #define CBAUD	0000377
diff -urNp linux-463/include/asm-ppc64/time.h linux-340/include/asm-ppc64/time.h
--- linux-463/include/asm-ppc64/time.h
+++ linux-340/include/asm-ppc64/time.h
@@ -59,6 +59,7 @@ static __inline__ void set_dec(int val)
 	if (lpaca->xLpPaca.xSharedProc) {
 		lpaca->xLpPaca.xVirtualDecr = val;
 		cur_dec = get_dec();
+ 		lpaca->xLpPaca.xSavedDecr = cur_dec;
 		if (cur_dec > val)
 			HvCall_setVirtualDecr();
 	} else
