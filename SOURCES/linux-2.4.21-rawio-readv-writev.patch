diff -urNp linux-7100/drivers/char/raw.c linux-7110/drivers/char/raw.c
--- linux-7100/drivers/char/raw.c
+++ linux-7110/drivers/char/raw.c
@@ -40,12 +40,16 @@ int	raw_ctl_ioctl(struct inode *, struct
 int	raw_ioctl(struct inode *, struct file *, unsigned int, unsigned long);
 int	raw_kvec_read(struct file *filp, kvec_cb_t cb, size_t size, loff_t pos);
 int	raw_kvec_write(struct file *filp, kvec_cb_t cb, size_t size, loff_t pos);
+ssize_t raw_readv(struct file *, const struct iovec *, unsigned long, loff_t *);
+ssize_t raw_writev(struct file *, const struct iovec *, unsigned long, loff_t *);
 
 static struct file_operations raw_fops = {
 	read:		raw_read,
 	write:		raw_write,
 	open:		raw_open,
 	release:	raw_release,
+	readv:		raw_readv,
+	writev:		raw_writev,
 	ioctl:		raw_ioctl,
 	aio_read:	generic_file_aio_read,
 	aio_write:	generic_file_aio_write,
@@ -58,6 +62,8 @@ static struct file_operations raw_ctl_fo
 	open:		raw_open,
 };
 
+extern int map_user_kiobuf_iovecs(int, struct kiobuf *, const struct iovec *, int);
+
 static int __init raw_init(void)
 {
 	int i;
@@ -488,3 +494,113 @@ out:
 	return err;
 }
 
+/*
+ * Process the readv/writev request by coalescing the iovecs into a 
+ * single kiobuf.  Some restrictions apply:  iov_base and iov_len must 
+ * be aligned to or a multiple of pagesize, and the total io size must be
+ * small enough (i.e., less than max_sectors) to go to brw_kiovec in one
+ * shot.  If these restrictions are not met, fall back to using normal
+ * read/write calls.
+ */
+ssize_t rwvec_raw_dev(int rw, struct file * filp, const struct iovec *iov, 
+		ulong iov_count, loff_t *offp)
+{
+	kdev_t	dev;
+	struct	kiobuf *iobuf;
+	ulong	blocknr, blocks, limit;
+	int	i, minor, err;
+	int	sector_size, sector_bits, sector_mask, max_sectors;
+	ssize_t	tot_len;
+
+	for (i = 0, tot_len = 0; i < iov_count; i++) {
+		ssize_t tmp = tot_len;
+		ssize_t len = (ssize_t) iov[i].iov_len;
+		ulong base = (ulong) iov[i].iov_base;
+		if ((len & ~PAGE_MASK) || (base & ~PAGE_MASK))
+			goto fallback;
+		if (len < 0)	/* size_t not fitting a ssize_t */
+			return -EINVAL;	
+		tot_len += len;
+		if (tot_len < tmp) /* math overflow on the ssize_t */
+			return -EINVAL;
+	}
+
+	minor = MINOR(filp->f_dentry->d_inode->i_rdev);
+
+	err = alloc_kiovec(1, &iobuf);
+	if (err)
+		return err;
+	iobuf->varyio = raw_devices[minor].varyio;
+
+	dev = to_kdev_t(raw_devices[minor].binding->bd_dev);
+	sector_size = raw_devices[minor].sector_size;
+	sector_bits = raw_devices[minor].sector_bits;
+	sector_mask = sector_size- 1;
+	max_sectors = KIO_MAX_SECTORS >> (sector_bits - 9);
+
+	if (blk_size[MAJOR(dev)])
+		limit = (((loff_t) blk_size[MAJOR(dev)][MINOR(dev)]) << BLOCK_SIZE_BITS) >> sector_bits;
+	else
+		limit = INT_MAX;
+
+	dprintk("rwvec_raw_dev: dev %d:%d (+%d)\n", 
+		MAJOR(dev), MINOR(dev), limit);
+
+	err = -EINVAL;
+	if ((*offp & sector_mask) || (tot_len & sector_mask))
+		goto out;
+	err = 0;
+	if (tot_len)
+		err = -ENXIO;
+	if ((*offp >> sector_bits) >= limit) 
+		goto out;
+
+	blocknr = *offp >> sector_bits;
+	blocks = tot_len >> sector_bits;
+
+	if (!blocks)
+		goto out;
+
+	if ((blocks > max_sectors) || (blocks > limit - blocknr))
+		goto fallback_free;
+
+	err = expand_kiobuf(iobuf, blocks);
+	if (err)
+		goto out;
+	err = map_user_kiobuf_iovecs(rw, iobuf, iov, iov_count);
+	if (err)
+		goto out;
+
+	for (i=0; i < blocks; i++)
+		iobuf->blocks[i] = blocknr++;
+
+	err = brw_kiovec(rw, 1, &iobuf, dev, iobuf->blocks, sector_size);
+
+	if (rw == READ && err > 0)
+		mark_dirty_kiobuf(iobuf, err);
+
+	unmap_kiobuf(iobuf);
+
+	if (err > 0) 
+		*offp += err;
+out:
+	free_kiovec(1, &iobuf);
+	return err;
+
+fallback_free:
+	free_kiovec(1, &iobuf);
+fallback:
+	return fallback_readv_writev(rw, filp, iov, iov_count, offp);
+}
+
+ssize_t raw_readv(struct file *filp, const struct iovec *iov,
+		unsigned long nr, loff_t *offp)
+{
+	return rwvec_raw_dev(READ, filp, iov, nr, offp);
+}
+
+ssize_t raw_writev(struct file *filp, const struct iovec *iov,
+		unsigned long nr, loff_t *offp) 
+{
+	return rwvec_raw_dev(WRITE, filp, iov, nr, offp);
+}
diff -urNp linux-7100/fs/read_write.c linux-7110/fs/read_write.c
--- linux-7100/fs/read_write.c
+++ linux-7110/fs/read_write.c
@@ -210,19 +210,56 @@ asmlinkage ssize_t sys_write(unsigned in
 	return ret;
 }
 
+ssize_t fallback_readv_writev(int rw, struct file *file, 
+			      const struct iovec *iov, int count,
+			      loff_t *offp)
+{
+	typedef ssize_t (*io_fn_t)(struct file *, char *, size_t, loff_t *);
+	io_fn_t fn;
+	int ret;
+	const struct iovec * vector;
+	
+	if (rw == READ)
+		fn = file->f_op->read;
+	else 
+		fn = (io_fn_t) file->f_op->write;
+	
+	ret = 0;
+	vector = iov;
+	while (count > 0) {
+		void * base;
+		size_t len;
+		ssize_t nr;
+
+		base = vector->iov_base;
+		len = vector->iov_len;
+		vector++;
+		count--;
 
+		nr = fn(file, base, len, &file->f_pos);
+
+		if (nr < 0) {
+			if (!ret) ret = nr;
+			break;
+		}
+		ret += nr;
+		if (nr != len)
+			break;
+	}
+
+	return ret;
+}
+	
 static ssize_t do_readv_writev(int type, struct file *file,
 			       const struct iovec * vector,
 			       unsigned long count)
 {
-	typedef ssize_t (*io_fn_t)(struct file *, char *, size_t, loff_t *);
 	typedef ssize_t (*iov_fn_t)(struct file *, const struct iovec *, unsigned long, loff_t *);
 
 	size_t tot_len;
 	struct iovec iovstack[UIO_FASTIOV];
 	struct iovec *iov=iovstack;
 	ssize_t ret, i;
-	io_fn_t fn;
 	iov_fn_t fnv;
 	struct inode *inode;
 
@@ -288,32 +325,8 @@ static ssize_t do_readv_writev(int type,
 		goto out;
 	}
 
-	/* VERIFY_WRITE actually means a read, as we write to user space */
-	fn = (type == VERIFY_WRITE ? file->f_op->read :
-	      (io_fn_t) file->f_op->write);
-
-	ret = 0;
-	vector = iov;
-	while (count > 0) {
-		void * base;
-		size_t len;
-		ssize_t nr;
-
-		base = vector->iov_base;
-		len = vector->iov_len;
-		vector++;
-		count--;
-
-		nr = fn(file, base, len, &file->f_pos);
-
-		if (nr < 0) {
-			if (!ret) ret = nr;
-			break;
-		}
-		ret += nr;
-		if (nr != len)
-			break;
-	}
+	ret = fallback_readv_writev(type == VERIFY_WRITE ? READ : WRITE,
+				    file, iov, count, &file->f_pos);
 
 out:
 	if (iov != iovstack)
diff -urNp linux-7100/include/linux/fs.h linux-7110/include/linux/fs.h
--- linux-7100/include/linux/fs.h
+++ linux-7110/include/linux/fs.h
@@ -1598,6 +1598,7 @@ extern void do_generic_file_read(struct 
 extern ssize_t do_generic_file_write(struct file *file,const char *buf,size_t count, loff_t *ppos);
 extern int generic_file_kvec_read(struct file *file, kvec_cb_t cb, size_t size, loff_t pos);
 extern int generic_file_kvec_write(struct file *file, kvec_cb_t cb, size_t size, loff_t pos);
+extern ssize_t fallback_readv_writev(int, struct file *, const struct iovec *, int, loff_t *);
 extern loff_t no_llseek(struct file *file, loff_t offset, int origin);
 extern loff_t generic_file_llseek(struct file *file, loff_t offset, int origin);
 extern ssize_t generic_read_dir(struct file *, char *, size_t, loff_t *);
diff -urNp linux-7100/mm/memory.c linux-7110/mm/memory.c
--- linux-7100/mm/memory.c
+++ linux-7110/mm/memory.c
@@ -2248,3 +2248,72 @@ int copy_user_to_kvec(struct kvec *to, s
 	return ret;
 }
 
+/* 
+ * Map the iovecs into a kiobuf.  
+ * Note iov_base and iov_len must be aligned to or a multiple of page size.
+ */
+int map_user_kiobuf_iovecs(int rw, struct kiobuf *iobuf, const struct iovec *iov, int iov_count)
+{
+	size_t len;
+	unsigned long va;
+	struct mm_struct *mm;
+	int i, err, iovpages, pgcount; 
+
+	/* Make sure the iobuf is not already mapped somewhere. */
+	if (iobuf->nr_pages)
+		return -EINVAL;
+
+	mm = current->mm;
+	dprintk ("map_user_kiobuf_iovecs: begin\n");
+
+	for (i=0, pgcount=0; i<iov_count; i++) {
+		va = (unsigned long)iov[i].iov_base;
+		len = iov[i].iov_len;
+		pgcount += (va + len + PAGE_SIZE - 1)/PAGE_SIZE - va/PAGE_SIZE;
+	}
+	/* mapping 0 bytes is not permitted */
+	if (!pgcount) BUG();
+	err = expand_kiobuf(iobuf, pgcount);
+	if (err)
+		return err;
+
+	iobuf->locked = 0;
+	iobuf->offset = 0;
+	iobuf->length = 0;
+
+	for (i=0, pgcount=0; i<iov_count; i++) {
+		va = (unsigned long)iov[i].iov_base;
+		len = iov[i].iov_len;
+		if (unlikely((va & ~PAGE_MASK)||(len & ~PAGE_MASK)))
+			BUG();
+		iobuf->length += len;
+
+		iovpages = (va + len + PAGE_SIZE - 1)/PAGE_SIZE - va/PAGE_SIZE;
+
+		/* Try to fault in all of the necessary pages */
+		down_read(&mm->mmap_sem);
+		/* rw==READ means read from disk, write into memory area */
+		err = __get_user_pages(current, mm, va, iovpages,
+			(rw==READ), 0, &iobuf->maplist[pgcount], NULL, 1);
+		up_read(&mm->mmap_sem);
+
+		/* return on error or in the case of a partially-mapped iovec */
+		if ((err < 0) || (err < iovpages)) {
+			iobuf->nr_pages = pgcount + (err > 0 ? err : 0);
+			unmap_kiobuf(iobuf);
+			dprintk ("map_user_kiobuf_iovecs: end %d\n", err);
+			return err < 0 ? err : -ENOMEM;
+		}
+		pgcount += iovpages;
+	}
+
+	iobuf->nr_pages = pgcount;
+	while (pgcount--) {
+		/* FIXME: flush superflous for rw==READ,
+		 * probably wrong function for rw==WRITE
+		 */
+		flush_dcache_page(iobuf->maplist[pgcount]);
+	}
+	dprintk ("map_user_kiobuf_iovecs: end OK\n");
+	return 0;
+}
