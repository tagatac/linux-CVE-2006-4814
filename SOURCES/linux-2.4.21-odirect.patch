diff -urNp linux-840/Documentation/filesystems/Locking linux-850/Documentation/filesystems/Locking
--- linux-840/Documentation/filesystems/Locking
+++ linux-850/Documentation/filesystems/Locking
@@ -135,7 +135,7 @@ prototypes:
 	int (*bmap)(struct address_space *, long);
 	int (*flushpage) (struct page *, unsigned long);
 	int (*releasepage) (struct page *, int);
-	int (*direct_IO)(int, struct inode *, struct kiobuf *, unsigned long, int);
+	int (*direct_IO)(int, struct inode *, struct kiobuf *, unsigned long, int, int, int);
 
 locking rules:
 	All may block
diff -urNp linux-840/fs/block_dev.c linux-850/fs/block_dev.c
--- linux-840/fs/block_dev.c
+++ linux-850/fs/block_dev.c
@@ -131,10 +131,10 @@ static int blkdev_get_block(struct inode
 	return 0;
 }
 
-static int blkdev_direct_IO(int rw, struct file * filp, struct kiobuf * iobuf, unsigned long blocknr, int blocksize)
+static int blkdev_direct_IO(int rw, struct file * filp, struct kiobuf * iobuf, unsigned long blocknr, int blocksize, int sectsize, int s_offset)
 {
 	struct inode * inode = filp->f_dentry->d_inode->i_mapping->host;
-	return generic_direct_IO(rw, inode, iobuf, blocknr, blocksize, blkdev_get_block);
+	return generic_direct_sector_IO(rw, inode, iobuf, blocknr, blocksize, sectsize, s_offset, blkdev_get_block, 1);
 }
 
 static int blkdev_writepage(struct page * page)
@@ -571,7 +571,12 @@ static int do_open(struct block_device *
 		if (bdev->bd_op->open)
 			ret = bdev->bd_op->open(inode, file);
 		if (!ret) {
-			bdev->bd_openers++;
+			if (!bdev->bd_openers++) {
+				int blksize = BLOCK_SIZE;
+				if (file->f_flags & O_DIRECT)
+					blksize = get_hardsect_size(dev);
+				set_blocksize(dev, blksize);
+			}
 			bdev->bd_inode->i_size = blkdev_size(dev);
 			bdev->bd_inode->i_blkbits = blksize_bits(block_size(dev));
 		} else {
@@ -669,7 +674,7 @@ struct address_space_operations def_blk_
 	sync_page: block_sync_page,
 	prepare_write: blkdev_prepare_write,
 	commit_write: blkdev_commit_write,
-	direct_IO: blkdev_direct_IO,
+	direct_sector_IO: blkdev_direct_IO,
 };
 
 struct file_operations def_blk_fops = {
diff -urNp linux-840/fs/buffer.c linux-850/fs/buffer.c
--- linux-840/fs/buffer.c
+++ linux-850/fs/buffer.c
@@ -472,26 +472,18 @@ out:
 	return ret;
 }
 
-asmlinkage long sys_fdatasync(unsigned int fd)
+int do_fdatasync(struct file *file)
 {
-	struct file * file;
-	struct dentry * dentry;
-	struct inode * inode;
 	int ret, err;
+	struct dentry *dentry;
+	struct inode *inode;
 
-	ret = -EBADF;
-	file = fget(fd);
-	if (!file)
-		goto out;
-
+	if (unlikely(!file->f_op || !file->f_op->fsync))
+		return -EINVAL;
+	
 	dentry = file->f_dentry;
 	inode = dentry->d_inode;
 
-	ret = -EINVAL;
-	if (!file->f_op || !file->f_op->fsync)
-		goto out_putf;
-
-	down(&inode->i_sem);
 	ret = filemap_fdatasync(inode->i_mapping);
 	err = file->f_op->fsync(file, dentry, 1);
 	if (err && !ret)
@@ -499,6 +491,23 @@ asmlinkage long sys_fdatasync(unsigned i
 	err = filemap_fdatawait(inode->i_mapping);
 	if (err && !ret)
 		ret = err;
+	return ret;
+}
+
+asmlinkage long sys_fdatasync(unsigned int fd)
+{
+	struct file * file;
+	struct inode *inode;
+	int ret;
+
+	ret = -EBADF;
+	file = fget(fd);
+	if (!file)
+		goto out;
+
+	inode = file->f_dentry->d_inode;
+	down(&inode->i_sem);
+	ret = do_fdatasync(file);
 	up(&inode->i_sem);
 
 out_putf:
@@ -2140,29 +2149,71 @@ int generic_block_bmap(struct address_sp
 	return tmp.b_blocknr;
 }
 
-int generic_direct_IO(int rw, struct inode * inode, struct kiobuf * iobuf, unsigned long blocknr, int blocksize, get_block_t * get_block)
+/*
+ * Main direct IO helper functions.  The on-disk mapping is constructed
+ * by consulting <get_block> on <blocksize>-sized blocks, but the actual
+ * IO is performed in <sectsize>-sized chunks, allowing
+ * sector-granularity direct IO on regular files. 
+ *
+ * It is up to the caller to ensure that sector-aligned IO is only
+ * requested if the device is known to be capable of varyIO. 
+ */
+
+int prepare_direct_IO_iobuf(int rw, struct inode * inode, 
+			    struct kiobuf * iobuf, 
+			    unsigned long blocknr, int blocksize, 
+			    int sectsize, int s_offset, 
+			    get_block_t * get_block, 
+			    int *beyond_eof)
 {
-	int i, nr_blocks, retval;
+	int j, retval = 0;
 	unsigned long * blocks = iobuf->blocks;
 	int length;
+	int sectors_per_block, sect_index = 0;
+	unsigned long sector;
+	int iosize = 0, chunksize, nr_sectors;
 
+	*beyond_eof = 0;
+	sectors_per_block = blocksize / sectsize;
 	length = iobuf->length;
-	nr_blocks = length / blocksize;
+	nr_sectors = length / sectsize;
+
+	/* Ugly, the blocks array size is currently hard-coded in iobuf.c. */
+	if (nr_sectors > KIO_MAX_SECTORS)
+		BUG();
+
 	/* build the blocklist */
-	for (i = 0; i < nr_blocks; i++, blocknr++) {
+	while (nr_sectors > 0) {
 		struct buffer_head bh;
 
 		bh.b_state = 0;
 		bh.b_dev = inode->i_dev;
 		bh.b_size = blocksize;
 
-		retval = get_block(inode, blocknr, &bh, rw == READ ? 0 : 1);
+		chunksize = sectors_per_block - s_offset;
+		if (chunksize > nr_sectors)
+			chunksize = nr_sectors;
+
+		if (((loff_t) blocknr) * blocksize >= inode->i_size) {
+			*beyond_eof = 1;
+			if (s_offset != 0 || chunksize != sectors_per_block) {
+				/* We can't safely do direct writes to a
+				 * partial filesystem block beyond EOF */
+				return -ENOTBLK;
+			}
+		}
+
+		/* Only allow get_block to create new blocks if we are safely
+		   beyond EOF.  O_DIRECT is unsafe inside sparse files. */
+		retval = get_block(inode, blocknr, &bh, 
+				   ((rw != READ) && *beyond_eof));
+
 		if (retval) {
-			if (!i)
+			if (!iosize)
 				/* report error to userspace */
 				goto out;
 			else
-				/* do short I/O utill 'i' */
+				/* do short I/O until 'i' */
 				break;
 		}
 
@@ -2171,28 +2222,74 @@ int generic_direct_IO(int rw, struct ino
 				BUG();
 			if (!buffer_mapped(&bh)) {
 				/* there was an hole in the filesystem */
-				blocks[i] = -1UL;
-				continue;
+				for (j=0; j < chunksize; j++)
+					blocks[sect_index++] = -1UL;
+				goto next;
 			}
 		} else {
 			if (buffer_new(&bh))
 				unmap_underlying_metadata(&bh);
 			if (!buffer_mapped(&bh))
-				BUG();
-		}
-		blocks[i] = bh.b_blocknr;
+				/* upper layers need to pass the error on or
+				 * fall back to buffered IO. */
+				return -ENOTBLK;
+		}
+		sector = bh.b_blocknr * sectors_per_block;
+		for (j=0; j<chunksize; j++)
+			blocks[sect_index++] = sector + s_offset + j;
+	next:
+		iosize += chunksize;
+		nr_sectors -= chunksize;
+		s_offset = 0;
+		blocknr++;
 	}
 
 	/* patch length to handle short I/O */
-	iobuf->length = i * blocksize;
-	retval = brw_kiovec(rw, 1, &iobuf, inode->i_dev, iobuf->blocks, blocksize);
+	iobuf->length = iosize * sectsize;
+
+out:
+	return retval;
+}
+
+int generic_direct_sector_IO(int rw, struct inode * inode, 
+			     struct kiobuf * iobuf, 
+			     unsigned long blocknr, int blocksize, 
+			     int sectsize, int s_offset, 
+			     get_block_t * get_block, int drop_locks)
+{
+	int retval, beyond_eof;
+	int old_length = iobuf->length;
+	
+	retval = prepare_direct_IO_iobuf(rw, inode, iobuf, blocknr, blocksize,
+					 sectsize, s_offset, get_block, 
+					 &beyond_eof);
+	if (retval)
+		goto out;
+	
+	if (drop_locks && !beyond_eof)
+		up(&inode->i_sem);
+	retval = brw_kiovec(rw, 1, &iobuf, inode->i_dev, iobuf->blocks, sectsize);
+	if (drop_locks && !beyond_eof)
+		down(&inode->i_sem);
+
 	/* restore orig length */
-	iobuf->length = length;
- out:
+	iobuf->length = old_length;
 
+ out:
 	return retval;
 }
 
+/* Compatibility old-style direct IO function */
+int generic_direct_IO(int rw, struct inode * inode, 
+		      struct kiobuf * iobuf, 
+		      unsigned long blocknr, int blocksize, 
+		      get_block_t * get_block)
+{
+	return generic_direct_sector_IO(rw, inode, iobuf, blocknr, blocksize,
+					blocksize, 0, get_block, 0);
+}
+
+
 /*
  * IO completion routine for a buffer_head being used for kiobuf IO: we
  * can't dispatch the kiobuf callback until io_count reaches 0.  
diff -urNp linux-840/fs/ext2/inode.c linux-850/fs/ext2/inode.c
--- linux-840/fs/ext2/inode.c
+++ linux-850/fs/ext2/inode.c
@@ -592,10 +592,10 @@ static int ext2_bmap(struct address_spac
 {
 	return generic_block_bmap(mapping,block,ext2_get_block);
 }
-static int ext2_direct_IO(int rw, struct file * filp, struct kiobuf * iobuf, unsigned long blocknr, int blocksize)
+static int ext2_direct_IO(int rw, struct file * filp, struct kiobuf * iobuf, unsigned long blocknr, int blocksize, int sectsize, int s_offset)
 {
 	struct inode * inode = filp->f_dentry->d_inode->i_mapping->host;
-	return generic_direct_IO(rw, inode, iobuf, blocknr, blocksize, ext2_get_block);
+	return generic_direct_sector_IO(rw, inode, iobuf, blocknr, blocksize, sectsize, s_offset, ext2_get_block, 1);
 }
 struct address_space_operations ext2_aops = {
 	readpage: ext2_readpage,
@@ -604,7 +604,7 @@ struct address_space_operations ext2_aop
 	prepare_write: ext2_prepare_write,
 	commit_write: generic_commit_write,
 	bmap: ext2_bmap,
-	direct_IO: ext2_direct_IO,
+	direct_sector_IO: ext2_direct_IO,
 };
 
 /*
diff -urNp linux-840/fs/ext3/file.c linux-850/fs/ext3/file.c
--- linux-840/fs/ext3/file.c
+++ linux-850/fs/ext3/file.c
@@ -61,7 +61,8 @@ static int ext3_open_file (struct inode 
 static ssize_t
 ext3_file_write(struct file *file, const char *buf, size_t count, loff_t *ppos)
 {
-	int ret, err;
+	int err;
+	ssize_t ret;
 	struct inode *inode = file->f_dentry->d_inode;
 
 	ret = generic_file_write(file, buf, count, ppos);
diff -urNp linux-840/fs/ext3/inode.c linux-850/fs/ext3/inode.c
--- linux-840/fs/ext3/inode.c
+++ linux-850/fs/ext3/inode.c
@@ -27,6 +27,7 @@
 #include <linux/ext3_jbd.h>
 #include <linux/jbd.h>
 #include <linux/locks.h>
+#include <linux/iobuf.h>
 #include <linux/smp_lock.h>
 #include <linux/highuid.h>
 #include <linux/quotaops.h>
@@ -732,9 +733,9 @@ err_out:
  * The BKL may not be held on entry here.  Be sure to take it early.
  */
 
-static int ext3_get_block_handle(handle_t *handle, struct inode *inode, 
-				 long iblock,
-				 struct buffer_head *bh_result, int create)
+static int
+ext3_get_block_handle(handle_t *handle, struct inode *inode, long iblock,
+		struct buffer_head *bh_result, int create, int extend_disksize)
 {
 	int err = -EIO;
 	int offsets[4];
@@ -814,16 +815,18 @@ out:
 	if (err)
 		goto cleanup;
 
-	new_size = inode->i_size;
-	/*
-	 * This is not racy against ext3_truncate's modification of i_disksize
-	 * because VM/VFS ensures that the file cannot be extended while
-	 * truncate is in progress.  It is racy between multiple parallel
-	 * instances of get_block, but we have the BKL.
-	 */
-	if (new_size > inode->u.ext3_i.i_disksize)
-		inode->u.ext3_i.i_disksize = new_size;
-
+	if (extend_disksize) {
+		/*
+		 * This is not racy against ext3_truncate's modification of
+		 * i_disksize because VM/VFS ensures that the file cannot be
+		 * extended while truncate is in progress.  It is racy between
+		 * multiple parallel instances of get_block, but we have BKL.
+		 */
+		struct ext3_inode_info *ei = EXT3_I(inode);
+		new_size = inode->i_size;
+		if (new_size > ei->i_disksize)
+			ei->i_disksize = new_size;
+	}
 	bh_result->b_state |= (1UL << BH_New);
 	goto got_it;
 
@@ -850,7 +853,38 @@ static int ext3_get_block(struct inode *
 		handle = ext3_journal_current_handle();
 		J_ASSERT(handle != 0);
 	}
-	ret = ext3_get_block_handle(handle, inode, iblock, bh_result, create);
+	ret = ext3_get_block_handle(handle, inode, iblock,
+				bh_result, create, 1);
+	return ret;
+}
+
+#define DIO_CREDITS (EXT3_RESERVE_TRANS_BLOCKS + 32)
+
+static int
+ext3_direct_io_get_block(struct inode *inode, long iblock,
+		struct buffer_head *bh_result, int create)
+{
+	handle_t *handle = journal_current_handle();
+	int ret = 0;
+
+	lock_kernel();
+	if (handle && handle->h_buffer_credits <= EXT3_RESERVE_TRANS_BLOCKS) {
+		/*
+		 * Getting low on buffer credits...
+		 */
+		if (!ext3_journal_extend(handle, DIO_CREDITS)) {
+			/*
+			 * Couldn't extend the transaction.  Start a new one
+			 */
+			ret = ext3_journal_restart(handle, DIO_CREDITS);
+		}
+	}
+	if (ret == 0)
+		ret = ext3_get_block_handle(handle, inode, iblock,
+					bh_result, create, 0);
+	if (ret == 0)
+		bh_result->b_size = (1 << inode->i_blkbits);
+	unlock_kernel();
 	return ret;
 }
 
@@ -868,7 +902,7 @@ struct buffer_head *ext3_getblk(handle_t
 	dummy.b_state = 0;
 	dummy.b_blocknr = -1000;
 	buffer_trace_init(&dummy.b_history);
-	*errp = ext3_get_block_handle(handle, inode, block, &dummy, create);
+	*errp = ext3_get_block_handle(handle, inode, block, &dummy, create, 1);
 	if (!*errp && buffer_mapped(&dummy)) {
 		struct buffer_head *bh;
 		bh = sb_getblk(inode->i_sb, dummy.b_blocknr);
@@ -1374,6 +1408,100 @@ static int ext3_releasepage(struct page 
 	return journal_try_to_free_buffers(journal, page, wait);
 }
 
+static int
+ext3_direct_IO(int rw, struct file * filp, struct kiobuf *iobuf,
+	       unsigned long blocknr, int blocksize, int sectsize, 
+	       int s_offset)
+{
+	struct inode * inode = filp->f_dentry->d_inode->i_mapping->host;
+	struct ext3_inode_info *ei = EXT3_I(inode);
+	handle_t *handle = NULL;
+	int ret, beyond_eof;
+	int orphan = 0;
+	loff_t offset = ((((loff_t) blocknr) * blocksize) +
+			 (s_offset * sectsize));	/* ugh */
+	ssize_t count = iobuf->length;			/* ditto */
+	int err = 0;
+
+	if (rw == WRITE) {
+		loff_t final_size = offset + count;
+
+		lock_kernel();
+		handle = ext3_journal_start(inode, DIO_CREDITS);
+		unlock_kernel();
+		if (IS_ERR(handle)) {
+			ret = PTR_ERR(handle);
+			goto out;
+		}
+		if (final_size > inode->i_size) {
+			lock_kernel();
+			ret = ext3_orphan_add(handle, inode);
+			unlock_kernel();
+			if (ret)
+				goto out_stop;
+			orphan = 1;
+			ei->i_disksize = inode->i_size;
+		}
+	}
+
+	ret = prepare_direct_IO_iobuf(rw, inode, iobuf, blocknr,
+				      blocksize, sectsize, s_offset,
+				      ext3_direct_io_get_block, &beyond_eof);
+
+out_stop:
+	if (handle) {
+		lock_kernel();
+		/* We need to stop the journal here: we can't retake the
+		   inode semaphore while holding the journal open as
+		   that violates lock ranking. */
+		err = ext3_journal_stop(handle, inode);
+		unlock_kernel();
+		if (!ret)
+			ret = err;
+	}
+
+	if (!ret) {
+		if (!beyond_eof)
+			up(&inode->i_sem);
+
+		ret = brw_kiovec(rw, 1, &iobuf, inode->i_dev,
+				 iobuf->blocks, sectsize);
+		iobuf->length = count;
+	
+		if (!beyond_eof)
+			down(&inode->i_sem);
+	}
+
+	if (orphan) {
+		lock_kernel();
+		handle = ext3_journal_start(inode, EXT3_SINGLEDATA_TRANS_BLOCKS);
+		if (IS_ERR(handle)) {
+			err = PTR_ERR(handle);
+			unlock_kernel();
+			goto out;
+		}
+		if (inode->i_nlink != 0)
+			ext3_orphan_del(handle, inode);
+		if (ret > 0) {
+			loff_t end = offset + ret;
+			if (end > inode->i_size) {
+				ei->i_disksize = end;
+				inode->i_size = end;
+				err = ext3_mark_inode_dirty(handle, inode);
+				if (!ret) 
+					ret = err;
+			}
+		}
+		err = ext3_journal_stop(handle, inode);
+		unlock_kernel();
+	}
+
+out:
+	if (ret == 0)
+		ret = err;
+	return ret;
+
+}
 
 struct address_space_operations ext3_aops = {
 	readpage:	ext3_readpage,		/* BKL not held.  Don't need */
@@ -1384,6 +1512,7 @@ struct address_space_operations ext3_aop
 	bmap:		ext3_bmap,		/* BKL held */
 	flushpage:	ext3_flushpage,		/* BKL not held.  Don't need */
 	releasepage:	ext3_releasepage,	/* BKL not held.  Don't need */
+	direct_sector_IO: ext3_direct_IO,	/* BKL not held.  Don't need */
 };
 
 /*
diff -urNp linux-840/fs/fcntl.c linux-850/fs/fcntl.c
--- linux-840/fs/fcntl.c
+++ linux-850/fs/fcntl.c
@@ -212,6 +212,12 @@ static int setfl(int fd, struct file * f
 	 */
 	if (!(arg & O_APPEND) && IS_APPEND(inode))
 		return -EPERM;
+	if ((arg & O_DIRECT) && !(inode->i_mapping && 
+				  inode->i_mapping->a_ops &&
+				  (inode->i_mapping->a_ops->direct_IO ||
+				   inode->i_mapping->a_ops->direct_sector_IO)))
+		return -EINVAL;
+
 
 	/* Did FASYNC state change? */
 	if ((arg ^ filp->f_flags) & FASYNC) {
diff -urNp linux-840/fs/inode.c linux-850/fs/inode.c
--- linux-840/fs/inode.c
+++ linux-850/fs/inode.c
@@ -150,6 +150,7 @@ void inode_init_once(struct inode *inode
 	INIT_LIST_HEAD(&inode->i_devices);
 	sema_init(&inode->i_sem, 1);
 	sema_init(&inode->i_zombie, 1);
+	init_rwsem(&inode->i_alloc_sem);
 	spin_lock_init(&inode->i_data.i_shared_lock);
 }
 
diff -urNp linux-840/fs/open.c linux-850/fs/open.c
--- linux-840/fs/open.c
+++ linux-850/fs/open.c
@@ -105,11 +105,13 @@ int do_truncate(struct dentry *dentry, l
 	if (length < 0)
 		return -EINVAL;
 
+	down_write(&inode->i_alloc_sem);
 	down(&inode->i_sem);
 	newattrs.ia_size = length;
 	newattrs.ia_valid = ATTR_SIZE | ATTR_CTIME;
 	error = notify_change(dentry, &newattrs);
 	up(&inode->i_sem);
+	up_write(&inode->i_alloc_sem);
 	return error;
 }
 
@@ -699,6 +701,16 @@ struct file *dentry_open(struct dentry *
 	}
 	f->f_flags &= ~(O_CREAT | O_EXCL | O_NOCTTY | O_TRUNC);
 
+	/* NB: we're sure to have correct a_ops only after f_op->open */
+	if (f->f_flags & O_DIRECT) {
+		if (!inode->i_mapping || !inode->i_mapping->a_ops ||
+		    !(inode->i_mapping->a_ops->direct_IO ||
+		      inode->i_mapping->a_ops->direct_sector_IO)) {
+			fput(f);
+			f = ERR_PTR(-EINVAL);
+		}
+	}
+
 	return f;
 
 cleanup_all:
diff -urNp linux-840/include/linux/fs.h linux-850/include/linux/fs.h
--- linux-840/include/linux/fs.h
+++ linux-850/include/linux/fs.h
@@ -403,6 +403,7 @@ struct address_space_operations {
 	int (*releasepage) (struct page *, int);
 #define KERNEL_HAS_O_DIRECT /* this is for modules out of the kernel */
 	int (*direct_IO)(int, struct file *, struct kiobuf *, unsigned long, int);
+	int (*direct_sector_IO)(int, struct file *, struct kiobuf *, unsigned long, int, int, int);
 	void (*removepage)(struct page *); /* called when page gets removed from the inode */
 };
 
@@ -464,6 +465,7 @@ struct inode {
 	unsigned long		i_version;
 	unsigned short		i_bytes;
 	struct semaphore	i_sem;
+	struct rw_semaphore	i_alloc_sem;
 	struct semaphore	i_zombie;
 	struct inode_operations	*i_op;
 	struct file_operations	*i_fop;	/* former ->i_op->default_file_ops */
@@ -1308,6 +1310,7 @@ static inline int fsync_inode_data_buffe
 	return fsync_buffers_list(&inode->i_dirty_data_buffers);
 }
 extern int inode_has_buffers(struct inode *);
+extern int do_fdatasync(struct file *);
 extern int filemap_fdatasync(struct address_space *);
 extern int filemap_fdatawait(struct address_space *);
 extern void sync_supers(kdev_t dev, int wait);
@@ -1544,7 +1547,9 @@ extern int block_sync_page(struct page *
 int generic_block_bmap(struct address_space *, long, get_block_t *);
 int generic_commit_write(struct file *, struct page *, unsigned, unsigned);
 int block_truncate_page(struct address_space *, loff_t, get_block_t *);
+extern int prepare_direct_IO_iobuf(int, struct inode *, struct kiobuf *, unsigned long, int, int, int, get_block_t *, int *);
 extern int generic_direct_IO(int, struct inode *, struct kiobuf *, unsigned long, int, get_block_t *);
+extern int generic_direct_sector_IO(int, struct inode *, struct kiobuf *, unsigned long, int, int, int, get_block_t *, int);
 extern int waitfor_one_page(struct page *);
 extern int writeout_one_page(struct page *);
 
@@ -1552,8 +1557,8 @@ extern int generic_file_mmap(struct file
 extern int file_read_actor(read_descriptor_t * desc, struct page *page, unsigned long offset, unsigned long size);
 extern ssize_t generic_file_read(struct file *, char *, size_t, loff_t *);
 extern ssize_t generic_file_write(struct file *, const char *, size_t, loff_t *);
-extern ssize_t generic_file_write_nolock(struct file *, const char *, size_t, loff_t *);
 extern void do_generic_file_read(struct file *, loff_t *, read_descriptor_t *, read_actor_t, int);
+extern ssize_t do_generic_file_write(struct file *file,const char *buf,size_t count, loff_t *ppos);
 extern int generic_file_kvec_read(struct file *file, kvec_cb_t cb, size_t size, loff_t pos);
 extern int generic_file_kvec_write(struct file *file, kvec_cb_t cb, size_t size, loff_t pos);
 extern loff_t no_llseek(struct file *file, loff_t offset, int origin);
diff -urNp linux-840/kernel/ksyms.c linux-850/kernel/ksyms.c
--- linux-840/kernel/ksyms.c
+++ linux-850/kernel/ksyms.c
@@ -237,6 +237,8 @@ EXPORT_SYMBOL(__bforget);
 EXPORT_SYMBOL(unlock_buffer);
 EXPORT_SYMBOL(__wait_on_buffer);
 EXPORT_SYMBOL(___wait_on_page);
+EXPORT_SYMBOL(prepare_direct_IO_iobuf);
+EXPORT_SYMBOL(generic_direct_sector_IO);
 EXPORT_SYMBOL(generic_direct_IO);
 EXPORT_SYMBOL(discard_bh_page);
 EXPORT_SYMBOL(block_write_full_page);
@@ -251,7 +253,7 @@ EXPORT_SYMBOL(generic_block_bmap);
 EXPORT_SYMBOL(generic_file_read);
 EXPORT_SYMBOL(do_generic_file_read);
 EXPORT_SYMBOL(generic_file_write);
-EXPORT_SYMBOL(generic_file_write_nolock);
+EXPORT_SYMBOL(do_generic_file_write);
 EXPORT_SYMBOL(generic_file_mmap);
 EXPORT_SYMBOL(generic_ro_fops);
 EXPORT_SYMBOL(generic_buffer_fdatasync);
diff -urNp linux-840/mm/filemap.c linux-850/mm/filemap.c
--- linux-840/mm/filemap.c
+++ linux-850/mm/filemap.c
@@ -1581,15 +1581,41 @@ no_cached_page:
 	UPDATE_ATIME(inode);
 }
 
-static ssize_t generic_file_direct_IO(int rw, struct file * filp, char * buf, size_t count, loff_t offset)
+/* Only files on a varyio-capable block device are allowed to do
+ * sector-aligned direct IO, and then only if the direct_sector_IO
+ * method is present.  Otherwise we need to constrain the IO to fs
+ * blocksize. */
+
+static inline int get_min_io_size(struct inode *inode)
+{
+	kdev_t dev = inode->i_dev;
+	if (inode->i_mapping->a_ops->direct_sector_IO != NULL &&
+	    get_blkdev_varyio(dev))
+		return get_hardsect_size(dev);
+	return 1 << inode->i_blkbits;
+}
+
+/*
+ * i_sem is already held on entry
+ * i_alloc_sem is taken during the function (exclusive for extends, shared for
+ * reads/overwrites)
+ * i_sem is dropped once we've mapped the new IO.
+ * i_alloc_sem is kept until the IO completes. 
+ */
+
+static ssize_t generic_file_direct_IO(int rw, struct file * filp, char * buf, size_t *d_count, loff_t offset, int *ret_errno)
 {
-	ssize_t retval;
-	int new_iobuf, chunk_size, blocksize_mask, blocksize, blocksize_bits, iosize, progress;
+	ssize_t retval, progress;
+	int new_iobuf, chunk_size, blocksize_mask, blocksize, blocksize_bits, iosize;
 	struct kiobuf * iobuf;
 	struct address_space * mapping = filp->f_dentry->d_inode->i_mapping;
 	struct inode * inode = mapping->host;
 	loff_t size = inode->i_size;
+	int sectsize = get_min_io_size(inode), good_sectsize = 0;
+	int sectsize_bits;
+	size_t count, count_orig = 0;
 
+	count = *d_count;
 	new_iobuf = 0;
 	iobuf = filp->f_iobuf;
 	if (test_and_set_bit(0, &filp->f_iobuf_lock)) {
@@ -1609,13 +1635,38 @@ static ssize_t generic_file_direct_IO(in
 	chunk_size = KIO_MAX_ATOMIC_IO << 10;
 
 	retval = -EINVAL;
-	if ((offset & blocksize_mask) || (count & blocksize_mask) || ((unsigned long) buf & blocksize_mask))
-		goto out_free;
-	if (!mapping->a_ops->direct_IO)
+
+	/* Work out the highest usable sector size that is compatible
+	 * with the input argument alignments.  If even the min sector
+	 * size doesn't work, we just fail with EINVAL. */
+	while (sectsize <= blocksize) {
+		int sectsize_mask = sectsize - 1;
+		
+		if ((offset & sectsize_mask) ||
+		    (count & sectsize_mask) ||
+		    ((unsigned long) buf & sectsize_mask))
+			break;
+		good_sectsize = sectsize;
+		sectsize *= 2;
+	}
+	if (!good_sectsize)
 		goto out_free;
+	sectsize = good_sectsize;
+	sectsize_bits = 9;
+	while (good_sectsize > 512)
+		good_sectsize >>= 1, sectsize_bits++;
+
+	/* If the last block in the file is a partial block, do I/O for a
+	 * full sector, and adjust the return value below. */
+	if ((rw == READ) && (offset + count > size)) {
+		int sectsize_mask = sectsize - 1;
 
-	if ((rw == READ) && (offset + count > size))
 		count = size - offset;
+		if (count & sectsize_mask) {
+			count_orig = count;
+			count = (count + sectsize) & ~sectsize_mask;
+		}
+	}
 
 	/*
 	 * Flush to disk exclusively the _data_, metadata must remain
@@ -1639,8 +1690,19 @@ static ssize_t generic_file_direct_IO(in
 		if (retval)
 			break;
 
-		retval = mapping->a_ops->direct_IO(rw, filp, iobuf, (offset+progress) >> blocksize_bits, blocksize);
-
+		if (mapping->a_ops->direct_sector_IO != NULL) 
+			retval = mapping->a_ops->direct_sector_IO
+				(rw, filp, iobuf,
+				 (offset+progress) >> blocksize_bits, 
+				 blocksize, sectsize, 
+				 ((offset+progress) & (blocksize_mask)) >> sectsize_bits);
+		else {
+			BUG_ON(blocksize != sectsize);
+			retval = mapping->a_ops->direct_IO
+				(rw, filp, iobuf,
+				 (offset+progress) >> blocksize_bits, 
+				 blocksize);
+		}
 		if (rw == READ && retval > 0)
 			mark_dirty_kiobuf(iobuf, retval);
 		
@@ -1649,6 +1711,8 @@ static ssize_t generic_file_direct_IO(in
 			buf += retval;
 			/* warning: weird semantics here, we're reporting a read behind the end of the file */
 			progress += retval;
+		} else {
+			*ret_errno = retval;
 		}
 
 		unmap_kiobuf(iobuf);
@@ -1656,10 +1720,15 @@ static ssize_t generic_file_direct_IO(in
 		if (retval != iosize)
 			break;
 	}
+	*d_count -= progress;
 
 	if (progress)
 		retval = progress;
 
+	/* truncate the read to the end of the file */
+	if (unlikely(count_orig && retval > count_orig && retval > 0))
+		retval = count_orig;
+
  out_free:
 	if (!new_iobuf)
 		clear_bit(0, &filp->f_iobuf_lock);
@@ -1691,7 +1760,7 @@ int file_read_actor(read_descriptor_t * 
 	return size;
 }
 
-static ssize_t generic_file_new_read(struct file * filp, char * buf, size_t count, loff_t *ppos, int flags)
+static ssize_t generic_file_new_read(struct file * filp, char * buf, size_t count, loff_t *ppos, int flags, int *ret_errno)
 {
 	ssize_t retval;
 
@@ -1727,16 +1796,22 @@ static ssize_t generic_file_new_read(str
 		loff_t pos = *ppos, size;
 		struct address_space *mapping = filp->f_dentry->d_inode->i_mapping;
 		struct inode *inode = mapping->host;
+		size_t d_count;
 
 		retval = 0;
 		if (!count)
 			goto out; /* skip atime */
+		d_count = count;
+		down_read(&inode->i_alloc_sem);
+		down(&inode->i_sem);
 		size = inode->i_size;
 		if (pos < size) {
-			retval = generic_file_direct_IO(READ, filp, buf, count, pos);
+			retval = generic_file_direct_IO(READ, filp, buf, &d_count, pos, ret_errno);
 			if (retval > 0)
 				*ppos = pos + retval;
 		}
+		up(&inode->i_sem);
+		up_read(&inode->i_alloc_sem);
 		UPDATE_ATIME(filp->f_dentry->d_inode);
 		goto out;
 	}
@@ -1748,7 +1823,8 @@ static ssize_t generic_file_new_read(str
  */
 ssize_t generic_file_read(struct file * filp, char * buf, size_t count, loff_t *ppos)
 {
-	return generic_file_new_read(filp, buf, count, ppos, 0);
+	int ret_errno = 0;
+	return generic_file_new_read(filp, buf, count, ppos, 0, &ret_errno);
 }
 
 static int file_send_actor(read_descriptor_t * desc, struct page *page, unsigned long offset , unsigned long size)
@@ -2985,42 +3061,18 @@ inline void remove_suid(struct inode *in
 }
 
 /*
- * Write to a file through the page cache. 
- *
- * We currently put everything into the page cache prior to writing it.
- * This is not a problem when writing full pages. With partial pages,
- * however, we first have to read the data into the cache, then
- * dirty the page, and finally schedule it for writing. Alternatively, we
- * could write-through just the portion of data that would go into that
- * page, but that would kill performance for applications that write data
- * line by line, and it's prone to race conditions.
- *
- * Note that this routine doesn't try to keep track of dirty pages. Each
- * file system has to do this all by itself, unfortunately.
- *							okir@monad.swb.de
+ * precheck_file_write():
+ * Check the conditions on a file descriptor prior to beginning a write
+ * on it.  Contains the common precheck code for both buffered and direct
+ * IO.
  */
-ssize_t generic_file_write_nolock(struct file * file, const char *buf,
-				  size_t count, loff_t *ppos)
+static int precheck_file_write(struct file *file, struct inode *inode,
+			       size_t *count, loff_t *ppos)
 {
-	struct address_space *mapping = file->f_dentry->d_inode->i_mapping;
-	struct inode	*inode = mapping->host;
-	unsigned long	limit = current->rlim[RLIMIT_FSIZE].rlim_cur;
-	loff_t		pos;
-	struct page	*page, *cached_page;
-	ssize_t		written;
-	long		status = 0;
 	ssize_t		err;
-	unsigned	bytes;
-
-	if ((ssize_t) count < 0)
-		return -EINVAL;
-
-	if (!access_ok(VERIFY_READ, buf, count))
-		return -EFAULT;
-
-	cached_page = NULL;
-
-	pos = *ppos;
+	unsigned long	limit = current->rlim[RLIMIT_FSIZE].rlim_cur;
+	loff_t		pos = *ppos;
+	
 	err = -EINVAL;
 	if (pos < 0)
 		goto out;
@@ -3031,11 +3083,9 @@ ssize_t generic_file_write_nolock(struct
 		goto out;
 	}
 
-	written = 0;
-
 	/* FIXME: this is for backwards compatibility with 2.4 */
 	if (!S_ISBLK(inode->i_mode) && file->f_flags & O_APPEND)
-		pos = inode->i_size;
+		*ppos = pos = inode->i_size;
 
 	/*
 	 * Check whether we've reached the file size limit.
@@ -3047,26 +3097,23 @@ ssize_t generic_file_write_nolock(struct
 			send_sig(SIGXFSZ, current, 0);
 			goto out;
 		}
-		/* Fix this up when we got to rlimit64 */
-		if (pos > 0xFFFFFFFFULL)
-			count = 0;
-		else if(count > limit - (u32)pos) {
+		if (*count > limit - (unsigned long)pos) {
 			/* send_sig(SIGXFSZ, current, 0); */
-			count = limit - (u32)pos;
+			*count = limit - (unsigned long)pos;
 		}
 	}
 
 	/*
 	 *	LFS rule 
 	 */
-	if ( pos + count > MAX_NON_LFS && !(file->f_flags&O_LARGEFILE)) {
+	if ( pos + *count > MAX_NON_LFS && !(file->f_flags&O_LARGEFILE)) {
 		if (pos >= MAX_NON_LFS) {
 			send_sig(SIGXFSZ, current, 0);
 			goto out;
 		}
-		if (count > MAX_NON_LFS - (u32)pos) {
+		if (*count > MAX_NON_LFS - (unsigned long)pos) {
 			/* send_sig(SIGXFSZ, current, 0); */
-			count = MAX_NON_LFS - (u32)pos;
+			*count = MAX_NON_LFS - (unsigned long)pos;
 		}
 	}
 
@@ -3083,7 +3130,7 @@ ssize_t generic_file_write_nolock(struct
 	if (!S_ISBLK(inode->i_mode)) {
 		if (pos >= inode->i_sb->s_maxbytes)
 		{
-			if (count || pos > inode->i_sb->s_maxbytes) {
+			if (*count || pos > inode->i_sb->s_maxbytes) {
 				send_sig(SIGXFSZ, current, 0);
 				err = -EFBIG;
 				goto out;
@@ -3091,35 +3138,71 @@ ssize_t generic_file_write_nolock(struct
 			/* zero-length writes at ->s_maxbytes are OK */
 		}
 
-		if (pos + count > inode->i_sb->s_maxbytes)
-			count = inode->i_sb->s_maxbytes - pos;
+		if (pos + *count > inode->i_sb->s_maxbytes)
+			*count = inode->i_sb->s_maxbytes - pos;
 	} else {
 		if (is_read_only(inode->i_rdev)) {
 			err = -EPERM;
 			goto out;
 		}
 		if (pos >= inode->i_size) {
-			if (count || pos > inode->i_size) {
+			if (*count || pos > inode->i_size) {
 				err = -ENOSPC;
 				goto out;
 			}
 		}
 
-		if (pos + count > inode->i_size)
-			count = inode->i_size - pos;
+		if (pos + *count > inode->i_size)
+			*count = inode->i_size - pos;
 	}
 
 	err = 0;
-	if (count == 0)
+	if (*count == 0)
 		goto out;
 
 	remove_suid(inode);
 	inode->i_ctime = inode->i_mtime = CURRENT_TIME;
 	mark_inode_dirty_sync(inode);
+	
+out:
+	return err;
+}
 
-	if (file->f_flags & O_DIRECT)
-		goto o_direct;
+/*
+ * Write to a file through the page cache. 
+ *
+ * We currently put everything into the page cache prior to writing it.
+ * This is not a problem when writing full pages. With partial pages,
+ * however, we first have to read the data into the cache, then
+ * dirty the page, and finally schedule it for writing. Alternatively, we
+ * could write-through just the portion of data that would go into that
+ * page, but that would kill performance for applications that write data
+ * line by line, and it's prone to race conditions.
+ *
+ * Note that this routine doesn't try to keep track of dirty pages. Each
+ * file system has to do this all by itself, unfortunately.
+ *							okir@monad.swb.de
+ */
+ssize_t
+do_generic_file_write(struct file *file,const char *buf,size_t count, loff_t *ppos)
+{
+	struct address_space *mapping = file->f_dentry->d_inode->i_mapping;
+	struct inode	*inode = mapping->host;
+	loff_t		pos;
+	struct page	*page, *cached_page;
+	ssize_t		written;
+	long		status = 0;
+	ssize_t		err;
+	unsigned	bytes;
 
+	cached_page = NULL;
+	pos = *ppos;
+	written = 0;
+	
+	err = precheck_file_write(file, inode, &count, &pos);
+	if (err != 0 || count == 0)
+		goto out;
+	
 	do {
 		unsigned long index, offset;
 		long page_fault;
@@ -3197,7 +3280,6 @@ done:
 			status = generic_osync_inode(inode, OSYNC_METADATA|OSYNC_DATA);
 	}
 	
-out_status:	
 	err = written ? written : status;
 out:
 
@@ -3217,9 +3299,31 @@ sync_failure:
 	if (pos + bytes > inode->i_size)
 		vmtruncate(inode, inode->i_size);
 	goto done;
+}
+
+ssize_t
+static do_generic_direct_write(struct file *file, const char *buf, size_t *d_count, loff_t *ppos, int *ret_errno)
+{
+	struct address_space *mapping = file->f_dentry->d_inode->i_mapping;
+	struct inode	*inode = mapping->host;
+	loff_t		pos;
+	ssize_t		written;
+	long		status = 0;
+	ssize_t		err;
+
+	pos = *ppos;
+	written = 0;
+	
+	err = precheck_file_write(file, inode, d_count, &pos);
+
+	if (err != 0 || *d_count == 0)
+		goto out;
+	
+	if (!file->f_flags & O_DIRECT)
+		BUG();
+
+	written = generic_file_direct_IO(WRITE, file, (char *) buf, d_count, pos, ret_errno);
 
-o_direct:
-	written = generic_file_direct_IO(WRITE, file, (char *) buf, count, pos);
 	if (written > 0) {
 		loff_t end = pos + written;
 		if (end > inode->i_size && !S_ISBLK(inode->i_mode)) {
@@ -3229,24 +3333,74 @@ o_direct:
 		*ppos = end;
 		invalidate_inode_pages2(mapping);
 	}
+
 	/*
 	 * Sync the fs metadata but not the minor inode changes and
 	 * of course not the data as we did direct DMA for the IO.
 	 */
 	if (written >= 0 && file->f_flags & O_SYNC)
 		status = generic_osync_inode(inode, OSYNC_METADATA);
-	goto out_status;
+
+	err = written ? written : status;
+out:
+	return err;
 }
 
-ssize_t generic_file_write(struct file *file, const char *buf,
-			   size_t count, loff_t *ppos)
+static ssize_t do_odirect_fallback(struct file *file, struct inode *inode,
+				   const char *buf, size_t count, loff_t *ppos)
 {
-	struct inode	*inode = file->f_dentry->d_inode->i_mapping->host;
-	int		err;
+	int err;
+	ssize_t ret;
 
 	down(&inode->i_sem);
-	err = generic_file_write_nolock(file, buf, count, ppos);
+	ret = do_generic_file_write(file, buf, count, ppos);
+	if (ret > 0) {
+		err = do_fdatasync(file);
+		if (err)
+			ret = err;
+	}
 	up(&inode->i_sem);
+	return ret;
+}
+
+ssize_t
+generic_file_write(struct file *file,const char *buf,size_t count, loff_t *ppos)
+{
+	struct inode	*inode = file->f_dentry->d_inode->i_mapping->host;
+	ssize_t		err;
+	int		ret_errno = 0;
+	size_t		d_count;
+
+	if ((ssize_t) count < 0)
+		return -EINVAL;
+
+	if (!access_ok(VERIFY_READ, buf, count))
+		return -EFAULT;
+
+	if (file->f_flags & O_DIRECT) {
+		d_count = count;
+		/* do_generic_direct_write may drop i_sem during the
+		   actual IO */
+		down_read(&inode->i_alloc_sem);
+		down(&inode->i_sem);
+		err = do_generic_direct_write(file, buf, &d_count, ppos, &ret_errno);
+		up(&inode->i_sem);
+		up_read(&inode->i_alloc_sem);
+		if (unlikely(err == -ENOTBLK || ret_errno == -ENOTBLK))  {
+			err = do_odirect_fallback(file, inode,
+				buf + (count - d_count), d_count, ppos);
+			if (err > 0)
+				err = (count - d_count) + err;
+			else if (d_count < count)
+				err = (count - d_count);
+			/* if dcount == count, then nothing has been written,
+			   so just return the error */
+		}
+	} else {
+		down(&inode->i_sem);
+		err = do_generic_file_write(file, buf, count, ppos);
+		up(&inode->i_sem);
+	}
 
 	return err;
 }
diff -urNp linux-840/mm/shmem.c linux-850/mm/shmem.c
--- linux-840/mm/shmem.c
+++ linux-850/mm/shmem.c
@@ -831,7 +831,7 @@ shmem_file_write(struct file *file,const
 	struct page	*page;
 	unsigned long	written;
 	long		status;
-	int		err;
+	ssize_t		err;
 	loff_t		maxpos;
 
 	if ((ssize_t) count < 0)
