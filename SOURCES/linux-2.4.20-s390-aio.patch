diff -urNp linux-422/arch/s390/kernel/entry.S linux-432/arch/s390/kernel/entry.S
--- linux-422/arch/s390/kernel/entry.S	
+++ linux-432/arch/s390/kernel/entry.S	
@@ -578,11 +578,11 @@ sys_call_table:
 	.long  sys_sched_getaffinity	 /* 240 */
 	.long  sys_tgkill
 	.long  sys_ni_syscall
-	.long  sys_ni_syscall
-	.long  sys_ni_syscall
-	.long  sys_ni_syscall		 /* 245 */
-	.long  sys_ni_syscall
-	.long  sys_ni_syscall
+	.long  sys_io_setup
+	.long  sys_io_destroy
+	.long  sys_io_getevents		 /* 245 */
+	.long  sys_io_submit
+	.long  sys_io_cancel
 	.long  sys_exit_group
 	.long  sys_ni_syscall
 	.long  sys_ni_syscall		 /* 250 */
diff -urNp linux-422/arch/s390/kernel/semaphore.c linux-432/arch/s390/kernel/semaphore.c
--- linux-422/arch/s390/kernel/semaphore.c	2001-04-17 20:19:25.000000000 -0400
+++ linux-432/arch/s390/kernel/semaphore.c	
@@ -10,6 +10,7 @@
  *
  */
 #include <linux/sched.h>
+#include <linux/worktodo.h>
 
 #include <asm/semaphore.h>
 
@@ -51,6 +52,69 @@ void __up(struct semaphore *sem)
 
 static spinlock_t semaphore_lock = SPIN_LOCK_UNLOCKED;
 
+void __wtd_down_from_wakeup(struct semaphore * sem, struct worktodo *wtd);
+
+void __wtd_down_action(void *data)
+{
+	struct worktodo *wtd = data;
+	struct semaphore *sem;
+
+	wtd_pop(wtd);
+	sem = wtd->data;
+
+	__wtd_down_from_wakeup(sem, wtd);
+}
+
+void __wtd_down_waiter(wait_queue_t *wait)
+{
+	struct worktodo *wtd = (struct worktodo *)wait;
+	struct semaphore *sem = wtd->data;
+
+	__remove_wait_queue(&sem->wait, &wtd->wait);
+	wtd_push(wtd, __wtd_down_action, wtd);
+	wtd_queue(wtd);
+}
+
+static void wtd_down_common(struct semaphore * sem, struct worktodo *wtd,
+    int do_incr)
+{
+	int gotit;
+	int sleepers;
+
+	init_waitqueue_func_entry(&wtd->wait, __wtd_down_waiter);
+	wtd->data = sem;
+
+	spin_lock_irq(&semaphore_lock);
+	sem->sleepers += do_incr;
+	sleepers = sem->sleepers;
+	gotit = add_wait_queue_exclusive_cond(&sem->wait, &wtd->wait,
+			atomic_add_negative(sleepers - 1, &sem->count));
+	if (gotit)
+		sem->sleepers = 0;
+	else
+		sem->sleepers = 1;
+	spin_unlock_irq(&semaphore_lock);
+
+	if (gotit) {
+		wake_up(&sem->wait);
+		wtd_queue(wtd);
+	}
+}
+
+void __wtd_down(struct semaphore * sem, struct worktodo *wtd)
+{
+	wtd_down_common(sem, wtd, 1);
+}
+
+/*
+ * Same as __wtd_down, but sem->sleepers is not incremented when
+ * coming from a wakeup.
+ */
+void __wtd_down_from_wakeup(struct semaphore * sem, struct worktodo *wtd)
+{
+	wtd_down_common(sem, wtd, 0);
+}
+
 void __down(struct semaphore * sem)
 {
 	struct task_struct *tsk = current;
diff -urNp linux-422/arch/s390x/kernel/entry.S linux-432/arch/s390x/kernel/entry.S
--- linux-422/arch/s390x/kernel/entry.S	
+++ linux-432/arch/s390x/kernel/entry.S	
@@ -616,11 +616,11 @@ sys_call_table:
 	.long  SYSCALL(sys_sched_getaffinity,sys32_sched_getaffinity_wrapper) /* 240 */
 	.long  SYSCALL(sys_tgkill,sys32_tgkill_wrapper)
 	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)
-	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)
-	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)
-	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)	/* 245 */
-	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)
-	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)
+	.long  SYSCALL(sys_io_setup,sys_ni_syscall)
+	.long  SYSCALL(sys_io_destroy,sys_ni_syscall)
+	.long  SYSCALL(sys_io_getevents,sys_ni_syscall)	/* 245 */
+	.long  SYSCALL(sys_io_submit,sys_ni_syscall)
+	.long  SYSCALL(sys_io_cancel,sys_ni_syscall)
 	.long  SYSCALL(sys_exit_group,sys32_exit_group_wrapper)
 	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)
 	.long  SYSCALL(sys_ni_syscall,sys_ni_syscall)	/* 250 */
diff -urNp linux-422/arch/s390x/kernel/semaphore.c linux-432/arch/s390x/kernel/semaphore.c
--- linux-422/arch/s390x/kernel/semaphore.c	2001-04-17 20:19:25.000000000 -0400
+++ linux-432/arch/s390x/kernel/semaphore.c	
@@ -10,6 +10,7 @@
  *
  */
 #include <linux/sched.h>
+#include <linux/worktodo.h>
 
 #include <asm/semaphore.h>
 
@@ -51,6 +52,69 @@ void __up(struct semaphore *sem)
 
 static spinlock_t semaphore_lock = SPIN_LOCK_UNLOCKED;
 
+void __wtd_down_from_wakeup(struct semaphore * sem, struct worktodo *wtd);
+
+void __wtd_down_action(void *data)
+{
+	struct worktodo *wtd = data;
+	struct semaphore *sem;
+
+	wtd_pop(wtd);
+	sem = wtd->data;
+
+	__wtd_down_from_wakeup(sem, wtd);
+}
+
+void __wtd_down_waiter(wait_queue_t *wait)
+{
+	struct worktodo *wtd = (struct worktodo *)wait;
+	struct semaphore *sem = wtd->data;
+
+	__remove_wait_queue(&sem->wait, &wtd->wait);
+	wtd_push(wtd, __wtd_down_action, wtd);
+	wtd_queue(wtd);
+}
+
+static void wtd_down_common(struct semaphore * sem, struct worktodo *wtd,
+    int do_incr)
+{
+	int gotit;
+	int sleepers;
+
+	init_waitqueue_func_entry(&wtd->wait, __wtd_down_waiter);
+	wtd->data = sem;
+
+	spin_lock_irq(&semaphore_lock);
+	sem->sleepers++;
+	sleepers = sem->sleepers;
+	gotit = add_wait_queue_exclusive_cond(&sem->wait, &wtd->wait,
+			atomic_add_negative(sleepers - 1, &sem->count));
+	if (gotit)
+		sem->sleepers = 0;
+	else
+		sem->sleepers = 1;
+	spin_unlock_irq(&semaphore_lock);
+
+	if (gotit) {
+		wake_up(&sem->wait);
+		wtd_queue(wtd);
+	}
+}
+
+void __wtd_down(struct semaphore * sem, struct worktodo *wtd)
+{
+	wtd_down_common(sem, wtd, 1);
+}
+
+/*
+ * Same as __wtd_down, but sem->sleepers is not incremented when
+ * coming from a wakeup.
+ */
+void __wtd_down_from_wakeup(struct semaphore * sem, struct worktodo *wtd)
+{
+	wtd_down_common(sem, wtd, 0);
+}
+
 void __down(struct semaphore * sem)
 {
 	struct task_struct *tsk = current;
diff -urNp linux-422/include/asm-s390/semaphore.h linux-432/include/asm-s390/semaphore.h
--- linux-422/include/asm-s390/semaphore.h	
+++ linux-432/include/asm-s390/semaphore.h	
@@ -62,6 +62,9 @@ asmlinkage int  __down_interruptible(str
 asmlinkage int  __down_trylock(struct semaphore * sem);
 asmlinkage void __up(struct semaphore * sem);
 
+struct worktodo;
+void __wtd_down(struct semaphore * sem, struct worktodo *wtd);
+
 static inline void down(struct semaphore * sem)
 {
 	if (atomic_dec_return(&sem->count) < 0)
@@ -92,6 +95,17 @@ static inline void up(struct semaphore *
 		__up(sem);
 }
 
+static inline int wtd_down(struct worktodo *wtd, struct semaphore *sem)
+{
+	int ret = 0;
+
+	if (atomic_dec_return(&sem->count) < 0) {
+		__wtd_down(sem, wtd);
+		ret = 1;
+	}
+	return ret;
+}
+
 static inline int sem_getcount(struct semaphore *sem)
 {
 	return atomic_read(&sem->count);
diff -urNp linux-422/include/asm-s390/unistd.h linux-432/include/asm-s390/unistd.h
--- linux-422/include/asm-s390/unistd.h	
+++ linux-432/include/asm-s390/unistd.h	
@@ -222,6 +222,12 @@
 #define __NR_sched_setaffinity	239
 #define __NR_sched_getaffinity	240
 #define __NR_tgkill		241
+#define __NR_io_setup		243
+#define __NR_io_destroy		244
+#define __NR_io_getevents	245
+#define __NR_io_submit		246
+#define __NR_io_cancel		247
+
 #define __NR_exit_group	248
 #define __NR_set_tid_address	252
 
diff -urNp linux-422/include/asm-s390x/semaphore.h linux-432/include/asm-s390x/semaphore.h
--- linux-422/include/asm-s390x/semaphore.h	
+++ linux-432/include/asm-s390x/semaphore.h	
@@ -62,6 +62,9 @@ asmlinkage int  __down_interruptible(str
 asmlinkage int  __down_trylock(struct semaphore * sem);
 asmlinkage void __up(struct semaphore * sem);
 
+struct worktodo;
+void __wtd_down(struct semaphore * sem, struct worktodo *wtd);
+
 static inline void down(struct semaphore * sem)
 {
 	if (atomic_dec_return(&sem->count) < 0)
@@ -92,6 +95,17 @@ static inline void up(struct semaphore *
 		__up(sem);
 }
 
+static inline int wtd_down(struct worktodo *wtd, struct semaphore *sem)
+{
+	int ret = 0;
+
+	if (atomic_dec_return(&sem->count) < 0) {
+		__wtd_down(sem, wtd);
+		ret = 1;
+	}
+	return ret;
+}
+
 static inline int sem_getcount(struct semaphore *sem)
 {
 	return atomic_read(&sem->count);
diff -urNp linux-422/include/asm-s390x/unistd.h linux-432/include/asm-s390x/unistd.h
--- linux-422/include/asm-s390x/unistd.h	
+++ linux-432/include/asm-s390x/unistd.h	
@@ -190,6 +190,12 @@
 #define __NR_sched_setaffinity	239
 #define __NR_sched_getaffinity	240
 #define __NR_tgkill		241
+#define __NR_io_setup		243
+#define __NR_io_destroy		244
+#define __NR_io_getevents	245
+#define __NR_io_submit		246
+#define __NR_io_cancel		247
+
 #define __NR_exit_group	248
 #define __NR_set_tid_address	252
 
