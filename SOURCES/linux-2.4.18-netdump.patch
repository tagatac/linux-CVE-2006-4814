diff -urNp linux-5160/Documentation/networking/netconsole.txt linux-5170/Documentation/networking/netconsole.txt
--- linux-5160/Documentation/networking/netconsole.txt
+++ linux-5170/Documentation/networking/netconsole.txt
@@ -0,0 +1,26 @@
+The netconsole module provides 3 pieces of functionality:
+
+    1) generation of syslog messages which are delivered to a remote syslog
+       server
+    2) generation of netconsole messages which are delivered to a remote
+       netdump server
+    3) a network kernel crash dump facility
+
+The configuration for the module is specified in the /etc/sysconfig/netdump
+file, which is self-documented.  Once the parameters are specified in that
+file, you can enable the module with a "service netdump start" command,
+provided you have installed the netdump rpm.
+
+Network drivers must implement a special hook in order to work with
+netconsole.  The following drivers implement this functionality, and thus
+can be used in conjunction with netconsole:
+
+    3c59x
+    b44
+    e100
+    e1000
+    eepro100
+    pcnet32
+    tg3
+    tlan
+    tulip
diff -urNp linux-5160/Documentation/sysrq.txt linux-5170/Documentation/sysrq.txt
--- linux-5160/Documentation/sysrq.txt
+++ linux-5170/Documentation/sysrq.txt
@@ -50,6 +50,10 @@ On all -  write a character to /proc/sys
 'b'     - Will immediately reboot the system without syncing or unmounting
           your disks.
 
+'c'     - Intentionally crash the system without syncing or unmounting
+          your disks.  This is most useful if the NETDUMP client package
+          has been installed.
+
 'o'     - Will shut your system off (if configured and supported).
 
 's'     - Will attempt to sync all mounted filesystems.
@@ -96,6 +100,10 @@ useful when you want to exit a program t
 re'B'oot is good when you're unable to shut down. But you should also 'S'ync
 and 'U'mount first.
 
+'C'rash immediately crashes your system.  This is most useful if the machine
+has been configured as a NETDUMP client because an OOPS report is generated
+and a kernel crash dump is sent to the NETDUMP server.
+
 'S'ync is great when your system is locked up, it allows you to sync your
 disks and will certainly lessen the chance of data loss and fscking. Note
 that the sync hasn't taken place until you see the "OK" and "Done" appear
diff -urNp linux-5160/arch/i386/kernel/Makefile linux-5170/arch/i386/kernel/Makefile
--- linux-5160/arch/i386/kernel/Makefile
+++ linux-5170/arch/i386/kernel/Makefile
@@ -14,7 +14,7 @@ all: kernel.o head.o init_task.o
 
 O_TARGET := kernel.o
 
-export-objs     := mca.o mtrr.o msr.o cpuid.o microcode.o i386_ksyms.o time.o
+export-objs     := mca.o mtrr.o msr.o cpuid.o microcode.o i386_ksyms.o time.o traps.o
 
 obj-y	:= process.o semaphore.o signal.o entry.o traps.o irq.o vm86.o \
 		ptrace.o i8259.o ioport.o ldt.o setup.o time.o sys_i386.o \
diff -urNp linux-5160/arch/i386/kernel/i386_ksyms.c linux-5170/arch/i386/kernel/i386_ksyms.c
--- linux-5160/arch/i386/kernel/i386_ksyms.c
+++ linux-5170/arch/i386/kernel/i386_ksyms.c
@@ -30,6 +30,7 @@
 #include <asm/pgalloc.h>
 #include <asm/edd.h>
 #include <asm/nmi.h>
+#include <linux/nmi.h>
 
 extern void dump_thread(struct pt_regs *, struct user *);
 extern spinlock_t rtc_lock;
@@ -149,6 +150,7 @@ EXPORT_SYMBOL(__global_cli);
 EXPORT_SYMBOL(__global_sti);
 EXPORT_SYMBOL(__global_save_flags);
 EXPORT_SYMBOL(__global_restore_flags);
+EXPORT_SYMBOL(dump_smp_call_function);
 EXPORT_SYMBOL(smp_call_function);
 
 /* TLB flushing */
@@ -156,10 +158,14 @@ EXPORT_SYMBOL(flush_tlb_page);
 EXPORT_SYMBOL_GPL(flush_tlb_mm);
 #endif
 
-#if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_PM)
+#ifdef CONFIG_X86_LOCAL_APIC
+EXPORT_SYMBOL_GPL(touch_nmi_watchdog);
+#ifdef CONFIG_PM
 EXPORT_SYMBOL_GPL(set_nmi_pm_callback);
 EXPORT_SYMBOL_GPL(unset_nmi_pm_callback);
-#endif
+#endif /* CONFIG_PM */
+#endif /* CONFIG_X86_LOCAL_APIC */
+
 #ifdef CONFIG_X86_IO_APIC
 EXPORT_SYMBOL(IO_APIC_get_PCI_irq_vector);
 #endif
@@ -202,6 +208,14 @@ EXPORT_SYMBOL(edd);
 EXPORT_SYMBOL(eddnr);
 #endif
 
+EXPORT_SYMBOL_GPL(show_mem);
+EXPORT_SYMBOL_GPL(show_state);
+EXPORT_SYMBOL_GPL(show_regs);
+extern int page_is_ram (unsigned long);
+EXPORT_SYMBOL_GPL(page_is_ram);
+extern unsigned long next_ram_page(unsigned long);
+EXPORT_SYMBOL_GPL(next_ram_page);
+
 extern unsigned long long __PAGE_KERNEL;
 EXPORT_SYMBOL_GPL(__PAGE_KERNEL);
 extern unsigned long long __supported_pte_mask;
diff -urNp linux-5160/arch/i386/kernel/process.c linux-5170/arch/i386/kernel/process.c
--- linux-5160/arch/i386/kernel/process.c
+++ linux-5170/arch/i386/kernel/process.c
@@ -412,7 +412,8 @@ void machine_restart(char * __unused)
 	 * Stop all CPUs and turn off local APICs and the IO-APIC, so
 	 * other OSs see a clean IRQ state.
 	 */
-	smp_send_stop();
+	if (!netdump_mode)
+		smp_send_stop();
 	disable_IO_APIC();
 #endif
 
diff -urNp linux-5160/arch/i386/kernel/smp.c linux-5170/arch/i386/kernel/smp.c
--- linux-5160/arch/i386/kernel/smp.c
+++ linux-5170/arch/i386/kernel/smp.c
@@ -512,6 +512,7 @@ void smp_send_reschedule_all(void)
  * static memory requirements. It also looks cleaner.
  */
 static spinlock_t call_lock = SPIN_LOCK_UNLOCKED;
+static spinlock_t dump_call_lock = SPIN_LOCK_UNLOCKED;
 
 struct call_data_struct {
 	void (*func) (void *info);
@@ -522,6 +523,65 @@ struct call_data_struct {
 };
 
 static struct call_data_struct * call_data;
+static struct call_data_struct * saved_call_data;
+
+/*
+ * dump version of smp_call_function to avoid deadlock in call_lock
+ */
+void dump_smp_call_function (void (*func) (void *info), void *info)
+{
+	static struct call_data_struct dumpdata;
+	static int dumping_cpu = -1;
+	int waitcount;
+
+	spin_lock(&dump_call_lock);
+	/*
+	 * The cpu that reaches here first will do dumping.  Only the dumping
+	 * cpu skips the if-statement below ONLY ONCE.  The other cpus freeze
+	 * themselves here.
+	 */
+	if (dumpdata.func) {
+		spin_unlock(&dump_call_lock);
+		/*
+		 * The dumping cpu reaches here in case that the netdump starts
+		 * after the diskdump fails.  In the case, the dumping cpu
+		 * needs to return to continue the netdump.  In other cases,
+		 * freezes itself by calling func().
+		 */
+		if (dumping_cpu == smp_processor_id())
+			return;
+
+		func(info);
+		for (;;);
+		/* NOTREACHED */
+	}
+
+	dumping_cpu = smp_processor_id();
+
+	/* freeze call_lock or wait for on-going IPIs to settle down */
+	waitcount = 0;
+	while (!spin_trylock(&call_lock)) {
+		if (waitcount++ > 1000) {
+			/* save original for dump analysis */
+			saved_call_data = call_data;
+			break;
+		}
+		udelay(1000);
+		barrier();
+	}
+
+	dumpdata.func = func;
+	dumpdata.info = info;
+	dumpdata.wait = 0; /* not used */
+	atomic_set(&dumpdata.started, 0); /* not used */
+	atomic_set(&dumpdata.finished, 0); /* not used */
+
+	call_data = &dumpdata;
+	mb();
+	send_IPI_allbutself(CALL_FUNCTION_VECTOR);
+	/* Don't wait */
+	spin_unlock(&dump_call_lock);
+}
 
 /*
  * this function sends a 'generic call function' IPI to all other CPUs
@@ -535,7 +595,7 @@ int smp_call_function (void (*func) (voi
  * <func> The function to run. This must be fast and non-blocking.
  * <info> An arbitrary pointer to pass to the function.
  * <nonatomic> currently unused.
- * <wait> If true, wait (atomically) until function has completed on other CPUs.
+ * <wait> If true, wait (atomically) until function has complete on other CPUs.
  * [RETURNS] 0 on success, else a negative status code. Does not return until
  * remote CPUs are nearly ready to execute <<func>> or are or have executed.
  *
diff -urNp linux-5160/arch/i386/kernel/traps.c linux-5170/arch/i386/kernel/traps.c
--- linux-5160/arch/i386/kernel/traps.c
+++ linux-5170/arch/i386/kernel/traps.c
@@ -138,7 +138,7 @@ void show_trace(unsigned long * stack)
 #if !CONFIG_FRAME_POINTER
 	int i;
 #endif
-	unsigned long addr;
+	unsigned long addr, limit;
 	/* static to not take up stackspace; if we race here too bad */
 	static char buffer[512];
 
@@ -163,7 +163,8 @@ void show_trace(unsigned long * stack)
 out:
 #else
 	i = 1;
-	while (((long) stack & (THREAD_SIZE-1)) != 0) {
+	limit = ((unsigned long)stack & ~(THREAD_SIZE - 1)) + THREAD_SIZE - 3;
+	while ((unsigned long)stack < limit) {
 		addr = *stack++;
 		if (kernel_text_address(addr)) {
 			lookup_symbol(addr, buffer, 512);
@@ -187,7 +188,7 @@ void show_trace_task(struct task_struct 
 
 void show_stack(unsigned long * esp)
 {
-	unsigned long *stack;
+	unsigned long *stack, limit;
 	int i;
 
 	// debugging aid: "show_stack(NULL);" prints the
@@ -197,8 +198,9 @@ void show_stack(unsigned long * esp)
 		esp=(unsigned long*)&esp;
 
 	stack = esp;
+	limit = ((unsigned long)stack & ~(THREAD_SIZE - 1)) + THREAD_SIZE - 3;
 	for(i=0; i < kstack_depth_to_print; i++) {
-		if (((long) stack & (THREAD_SIZE-1)) == 0)
+		if ((unsigned long)stack >= limit)
 			break;
 		if (i && ((i % 8) == 0))
 			printk("\n       ");
@@ -260,7 +262,7 @@ void show_registers(struct pt_regs *regs
 		printk("\nStack: ");
 		show_stack((unsigned long*)esp);
 
-		printk("\nCode: ");
+		printk("Code:");
 		if(regs->eip < PAGE_OFFSET)
 			goto bad;
 
@@ -272,8 +274,9 @@ bad:
 				printk(" Bad EIP value.");
 				break;
 			}
-			printk("%02x ", c);
+			printk(" %02x", c);
 		}
+		printk("\n");
 	}
 	printk("\n");
 }	
@@ -337,6 +340,13 @@ void die(const char * str, struct pt_reg
 	handle_BUG(regs);
 	printk("%s: %04lx\n", str, err & 0xffff);
 	show_registers(regs);
+	if (netdump_func)
+		netdump_func(regs);
+	if (panic_on_oops) {
+		if (netdump_func)
+			netdump_func = NULL;
+		panic("Fatal exception");
+	}
 	bust_spinlocks(0);
 	spin_unlock_irq(&die_lock);
 	do_exit(SIGSEGV);
@@ -1128,3 +1138,8 @@ void __init trap_init(void)
 	cobalt_init();
 #endif
 }
+
+#if CONFIG_X86_LOCAL_APIC
+EXPORT_SYMBOL_GPL(nmi_watchdog);
+#endif
+
diff -urNp linux-5160/arch/i386/mm/init.c linux-5170/arch/i386/mm/init.c
--- linux-5160/arch/i386/mm/init.c
+++ linux-5170/arch/i386/mm/init.c
@@ -446,7 +446,7 @@ void __init test_wp_bit(void)
 	}
 }
 
-static inline int page_is_ram (unsigned long pagenr)
+int page_is_ram (unsigned long pagenr)
 {
 	int i;
 
@@ -468,6 +468,29 @@ static inline int page_is_ram (unsigned 
 	return 0;
 }
 
+unsigned long next_ram_page(unsigned long pagenr)
+{
+	int i;
+	unsigned long addr, end;
+	unsigned long min_pageno = ULONG_MAX;
+
+	pagenr++;
+
+	for (i = 0; i < e820.nr_map; i++) {
+
+		if (e820.map[i].type != E820_RAM)	/* not usable memory */
+			continue;
+
+		addr = (e820.map[i].addr+PAGE_SIZE-1) >> PAGE_SHIFT;
+		end = (e820.map[i].addr+e820.map[i].size) >> PAGE_SHIFT;
+		if  ((pagenr >= addr) && (pagenr < end))
+			return pagenr;
+		if ((pagenr < addr) && (addr < min_pageno))
+			min_pageno = addr;
+	}
+	return min_pageno;
+}
+
 static inline int page_kills_ppro(unsigned long pagenr)
 {
 	if(pagenr >= 0x70000 && pagenr <= 0x7003F)
diff -urNp linux-5160/arch/ia64/kernel/ia64_ksyms.c linux-5170/arch/ia64/kernel/ia64_ksyms.c
--- linux-5160/arch/ia64/kernel/ia64_ksyms.c
+++ linux-5170/arch/ia64/kernel/ia64_ksyms.c
@@ -88,6 +88,7 @@ EXPORT_SYMBOL(smp_flush_tlb_all);
 EXPORT_SYMBOL(synchronize_irq);
 
 #include <asm/smp.h>
+EXPORT_SYMBOL(dump_smp_call_function);
 EXPORT_SYMBOL(smp_call_function);
 EXPORT_SYMBOL(smp_call_function_single);
 EXPORT_SYMBOL(cpu_online_map);
@@ -180,3 +181,19 @@ EXPORT_SYMBOL_GPL(iosapic_fixup_pci_inte
 
 #include <linux/efi.h>
 EXPORT_SYMBOL(efi_mem_type);
+
+#include <asm/unwind.h>
+extern void ia64_freeze_cpu (struct unw_frame_info *info, void *arg);
+EXPORT_SYMBOL(ia64_freeze_cpu);
+extern void ia64_start_dump(struct unw_frame_info *, void *arg);
+EXPORT_SYMBOL(ia64_start_dump);
+
+extern int page_is_ram (unsigned long pagenr);
+EXPORT_SYMBOL(page_is_ram);
+EXPORT_SYMBOL(unw_init_running);
+extern unsigned long next_ram_page(unsigned long);
+EXPORT_SYMBOL_GPL(next_ram_page);
+
+EXPORT_SYMBOL_GPL(show_mem);
+EXPORT_SYMBOL_GPL(show_state);
+EXPORT_SYMBOL_GPL(show_regs);
diff -urNp linux-5160/arch/ia64/kernel/smp.c linux-5170/arch/ia64/kernel/smp.c
--- linux-5160/arch/ia64/kernel/smp.c
+++ linux-5170/arch/ia64/kernel/smp.c
@@ -59,6 +59,7 @@ spinlock_t kernel_flag __cacheline_align
  * requirements. It also looks cleaner.
  */
 static spinlock_t call_lock = SPIN_LOCK_UNLOCKED;
+static spinlock_t dump_call_lock = SPIN_LOCK_UNLOCKED;
 
 struct call_data_struct {
 	void (*func) (void *info);
@@ -69,6 +70,7 @@ struct call_data_struct {
 };
 
 static volatile struct call_data_struct *call_data;
+static volatile struct call_data_struct *saved_call_data;
 
 #define IPI_CALL_FUNC		0
 #define IPI_CPU_STOP		1
@@ -255,6 +257,64 @@ smp_call_function_single (int cpuid, voi
 }
 
 /*
+ * dump version of smp_call_function to avoid deadlock in call_lock
+ */
+void dump_smp_call_function (void (*func) (void *info), void *info)
+{
+	static struct call_data_struct dumpdata;
+	static int dumping_cpu = -1;
+	int waitcount;
+
+	spin_lock(&dump_call_lock);
+	/*
+	 * The cpu that reaches here first will do dumping.  Only the dumping
+	 * cpu skips the if-statement below ONLY ONCE.  The other cpus freeze
+	 * themselves here.
+	 */
+	if (dumpdata.func) {
+		spin_unlock(&dump_call_lock);
+		/*
+		 * The dumping cpu reaches here in case that the netdump starts
+		 * after the diskdump fails.  In the case, the dumping cpu
+		 * needs to return to continue the netdump.  In other cases,
+		 * freezes itself by calling func().
+		 */
+		if (dumping_cpu == smp_processor_id())
+			return;
+
+		func(info);
+		for (;;);
+		/* NOTREACHED */
+	}
+
+	dumping_cpu = smp_processor_id();
+
+	/* freeze call_lock or wait for on-going IPIs to settle down */
+	waitcount = 0;
+	while (!spin_trylock(&call_lock)) {
+		if (waitcount++ > 1000) {
+			/* save original for dump analysis */
+			saved_call_data = call_data;
+			break;
+		}
+		udelay(1000);
+		barrier();
+	}
+
+	dumpdata.func = func;
+	dumpdata.info = info;
+	dumpdata.wait = 0; /* not used */
+	atomic_set(&dumpdata.started, 0); /* not used */
+	atomic_set(&dumpdata.finished, 0); /* not used */
+
+	call_data = &dumpdata;
+	mb();
+	send_IPI_allbutself(IPI_CALL_FUNC);
+	/* Don't wait */
+	spin_unlock(&dump_call_lock);
+}
+
+/*
  * this function sends a 'generic call function' IPI to all other CPUs
  * in the system.
  */
diff -urNp linux-5160/arch/ia64/kernel/traps.c linux-5170/arch/ia64/kernel/traps.c
--- linux-5160/arch/ia64/kernel/traps.c
+++ linux-5170/arch/ia64/kernel/traps.c
@@ -116,6 +116,13 @@ die (const char *str, struct pt_regs *re
   	} else
 		printk(KERN_ERR "Recursive die() failure, output suppressed\n");
 
+	if (netdump_func)
+		netdump_func(regs);
+	if (panic_on_oops) {
+		if (netdump_func)
+			netdump_func = NULL;
+		panic("Fatal exception");
+	}
 	bust_spinlocks(0);
 	die.lock_owner = -1;
 	spin_unlock_irq(&die.lock);
diff -urNp linux-5160/arch/ia64/mm/init.c linux-5170/arch/ia64/mm/init.c
--- linux-5160/arch/ia64/mm/init.c
+++ linux-5170/arch/ia64/mm/init.c
@@ -53,6 +53,92 @@ unsigned long vmalloc_end = VMALLOC_END_
 static struct page *vmem_map;
 static unsigned long num_dma_physpages;
 
+struct curr_mem_request {
+	unsigned long requested;
+	unsigned long min_physaddr;
+	int found;
+};
+
+/*
+ *  Check whether a physical address fits within the memory descriptor
+ *  block sent from efi_mmap_walk(). If it fits, set found.
+ */
+static int
+verify_physaddr (unsigned long start, unsigned long end, void *arg)
+{
+	struct curr_mem_request *cr = (struct curr_mem_request *)arg;
+
+	start = __pa(start);
+	end = __pa(end);
+
+	if ((cr->requested >= start) && (cr->requested + PAGE_SIZE) <= end) {
+		cr->found = 1;
+		return -1;
+	}
+
+	return 0;
+}
+
+/* 
+ * If physical page 'nr' is valid RAM then return 1.  Otherwise return 0.
+ */
+int
+page_is_ram (unsigned long pagenr)
+{
+	struct curr_mem_request cr;
+
+	if (pagenr >= max_mapnr)
+		return 0;
+
+	cr.requested = pagenr << PAGE_SHIFT;
+	cr.found = 0;
+
+	efi_memmap_walk(verify_physaddr, &cr);
+
+	return cr.found;
+}
+
+static int
+find_next (unsigned long start, unsigned long end, void *arg)
+{
+	struct curr_mem_request *cr = (struct curr_mem_request *)arg;
+
+	start = __pa(start);
+	end = __pa(end);
+
+	if ((cr->requested >= start) && (cr->requested + PAGE_SIZE) <= end) {
+		cr->min_physaddr = cr->requested;
+		cr->found = 1;
+		return -1;
+	}
+	if ((cr->requested < start) && (start + PAGE_SIZE) <= end)
+		if (start < cr->min_physaddr) {
+			cr->min_physaddr = start;
+			cr->found = 1;
+		}
+
+	return 0;
+}
+
+unsigned long
+next_ram_page (unsigned long pagenr)
+{
+	struct curr_mem_request cr;
+
+	pagenr++;
+
+	cr.requested = pagenr << PAGE_SHIFT;
+	cr.found = 0;
+	cr.min_physaddr = ULONG_MAX;
+
+	efi_memmap_walk(find_next, &cr);
+
+	if (cr.found)
+		return cr.min_physaddr >> PAGE_SHIFT;
+	else
+		return ULONG_MAX;
+}
+
 int
 do_check_pgt_cache (int low, int high)
 {
diff -urNp linux-5160/arch/ppc64/kernel/ppc_ksyms.c linux-5170/arch/ppc64/kernel/ppc_ksyms.c
--- linux-5160/arch/ppc64/kernel/ppc_ksyms.c
+++ linux-5170/arch/ppc64/kernel/ppc_ksyms.c
@@ -193,6 +193,14 @@ EXPORT_SYMBOL(_outsl_ns);
 EXPORT_SYMBOL(ioremap);
 EXPORT_SYMBOL(__ioremap);
 EXPORT_SYMBOL(iounmap);
+EXPORT_SYMBOL(show_mem);
+EXPORT_SYMBOL(show_state);
+EXPORT_SYMBOL(show_regs);
+extern int page_is_ram (unsigned long);
+EXPORT_SYMBOL(page_is_ram);
+extern unsigned long next_ram_page(unsigned long);
+EXPORT_SYMBOL_GPL(next_ram_page);
+
 
 #ifdef CONFIG_PCI
 EXPORT_SYMBOL(pci_alloc_consistent);
@@ -239,6 +247,8 @@ EXPORT_SYMBOL(__global_cli);
 EXPORT_SYMBOL(__global_sti);
 EXPORT_SYMBOL(__global_save_flags);
 EXPORT_SYMBOL(__global_restore_flags);
+EXPORT_SYMBOL(smp_call_function);
+EXPORT_SYMBOL(dump_smp_call_function);
 #ifdef CONFIG_PPC_ISERIES
 EXPORT_SYMBOL(__no_use_restore_flags);
 EXPORT_SYMBOL(__no_use_save_flags);
diff -urNp linux-5160/arch/ppc64/kernel/smp.c linux-5170/arch/ppc64/kernel/smp.c
--- linux-5160/arch/ppc64/kernel/smp.c
+++ linux-5170/arch/ppc64/kernel/smp.c
@@ -489,6 +489,7 @@ void smp_send_stop(void)
  * Stolen from the i386 version.
  */
 static spinlock_t call_lock __cacheline_aligned_in_smp = SPIN_LOCK_UNLOCKED;
+static spinlock_t dump_call_lock __cacheline_aligned_in_smp = SPIN_LOCK_UNLOCKED;
 
 static struct call_data_struct {
 	void (*func) (void *info);
@@ -496,7 +497,52 @@ static struct call_data_struct {
 	atomic_t started;
 	atomic_t finished;
 	int wait;
-} *call_data;
+};
+
+static struct call_data_struct *call_data;
+static struct call_data_struct *saved_call_data;
+
+/*
+ * dump version of smp_call_function to avoid deadlock in call_lock
+ */
+void dump_smp_call_function (void (*func) (void *info), void *info)
+{
+	struct call_data_struct dumpdata;
+	int waitcount;
+
+	spin_lock_bh(&dump_call_lock);
+	/* if another cpu beat us, they win! */
+	if (dumpdata.func) {
+		spin_unlock(&dump_call_lock);
+		func(info);
+		for (;;);
+		/* NOTREACHED */
+	}
+
+	/* freeze call_lock or wait for on-going IPIs to settle down */
+	waitcount = 0;
+	while (!spin_trylock(&call_lock)) {
+		if (waitcount++ > 1000) {
+			/* save original for dump analysis */
+			saved_call_data = call_data;
+			break;
+		}
+		udelay(1000);
+		barrier();
+	}
+
+	dumpdata.func = func;
+	dumpdata.info = info;
+	dumpdata.wait = 0; /* not used */
+	atomic_set(&dumpdata.started, 0); /* not used */
+	atomic_set(&dumpdata.finished, 0); /* not used */
+
+	call_data = &dumpdata;
+	mb();
+	smp_message_pass(MSG_ALL_BUT_SELF, PPC_MSG_CALL_FUNCTION, 0, 0);
+	/* Don't wait */
+	spin_unlock_bh(&dump_call_lock);
+}
 
 /*
  * This function sends a 'generic call function' IPI to all other CPUs
diff -urNp linux-5160/arch/ppc64/kernel/traps.c linux-5170/arch/ppc64/kernel/traps.c
--- linux-5160/arch/ppc64/kernel/traps.c
+++ linux-5170/arch/ppc64/kernel/traps.c
@@ -108,6 +108,9 @@ _exception(int signr, siginfo_t *info, s
 	if (!user_mode(regs))
 	{
 		show_regs(regs);
+		if (netdump_func)
+			netdump_func(regs);
+
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 		debugger(regs);
 #endif
@@ -294,6 +297,8 @@ MachineCheckException(struct pt_regs *re
 	printk(KERN_EMERG "Unrecoverable Machine check.\n");
 	printk(KERN_EMERG "Caused by (from SRR1=%lx): ", regs->msr);
 	show_regs(regs);
+	if (netdump_func)
+		netdump_func(regs);
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 	debugger(regs);
 #endif
@@ -307,6 +312,8 @@ MachineCheckException(struct pt_regs *re
 void
 SMIException(struct pt_regs *regs)
 {
+	if (netdump_func)
+		netdump_func(regs);
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 	{
 		debugger(regs);
diff -urNp linux-5160/arch/ppc64/mm/fault.c linux-5170/arch/ppc64/mm/fault.c
--- linux-5160/arch/ppc64/mm/fault.c
+++ linux-5170/arch/ppc64/mm/fault.c
@@ -237,6 +237,8 @@ bad_page_fault(struct pt_regs *regs, uns
 
 	/* kernel has accessed a bad area */
 	show_regs(regs);
+	if (netdump_func)
+		netdump_func(regs);
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 	if (debugger_kernel_faults)
 		debugger(regs);
diff -urNp linux-5160/arch/ppc64/mm/init.c linux-5170/arch/ppc64/mm/init.c
--- linux-5160/arch/ppc64/mm/init.c
+++ linux-5170/arch/ppc64/mm/init.c
@@ -303,6 +303,56 @@ void iounmap(void *addr) 
 #endif
 }
 
+int
+page_is_ram(unsigned long pfn)
+{
+	int i;
+	unsigned long paddr = pfn << PAGE_SHIFT;
+
+	for (i=0; i < lmb.memory.cnt; i++) {
+		unsigned long base;
+
+#ifdef CONFIG_MSCHUNKS
+		base = lmb.memory.region[i].physbase;
+#else
+		base = lmb.memory.region[i].base;
+#endif
+		if ((paddr >= base) &&
+			(paddr < (base + lmb.memory.region[i].size))) {
+			return 1;
+		}
+	}
+                                                                                
+	return 0;
+}
+
+unsigned long next_ram_page(unsigned long pfn)
+{
+        int i;
+        unsigned long paddr, base;
+        unsigned long best_base = (ULONG_MAX << PAGE_SHIFT);
+
+        pfn++;
+        paddr = (pfn << PAGE_SHIFT);
+
+        for (i=0; i < lmb.memory.cnt; i++) {
+#ifdef CONFIG_MSCHUNKS
+                base = lmb.memory.region[i].physbase;
+#else
+                base = lmb.memory.region[i].base;
+#endif
+                if ((paddr >= base)
+                    && (paddr < (base + lmb.memory.region[i].size)))
+                        return (paddr >> PAGE_SHIFT);
+                if ((paddr < base) && (base < best_base))
+                        best_base = base;
+        }
+        if (best_base < (ULONG_MAX << PAGE_SHIFT))
+                return (best_base >> PAGE_SHIFT);
+        else
+                return ULONG_MAX;
+}
+
 /*
  * map_io_page currently only called by __ioremap
  * map_io_page adds an entry to the ioremap page table
diff -urNp linux-5160/arch/s390/kernel/traps.c linux-5170/arch/s390/kernel/traps.c
--- linux-5160/arch/s390/kernel/traps.c
+++ linux-5170/arch/s390/kernel/traps.c
@@ -338,6 +338,13 @@ void die(const char * str, struct pt_reg
 	bust_spinlocks(1);
         printk("%s: %04lx\n", str, err & 0xffff);
         show_regs(regs);
+	if (netdump_func)
+		netdump_func(regs);
+	if (panic_on_oops) {
+		if (netdump_func)
+			netdump_func = NULL;
+		panic("Fatal exception");
+	}
 	bust_spinlocks(0);
         spin_unlock_irq(&die_lock);
         do_exit(SIGSEGV);
diff -urNp linux-5160/arch/s390x/kernel/traps.c linux-5170/arch/s390x/kernel/traps.c
--- linux-5160/arch/s390x/kernel/traps.c
+++ linux-5170/arch/s390x/kernel/traps.c
@@ -342,6 +342,13 @@ void die(const char * str, struct pt_reg
 	bust_spinlocks(1);
         printk("%s: %04lx\n", str, err & 0xffff);
         show_regs(regs);
+	if (netdump_func)
+		netdump_func(regs);
+	if (panic_on_oops) {
+		if (netdump_func)
+			netdump_func = NULL;
+		panic("Fatal exception");
+	}
 	bust_spinlocks(0);
         spin_unlock_irq(&die_lock);
         do_exit(SIGSEGV);
diff -urNp linux-5160/arch/x86_64/kernel/smp.c linux-5170/arch/x86_64/kernel/smp.c
--- linux-5160/arch/x86_64/kernel/smp.c
+++ linux-5170/arch/x86_64/kernel/smp.c
@@ -331,6 +331,7 @@ void smp_send_reschedule(int cpu)
  * static memory requirements. It also looks cleaner.
  */
 static spinlock_t call_lock = SPIN_LOCK_UNLOCKED;
+static spinlock_t dump_call_lock = SPIN_LOCK_UNLOCKED;
 
 struct call_data_struct {
 	void (*func) (void *info);
@@ -341,6 +342,65 @@ struct call_data_struct {
 };
 
 static struct call_data_struct * call_data;
+static struct call_data_struct * saved_call_data;
+
+/*
+ * dump version of smp_call_function to avoid deadlock in call_lock
+ */
+void dump_smp_call_function (void (*func) (void *info), void *info)
+{
+	static struct call_data_struct dumpdata;
+	static int dumping_cpu = -1;
+	int waitcount;
+
+	spin_lock(&dump_call_lock);
+	/*
+	 * The cpu that reaches here first will do dumping.  Only the dumping
+	 * cpu skips the if-statement below ONLY ONCE.  The other cpus freeze
+	 * themselves here.
+	 */
+	if (dumpdata.func) {
+		spin_unlock(&dump_call_lock);
+		/*
+		 * The dumping cpu reaches here in case that the netdump starts
+		 * after the diskdump fails.  In the case, the dumping cpu
+		 * needs to return to continue the netdump.  In other cases,
+		 * freezes itself by calling func().
+		 */
+		if (dumping_cpu == smp_processor_id())
+			return;
+
+		func(info);
+		for (;;);
+		/* NOTREACHED */
+	}
+
+	dumping_cpu = smp_processor_id();
+
+	/* freeze call_lock or wait for on-going IPIs to settle down */
+	waitcount = 0;
+	while (!spin_trylock(&call_lock)) {
+		if (waitcount++ > 1000) {
+			/* save original for dump analysis */
+			saved_call_data = call_data;
+			break;
+		}
+		udelay(1000);
+		barrier();
+	}
+
+	dumpdata.func = func;
+	dumpdata.info = info;
+	dumpdata.wait = 0; /* not used */
+	atomic_set(&dumpdata.started, 0); /* not used */
+	atomic_set(&dumpdata.finished, 0); /* not used */
+
+	call_data = &dumpdata;
+	wmb();
+	send_IPI_allbutself(CALL_FUNCTION_VECTOR);
+	/* Don't wait */
+	spin_unlock(&dump_call_lock);
+}
 
 /*
  * this function sends a 'generic call function' IPI to all other CPUs
@@ -354,7 +414,7 @@ int smp_call_function (void (*func) (voi
  * <func> The function to run. This must be fast and non-blocking.
  * <info> An arbitrary pointer to pass to the function.
  * <nonatomic> currently unused.
- * <wait> If true, wait (atomically) until function has completed on other CPUs.
+ * <wait> If true, wait (atomically) until function has complete on other CPUs.
  * [RETURNS] 0 on success, else a negative status code. Does not return until
  * remote CPUs are nearly ready to execute <<func>> or are or have executed.
  *
diff -urNp linux-5160/arch/x86_64/kernel/traps.c linux-5170/arch/x86_64/kernel/traps.c
--- linux-5160/arch/x86_64/kernel/traps.c
+++ linux-5170/arch/x86_64/kernel/traps.c
@@ -313,7 +313,7 @@ void show_registers(struct pt_regs *regs
 		printk("Stack: ");
 		show_stack((unsigned long*)rsp);
 
-		printk("\nCode: ");
+		printk("\nCode:");
 		if(regs->rip < PAGE_OFFSET)
 			goto bad;
 
@@ -325,8 +325,9 @@ bad:
 				printk(" Bad RIP value.");
 				break;
 			}
-			printk("%02x ", c);
+			printk(" %02x", c);
 		}
+		printk("\n");
 	}
 	printk("\n");
 }	
@@ -371,6 +372,13 @@ void die(const char * str, struct pt_reg
 	}
 	die_owner = cpu; 
 	show_registers(regs);
+	if (netdump_func)
+		netdump_func(regs);
+	if (panic_on_oops) {
+		if (netdump_func)
+			netdump_func = NULL;
+		panic("Fatal exception");
+	}
 	bust_spinlocks(0);
 	spin_unlock_irq(&die_lock);
 	do_exit(SIGSEGV);
diff -urNp linux-5160/arch/x86_64/kernel/x8664_ksyms.c linux-5170/arch/x86_64/kernel/x8664_ksyms.c
--- linux-5160/arch/x86_64/kernel/x8664_ksyms.c
+++ linux-5170/arch/x86_64/kernel/x8664_ksyms.c
@@ -121,6 +121,7 @@ EXPORT_SYMBOL(__global_cli);
 EXPORT_SYMBOL(__global_sti);
 EXPORT_SYMBOL(__global_save_flags);
 EXPORT_SYMBOL(__global_restore_flags);
+EXPORT_SYMBOL(dump_smp_call_function);
 EXPORT_SYMBOL(smp_call_function);
 
 /* TLB flushing */
@@ -237,3 +238,14 @@ EXPORT_SYMBOL_GPL(execve);
 
 extern int swiotlb;
 EXPORT_SYMBOL(swiotlb);
+
+extern int page_is_ram(unsigned long);
+EXPORT_SYMBOL_GPL(page_is_ram);
+extern int kern_addr_valid(unsigned long addr);
+EXPORT_SYMBOL_GPL(kern_addr_valid);
+extern unsigned long next_ram_page(unsigned long);
+EXPORT_SYMBOL_GPL(next_ram_page);
+
+EXPORT_SYMBOL_GPL(show_mem);
+EXPORT_SYMBOL_GPL(show_state);
+EXPORT_SYMBOL_GPL(show_regs);
diff -urNp linux-5160/arch/x86_64/mm/init.c linux-5170/arch/x86_64/mm/init.c
--- linux-5160/arch/x86_64/mm/init.c
+++ linux-5170/arch/x86_64/mm/init.c
@@ -325,8 +325,9 @@ void __init paging_init(void)
 	}
 	free_area_init(zones_size);
 }
+#endif
 
-static inline int page_is_ram (unsigned long pagenr)
+int page_is_ram(unsigned long pagenr)
 {
 	int i;
 
@@ -347,7 +348,29 @@ static inline int page_is_ram (unsigned 
 	}
 	return 0;
 }
-#endif
+
+unsigned long next_ram_page (unsigned long pagenr)
+{
+	int i;
+	unsigned long min_pageno = ULONG_MAX;
+
+	pagenr++;
+
+	for (i = 0; i < e820.nr_map; i++) {
+		unsigned long addr, end;
+
+		if (e820.map[i].type != E820_RAM)	/* not usable memory */
+			continue;
+
+		addr = (e820.map[i].addr+PAGE_SIZE-1) >> PAGE_SHIFT;
+		end = (e820.map[i].addr+e820.map[i].size) >> PAGE_SHIFT;
+		if  ((pagenr >= addr) && (pagenr < end))
+			return pagenr;
+		if ((pagenr < addr) && (addr < min_pageno))
+			min_pageno = addr;
+	}
+	return min_pageno;
+}
 
 void __init mem_init(void)
 {
diff -urNp linux-5160/drivers/char/sysrq.c linux-5170/drivers/char/sysrq.c
--- linux-5160/drivers/char/sysrq.c
+++ linux-5170/drivers/char/sysrq.c
@@ -112,6 +112,16 @@ static struct sysrq_key_op sysrq_reboot_
 	action_msg:	"Resetting",
 };
 
+/* crash sysrq handler */
+static void sysrq_handle_crash(int key, struct pt_regs *pt_regs,
+		struct kbd_struct *kbd, struct tty_struct *tty) {
+	*( (char *) 0) = 0;
+}
+static struct sysrq_key_op sysrq_crash_op = {
+	handler:        sysrq_handle_crash,
+	help_msg:       "Crash",
+	action_msg:     "Crashing the kernel by request",
+};
 
 
 /* SYNC SYSRQ HANDLERS BLOCK */
@@ -374,7 +384,7 @@ static struct sysrq_key_op *sysrq_key_ta
 		 it is handled specially on the spark
 		 and will never arive */
 /* b */	&sysrq_reboot_op,
-/* c */	NULL,
+/* c */ &sysrq_crash_op,
 /* d */	NULL,
 /* e */	&sysrq_term_op,
 /* f */	NULL,
diff -urNp linux-5160/drivers/net/Config.in linux-5170/drivers/net/Config.in
--- linux-5160/drivers/net/Config.in
+++ linux-5170/drivers/net/Config.in
@@ -286,6 +286,8 @@ if [ "$CONFIG_FDDI" = "y" ]; then
    dep_tristate '  SysKonnect FDDI PCI support' CONFIG_SKFP $CONFIG_PCI
 fi
 
+tristate 'Network logging support' CONFIG_NETCONSOLE
+
 if [ "$CONFIG_EXPERIMENTAL" = "y" ]; then
    if [ "$CONFIG_INET" = "y" ]; then
       bool 'HIPPI driver support (EXPERIMENTAL)' CONFIG_HIPPI
diff -urNp linux-5160/drivers/net/Makefile linux-5170/drivers/net/Makefile
--- linux-5160/drivers/net/Makefile
+++ linux-5170/drivers/net/Makefile
@@ -240,6 +240,8 @@ subdir-y	+= ../acorn/net
 obj-y		+= ../acorn/net/acorn-net.o
 endif
 
+obj-$(CONFIG_NETCONSOLE) += netconsole.o
+
 #
 # HIPPI adapters
 #
diff -urNp linux-5160/drivers/net/netconsole.c linux-5170/drivers/net/netconsole.c
--- linux-5160/drivers/net/netconsole.c
+++ linux-5170/drivers/net/netconsole.c
@@ -0,0 +1,1334 @@
+/*
+ *  linux/drivers/net/netconsole.c
+ *
+ *  Copyright (C) 2001  Ingo Molnar <mingo@redhat.com>
+ *  Copyright (C) 2002  Red Hat, Inc.
+ *
+ *  This file contains the implementation of an IRQ-safe, crash-safe
+ *  kernel console implementation that outputs kernel messages to the
+ *  network.
+ *
+ * Modification history:
+ *
+ * 2001-09-17    started by Ingo Molnar.
+ * 2002-03-14    simultaneous syslog packet option by Michael K. Johnson
+ */
+
+/****************************************************************
+ *      This program is free software; you can redistribute it and/or modify
+ *      it under the terms of the GNU General Public License as published by
+ *      the Free Software Foundation; either version 2, or (at your option)
+ *      any later version.
+ *
+ *      This program is distributed in the hope that it will be useful,
+ *      but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *      GNU General Public License for more details.
+ *
+ *      You should have received a copy of the GNU General Public License
+ *      along with this program; if not, write to the Free Software
+ *      Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ ****************************************************************/
+
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <linux/mm.h>
+#include <linux/tty.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/random.h>
+#include <linux/reboot.h>
+#include <linux/module.h>
+#include <asm/unaligned.h>
+#include <asm/pgtable.h>
+#if CONFIG_X86_LOCAL_APIC
+#include <asm/apic.h>
+#endif
+#include <linux/console.h>
+#include <linux/smp_lock.h>
+#include <linux/netdevice.h>
+#include <linux/tty_driver.h>
+#include <linux/etherdevice.h>
+#include <linux/elf.h>
+#include <linux/nmi.h>
+
+static struct net_device *netconsole_dev;
+static u16 source_port, netdump_target_port, netlog_target_port, syslog_target_port;
+static u32 source_ip, netdump_target_ip, netlog_target_ip, syslog_target_ip;
+static unsigned char netdump_daddr[6] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff} ;
+static unsigned char netlog_daddr[6] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff} ;
+static unsigned char syslog_daddr[6] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff} ;
+
+static unsigned int mhz = 1000, idle_timeout;
+static unsigned long long mhz_cycles, jiffy_cycles;
+
+#include "netconsole.h"
+#include <asm/netdump.h>
+
+#define MAX_UDP_CHUNK 1460
+#define MAX_PRINT_CHUNK (MAX_UDP_CHUNK-HEADER_LEN)
+
+#define DEBUG 0
+#if DEBUG
+# define Dprintk(x...) printk(KERN_INFO x)
+#else
+# define Dprintk(x...)
+#endif
+/*
+ * We maintain a small pool of fully-sized skbs,
+ * to make sure the message gets out even in
+ * extreme OOM situations.
+ */
+#define MAX_NETCONSOLE_SKBS 128
+
+#define MAX_NETCONSOLE_TX_RETRIES 2500
+
+static spinlock_t netconsole_lock = SPIN_LOCK_UNLOCKED;
+static int nr_netconsole_skbs;
+static struct sk_buff *netconsole_skbs;
+/* the following tunes whether we should send printk's via netconsole.  The
+ * default is to on.  During a netdump, though, we don't want to send output
+ * to the network console, so we disable it for that time.
+ */
+static int emit_printks = 1;
+static asmlinkage void do_netdump(struct pt_regs *regs, void *arg);
+
+#define MAX_SKB_SIZE \
+		(MAX_UDP_CHUNK + sizeof(struct udphdr) + \
+				sizeof(struct iphdr) + sizeof(struct ethhdr))
+
+static int new_arp = 0;
+static unsigned char arp_sha[ETH_ALEN], arp_tha[ETH_ALEN];
+static u32 arp_sip, arp_tip;
+
+static void send_netconsole_arp(struct net_device *dev);
+
+static void __refill_netconsole_skbs(void)
+{
+	struct sk_buff *skb;
+	unsigned long flags;
+
+	spin_lock_irqsave(&netconsole_lock, flags);
+	while (nr_netconsole_skbs < MAX_NETCONSOLE_SKBS) {
+		skb = alloc_skb(MAX_SKB_SIZE, GFP_ATOMIC);
+		if (!skb)
+			break;
+		if (netconsole_skbs)
+			skb->next = netconsole_skbs;
+		else
+			skb->next = NULL;
+		netconsole_skbs = skb;
+		nr_netconsole_skbs++;
+	}
+	spin_unlock_irqrestore(&netconsole_lock, flags);
+}
+
+static struct sk_buff * get_netconsole_skb(void)
+{
+	struct sk_buff *skb;
+
+	unsigned long flags;
+
+	spin_lock_irqsave(&netconsole_lock, flags);
+	skb = netconsole_skbs;
+	if (skb) {
+		netconsole_skbs = skb->next;
+		skb->next = NULL;
+		nr_netconsole_skbs--;
+	}
+	spin_unlock_irqrestore(&netconsole_lock, flags);
+
+	return skb;
+}
+
+static unsigned long long t0;
+
+/*
+ * Do cleanups:
+ * - zap completed output skbs.
+ * - send ARPs if requested
+ * - reboot the box if inactive for more than N seconds.
+ */
+static void zap_completion_queue(void)
+{
+	unsigned long long t1;
+	int cpu = smp_processor_id();
+
+	if (softnet_data[cpu].completion_queue) {
+		struct sk_buff *clist;
+		unsigned long flags;
+
+		local_irq_save(flags);
+		clist = softnet_data[cpu].completion_queue;
+		softnet_data[cpu].completion_queue = NULL;
+		local_irq_restore(flags);
+
+		while (clist != NULL) {
+			struct sk_buff *skb = clist;
+			clist = clist->next;
+			__kfree_skb(skb);
+		}
+	}
+
+	if (new_arp) {
+		Dprintk("got ARP req - sending reply.\n");
+		new_arp = 0;
+		send_netconsole_arp(netconsole_dev);
+	}
+
+	platform_timestamp(t1);
+
+	if (idle_timeout) {
+		if (t0) {
+			if (((t1 - t0) >> 20) > mhz_cycles * (unsigned long long)idle_timeout) {
+				t0 = t1;
+				printk("netdump idle timeout - rebooting in 3 seconds.\n");
+				mdelay(3000);
+				machine_restart(NULL);
+			}
+		}
+	}
+	/* maintain jiffies in a polling fashion, based on rdtsc. */
+	if (netdump_mode) {
+		static unsigned long long prev_tick;
+
+		if (t1 - prev_tick >= jiffy_cycles) {
+			prev_tick = t1;
+			jiffies++;
+		}
+	}
+
+	/* update alert counters for this and other cpus */
+	touch_nmi_watchdog();
+}
+
+static struct sk_buff * alloc_netconsole_skb(struct net_device *dev, int len, int reserve)
+{
+	int once = 1;
+	int count = 0;
+	struct sk_buff *skb = NULL;
+
+repeat:
+	zap_completion_queue();
+	if (nr_netconsole_skbs < MAX_NETCONSOLE_SKBS)
+		__refill_netconsole_skbs();
+
+	skb = alloc_skb(len, GFP_ATOMIC);
+	if (!skb) {
+		skb = get_netconsole_skb();
+		if (!skb) {
+			count++;
+			if (once && (count == 1000000)) {
+				printk("possibly FATAL: out of netconsole skbs!!! will keep retrying.\n");
+				once = 0;
+			}
+			Dprintk("alloc skb: polling controller ...\n");
+			if (dev->poll_controller)
+				dev->poll_controller(dev);
+			goto repeat;
+		}
+	}
+
+	atomic_set(&skb->users, 1);
+	skb_reserve(skb, reserve);
+	return skb;
+}
+
+static void transmit_raw_skb(struct sk_buff *skb, struct net_device *dev)
+{
+	int poll_count = 0;
+
+repeat_poll:
+	/* drop the packet if we are making no progress */
+	if (likely(!netdump_mode) && 
+	    poll_count++ > MAX_NETCONSOLE_TX_RETRIES) {
+		dev_kfree_skb_any(skb);
+		return;
+	}
+
+	spin_lock(&dev->xmit_lock);
+	dev->xmit_lock_owner = smp_processor_id();
+
+	if (netif_queue_stopped(dev)) {
+		dev->xmit_lock_owner = -1;
+		spin_unlock(&dev->xmit_lock);
+
+		Dprintk("xmit skb: polling controller ...\n");
+		if (dev->poll_controller)
+			dev->poll_controller(dev);
+		zap_completion_queue();
+		udelay(50);
+		goto repeat_poll;
+	}
+
+	/* tell the hard_start_xmit routine that we got here via netconsole */
+	dev->priv_flags |= IFF_NETCONSOLE;
+
+	dev->hard_start_xmit(skb, dev);
+
+	dev->priv_flags &= ~IFF_NETCONSOLE;
+	dev->xmit_lock_owner = -1;
+	spin_unlock(&dev->xmit_lock);
+}
+
+static void transmit_netconsole_skb(struct sk_buff *skb, struct net_device *dev,
+	int ip_len, int udp_len,
+	u16 source_port, u16 target_port, u32 source_ip, u32 target_ip,
+	unsigned char * macdaddr)
+{
+	struct udphdr *udph;
+	struct iphdr *iph;
+	struct ethhdr *eth;
+
+	udph = (struct udphdr *) skb_push(skb, sizeof(*udph));
+	udph->source = source_port;
+	udph->dest = target_port;
+	udph->len = htons(udp_len);
+	udph->check = 0;
+
+	iph = (struct iphdr *)skb_push(skb, sizeof(*iph));
+	skb->nh.iph   = iph;
+
+/*	iph->version  = 4; iph->ihl      = 5; */
+        put_unaligned(0x45, (unsigned char *)iph);
+	iph->tos      = 0;
+	iph->tot_len  = htons(ip_len);
+	iph->id       = 0;
+	iph->frag_off = 0;
+	iph->ttl      = 64;
+	iph->protocol = IPPROTO_UDP;
+	iph->check    = 0;
+        put_unaligned(source_ip, &(iph->saddr));
+        put_unaligned(target_ip, &(iph->daddr));
+	iph->check    = ip_fast_csum((unsigned char *)iph, 5);
+
+	eth = (struct ethhdr *) skb_push(skb, ETH_HLEN);
+
+	eth->h_proto = htons(ETH_P_IP);
+	memcpy(eth->h_source, dev->dev_addr, dev->addr_len);
+	memcpy(eth->h_dest, macdaddr, dev->addr_len);
+
+	transmit_raw_skb(skb, dev);
+}
+
+static void send_netconsole_arp(struct net_device *dev)
+{
+	int total_len, arp_len, arp_data_len;
+	struct sk_buff *skb;
+	unsigned char *arp;
+	struct arphdr *arph;
+	struct ethhdr *eth;
+
+	arp_data_len = 2*4 + 2*ETH_ALEN;
+	arp_len = arp_data_len + sizeof(struct arphdr);
+	total_len = arp_len + ETH_HLEN;
+
+	skb = alloc_netconsole_skb(dev, total_len, total_len - arp_data_len);
+
+	arp = skb->data;
+
+	memcpy(arp, dev->dev_addr, ETH_ALEN);
+	arp += ETH_ALEN;
+
+	memcpy(arp, &source_ip, 4);
+	arp += 4;
+
+	memcpy(arp, arp_sha, ETH_ALEN);
+	arp += ETH_ALEN;
+
+	memcpy(arp, &arp_sip, 4);
+	arp += 4;
+
+	skb->len += 2*4 + 2*ETH_ALEN;
+
+	arph = (struct arphdr *)skb_push(skb, sizeof(*arph));
+	skb->nh.arph = arph;
+
+	arph->ar_hrd = htons(dev->type);
+	arph->ar_pro = __constant_htons(ETH_P_IP);
+	arph->ar_hln = ETH_ALEN;
+	arph->ar_pln = 4;
+	arph->ar_op = __constant_htons(ARPOP_REPLY);
+
+	eth = (struct ethhdr *) skb_push(skb, ETH_HLEN);
+
+	eth->h_proto = htons(ETH_P_ARP);
+	memcpy(eth->h_source, dev->dev_addr, dev->addr_len);
+	memcpy(eth->h_dest, arp_sha, dev->addr_len);
+
+	transmit_raw_skb(skb, dev);
+}
+
+static void send_netdump_skb(struct net_device *dev, const char *msg, unsigned int msg_len, reply_t *reply)
+{
+	int total_len, ip_len, udp_len;
+	struct sk_buff *skb;
+
+	udp_len = msg_len + HEADER_LEN + sizeof(struct udphdr);
+	ip_len = udp_len + sizeof(struct iphdr);
+	total_len = ip_len + ETH_HLEN;
+
+	skb = alloc_netconsole_skb(dev, total_len, total_len - msg_len - HEADER_LEN);
+
+	skb->data[0] = NETCONSOLE_VERSION;
+	put_unaligned(htonl(reply->nr), (u32 *) (skb->data + 1));
+	put_unaligned(htonl(reply->code), (u32 *) (skb->data + 5));
+	put_unaligned(htonl(reply->info), (u32 *) (skb->data + 9));
+
+	memcpy(skb->data + HEADER_LEN, msg, msg_len);
+	skb->len += msg_len + HEADER_LEN;
+
+	transmit_netconsole_skb(skb, dev, ip_len, udp_len,
+		source_port, netdump_target_port, source_ip, netdump_target_ip, netdump_daddr);
+}
+
+#define SYSLOG_HEADER_LEN 4
+
+static void send_netlog_skb(struct net_device *dev, const char *msg, unsigned int msg_len, reply_t *reply)
+{
+	int total_len, ip_len, udp_len;
+	struct sk_buff *skb;
+
+	udp_len = msg_len + HEADER_LEN + sizeof(struct udphdr);
+	ip_len = udp_len + sizeof(struct iphdr);
+	total_len = ip_len + ETH_HLEN;
+
+	skb = alloc_netconsole_skb(dev, total_len, total_len - msg_len - HEADER_LEN);
+
+	skb->data[0] = NETCONSOLE_VERSION;
+	put_unaligned(htonl(reply->nr), (u32 *) (skb->data + 1));
+	put_unaligned(htonl(reply->code), (u32 *) (skb->data + 5));
+	put_unaligned(htonl(reply->info), (u32 *) (skb->data + 9));
+
+	memcpy(skb->data + HEADER_LEN, msg, msg_len);
+	skb->len += msg_len + HEADER_LEN;
+
+	transmit_netconsole_skb(skb, dev, ip_len, udp_len,
+		source_port, netlog_target_port, source_ip, netlog_target_ip, netlog_daddr);
+}
+
+#define SYSLOG_HEADER_LEN 4
+
+static void send_syslog_skb(struct net_device *dev, const char *msg, unsigned int msg_len, int pri)
+{
+	int total_len, ip_len, udp_len;
+	struct sk_buff *skb;
+
+	udp_len = msg_len + SYSLOG_HEADER_LEN + sizeof(struct udphdr);
+	ip_len = udp_len + sizeof(struct iphdr);
+	total_len = ip_len + ETH_HLEN;
+
+	skb = alloc_netconsole_skb(dev, total_len, total_len - msg_len - SYSLOG_HEADER_LEN);
+
+	skb->data[0] = '<';
+	skb->data[1] = pri + '0';
+	skb->data[2]= '>';
+	skb->data[3]= ' ';
+
+	memcpy(skb->data + SYSLOG_HEADER_LEN, msg, msg_len);
+	skb->len += msg_len + SYSLOG_HEADER_LEN;
+
+	transmit_netconsole_skb(skb, dev, ip_len, udp_len, source_port,
+		syslog_target_port, source_ip, syslog_target_ip, syslog_daddr);
+}
+
+#define MAX_SYSLOG_CHARS 1000
+
+static spinlock_t syslog_lock = SPIN_LOCK_UNLOCKED;
+static int syslog_chars;
+static unsigned char syslog_line [MAX_SYSLOG_CHARS + 10];
+
+/*
+ * We feed kernel messages char by char, and send the UDP packet
+ * one linefeed. We buffer all characters received.
+ */
+static inline void feed_syslog_char(struct net_device *dev, const unsigned char c)
+{
+	if (syslog_chars == MAX_SYSLOG_CHARS)
+		syslog_chars--;
+	syslog_line[syslog_chars] = c;
+	syslog_chars++;
+	if (c == '\n') {
+		send_syslog_skb(dev, syslog_line, syslog_chars, 5);
+		syslog_chars = 0;
+	}
+}
+
+static spinlock_t sequence_lock = SPIN_LOCK_UNLOCKED;
+static unsigned int log_offset;
+
+static void write_netconsole_msg(struct console *con, const char *msg0, unsigned int msg_len)
+{
+	int len, left, i;
+	struct net_device *dev;
+	const char *msg = msg0;
+	reply_t reply;
+
+	dev = netconsole_dev;
+	if (!dev || !emit_printks)
+		return;
+
+	if (dev->poll_controller && netif_running(dev)) {
+		unsigned long flags;
+
+		__save_flags(flags);
+		__cli();
+		left = msg_len;
+		if (netlog_target_ip) {
+			while (left) {
+				if (left > MAX_PRINT_CHUNK)
+					len = MAX_PRINT_CHUNK;
+				else
+					len = left;
+				reply.code = REPLY_LOG;
+				reply.nr = 0;
+				spin_lock(&sequence_lock);
+				reply.info = log_offset;
+				log_offset += len;
+				spin_unlock(&sequence_lock);
+				send_netlog_skb(dev, msg, len, &reply);
+				msg += len;
+				left -= len;
+			}
+		}
+		if (syslog_target_ip) {
+			spin_lock(&syslog_lock);
+			for (i = 0; i < msg_len; i++)
+				feed_syslog_char(dev, msg0[i]);
+			spin_unlock(&syslog_lock);
+		}
+
+		__restore_flags(flags);
+	}
+}
+
+static unsigned short udp_check(struct udphdr *uh, int len, unsigned long saddr, unsigned long daddr, unsigned long base)
+{
+	return(csum_tcpudp_magic(saddr, daddr, len, IPPROTO_UDP, base));
+}
+
+static int udp_checksum_init(struct sk_buff *skb, struct udphdr *uh,
+			     unsigned short ulen, u32 saddr, u32 daddr)
+{
+	if (uh->check == 0) {
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+	} else if (skb->ip_summed == CHECKSUM_HW) {
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+		if (!udp_check(uh, ulen, saddr, daddr, skb->csum))
+			return 0;
+		skb->ip_summed = CHECKSUM_NONE;
+	}
+	if (skb->ip_summed != CHECKSUM_UNNECESSARY)
+		skb->csum = csum_tcpudp_nofold(saddr, daddr, ulen, IPPROTO_UDP,
+0);
+	/* Probably, we should checksum udp header (it should be in cache
+	 * in any case) and data in tiny packets (< rx copybreak).
+	 */
+	return 0;
+}
+
+static __inline__ int __udp_checksum_complete(struct sk_buff *skb)
+{
+	return (unsigned short)csum_fold(skb_checksum(skb, 0, skb->len, skb->csum));
+}
+
+static __inline__ int udp_checksum_complete(struct sk_buff *skb)
+{
+	return skb->ip_summed != CHECKSUM_UNNECESSARY &&
+		__udp_checksum_complete(skb);
+}
+
+/*
+ * NOTE: security depends on the trusted path between the netconsole
+ *       server and netconsole client, since none of the packets are
+ *       encrypted. The random magic number protects the protocol
+ *       against spoofing.
+ */
+static u64 netconsole_magic;
+static u32 magic1, magic2;
+
+static spinlock_t req_lock = SPIN_LOCK_UNLOCKED;
+static int nr_req = 0;
+static LIST_HEAD(request_list);
+
+static void add_new_req(req_t *req)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&req_lock, flags);
+	list_add_tail(&req->list, &request_list);
+	nr_req++;
+	Dprintk("pending requests: %d.\n", nr_req);
+	spin_unlock_irqrestore(&req_lock, flags);
+
+	platform_timestamp(t0);
+}
+
+static req_t *get_new_req(void)
+{
+	req_t *req = NULL;
+	unsigned long flags;
+
+	spin_lock_irqsave(&req_lock, flags);
+	if (nr_req) {
+		req = list_entry(request_list.next, req_t, list);
+		list_del(&req->list);
+		nr_req--;
+	}
+	spin_unlock_irqrestore(&req_lock, flags);
+
+	return req;
+}
+
+static req_t *alloc_req(void)
+{
+	req_t *req;
+
+	req = (req_t *) kmalloc(sizeof(*req), GFP_ATOMIC);
+	return req;
+}
+
+int netconsole_rx(struct sk_buff *skb)
+{
+	int proto;
+	struct iphdr *iph;
+	struct udphdr *uh;
+	__u32 len, saddr, daddr, ulen;
+	req_t *__req;
+	req_t *req;
+	struct net_device *dev;
+
+	if (!netdump_mode)
+		return NET_RX_SUCCESS;
+#if DEBUG
+	{
+		static int packet_count;
+		Dprintk("        %d\r", ++packet_count);
+	}
+#endif
+	dev = skb->dev;
+	if (dev->type != ARPHRD_ETHER)
+		goto out;
+	proto = ntohs(skb->mac.ethernet->h_proto);
+	Dprintk("rx got skb %p (len: %d, users: %d), dev %s, h_proto: %04x.\n", skb, skb->len, atomic_read(&skb->users), dev->name, proto);
+	#define D(x) skb->mac.ethernet->h_dest[x]
+	Dprintk("... h_dest:   %02X:%02X:%02X:%02X:%02X:%02X.\n", D(0), D(1), D(2), D(3), D(4), D(5));
+	#undef D
+	#define D(x) skb->mac.ethernet->h_source[x]
+	Dprintk("... h_source: %02X:%02X:%02X:%02X:%02X:%02X.\n", D(0), D(1), D(2), D(3), D(4), D(5));
+	#undef D
+	if (skb->pkt_type == PACKET_OTHERHOST)
+		goto out;
+	if (skb_shared(skb))
+		goto out;
+	if (proto == ETH_P_ARP) {
+		struct arphdr *arp;
+		unsigned char *arp_ptr;
+
+		Dprintk("got arp skb.\n");
+		arp = (struct arphdr *)skb->data;
+		if (!pskb_may_pull(skb, sizeof(struct arphdr) + 2*4 + 2*ETH_ALEN))
+			goto out;
+		if (htons(dev->type) != arp->ar_hrd)
+			goto out;
+		if (arp->ar_pro != __constant_htons(ETH_P_IP))
+			goto out;
+		if (arp->ar_hln != ETH_ALEN)
+			goto out;
+		if (arp->ar_pln != 4)
+			goto out;
+		if (arp->ar_op != __constant_htons(ARPOP_REQUEST))
+			goto out;
+		/*
+		 * ARP header looks ok so far, extract fields:
+		 */
+		arp_ptr = (unsigned char *)(arp + 1);
+
+		memcpy(arp_sha, arp_ptr, ETH_ALEN);
+		arp_ptr += ETH_ALEN;
+
+		memcpy(&arp_sip, arp_ptr, 4);
+		arp_ptr += 4;
+
+		memcpy(arp_tha, arp_ptr, ETH_ALEN);
+		arp_ptr += ETH_ALEN;
+
+		memcpy(&arp_tip, arp_ptr, 4);
+
+		#define D(x) arp_sha[x]
+		Dprintk("... arp_sha:   %02X:%02X:%02X:%02X:%02X:%02X.\n", D(0), D(1), D(2), D(3), D(4), D(5));
+		#undef D
+		#define D(x) ((unsigned char *)&arp_sip)[x]
+		Dprintk("... arp_sip:   %d.%d.%d.%d.\n", D(0), D(1), D(2), D(3));
+		#undef D
+		#define D(x) arp_tha[x]
+		Dprintk("... arp_tha:   %02X:%02X:%02X:%02X:%02X:%02X.\n", D(0), D(1), D(2), D(3), D(4), D(5));
+		#undef D
+		#define D(x) ((unsigned char *)&arp_tip)[x]
+		Dprintk("... arp_tip:   %d.%d.%d.%d.\n", D(0), D(1), D(2), D(3));
+		#undef D
+		#define D(x) ((unsigned char *)&source_ip)[x]
+		Dprintk("... (source_ip):   %d.%d.%d.%d.\n", D(0), D(1), D(2), D(3));
+		#undef D
+
+		if (LOOPBACK(arp_tip) || MULTICAST(arp_tip))
+			goto out;
+
+		if (arp_tip != source_ip)
+			goto out;
+		new_arp = 1;
+		goto out;
+	}
+	if (proto != ETH_P_IP)
+		goto out;
+	/*
+	 * IP header correctness testing:
+	 */
+	iph = (struct iphdr *)skb->data;
+	if (!pskb_may_pull(skb, sizeof(struct iphdr)))
+		goto out;
+	Dprintk("... IP ihl*4: %d, version: %d.\n", iph->ihl*4, iph->version);
+	if (iph->ihl < 5 || iph->version != 4)
+		goto out;
+	if (!pskb_may_pull(skb, iph->ihl*4))
+		goto out;
+	if (ip_fast_csum((u8 *)iph, iph->ihl) != 0)
+		goto out;
+	len = ntohs(iph->tot_len);
+	Dprintk("... IP len: %d.\n", len);
+	if (skb->len < len || len < iph->ihl*4)
+		goto out;
+	saddr = iph->saddr;
+	daddr = iph->daddr;
+	Dprintk("... IP src: %08x, dst: %08x.\n", saddr, daddr);
+	Dprintk("... IP protocol: %d.\n", iph->protocol);
+	if (iph->protocol != IPPROTO_UDP)
+		goto out;
+	Dprintk("... netdump src: %08x, dst: %08x.\n", source_ip, netlog_target_ip);
+	if (source_ip != daddr)
+		goto out;
+	if (netlog_target_ip != saddr)
+		goto out;
+	len -= iph->ihl*4;
+	uh = (struct udphdr *)(((char *)iph) + iph->ihl*4);
+	ulen = ntohs(uh->len);
+	Dprintk("... UDP len: %d (left %d).\n", ulen, len);
+
+#define MIN_COMM_SIZE (sizeof(*uh) + NETDUMP_REQ_SIZE)
+	if (ulen != len || ulen < MIN_COMM_SIZE) {
+		Dprintk("... UDP, hm, len not ok.\n");
+		goto out;
+	}
+	if (udp_checksum_init(skb, uh, ulen, saddr, daddr) < 0) {
+		Dprintk("... UDP, hm, checksum init not ok.\n");
+		goto out;
+	}
+	if (udp_checksum_complete(skb)) {
+		Dprintk("... UDP, hm, checksum complete not ok.\n");
+		goto out;
+	}
+	Dprintk("... UDP packet OK!\n");
+	Dprintk("... UDP src port: %d, dst port: %d.\n", uh->source, uh->dest);
+	if (source_port != uh->source)
+		goto out;
+	if (netlog_target_port != uh->dest)
+		goto out;
+	__req = (req_t *)(uh + 1);
+	Dprintk("... UDP netdump packet OK!\n");
+
+	req = alloc_req();
+	if (!req) {
+		printk("no more RAM to allocate request - dropping it.\n");
+		goto out;
+	}
+
+	req->magic = ntohl(__req->magic);
+	req->command = ntohl(__req->command);
+	req->from = ntohl(__req->from);
+	req->to = ntohl(__req->to);
+	req->nr = ntohl(__req->nr);
+
+	Dprintk("... netdump magic:   %08Lx.\n", req->magic);
+	Dprintk("... netdump command: %08x.\n", req->command);
+	Dprintk("... netdump from:    %08x.\n", req->from);
+	Dprintk("... netdump to:      %08x.\n", req->to);
+
+	add_new_req(req);
+out:
+	return NET_RX_DROP;
+}
+
+int netconsole_receive_skb(struct sk_buff *skb)
+{
+	int ret;
+	unsigned long flags;
+
+	if (!netdump_mode)
+		return NET_RX_SUCCESS;
+
+	local_irq_save(flags);
+	ret = netconsole_rx(skb);
+	local_irq_restore(flags);
+
+	return ret;
+}
+
+static void send_netdump_mem (struct net_device *dev, req_t *req)
+{
+	int i;
+	char *kaddr;
+	char str[1024];
+	struct page *page = NULL;
+	unsigned long nr = req->from;
+	int nr_chunks = PAGE_SIZE/1024;
+	reply_t reply;
+	
+	reply.nr = req->nr;
+	reply.info = 0;
+	if (req->from >= platform_max_pfn()) {
+		sprintf(str, "page %08lx is bigger than max page # %08lx!\n", 
+			nr, platform_max_pfn());
+		reply.code = REPLY_ERROR;
+		send_netdump_skb(dev, str, strlen(str), &reply);
+		return;
+	}
+        if (platform_page_is_ram(nr)) {
+                page = pfn_to_page(nr);
+                if (page_to_pfn(page) == nr) {
+			kaddr = (char *)kmap_atomic(page, KM_NETDUMP);
+			if (!kern_addr_valid((unsigned long)kaddr)) {
+				kunmap_atomic(kaddr, KM_NETDUMP);
+				page = NULL;
+			}
+		} else
+                        page = NULL;
+        }
+        if (!page) {
+                reply.code = REPLY_RESERVED;
+                reply.info = platform_next_available(nr);
+                send_netdump_skb(dev, str, 0, &reply);
+                return;
+	}
+
+	for (i = 0; i < nr_chunks; i++) {
+		unsigned int offset = i*1024;
+		reply.code = REPLY_MEM;
+		reply.info = offset;
+		send_netdump_skb(dev, kaddr + offset, 1024, &reply);
+	}
+
+	kunmap_atomic(kaddr, KM_NETDUMP);
+}
+
+static unsigned char effective_version = NETCONSOLE_VERSION;
+
+/*
+ * This function waits for the client to acknowledge the receipt
+ * of the netdump startup reply, with the possibility of packets
+ * getting lost. We resend the startup packet if no ACK is received,
+ * after a 1 second delay.
+ *
+ * (The client can test the success of the handshake via the HELLO
+ * command, and send ACKs until we enter netdump mode.)
+ */
+static void netdump_startup_handshake(struct net_device *dev)
+{
+	char tmp[200];
+	reply_t reply;
+	req_t *req = NULL;
+	int i;
+
+	netdump_mode = 1;
+	emit_printks = 0;
+repeat:
+        sprintf(tmp,
+            "task_struct:0x%lx page_offset:0x%llx netdump_magic:0x%llx\n",
+                (unsigned long)current, (unsigned long long)PAGE_OFFSET,
+                (unsigned long long)netconsole_magic);
+	reply.code = REPLY_START_NETDUMP;
+	reply.nr = platform_machine_type();
+	reply.info = NETDUMP_VERSION_MAX;
+	send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+
+	for (i = 0; i < 10000; i++) {
+		// wait 1 sec.
+		udelay(100);
+		Dprintk("handshake: polling controller ...\n");
+		if (!dev->poll_controller) {
+			printk("device %s does not support netconsole!\n",
+			       dev->name);
+			mdelay(3000);
+			machine_restart(NULL);
+		}
+		dev->poll_controller(dev);
+		zap_completion_queue();
+		req = get_new_req();
+		if (req)
+			break;
+	}
+	if (!req)
+		goto repeat;
+	if (req->command != COMM_START_NETDUMP_ACK) {
+		kfree(req);
+		goto repeat;
+	}
+
+        /*
+         *  Negotiate an effective version that works with the server.
+         */
+        if ((effective_version = platform_effective_version(req)) == 0) {
+                printk(KERN_ERR
+                        "netdump: server cannot handle this client -- rebooting.\n");
+                mdelay(3000);
+                machine_restart(NULL);
+        }
+
+	kfree(req);
+
+	printk("NETDUMP START!\n");
+}
+
+#if 0
+
+static inline void print_status (req_t *req)
+{
+	static int count = 0;
+
+	switch (++count & 3) {
+		case 0: printk("/\r"); break;
+		case 1: printk("|\r"); break;
+		case 2: printk("\\\r"); break;
+		case 3: printk("-\r"); break;
+	}
+}
+
+#else
+
+static inline void print_status (req_t *req)
+{
+	static int count = 0;
+	static int prev_jiffies = 0;
+
+	if (jiffies/HZ != prev_jiffies/HZ) {
+		prev_jiffies = jiffies;
+		count++;
+		switch (count & 3) {
+			case 0: printk("%d(%ld)/\r", nr_req, jiffies); break;
+			case 1: printk("%d(%ld)|\r", nr_req, jiffies); break;
+			case 2: printk("%d(%ld)\\\r", nr_req, jiffies); break;
+			case 3: printk("%d(%ld)-\r", nr_req, jiffies); break;
+		}
+	}
+}
+
+#endif
+
+#define CLI 1
+
+#ifdef CONFIG_SMP
+static char cpus_frozen[NR_CPUS] = { 0 }; 
+
+static void freeze_cpu (void * dummy)
+{
+	cpus_frozen[smp_processor_id()] = 1;
+	platform_freeze_cpu();
+}
+#endif
+
+static void netconsole_netdump (struct pt_regs *regs)
+{
+	unsigned long flags;
+#ifdef CONFIG_SMP
+	int i;
+#endif
+
+	__save_flags(flags);
+	__cli();
+#ifdef CONFIG_SMP
+	dump_smp_call_function(freeze_cpu, NULL);
+	mdelay(3000);
+	for (i = 0; i < NR_CPUS; i++) {
+		if (cpus_frozen[i])
+			printk("CPU#%d is frozen.\n", i);
+		else if (i == smp_processor_id())
+			printk("CPU#%d is executing netdump.\n", i);
+	}
+#else
+	mdelay(1000);
+#endif /* CONFIG_SMP */
+
+        platform_start_netdump(do_netdump, regs);
+
+	__restore_flags(flags);
+}
+
+static char command_tmp[1024];
+
+static asmlinkage void do_netdump(struct pt_regs *regs, void *platform_arg)
+{
+        reply_t reply;
+        char *tmp = command_tmp;
+        struct net_device *dev = netconsole_dev;
+        struct pt_regs myregs;
+	struct sysinfo si;
+        req_t *req;
+
+	/*
+	 * Just in case we are crashing within the networking code
+	 * ... attempt to fix up.
+	 */
+	spin_lock_init(&dev->xmit_lock);
+
+	platform_fix_regs();
+
+	platform_timestamp(t0);
+
+	printk("< netdump activated - performing handshake with the server. >\n");
+	netdump_startup_handshake(dev);
+
+	printk("< handshake completed - listening for dump requests. >\n");
+
+	while (netdump_mode) {
+		__cli();
+		Dprintk("main netdump loop: polling controller ...\n");
+		if (dev->poll_controller)
+			dev->poll_controller(dev);
+		zap_completion_queue();
+#if !CLI
+		__sti();
+#endif
+		req = get_new_req();
+		if (!req)
+			continue;
+		Dprintk("got new req, command %d.\n", req->command);
+		print_status(req);
+		switch (req->command) {
+		case COMM_NONE:
+			Dprintk("got NO command.\n");
+			break;
+
+		case COMM_SEND_MEM:
+			Dprintk("got MEM command.\n");
+			// send ->from ->to.
+			send_netdump_mem(dev, req);
+			break;
+
+		case COMM_EXIT:
+			Dprintk("got EXIT command.\n");
+			netdump_mode = 0;
+			break;
+
+		case COMM_REBOOT:
+			Dprintk("got REBOOT command.\n");
+			printk("netdump: rebooting in 3 seconds.\n");
+			mdelay(3000);
+			machine_restart(NULL);
+			break;
+
+		case COMM_HELLO:
+			sprintf(tmp, "Hello, this is netdump version 0.%02d\n", NETCONSOLE_VERSION);
+			reply.code = REPLY_HELLO;
+			reply.nr = req->nr;
+			reply.info = NETCONSOLE_VERSION;
+			send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+			break;
+
+		case COMM_GET_PAGE_SIZE:
+			sprintf(tmp, "PAGE_SIZE: %ld\n", PAGE_SIZE);
+			reply.code = REPLY_PAGE_SIZE;
+			reply.nr = req->nr;
+			reply.info = PAGE_SIZE;
+			send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+			break;
+
+		case COMM_GET_REGS:
+                        reply.code = REPLY_REGS;
+                        reply.nr = req->nr;
+			si_meminfo(&si);
+                        reply.info = (u32)si.totalram;
+			send_netdump_skb(dev, tmp, platform_get_regs(tmp, &myregs), &reply);
+			break;
+
+		case COMM_GET_NR_PAGES:
+			reply.code = REPLY_NR_PAGES;
+			reply.nr = req->nr;
+			reply.info = platform_max_pfn();
+			sprintf(tmp, "Number of pages: %ld\n", platform_max_pfn());
+			send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+			break;
+
+		case COMM_SHOW_STATE:
+			/* send response first */
+			reply.code = REPLY_SHOW_STATE;
+			reply.nr = req->nr;
+			reply.info = 0;
+			send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+
+			emit_printks = 1;
+			if (regs)
+				show_regs(regs);
+			show_state();
+			show_mem();
+			emit_printks = 0;
+			break;
+
+		default:
+			reply.code = REPLY_ERROR;
+			reply.nr = req->nr;
+			reply.info = req->command;
+			Dprintk("got UNKNOWN command!\n");
+			sprintf(tmp, "Got unknown command code %d!\n", req->command);
+			send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+			break;
+		}
+		kfree(req);
+		req = NULL;
+	}
+	sprintf(tmp, "NETDUMP end.\n");
+	reply.code = REPLY_END_NETDUMP;
+	reply.nr = 0;
+	reply.info = 0;
+	send_netdump_skb(dev, tmp, strlen(tmp), &reply);
+	printk("NETDUMP END!\n");
+}
+
+static char *dev;
+static int netdump_target_eth_byte0 = 255;
+static int netdump_target_eth_byte1 = 255;
+static int netdump_target_eth_byte2 = 255;
+static int netdump_target_eth_byte3 = 255;
+static int netdump_target_eth_byte4 = 255;
+static int netdump_target_eth_byte5 = 255;
+
+static int netlog_target_eth_byte0 = 255;
+static int netlog_target_eth_byte1 = 255;
+static int netlog_target_eth_byte2 = 255;
+static int netlog_target_eth_byte3 = 255;
+static int netlog_target_eth_byte4 = 255;
+static int netlog_target_eth_byte5 = 255;
+
+static int syslog_target_eth_byte0 = 255;
+static int syslog_target_eth_byte1 = 255;
+static int syslog_target_eth_byte2 = 255;
+static int syslog_target_eth_byte3 = 255;
+static int syslog_target_eth_byte4 = 255;
+static int syslog_target_eth_byte5 = 255;
+
+MODULE_PARM(netdump_target_ip, "i");
+MODULE_PARM_DESC(netdump_target_ip,
+	"remote netdump IP address as a native (not network) endian integer");
+MODULE_PARM(netlog_target_ip, "i");
+MODULE_PARM_DESC(netlog_target_ip,
+	"remote netlog IP address as a native (not network) endian integer");
+MODULE_PARM(syslog_target_ip, "i");
+MODULE_PARM_DESC(syslog_target_ip,
+	"remote syslog IP address as a native (not network) endian integer");
+
+MODULE_PARM(source_port, "h");
+MODULE_PARM_DESC(source_port,
+	"local port from which to send netdump packets");
+
+MODULE_PARM(netdump_target_port, "h");
+MODULE_PARM_DESC(netdump_target_port,
+	"remote port to which to send netdump packets");
+MODULE_PARM(netlog_target_port, "h");
+MODULE_PARM_DESC(netlog_target_port,
+	"remote port to which to send netlog packets");
+MODULE_PARM(syslog_target_port, "h");
+MODULE_PARM_DESC(syslog_target_port,
+	"remote port to which to send syslog packets");
+
+#define ETH_BYTE(name,nr) \
+	MODULE_PARM(name##_target_eth_byte##nr, "i"); \
+	MODULE_PARM_DESC(name##_target_eth_byte##nr, \
+		"byte "#nr" of the netdump server MAC address")
+
+#define ETH_BYTES(name) \
+	ETH_BYTE(name, 0); ETH_BYTE(name, 1); ETH_BYTE(name, 2); \
+	ETH_BYTE(name, 3); ETH_BYTE(name, 4); ETH_BYTE(name, 5);
+
+ETH_BYTES(netdump);
+ETH_BYTES(netlog);
+ETH_BYTES(syslog);
+
+MODULE_PARM(magic1, "i");
+MODULE_PARM_DESC(magic1,
+	"lower 32 bits of magic cookie shared between client and server");
+MODULE_PARM(magic2, "i");
+MODULE_PARM_DESC(magic2,
+	"upper 32 bits of magic cookie shared between client and server");
+MODULE_PARM(dev, "s");
+MODULE_PARM_DESC(dev,
+	"name of the device from which to send netdump and syslog packets");
+MODULE_PARM(mhz, "i");
+MODULE_PARM_DESC(mhz,
+	"one second wall clock time takes this many million CPU cycles");
+MODULE_PARM(idle_timeout, "i");
+MODULE_PARM_DESC(idle_timeout,
+	"reboot system after this many idle seconds");
+
+static struct console netconsole =
+	 { flags: CON_ENABLED, write: write_netconsole_msg };
+
+static int init_netconsole(void)
+{
+	struct net_device *ndev = NULL;
+	struct in_device *in_dev;
+
+	printk(KERN_INFO "netlog: using network device <%s>\n", dev);
+	// this will be valid once the device goes up.
+	if (dev)
+		ndev = dev_get_by_name(dev);
+	if (!ndev) {
+		printk(KERN_ERR "netlog: network device %s does not exist, aborting.\n", dev);
+		return -1;
+	}
+	if (!ndev->poll_controller) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: %s's network driver does not implement netlogging yet, aborting.\n", dev);
+		return -1;
+	}
+	in_dev = in_dev_get(ndev);
+	if (!in_dev) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: network device %s is not an IP protocol device, aborting.\n", dev);
+		return -1;
+	}
+	in_dev_put(in_dev);
+
+	if (!magic1 || !magic2) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: magic cookie (magic1,magic2) not specified.\n");
+		return -1;
+	}
+	netconsole_magic = magic1 + (((u64)magic2)<<32);
+
+	source_ip = ntohl(in_dev->ifa_list->ifa_local);
+	if (!source_ip) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: network device %s has no local address, aborting.\n", dev);
+		return -1;
+	}
+	printk(KERN_INFO "netlog: using source IP %u.%u.%u.%u\n",
+	       HIPQUAD(source_ip));
+	source_ip = htonl(source_ip);
+	if (!source_port) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: source_port parameter not specified, aborting.\n");
+		return -1;
+	}
+	printk(KERN_INFO "netlog: using source UDP port: %u\n", source_port);
+	source_port = htons(source_port);
+
+	if (!netdump_target_ip && !netlog_target_ip && !syslog_target_ip) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: target_ip parameter not specified, aborting.\n");
+		return -1;
+	}
+	if (netdump_target_ip) {
+		printk(KERN_INFO "netlog: using netdump target IP %u.%u.%u.%u\n",
+		       HIPQUAD(netdump_target_ip));
+		netdump_target_ip = htonl(netdump_target_ip);
+	}
+	if (netlog_target_ip) {
+		printk(KERN_INFO "netlog: using netlog target IP %u.%u.%u.%u\n",
+		       HIPQUAD(netlog_target_ip));
+		netlog_target_ip = htonl(netlog_target_ip);
+	}
+	if (syslog_target_ip) {
+		if (!syslog_target_port)
+			syslog_target_port = 514;
+		printk("netlog: using syslog target IP %u.%u.%u.%u, port: %d\n",
+			HIPQUAD(syslog_target_ip), syslog_target_port);
+		syslog_target_ip = htonl(syslog_target_ip);
+		syslog_target_port = htons(syslog_target_port);
+	}
+	if (!netdump_target_port && !netlog_target_port && !syslog_target_port) {
+		dev_put(ndev);
+		printk(KERN_ERR "netlog: target_port parameter not specified, aborting.\n");
+		return -1;
+	}
+	if (netdump_target_port) {
+		printk(KERN_INFO "netlog: using target UDP port: %u\n", netdump_target_port);
+		netdump_target_port = htons(netdump_target_port);
+	}
+	if (netlog_target_port) {
+		printk(KERN_INFO "netlog: using target UDP port: %u\n", netlog_target_port);
+		netlog_target_port = htons(netlog_target_port);
+	}
+
+	netdump_daddr[0] = netdump_target_eth_byte0;
+	netdump_daddr[1] = netdump_target_eth_byte1;
+	netdump_daddr[2] = netdump_target_eth_byte2;
+	netdump_daddr[3] = netdump_target_eth_byte3;
+	netdump_daddr[4] = netdump_target_eth_byte4;
+	netdump_daddr[5] = netdump_target_eth_byte5;
+
+	if ((netdump_daddr[0] & netdump_daddr[1] & netdump_daddr[2] & netdump_daddr[3] & netdump_daddr[4] & netdump_daddr[5]) == 255)
+		printk(KERN_INFO "netlog: using broadcast ethernet frames to send netdump packets.\n");
+	else
+		printk(KERN_INFO "netlog: using netdump target ethernet address %02x:%02x:%02x:%02x:%02x:%02x.\n",
+				netdump_daddr[0], netdump_daddr[1], netdump_daddr[2], netdump_daddr[3], netdump_daddr[4], netdump_daddr[5]);
+
+	netlog_daddr[0] = netlog_target_eth_byte0;
+	netlog_daddr[1] = netlog_target_eth_byte1;
+	netlog_daddr[2] = netlog_target_eth_byte2;
+	netlog_daddr[3] = netlog_target_eth_byte3;
+	netlog_daddr[4] = netlog_target_eth_byte4;
+	netlog_daddr[5] = netlog_target_eth_byte5;
+
+	if ((netlog_daddr[0] & netlog_daddr[1] & netlog_daddr[2] & netlog_daddr[3] & netlog_daddr[4] & netlog_daddr[5]) == 255)
+		printk(KERN_INFO "netlog: using broadcast ethernet frames to send netdump packets.\n");
+	else
+		printk(KERN_INFO "netlog: using netdump target ethernet address %02x:%02x:%02x:%02x:%02x:%02x.\n",
+				netlog_daddr[0], netlog_daddr[1], netlog_daddr[2], netlog_daddr[3], netlog_daddr[4], netlog_daddr[5]);
+	syslog_daddr[0] = syslog_target_eth_byte0;
+	syslog_daddr[1] = syslog_target_eth_byte1;
+	syslog_daddr[2] = syslog_target_eth_byte2;
+	syslog_daddr[3] = syslog_target_eth_byte3;
+	syslog_daddr[4] = syslog_target_eth_byte4;
+	syslog_daddr[5] = syslog_target_eth_byte5;
+
+	if ((syslog_daddr[0] & syslog_daddr[1] & syslog_daddr[2] & syslog_daddr[3] & syslog_daddr[4] & syslog_daddr[5]) == 255)
+		printk(KERN_INFO "netlog: using broadcast ethernet frames to send syslog packets.\n");
+	else
+		printk(KERN_INFO "netlog: using syslog target ethernet address %02x:%02x:%02x:%02x:%02x:%02x.\n",
+				syslog_daddr[0], syslog_daddr[1], syslog_daddr[2], syslog_daddr[3], syslog_daddr[4], syslog_daddr[5]);
+
+	platform_cycles(mhz, &jiffy_cycles, &mhz_cycles);
+
+	INIT_LIST_HEAD(&request_list);
+
+	if (netdump_target_ip && platform_supports_netdump) {
+		if (netdump_register_hooks(netconsole_rx, 
+					      netconsole_receive_skb,
+					      netconsole_netdump)) {
+			printk("netdump: failed to register hooks.\n");
+		}
+	}
+	netconsole_dev = ndev;
+#define STARTUP_MSG "[...network console startup...]\n"
+	write_netconsole_msg(NULL, STARTUP_MSG, strlen(STARTUP_MSG));
+
+	register_console(&netconsole);
+	printk(KERN_INFO "netlog: network logging started up successfully!\n");
+	return 0;
+}
+
+static void cleanup_netconsole(void)
+{
+	printk(KERN_INFO "netlog: network logging shut down.\n");
+	unregister_console(&netconsole);
+
+#define SHUTDOWN_MSG "[...network console shutdown...]\n"
+	write_netconsole_msg(NULL, SHUTDOWN_MSG, strlen(SHUTDOWN_MSG));
+	dev_put(netconsole_dev);
+	netconsole_dev = NULL;
+	netdump_unregister_hooks();
+}
+
+module_init(init_netconsole);
+module_exit(cleanup_netconsole);
+
+MODULE_LICENSE("GPL");
diff -urNp linux-5160/drivers/net/netconsole.h linux-5170/drivers/net/netconsole.h
--- linux-5160/drivers/net/netconsole.h
+++ linux-5170/drivers/net/netconsole.h
@@ -0,0 +1,83 @@
+/*
+ *  linux/drivers/net/netconsole.h
+ *
+ *  Copyright (C) 2001  Ingo Molnar <mingo@redhat.com>
+ *
+ *  This file contains the implementation of an IRQ-safe, crash-safe
+ *  kernel console implementation that outputs kernel messages to the
+ *  network.
+ *
+ * Modification history:
+ *
+ * 2001-09-17    started by Ingo Molnar.
+ */
+
+/****************************************************************
+ *      This program is free software; you can redistribute it and/or modify
+ *      it under the terms of the GNU General Public License as published by
+ *      the Free Software Foundation; either version 2, or (at your option)
+ *      any later version.
+ *
+ *      This program is distributed in the hope that it will be useful,
+ *      but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *      GNU General Public License for more details.
+ *
+ *      You should have received a copy of the GNU General Public License
+ *      along with this program; if not, write to the Free Software
+ *      Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ ****************************************************************/
+
+#define NETCONSOLE_VERSION 0x04
+
+#define NETDUMP_VERSION_MAX 0x5
+
+enum netdump_commands {
+	COMM_NONE = 0,
+	COMM_SEND_MEM = 1,
+	COMM_EXIT = 2,
+	COMM_REBOOT = 3,
+	COMM_HELLO = 4,
+	COMM_GET_NR_PAGES = 5,
+	COMM_GET_PAGE_SIZE = 6,
+	COMM_START_NETDUMP_ACK = 7,
+	COMM_GET_REGS = 8,
+	COMM_SHOW_STATE = 9,
+};
+
+#define NETDUMP_REQ_SIZE (8+4*4)
+
+typedef struct netdump_req_s {
+	u64 magic;
+	u32 nr;
+	u32 command;
+	u32 from;
+	u32 to;
+	struct list_head list; 
+} req_t;
+
+enum netdump_replies {
+	REPLY_NONE = 0,
+	REPLY_ERROR = 1,
+	REPLY_LOG = 2,
+	REPLY_MEM = 3,
+	REPLY_RESERVED = 4,
+	REPLY_HELLO = 5,
+	REPLY_NR_PAGES = 6,
+	REPLY_PAGE_SIZE = 7,
+	REPLY_START_NETDUMP = 8,
+	REPLY_END_NETDUMP = 9,
+	REPLY_REGS = 10,
+	REPLY_MAGIC = 11,
+	REPLY_SHOW_STATE = 12,
+};
+
+typedef struct netdump_reply_s {
+	u32 nr;
+	u32 code;
+	u32 info;
+} reply_t;
+
+#define HEADER_LEN (1 + sizeof(reply_t))
+
diff -urNp linux-5160/include/asm-generic/netdump.h linux-5170/include/asm-generic/netdump.h
--- linux-5160/include/asm-generic/netdump.h
+++ linux-5170/include/asm-generic/netdump.h
@@ -0,0 +1,56 @@
+#ifndef _ASM_GENERIC_NETDUMP_H_
+#define _ASM_GENERIC_NETDUMP_H_
+
+/*
+ * linux/include/asm-generic/netdump.h
+ *
+ * Copyright (c) 2003 Red Hat, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#ifdef __KERNEL__
+
+#warning netdump is not supported on this platform
+const static int platform_supports_netdump = 0;
+
+static inline int page_is_ram(unsigned long x) { return 0; }
+
+#define platform_timestamp(x) do { (x) = 0; } while (0)  
+
+#define platform_fix_regs() do { } while (0)
+
+#undef ELF_CORE_COPY_REGS
+#define ELF_CORE_COPY_REGS(x, y) do { struct pt_regs *z; z = (y); } while (0)
+
+#define show_mem() do {} while (0)
+
+#define show_state() do {} while (0)
+
+#define show_regs(x) do { struct pt_regs *z; z = (x); } while (0)
+
+#define platform_start_netdump(dumpfunc, regs) do { } while (0)
+#define platform_freeze_cpu() do { } while (0)
+#define platform_machine_type() (EM_NONE)
+#define platform_effective_version(x) (0)
+#define platform_max_pfn() (0)
+#define platform_get_regs(x,y) (0)
+#define platform_page_is_ram(x) (0)
+#define platform_next_available(x) ((u32)0)
+#define platform_cycles(x,y,z) do { } while (0)
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_GENERIC_NETDUMP_H */
diff -urNp linux-5160/include/asm-i386/kmap_types.h linux-5170/include/asm-i386/kmap_types.h
--- linux-5160/include/asm-i386/kmap_types.h
+++ linux-5170/include/asm-i386/kmap_types.h
@@ -26,6 +26,7 @@ enum km_type {
 	KM_PTE2,
 	KM_SOFTIRQ0,
 	KM_SOFTIRQ1,
+	KM_NETDUMP,
 	KM_TYPE_NR
 };
 
diff -urNp linux-5160/include/asm-i386/netdump.h linux-5170/include/asm-i386/netdump.h
--- linux-5160/include/asm-i386/netdump.h
+++ linux-5170/include/asm-i386/netdump.h
@@ -0,0 +1,117 @@
+#ifndef _ASM_I386_NETDUMP_H
+#define _ASM_I386_NETDUMP_H
+
+/*
+ * linux/include/asm-i386/netdump.h
+ *
+ * Copyright (c) 2003 Red Hat, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+
+#ifdef __KERNEL__
+
+const static int platform_supports_netdump = 1;
+#define platform_machine_type() (EM_386)
+
+extern int page_is_ram (unsigned long);
+#define platform_page_is_ram(x) (page_is_ram(x))
+#define platform_max_pfn() (num_physpages)
+
+#define platform_timestamp(x) rdtscll(x)
+
+#define platform_freeze_cpu() \
+{                             \
+        for (;;) __cli();     \
+}
+
+#define platform_fix_regs() \
+{                                                                      \
+       unsigned long esp;                                              \
+       unsigned short ss;                                              \
+       esp = (unsigned long) ((char *)regs + sizeof (struct pt_regs)); \
+       ss = __KERNEL_DS;                                               \
+       if (regs->xcs & 3) {                                            \
+               esp = regs->esp;                                        \
+               ss = regs->xss & 0xffff;                                \
+       }                                                               \
+       myregs = *regs;                                                 \
+       myregs.esp = esp;                                               \
+       myregs.xss = (myregs.xss & 0xffff0000) | ss;                    \
+}
+
+typedef void (*netdump_func_t)(struct pt_regs *, void *);
+
+static inline void platform_start_netdump(netdump_func_t dumpfunc,
+                                          struct pt_regs *regs)
+{
+	dumpfunc(regs, NULL);
+}
+
+
+static inline unsigned char platform_effective_version(req_t *req)
+{
+        if (req->from == 0)
+                return NETCONSOLE_VERSION;
+        else
+                return min_t(unsigned char, req->from, NETDUMP_VERSION_MAX);
+}
+
+static inline unsigned int platform_get_regs(char *tmp, struct pt_regs *myregs)
+{
+        elf_gregset_t elf_regs;
+        char *tmp2;
+
+        tmp2 = tmp + sprintf(tmp, "Sending register info.\n");
+        ELF_CORE_COPY_REGS(elf_regs, myregs);
+        memcpy(tmp2, &elf_regs, sizeof(elf_regs));
+
+        return(strlen(tmp) + sizeof(elf_regs));
+}
+
+extern unsigned long next_ram_page(unsigned long);
+
+static inline u32 platform_next_available(unsigned long pfn)
+{
+        unsigned long pgnum = next_ram_page(pfn);
+
+        if (pgnum < platform_max_pfn()) 
+                return (u32)pgnum;
+
+        return 0;
+}
+
+static inline void platform_cycles(unsigned int mhz, unsigned long long *jp, unsigned long long *mp)
+{
+        unsigned long long t0, t1;
+
+        platform_timestamp(t0);
+        mdelay(1);
+        platform_timestamp(t1);
+        if (t1 > t0) {
+		*mp = (t1-t0) * 1000ULL;
+                *jp = (unsigned long long)(((unsigned long)(t1-t0) * 1000UL)/HZ);
+	} else {
+		if (!mhz)
+			mhz = 1000;
+        	*mp = (unsigned long long)mhz * 1000000ULL;
+        	*jp = (unsigned long long)mhz * (1000000/HZ);
+	}
+}
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_I386_NETDUMP_H */
diff -urNp linux-5160/include/asm-ia64/netdump.h linux-5170/include/asm-ia64/netdump.h
--- linux-5160/include/asm-ia64/netdump.h
+++ linux-5170/include/asm-ia64/netdump.h
@@ -0,0 +1,121 @@
+#ifndef _ASM_IA64_NETDUMP_H_
+#define _ASM_IA64_NETDUMP_H_
+
+/*
+ * ./include/asm-ia64/netdump.h
+ *
+ * Copyright (c) 2003, 2004 Red Hat, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#ifdef __KERNEL__
+
+#include <linux/elf.h>
+#include <asm/unwind.h>
+
+const static int platform_supports_netdump = 1;
+
+#define platform_machine_type() (EM_IA_64)
+
+extern int page_is_ram (unsigned long);
+#define platform_page_is_ram(x) (page_is_ram(x))
+
+#define platform_max_pfn() ((__pa(high_memory)) / PAGE_SIZE)
+
+#define platform_timestamp(x) ({ x = ia64_get_itc(); })
+
+#define platform_fix_regs()                                     \
+{                                                               \
+        struct unw_frame_info *info = platform_arg;             \
+                                                                \
+        current->thread.ksp = (__u64)info->sw - 16;             \
+        myregs = *regs;                                         \
+}
+
+extern void ia64_freeze_cpu(struct unw_frame_info *, void *arg);
+static struct switch_stack *sw[NR_CPUS];
+
+#define platform_freeze_cpu()                                   \
+{                                                               \
+        unw_init_running(ia64_freeze_cpu,                       \
+                &sw[smp_processor_id()]);			\
+}
+
+extern void ia64_start_dump(struct unw_frame_info *, void *arg);
+
+typedef void (*netdump_func_t)(struct pt_regs *, void *);
+
+static inline void platform_start_netdump(netdump_func_t dumpfunc,
+                                          struct pt_regs *regs)
+{
+        struct dump_call_param param;
+
+        param.func = dumpfunc;
+        param.regs = regs;
+        unw_init_running(ia64_start_dump, &param);
+}
+
+static inline unsigned char platform_effective_version(req_t *req)
+{
+        if (req->from > 0)
+                return min_t(unsigned char, req->from, NETDUMP_VERSION_MAX);
+        else
+                return 0;
+}
+
+extern unsigned long next_ram_page(unsigned long);
+
+static inline u32 platform_next_available(unsigned long pfn)
+{
+        unsigned long pgnum = next_ram_page(pfn);
+
+        if (pgnum < platform_max_pfn()) 
+                return (u32)pgnum;
+
+        return 0;
+}
+
+static inline unsigned int platform_get_regs(char *tmp, struct pt_regs *myregs)
+{
+        char *tmp2;
+
+        tmp2 = tmp + sprintf(tmp, "Sending register info.\n");
+        memcpy(tmp2, myregs, sizeof(struct pt_regs));
+
+        return(strlen(tmp) + sizeof(struct pt_regs));
+}
+
+static inline void platform_cycles(unsigned int mhz, unsigned long long *jp, unsigned long long *mp)
+{
+        unsigned long long t0, t1;
+
+        platform_timestamp(t0);
+        mdelay(1);
+        platform_timestamp(t1);
+        if (t1 > t0) {
+		*mp = (t1-t0) * 1000ULL;
+                *jp = ((t1-t0) * 1000ULL)/HZ;
+	} else {
+                if (!mhz)
+                        mhz = 1000;
+                *mp = (unsigned long long)mhz * 1000000ULL;
+                *jp = (unsigned long long)mhz * (1000000/HZ);
+        }
+}
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_IA64_NETDUMP_H */
diff -urNp linux-5160/include/asm-ppc64/kmap_types.h linux-5170/include/asm-ppc64/kmap_types.h
--- linux-5160/include/asm-ppc64/kmap_types.h
+++ linux-5170/include/asm-ppc64/kmap_types.h
@@ -16,6 +16,7 @@ enum km_type {
 	KM_IRQ1,
 	KM_SOFTIRQ0,
 	KM_SOFTIRQ1,	
+	KM_NETDUMP,
 	KM_TYPE_NR
 };
 
diff -urNp linux-5160/include/asm-ppc64/netdump.h linux-5170/include/asm-ppc64/netdump.h
--- linux-5160/include/asm-ppc64/netdump.h
+++ linux-5170/include/asm-ppc64/netdump.h
@@ -0,0 +1,115 @@
+#ifndef _ASM_PPC64_NETDUMP_H
+#define _ASM_PPC64_NETDUMP_H
+
+/*
+ * linux/include/asm-ppc64/netdump.h
+ *
+ * Copyright (c) 2003 Red Hat, Inc. All rights reserved.
+ * Copyright (C) 2004 IBM Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+#include <asm/time.h>
+
+#ifdef __KERNEL__
+
+#ifdef CONFIG_PPC_PSERIES
+const static int platform_supports_netdump = 1;
+#else
+const static int platform_supports_netdump = 0;
+#endif /* CONFIG_PPC_PSERIES */
+
+
+#define platform_machine_type() (EM_PPC64)
+
+extern int page_is_ram (unsigned long);
+#define platform_page_is_ram(x) (page_is_ram(x))
+#define platform_max_pfn() (num_physpages)
+
+#define platform_timestamp(x) (x = get_tb())
+
+#define platform_freeze_cpu() 			\
+{                             			\
+	unsigned long sp;			\
+	asm("mr %0,1" : "=r" (sp) :);		\
+	current->thread.ksp = sp;		\
+        for (;;) __cli();     			\
+}
+
+#define platform_fix_regs() memcpy(&myregs, regs, sizeof(struct pt_regs))
+
+typedef void (*netdump_func_t)(struct pt_regs *, void *);
+
+static inline void platform_start_netdump(netdump_func_t dumpfunc,
+                                          struct pt_regs *regs)
+{
+	dumpfunc(regs, NULL);
+}
+
+
+static inline unsigned char platform_effective_version(req_t *req)
+{
+	if (req->from > 0)
+		return min_t(unsigned char, req->from, NETDUMP_VERSION_MAX);
+	else
+		return 0;
+}
+
+static inline unsigned int platform_get_regs(char *tmp, struct pt_regs *myregs)
+{
+        elf_gregset_t elf_regs;
+        char *tmp2;
+
+        tmp2 = tmp + sprintf(tmp, "Sending register info.\n");
+        ELF_CORE_COPY_REGS(elf_regs, myregs);
+        memcpy(tmp2, &elf_regs, sizeof(elf_regs));
+
+        return(strlen(tmp) + sizeof(elf_regs));
+}
+
+extern unsigned long next_ram_page(unsigned long);
+
+static inline u32 platform_next_available(unsigned long pfn)
+{
+        unsigned long pgnum = next_ram_page(pfn);
+
+        if (pgnum < platform_max_pfn()) 
+                return (u32)pgnum;
+
+        return 0;
+}
+
+static inline void platform_cycles(unsigned int mhz, unsigned long long *jp, unsigned long long *mp)
+{
+        unsigned long long t0, t1;
+
+        platform_timestamp(t0);
+        mdelay(1);
+        platform_timestamp(t1);
+        if (t1 > t0) {
+		*mp = (t1-t0) * 1000ULL;
+                *jp = ((t1-t0) * 1000ULL)/HZ;
+	} else {
+                if (!mhz)
+                        mhz = 1000;
+                *mp = (unsigned long long)mhz * 1000000ULL;
+                *jp = (unsigned long long)mhz * (1000000/HZ);
+        }
+}
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_PPC64_NETDUMP_H */
diff -urNp linux-5160/include/asm-s390/netdump.h linux-5170/include/asm-s390/netdump.h
--- linux-5160/include/asm-s390/netdump.h
+++ linux-5170/include/asm-s390/netdump.h
@@ -0,0 +1,6 @@
+#ifndef _ASM_S390_NETDUMP_H_
+#define _ASM_S390_NETDUMP_H_
+
+#include <asm-generic/netdump.h>
+
+#endif /* _ASM_S390_NETDUMP_H_ */
diff -urNp linux-5160/include/asm-s390x/netdump.h linux-5170/include/asm-s390x/netdump.h
--- linux-5160/include/asm-s390x/netdump.h
+++ linux-5170/include/asm-s390x/netdump.h
@@ -0,0 +1,6 @@
+#ifndef _ASM_S390X_NETDUMP_H_
+#define _ASM_S390X_NETDUMP_H_
+
+#include <asm-generic/netdump.h>
+
+#endif /* _ASM_S390X_NETDUMP_H_ */
diff -urNp linux-5160/include/asm-x86_64/kmap_types.h linux-5170/include/asm-x86_64/kmap_types.h
--- linux-5160/include/asm-x86_64/kmap_types.h
+++ linux-5170/include/asm-x86_64/kmap_types.h
@@ -11,6 +11,7 @@ enum km_type {
 	KM_IRQ1,
 	KM_SOFTIRQ0,
 	KM_SOFTIRQ1,
+	KM_NETDUMP,
 	KM_TYPE_NR
 };
 
diff -urNp linux-5160/include/asm-x86_64/netdump.h linux-5170/include/asm-x86_64/netdump.h
--- linux-5160/include/asm-x86_64/netdump.h
+++ linux-5170/include/asm-x86_64/netdump.h
@@ -0,0 +1,119 @@
+#ifndef _ASM_X86_64_NETDUMP_H_
+#define _ASM_X86_64_NETDUMP_H_
+
+/*
+ * ./include/asm-x86_64/netdump.h
+ *
+ * Copyright (c) 2003, 2004 Red Hat, Inc. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ */
+
+#ifdef __KERNEL__
+
+#include <linux/elf.h>
+
+const static int platform_supports_netdump = 1;
+
+#define platform_machine_type() (EM_X86_64)
+
+extern int page_is_ram (unsigned long);
+#define platform_page_is_ram(x) (page_is_ram(x) && \
+                kern_addr_valid((unsigned long)pfn_to_kaddr(x)))
+
+#define platform_max_pfn() (num_physpages)
+
+#define platform_timestamp(x) rdtscll(x)
+
+#define platform_freeze_cpu() \
+{                             \
+        for (;;) __cli();     \
+}
+
+#define platform_fix_regs() \
+{                                                                      \
+       unsigned long rsp;                                              \
+       unsigned short ss;                                              \
+                                                                       \
+       rsp = (unsigned long) ((char *)regs + sizeof (struct pt_regs)); \
+       if (regs->rsp < TASK_SIZE) {                                    \
+                rsp = regs->rsp;                                       \
+       }                                                               \
+       myregs = *regs;                                                 \
+       myregs.rsp = rsp;                                               \
+                                                                       \
+}
+
+typedef void (*netdump_func_t)(struct pt_regs *, void *);
+
+static inline void platform_start_netdump(netdump_func_t dumpfunc,
+                                          struct pt_regs *regs)
+{
+        dumpfunc(regs, NULL);
+}
+
+static inline unsigned char platform_effective_version(req_t *req)
+{
+        if (req->from > 0)
+                return min_t(unsigned char, req->from, NETDUMP_VERSION_MAX);
+        else
+                return 0;
+}
+
+extern unsigned long next_ram_page(unsigned long);
+
+static inline u32 platform_next_available(unsigned long pfn)
+{
+        unsigned long pgnum = next_ram_page(pfn);
+
+        if (pgnum < platform_max_pfn())
+                return (u32)pgnum;
+
+        return 0;
+}
+
+static inline unsigned int platform_get_regs(char *tmp, struct pt_regs *myregs)
+{
+        elf_gregset_t elf_regs;
+        char *tmp2;
+
+        tmp2 = tmp + sprintf(tmp, "Sending register info.\n");
+        ELF_CORE_COPY_REGS(elf_regs, myregs);
+        memcpy(tmp2, &elf_regs, sizeof(elf_regs));
+
+        return(strlen(tmp) + sizeof(elf_regs));
+}
+
+static inline void platform_cycles(unsigned int mhz, unsigned long long *jp, unsigned long long *mp)
+{
+        unsigned long long t0, t1;
+
+        platform_timestamp(t0);
+        mdelay(1);
+        platform_timestamp(t1);
+        if (t1 > t0) {
+		*mp = (t1-t0) * 1000ULL;
+                *jp = ((t1-t0) * 1000ULL)/HZ;
+	} else {
+                if (!mhz)
+                        mhz = 1000;
+                *mp = (unsigned long long)mhz * 1000000ULL;
+                *jp = (unsigned long long)mhz * (1000000/HZ);
+        }
+}
+
+#endif /* __KERNEL__ */
+
+#endif /* _ASM_X86_64_NETDUMP_H */
diff -urNp linux-5160/include/linux/if.h linux-5170/include/linux/if.h
--- linux-5160/include/linux/if.h
+++ linux-5170/include/linux/if.h
@@ -50,6 +50,8 @@
 
 /* Private (from user) interface flags (netdevice->priv_flags). */
 #define IFF_802_1Q_VLAN 0x1             /* 802.1Q VLAN device.          */
+/* this flag is put at 0x4 since upstream has at least used 0x2 already. */
+#define IFF_NETCONSOLE  0x4             /* called via netconsole */
 
 
 #define IF_GET_IFACE	0x0001		/* for querying only */
diff -urNp linux-5160/include/linux/kernel.h linux-5170/include/linux/kernel.h
--- linux-5160/include/linux/kernel.h
+++ linux-5170/include/linux/kernel.h
@@ -107,6 +107,10 @@ static inline void console_verbose(void)
 
 extern void bust_spinlocks(int yes);
 extern int oops_in_progress;		/* If set, an oops, panic(), BUG() or die() is in progress */
+extern int panic_on_oops;
+struct pt_regs;
+extern void (*netdump_func)(struct pt_regs *regs);
+extern int netdump_mode;
 
 extern int tainted;
 extern const char *print_tainted(void);
diff -urNp linux-5160/include/linux/netdevice.h linux-5170/include/linux/netdevice.h
--- linux-5160/include/linux/netdevice.h
+++ linux-5170/include/linux/netdevice.h
@@ -439,6 +439,8 @@ struct net_device
 						     unsigned char *haddr);
 	int			(*neigh_setup)(struct net_device *dev, struct neigh_parms *);
 	int			(*accept_fastpath)(struct net_device *, struct dst_entry*);
+#define HAVE_POLL_CONTROLLER
+	void			(*poll_controller)(struct net_device *dev);
 
 	/* open/release and usage marking */
 	struct module *owner;
@@ -623,6 +625,12 @@ extern void		dev_init(void);
 
 extern int		netdev_nit;
 
+/* netconsole rx hook registration */
+extern int netdump_register_hooks(int (*)(struct sk_buff *),
+				  int (*)(struct sk_buff *),
+				  void (*)(struct pt_regs *));
+extern void netdump_unregister_hooks(void);
+
 /* Post buffer to the network code from _non interrupt_ context.
  * see net/core/dev.c for netif_rx description.
  */
diff -urNp linux-5160/include/linux/smp.h linux-5170/include/linux/smp.h
--- linux-5160/include/linux/smp.h
+++ linux-5170/include/linux/smp.h
@@ -51,6 +51,7 @@ extern void smp_commence(void);
  */
 extern int smp_call_function (void (*func) (void *info), void *info,
 			      int retry, int wait);
+extern void dump_smp_call_function (void (*func) (void *info), void *info);
 
 /*
  * Call a function on all processors
diff -urNp linux-5160/kernel/ksyms.c linux-5170/kernel/ksyms.c
--- linux-5160/kernel/ksyms.c
+++ linux-5170/kernel/ksyms.c
@@ -53,6 +53,7 @@
 #include <linux/crc32.h>
 #include <asm/checksum.h>
 #include <linux/unistd.h>
+#include <linux/netdevice.h>
 
 
 #if defined(CONFIG_PROC_FS)
@@ -652,3 +653,8 @@ EXPORT_SYMBOL_GPL(set_special_pids);
 extern void check_tasklist_locked(void);
 EXPORT_SYMBOL_GPL(check_tasklist_locked);
 EXPORT_SYMBOL(dump_stack);
+
+EXPORT_SYMBOL_GPL(netdump_func);
+EXPORT_SYMBOL_GPL(netdump_mode);
+EXPORT_SYMBOL_GPL(netdump_register_hooks);
+EXPORT_SYMBOL_GPL(netdump_unregister_hooks);
diff -urNp linux-5160/kernel/panic.c linux-5170/kernel/panic.c
--- linux-5160/kernel/panic.c
+++ linux-5170/kernel/panic.c
@@ -16,12 +16,14 @@
 #include <linux/init.h>
 #include <linux/sysrq.h>
 #include <linux/interrupt.h>
+#include <linux/nmi.h>
 #include <linux/vt_kern.h>
 #include <linux/pc_keyb.h>
 
 asmlinkage void sys_sync(void);	/* it's really int */
 
 int panic_timeout;
+int panic_on_oops = 1;
 
 struct notifier_block *panic_notifier_list;
 
@@ -188,6 +190,8 @@ __setup("panicblink=", panicblink_setup)
  *
  *	This function never returns.
  */
+
+int netdump_mode = 0;
  
 NORET_TYPE void panic(const char * fmt, ...)
 {
@@ -202,6 +206,8 @@ NORET_TYPE void panic(const char * fmt, 
 	vsprintf(buf, fmt, args);
 	va_end(args);
 	printk(KERN_EMERG "Kernel panic: %s\n",buf);
+	if (netdump_func)
+		BUG();
 	if (in_interrupt())
 		printk(KERN_EMERG "In interrupt handler - not syncing\n");
 	else if (!current->pid)
@@ -209,6 +215,7 @@ NORET_TYPE void panic(const char * fmt, 
 	else
 		sys_sync();
 	bust_spinlocks(0);
+	printk("\n");
 
 #ifdef CONFIG_SMP
 	smp_send_stop();
@@ -218,12 +225,18 @@ NORET_TYPE void panic(const char * fmt, 
 
 	if (panic_timeout > 0)
 	{
+		int i;
 		/*
 	 	 * Delay timeout seconds before rebooting the machine. 
 		 * We can't use the "normal" timers since we just panicked..
 	 	 */
-		printk(KERN_EMERG "Rebooting in %d seconds..",panic_timeout);
-		mdelay(panic_timeout*1000);
+		printk(KERN_EMERG "Rebooting in %d second%s..",
+			panic_timeout, "s" + (panic_timeout == 1));
+		for (i = 0; i < panic_timeout; i++) {
+			touch_nmi_watchdog();
+			mdelay(1000);
+		}
+		printk("\n");
 		/*
 		 *	Should we run the reboot notifier. For the moment Im
 		 *	choosing not too. It might crash, be corrupt or do
@@ -253,7 +266,7 @@ NORET_TYPE void panic(const char * fmt, 
 #if defined(CONFIG_ARCH_S390)
         disabled_wait(caller);
 #endif
-	sti();
+	local_irq_enable();
 	for(;;) {
 		panic_blink(buf); 
 		CHECK_EMERGENCY_SYNC
diff -urNp linux-5160/kernel/printk.c linux-5170/kernel/printk.c
--- linux-5160/kernel/printk.c
+++ linux-5170/kernel/printk.c
@@ -307,6 +307,20 @@ asmlinkage long sys_syslog(int type, cha
 }
 
 /*
+ * Netdump special routine. Don't print to global log_buf, just to the
+ * actual console device(s).
+ */
+static void netdump_call_console_drivers(const char *buf, unsigned long len)
+{
+	struct console *con;
+
+	for (con = console_drivers; con; con = con->next) {
+		if ((con->flags & CON_ENABLED) && con->write)
+			con->write(con, buf, len);
+	}
+}
+
+/*
  * Call the console drivers on a range of log_buf
  */
 static void __call_console_drivers(unsigned long start, unsigned long end)
@@ -480,6 +494,12 @@ asmlinkage int printk(const char *fmt, .
 	printed_len = vsnprintf(printk_buf, sizeof(printk_buf), fmt, args);
 	va_end(args);
 
+	if (unlikely(netdump_mode)) {
+		netdump_call_console_drivers(printk_buf, printed_len);
+		spin_unlock_irqrestore(&logbuf_lock, flags);
+		goto out;
+	}
+
 	/*
 	 * Copy the output into log_buf.  If the caller didn't provide
 	 * appropriate log level tags, we insert them here
diff -urNp linux-5160/kernel/sysctl.c linux-5170/kernel/sysctl.c
--- linux-5160/kernel/sysctl.c
+++ linux-5170/kernel/sysctl.c
@@ -196,6 +196,8 @@ static ctl_table kern_table[] = {
 	 0644, NULL, &proc_doutsstring, &sysctl_string},
 	{KERN_PANIC, "panic", &panic_timeout, sizeof(int),
 	 0644, NULL, &proc_dointvec},
+	{KERN_PANIC, "panic_on_oops", &panic_on_oops, sizeof(int),
+	 0644, NULL, &proc_dointvec},
 	{KERN_PANIC, "print_fatal_signals", &print_fatal_signals, sizeof(int),
 	 0644, NULL, &proc_dointvec},
 	{KERN_PANIC, "exec-shield", &exec_shield, sizeof(int),
diff -urNp linux-5160/net/core/dev.c linux-5170/net/core/dev.c
--- linux-5160/net/core/dev.c
+++ linux-5170/net/core/dev.c
@@ -194,6 +194,16 @@ int netdev_fastroute_obstacles;
 #endif
 
 
+/*
+ *  Netdump  stuff.
+ */
+typedef int (netdump_rx_cb_t)(struct sk_buff *);
+typedef int (netdump_napi_rx_cb_t)(struct sk_buff *);
+
+static netdump_rx_cb_t *netdump_rx;
+static netdump_napi_rx_cb_t *netdump_receive_skb;
+void (*netdump_func) (struct pt_regs *regs) = NULL;
+
 /******************************************************************************************
 
 		Protocol management and registration routines
@@ -1312,6 +1322,13 @@ int netif_rx(struct sk_buff *skb)
 
 	local_irq_save(flags);
 
+	if (unlikely(netdump_func != NULL)) {
+
+		if (netdump_rx && netdump_rx(skb) == NET_RX_DROP) {
+			goto drop;
+		}
+        }
+
 	netdev_rx_stat[this_cpu].total++;
 	if (queue->input_pkt_queue.qlen <= netdev_max_backlog) {
 		if (queue->input_pkt_queue.qlen) {
@@ -2935,3 +2952,24 @@ static int net_run_sbin_hotplug(struct n
 	return call_usermodehelper(argv [0], argv, envp);
 }
 #endif
+
+int netdump_register_hooks(netdump_rx_cb_t *rx_hook, 
+			   netdump_napi_rx_cb_t *napi_rx_hook,
+			   void (*dump_func) (struct pt_regs *))
+{
+	if (!rx_hook || !napi_rx_hook || !dump_func)
+		return -1;
+
+	netdump_rx = rx_hook;
+	netdump_receive_skb = napi_rx_hook;
+	netdump_func = dump_func;
+
+	return 0;
+}
+
+void netdump_unregister_hooks(void)
+{
+	netdump_rx = NULL;
+	netdump_receive_skb = NULL;
+	netdump_func = NULL;
+}
