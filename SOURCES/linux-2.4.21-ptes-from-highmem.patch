diff -urNp linux-1223/arch/i386/mm/pgtable.c linux-1224/arch/i386/mm/pgtable.c
--- linux-1223/arch/i386/mm/pgtable.c
+++ linux-1224/arch/i386/mm/pgtable.c
@@ -153,7 +153,7 @@ struct page *pte_alloc_one(struct mm_str
    
    	do {
 #if CONFIG_HIGHPTE
-		pte = alloc_pages(GFP_KERNEL | __GFP_HIGHMEM, 0);
+		pte = alloc_pages(GFP_KERNEL | __GFP_HIGHMEM | __GFP_WIRED, 0);
 #else
 		pte = alloc_pages(GFP_KERNEL, 0);
 #endif
diff -urNp linux-1223/fs/ramfs/inode.c linux-1224/fs/ramfs/inode.c
--- linux-1223/fs/ramfs/inode.c
+++ linux-1224/fs/ramfs/inode.c
@@ -109,6 +109,10 @@ struct inode *ramfs_get_inode(struct sup
 		inode->i_blocks = 0;
 		inode->i_rdev = NODEV;
 		inode->i_mapping->a_ops = &ramfs_aops;
+#ifdef CONFIG_HIGHMEM
+		/* try really hard to alloc the pages from highmem */
+		inode->i_mapping->gfp_mask |= __GFP_WIRED;
+#endif
 		inode->i_atime = inode->i_mtime = inode->i_ctime = CURRENT_TIME;
 		switch (mode & S_IFMT) {
 		default:
diff -urNp linux-1223/include/linux/mm.h linux-1224/include/linux/mm.h
--- linux-1223/include/linux/mm.h
+++ linux-1224/include/linux/mm.h
@@ -837,6 +837,7 @@ extern struct page *filemap_nopage(struc
 #define __GFP_IO	0x40	/* Can start low memory physical IO? */
 #define __GFP_HIGHIO	0x80	/* Can start high mem physical IO? */
 #define __GFP_FS	0x100	/* Can call down to low-level FS? */
+#define __GFP_WIRED	0x200   /* Highmem bias and wired */
 
 #define GFP_NOHIGHIO	(__GFP_HIGH | __GFP_WAIT | __GFP_IO)
 #define GFP_NOIO	(__GFP_HIGH | __GFP_WAIT)
diff -urNp linux-1223/mm/page_alloc.c linux-1224/mm/page_alloc.c
--- linux-1223/mm/page_alloc.c
+++ linux-1224/mm/page_alloc.c
@@ -381,8 +381,8 @@ void fixup_freespace(zone_t * zone, int 
 			if ((page = reclaim_page(zone))) {
 				if (page_count(page) != 1)
 					printk("fixup_freespace(): incorrect sub-page count %08x, of page %016Lx(%08lx).\n", page_count(page), (unsigned long long)(page-mem_map)*PAGE_SIZE, page->flags);
-					set_page_count(page, 0);
-					__free_pages_ok(page, 0);
+				set_page_count(page, 0);
+				__free_pages_ok(page, 0);
 			}
 		} while (page && worktodo-- > 0);
 	}
@@ -393,13 +393,27 @@ void fixup_freespace(zone_t * zone, int 
 #define PAGES_LOW	2
 #define PAGES_HIGH	3
 
+static int enough_freeable_memory(zone_t *z)
+{
+	int pages;
+
+	pages = z->free_pages + z->inactive_clean_pages +
+		z->inactive_laundry_pages + z->inactive_dirty_pages +
+		z->active_cache_pages + z->active_anon_pages;
+
+	if (pages > z->size * 10 / 100)
+		return 1;
+	else
+		return 0;
+}
+
 /*
  * This function does the dirty work for __alloc_pages
  * and is separated out to keep the code size smaller.
  * (suggested by Davem at 1:30 AM, typed by Rik at 6 AM)
  */
 static struct page * __alloc_pages_limit(zonelist_t *zonelist,
-			unsigned long order, int limit, int direct_reclaim)
+			unsigned long order, int limit, int direct_reclaim, int wired)
 {
 	zone_t **zone = zonelist->zones;
 	unsigned long water_mark = 0;
@@ -441,6 +455,9 @@ static struct page * __alloc_pages_limit
 			if (page)
 				return page;
 		}
+
+		if (wired && enough_freeable_memory(z))
+			break;
 	}
 
 	/* Found nothing. */
@@ -455,6 +472,7 @@ struct page * __alloc_pages(unsigned int
 	zone_t **zone;
 	int min, direct_reclaim = 0;
 	struct page * page;
+	int wired = gfp_mask & __GFP_WIRED;
 
 	/*
 	 * (If anyone calls gfp from interrupts nonatomically then it
@@ -489,13 +507,15 @@ try_again:
 			break;
 		if (!z->size)
 			continue;
-
-		if (z->free_pages > z->pages_low) {
+		if (z->free_pages > ((wired && zone_is_highmem(z)) ? z->pages_min:z->pages_low)) {
 			page = rmqueue(z, order);
 			if (page)
 				return page;
 		} else if (z->free_pages < z->pages_min)
 			fixup_freespace(z, direct_reclaim);
+
+		if (wired)
+			break;
 	}
 
 	/*
@@ -506,7 +526,7 @@ try_again:
 	 * will be high and we'll have a good chance of
 	 * finding a page using the HIGH limit.
 	 */
-	page = __alloc_pages_limit(zonelist, order, PAGES_HIGH, direct_reclaim);
+	page = __alloc_pages_limit(zonelist, order, PAGES_HIGH, direct_reclaim, wired);
 	if (page)
 		return page;
 
@@ -518,7 +538,7 @@ try_again:
 	 * is low, we're most likely to have our allocation
 	 * succeed here.
 	 */
-	page = __alloc_pages_limit(zonelist, order, PAGES_LOW, direct_reclaim);
+	page = __alloc_pages_limit(zonelist, order, PAGES_LOW, direct_reclaim, wired);
 	if (page)
 		return page;
 
@@ -544,7 +564,7 @@ try_again:
 	 * Kswapd should, in most situations, bring the situation
 	 * back to normal in no time.
 	 */
-	page = __alloc_pages_limit(zonelist, order, PAGES_MIN, direct_reclaim);
+	page = __alloc_pages_limit(zonelist, order, PAGES_MIN, direct_reclaim, wired);
 	if (page)
 		return page;
 
@@ -554,7 +574,7 @@ try_again:
 	 * the SCSI layer isn't happy ...
 	 */
 	if (gfp_mask & __GFP_HIGH) {
-		page = __alloc_pages_limit(zonelist, order, PAGES_KERNEL, direct_reclaim);
+		page = __alloc_pages_limit(zonelist, order, PAGES_KERNEL, direct_reclaim, wired);
 		if (page)
 			return page;
 	}
@@ -592,8 +612,10 @@ try_again:
 			yield();
 			if (!order || free_high(ALL_ZONES) >= 0) {
 				int progress = try_to_free_pages(gfp_mask);
-				if (progress || (gfp_mask & __GFP_FS))
+				if (progress || (gfp_mask & __GFP_FS)) {
+					wired = 0;
 					goto try_again;
+				}
 				/*
 				 * Fail if no progress was made and the
 				 * allocation may not be able to block on IO.
diff -urNp linux-1223/mm/vmscan.c linux-1224/mm/vmscan.c
--- linux-1223/mm/vmscan.c
+++ linux-1224/mm/vmscan.c
@@ -963,7 +963,9 @@ static int do_try_to_free_pages(unsigned
 	/*
 	 * Mhwahahhaha! This is the part I really like. Giggle.
 	 */
-	if (!ret && free_min(ANY_ZONE) > 0 && (gfp_mask & __GFP_FS))
+	if (!ret && free_min(ANY_ZONE) > 0 && (gfp_mask & __GFP_FS) &&
+	    !((gfp_mask & __GFP_WIRED) &&
+	      free_min(&pgdat_list->node_zones[ZONE_NORMAL]) < 0))
 		out_of_memory();
 
 	return ret;
