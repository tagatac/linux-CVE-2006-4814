--- linux-2.4.21/drivers/md/lvm.c.=K0001=.orig
+++ linux-2.4.21/drivers/md/lvm.c
@@ -1426,7 +1426,7 @@ static int lvm_push_callback(lv_t *lv, i
 	nbh->b_end_io	  = lvm_bh_callback;
 	nbh->b_private	  = callback;
 
-	down_read(&lv->lv_io_sem);
+	lvm_start_io(lv);
 	generic_make_request(rw, nbh);
 	
 	return 0; /* Tell generic_make_request not to pursue the
@@ -1444,7 +1444,7 @@ static void lvm_bh_callback(struct buffe
 	lv = callback->lv;
 	obh = callback->bh_orig;
 	
-	up_read(&lv->lv_io_sem);
+	lvm_complete_io(lv);
 	
 	mempool_free(callback, lvm_callback_mempool);
 	if (obh->b_end_io)
@@ -1657,11 +1657,11 @@ static int lvm_do_pe_locked_copy(vg_t *v
            can't mutex just one PE without tracking outstanding IO on a
            per-extent basis.) */
 
-	down_write(&lv_ptr->lv_io_sem);
+	lvm_io_take_barrier(lv_ptr);
 	err = do_pe_lock(lv_ptr->lv_dev,
 			 pe_copy_req.old_dev, 
 			 pe_copy_req.old_pe);
-	up_write(&lv_ptr->lv_io_sem);
+	lvm_io_drop_barrier(lv_ptr);
 
 	if (err)
 		return err;
@@ -2241,7 +2241,7 @@ static int lvm_do_lv_create(int minor, c
 	lv_ptr->lv_snapshot_hash_table_size = 0;
 	lv_ptr->lv_snapshot_hash_mask = 0;
 	init_rwsem(&lv_ptr->lv_lock);
-	init_rwsem(&lv_ptr->lv_io_sem);
+	lvm_init_barrier(lv_ptr);
 	
 	lv_ptr->lv_snapshot_use_rate = 0;
 
--- linux-2.4.21/include/linux/lvm.h.=K0001=.orig
+++ linux-2.4.21/include/linux/lvm.h
@@ -577,13 +577,79 @@ typedef struct lv_v5 {
 	struct vg_v3	*vg;
 
 	uint lv_allocated_snapshot_le;
-
-	struct rw_semaphore lv_io_sem;
+	
+	spinlock_t lv_ios_spinlock;
+	atomic_t lv_ios_outstanding;
+	int lv_io_barrier;
+	wait_queue_head_t lv_ios_wq;
 #else
 	char dummy[200];
 #endif
 } lv_t;
 
+#ifdef __KERNEL__
+static inline void lvm_init_barrier(lv_t *lv)
+{
+	spin_lock_init(&lv->lv_ios_spinlock);
+	atomic_set(&lv->lv_ios_outstanding, 0);
+	lv->lv_io_barrier = 0;
+	init_waitqueue_head(&lv->lv_ios_wq);
+}
+
+static inline void lvm_io_take_barrier(lv_t *lv)
+{
+repeat:
+	spin_lock(&lv->lv_ios_spinlock);
+
+	if (atomic_read(&lv->lv_ios_outstanding)) {
+		spin_unlock(&lv->lv_ios_spinlock);
+		wait_event(lv->lv_ios_wq,
+			   atomic_read(&lv->lv_ios_outstanding) == 0);
+		goto repeat;
+	}
+	
+	if (lv->lv_io_barrier) {
+		spin_unlock(&lv->lv_ios_spinlock);
+		wait_event(lv->lv_ios_wq,
+			   lv->lv_io_barrier == 0);
+		goto repeat;
+	}
+		
+	lv->lv_io_barrier = 1;
+	spin_unlock(&lv->lv_ios_spinlock);
+}
+
+static inline void lvm_io_drop_barrier(lv_t *lv)
+{
+	spin_lock(&lv->lv_ios_spinlock);
+	BUG_ON(lv->lv_io_barrier != 1);
+	lv->lv_io_barrier = 0;
+	wake_up(&lv->lv_ios_wq);
+	spin_unlock(&lv->lv_ios_spinlock);
+}
+
+static inline void lvm_start_io(lv_t *lv)
+{
+repeat:
+	spin_lock(&lv->lv_ios_spinlock);
+	if (lv->lv_io_barrier) {
+		spin_unlock(&lv->lv_ios_spinlock);
+		wait_event(lv->lv_ios_wq,
+			   lv->lv_io_barrier == 0);
+		goto repeat;
+	}
+	atomic_inc(&lv->lv_ios_outstanding);
+	spin_unlock(&lv->lv_ios_spinlock);
+}
+
+static inline void lvm_complete_io(lv_t *lv)
+{
+	if (atomic_dec_and_test(&lv->lv_ios_outstanding))
+		wake_up(&lv->lv_ios_wq);
+}
+#endif
+
+
 /* disk */
 typedef struct lv_disk_v3 {
 	uint8_t lv_name[NAME_LEN];
