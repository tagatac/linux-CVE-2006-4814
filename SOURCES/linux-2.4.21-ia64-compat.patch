diff -urNp linux-268/arch/ia64/config.in linux-270/arch/ia64/config.in
--- linux-268/arch/ia64/config.in
+++ linux-270/arch/ia64/config.in
@@ -90,7 +90,10 @@ define_bool CONFIG_KCORE_ELF y	# On IA-6
 
 bool 'Use PAL_HALT_LIGHT in idle loop' CONFIG_IA64_PAL_IDLE
 bool 'SMP support' CONFIG_SMP
-tristate 'Support running of Linux/x86 binaries' CONFIG_IA32_SUPPORT
+bool 'Support running of Linux/x86 binaries' CONFIG_IA32_SUPPORT
+if [ "$CONFIG_IA32_SUPPORT" = "y" ]; then
+  define_bool CONFIG_COMPAT y
+fi
 bool 'Performance monitor support' CONFIG_PERFMON
 tristate '/proc/pal support' CONFIG_IA64_PALINFO
 tristate '/proc/efi/vars support' CONFIG_EFI_VARS
diff -urNp linux-268/arch/ia64/ia32/binfmt_elf32.c linux-270/arch/ia64/ia32/binfmt_elf32.c
--- linux-268/arch/ia64/ia32/binfmt_elf32.c
+++ linux-270/arch/ia64/ia32/binfmt_elf32.c
@@ -17,6 +17,8 @@
 #include <asm/signal.h>
 #include <asm/ia32.h>
 
+#include "elfcore32.h"
+
 #define CONFIG_BINFMT_ELF32
 
 /* Override some function names */
@@ -60,7 +62,7 @@ extern unsigned long *ia32_gdt;
 struct page *
 ia32_install_shared_page (struct vm_area_struct *vma, unsigned long address, int no_share)
 {
-	struct page *pg = ia32_shared_page[(address - vma->vm_start)/PAGE_SIZE];
+	struct page *pg = ia32_shared_page[smp_processor_id()];
 
 	get_page(pg);
 	return pg;
@@ -84,7 +86,7 @@ ia64_elf32_init (struct pt_regs *regs)
 	if (vma) {
 		vma->vm_mm = current->mm;
 		vma->vm_start = IA32_GDT_OFFSET;
-		vma->vm_end = vma->vm_start + max(PAGE_SIZE, 2*IA32_PAGE_SIZE);
+		vma->vm_end = vma->vm_start + PAGE_SIZE;
 		vma->vm_page_prot = PAGE_SHARED;
 		vma->vm_flags = VM_READ|VM_MAYREAD;
 		vma->vm_ops = &ia32_shared_page_vm_ops;
@@ -221,3 +223,16 @@ elf32_map (struct file *filep, unsigned 
 	return ia32_do_mmap(filep, (addr & IA32_PAGE_MASK), eppnt->p_filesz + pgoff, prot, type,
 			    eppnt->p_offset - pgoff);
 }
+
+#define cpu_uses_ia32el()	(local_cpu_data->family > 0x1f)
+
+static int __init check_elf32_binfmt(void)
+{
+	if (cpu_uses_ia32el()) {
+		printk(KERN_INFO "IA-32 emulation not present, assuming IA-32EL is installed\n");
+		return unregister_binfmt(&elf_format);
+	}
+	return 0;
+}
+
+module_init(check_elf32_binfmt)
diff -urNp linux-268/arch/ia64/ia32/elfcore32.h linux-270/arch/ia64/ia32/elfcore32.h
--- linux-268/arch/ia64/ia32/elfcore32.h
+++ linux-270/arch/ia64/ia32/elfcore32.h
@@ -0,0 +1,130 @@
+/*
+ * IA-32 ELF core dump support.
+ *
+ * Copyright (C) 2003 Arun Sharma <arun sharma intel com>
+ *
+ * Derived from the x86_64 version
+ */
+#ifndef _ELFCORE32_H_
+#define _ELFCORE32_H_
+
+#include <linux/compat.h>
+
+#define USE_ELF_CORE_DUMP 1
+
+/* Override elfcore.h */ 
+#define _LINUX_ELFCORE_H 1
+typedef unsigned int elf_greg_t;
+
+#define ELF_NGREG (sizeof (struct user_regs_struct32) / sizeof(elf_greg_t))
+typedef elf_greg_t elf_gregset_t[ELF_NGREG];
+
+typedef struct ia32_user_i387_struct elf_fpregset_t;
+typedef struct ia32_user_fxsr_struct elf_fpxregset_t;
+
+struct elf_siginfo
+{
+	int	si_signo;			/* signal number */
+	int	si_code;			/* extra code */
+	int	si_errno;			/* errno */
+};
+
+#define jiffies_to_timeval(a,b) do { (b)->tv_usec = 0; (b)->tv_sec = (a)/HZ; }while(0)
+
+struct elf_prstatus
+{
+	struct elf_siginfo pr_info;	/* Info associated with signal */
+	short	pr_cursig;		/* Current signal */
+	unsigned int pr_sigpend;	/* Set of pending signals */
+	unsigned int pr_sighold;	/* Set of held signals */
+	pid_t	pr_pid;
+	pid_t	pr_ppid;
+	pid_t	pr_pgrp;
+	pid_t	pr_sid;
+	struct compat_timeval pr_utime;	/* User time */
+	struct compat_timeval pr_stime;	/* System time */
+	struct compat_timeval pr_cutime;	/* Cumulative user time */
+	struct compat_timeval pr_cstime;	/* Cumulative system time */
+	elf_gregset_t pr_reg;	/* GP registers */
+	int pr_fpvalid;		/* True if math co-processor being used.  */
+};
+
+#define ELF_PRARGSZ	(80)	/* Number of chars for args */
+
+struct elf_prpsinfo
+{
+	char	pr_state;	/* numeric process state */
+	char	pr_sname;	/* char for pr_state */
+	char	pr_zomb;	/* zombie */
+	char	pr_nice;	/* nice val */
+	unsigned int pr_flag;	/* flags */
+	__u16	pr_uid;
+	__u16	pr_gid;
+	pid_t	pr_pid, pr_ppid, pr_pgrp, pr_sid;
+	/* Lots missing */
+	char	pr_fname[16];	/* filename of executable */
+	char	pr_psargs[ELF_PRARGSZ];	/* initial part of arg list */
+};
+
+#define ELF_CORE_COPY_REGS(pr_reg, regs)       		\
+	pr_reg[0] = regs->r11;				\
+	pr_reg[1] = regs->r9;				\
+	pr_reg[2] = regs->r10;				\
+	pr_reg[3] = regs->r14;				\
+	pr_reg[4] = regs->r15;				\
+	pr_reg[5] = regs->r13;				\
+	pr_reg[6] = regs->r8;				\
+	pr_reg[7] = regs->r16 & 0xffff;			\
+	pr_reg[8] = (regs->r16 >> 16) & 0xffff;		\
+	pr_reg[9] = (regs->r16 >> 32) & 0xffff;		\
+	pr_reg[10] = (regs->r16 >> 48) & 0xffff;	\
+	pr_reg[11] = regs->r1; 				\
+	pr_reg[12] = regs->cr_iip;			\
+	pr_reg[13] = regs->r17 & 0xffff;		\
+	asm volatile ("mov %0=ar.eflag ;;"		\
+		      : "=r"(pr_reg[14]));		\
+	pr_reg[15] = regs->r12;				\
+	pr_reg[16] = (regs->r17 >> 16) & 0xffff;
+
+static inline void elf_core_copy_regs(elf_gregset_t *elfregs,
+				      struct pt_regs *regs)
+{
+	ELF_CORE_COPY_REGS((*elfregs), regs)
+}
+
+static inline int elf_core_copy_task_regs(struct task_struct *t,
+					  elf_gregset_t* elfregs)
+{	
+	struct pt_regs *pp = ia64_task_regs(t);
+	ELF_CORE_COPY_REGS((*elfregs), pp);
+	return 1; 
+}
+
+static inline int 
+elf_core_copy_task_fpregs(struct task_struct *tsk, elf_fpregset_t *fpu)
+{
+	struct ia32_user_i387_struct *fpstate = (void*)fpu;
+
+	if (!tsk->used_math) 
+		return 0;
+
+	save_ia32_fpstate(tsk, fpstate);
+
+	return 1; 
+}
+
+#define ELF_CORE_COPY_XFPREGS 1
+static inline int 
+elf_core_copy_task_xfpregs(struct task_struct *tsk, elf_fpxregset_t *xfpu)
+{
+	struct ia32_user_fxsr_struct *fpxstate = (void*) xfpu; 
+
+	if (!tsk->used_math) 
+		return 0;
+
+	save_ia32_fpxstate(tsk, fpxstate);
+	
+	return 1;
+}
+
+#endif /* _ELFCORE32_H_ */
diff -urNp linux-268/arch/ia64/ia32/ia32_entry.S linux-270/arch/ia64/ia32/ia32_entry.S
--- linux-268/arch/ia64/ia32/ia32_entry.S
+++ linux-270/arch/ia64/ia32/ia32_entry.S
@@ -31,7 +31,7 @@ END(ia32_execve)
 
 ENTRY(ia32_clone)
 	.prologue ASM_UNW_PRLG_RP|ASM_UNW_PRLG_PFS, ASM_UNW_PRLG_GRSAVE(2)
-	alloc r16=ar.pfs,2,2,4,0
+	alloc r16=ar.pfs,5,2,6,0
 	DO_SAVE_SWITCH_STACK
 	mov loc0=rp
 	mov loc1=r16				// save ar.pfs across do_fork
@@ -40,6 +40,8 @@ ENTRY(ia32_clone)
 	mov out3=16				// stacksize (compensates for 16-byte scratch area)
 	adds out2=IA64_SWITCH_STACK_SIZE+16,sp	// out2 = &regs
 	zxt4 out0=in0				// out0 = clone_flags
+	zxt4 out4=in2				// out4 = parent_tidptr
+	zxt4 out5=in4				// out5 = child_tidptr
 	br.call.sptk.many rp=do_fork
 .ret0:	.restore sp
 	adds sp=IA64_SWITCH_STACK_SIZE,sp	// pop the switch stack
@@ -131,6 +133,19 @@ GLOBAL_ENTRY(ia32_trace_syscall)
 	;;
 	st8 [r2]=r3				// initialize return code to -ENOSYS
 	br.call.sptk.few rp=invoke_syscall_trace // give parent a chance to catch syscall args
+	// Need to reload arguments (they may be changed by the tracing process)
+	adds r2=IA64_PT_REGS_R9_OFFSET+16,sp	// r2 = &pt_regs.r9
+	adds r3=IA64_PT_REGS_R13_OFFSET+16,sp	// r3 = &pt_regs.r13
+	;;
+	ld4 r33=[r2],8				// r9 == ecx
+	ld4 r37=[r3],8				// r13 == ebp
+	;;
+	ld4 r34=[r2],8				// r10 == edx
+	ld4 r35=[r3],8				// r14 == esi
+	;;
+	ld4 r32=[r2],8				// r11 == ebx
+	ld4 r36=[r3],8				// r15 == edi
+	;;
 .ret2:	br.call.sptk.few rp=b6			// do the syscall
 .ia32_strace_check_retval:
 	cmp.lt p6,p0=r8,r0			// syscall failed?
@@ -401,10 +416,51 @@ ia32_syscall_table:
 	data8 sys_ni_syscall		/* reserved for Security */
 	data8 sys_gettid
 	data8 sys_readahead	  /* 225 */
+	data8 sys_setxattr
+	data8 sys_lsetxattr
+	data8 sys_fsetxattr
+	data8 sys_getxattr
+	data8 sys_lgetxattr    /* 230 */
+	data8 sys_fgetxattr
+	data8 sys_listxattr
+	data8 sys_llistxattr
+	data8 sys_flistxattr
+	data8 sys_removexattr    /* 235 */
+	data8 sys_lremovexattr
+	data8 sys_fremovexattr
+	data8 sys_tkill
+	data8 sys_sendfile64
+	data8 compat_sys_futex  /* 240 */
+	data8 compat_sys_sched_setaffinity
+	data8 compat_sys_sched_getaffinity
+	data8 sys32_set_thread_area
+	data8 sys32_get_thread_area
+	data8 compat_sys_io_setup    /* 245 */
+	data8 sys_io_destroy
+	data8 compat_sys_io_getevents
+	data8 compat_sys_io_submit
+	data8 sys_io_cancel
+	data8 sys_ni_syscall    /* 250 */
+        data8 sys_ni_syscall
+	data8 sys_exit_group
+	data8 sys_lookup_dcookie
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall    /* 255 */
+	data8 sys_ni_syscall
+	data8 sys_remap_file_pages
+	data8 sys_set_tid_address
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall    /* 260 */
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall
+	data8 sys_ni_syscall    /* 265 */
 	data8 sys_ni_syscall
 	data8 sys_ni_syscall
 	data8 sys_ni_syscall
 	data8 sys_ni_syscall
+	data8 sys_tgkill        /* 270 */
 	/*
 	 *  CAUTION: If any system calls are added beyond this point
 	 *	then the check in `arch/ia64/kernel/ivt.S' will have
diff -urNp linux-268/arch/ia64/ia32/ia32_ldt.c linux-270/arch/ia64/ia32/ia32_ldt.c
--- linux-268/arch/ia64/ia32/ia32_ldt.c
+++ linux-270/arch/ia64/ia32/ia32_ldt.c
@@ -81,7 +81,7 @@ read_default_ldt (void * ptr, unsigned l
 static int
 write_ldt (void * ptr, unsigned long bytecount, int oldmode)
 {
-	struct ia32_modify_ldt_ldt_s ldt_info;
+	struct ia32_user_desc ldt_info;
 	__u64 entry;
 	int ret;
 
diff -urNp linux-268/arch/ia64/ia32/ia32_signal.c linux-270/arch/ia64/ia32/ia32_signal.c
--- linux-268/arch/ia64/ia32/ia32_signal.c
+++ linux-270/arch/ia64/ia32/ia32_signal.c
@@ -614,7 +614,7 @@ sys32_rt_sigtimedwait (sigset32_t *uthes
 			return -EFAULT;
 	}
 	set_fs(KERNEL_DS);
-	ret = sys_rt_sigtimedwait(&s, &info, &t, sigsetsize);
+	ret = sys_rt_sigtimedwait(&s, uinfo? &info :NULL, uts? &t :NULL, sigsetsize);
 	set_fs(old_fs);
 	if (ret >= 0 && uinfo) {
 		if (copy_siginfo_to_user32(uinfo, &info))
@@ -740,12 +740,12 @@ restore_sigcontext_ia32 (struct pt_regs 
 
 #define COPY(ia64x, ia32x)	err |= __get_user(regs->ia64x, &sc->ia32x)
 
-#define copyseg_gs(tmp)		(regs->r16 |= (unsigned long) tmp << 48)
-#define copyseg_fs(tmp)		(regs->r16 |= (unsigned long) tmp << 32)
-#define copyseg_cs(tmp)		(regs->r17 |= tmp)
-#define copyseg_ss(tmp)		(regs->r17 |= (unsigned long) tmp << 16)
-#define copyseg_es(tmp)		(regs->r16 |= (unsigned long) tmp << 16)
-#define copyseg_ds(tmp)		(regs->r16 |= tmp)
+#define copyseg_gs(tmp)		(regs->r16 |= (unsigned long) (tmp) << 48)
+#define copyseg_fs(tmp)		(regs->r16 |= (unsigned long) (tmp) << 32)
+#define copyseg_cs(tmp)		(regs->r17 |= (tmp))
+#define copyseg_ss(tmp)		(regs->r17 |= (unsigned long) (tmp) << 16)
+#define copyseg_es(tmp)		(regs->r16 |= (unsigned long) (tmp) << 16)
+#define copyseg_ds(tmp)		(regs->r16 |= (tmp))
 
 #define COPY_SEG(seg)					\
 	{						\
@@ -892,8 +892,6 @@ setup_frame_ia32 (int sig, struct k_siga
 	regs->cr_iip = IA32_SA_HANDLER(ka);
 
 	set_fs(USER_DS);
-	regs->r16 = (__USER_DS << 16) |  (__USER_DS); /* ES == DS, GS, FS are zero */
-	regs->r17 = (__USER_DS << 16) | __USER_CS;
 
 #if 0
 	regs->eflags &= ~TF_MASK;
@@ -966,9 +964,6 @@ setup_rt_frame_ia32 (int sig, struct k_s
 
 	set_fs(USER_DS);
 
-	regs->r16 = (__USER_DS << 16) |  (__USER_DS); /* ES == DS, GS, FS are zero */
-	regs->r17 = (__USER_DS << 16) | __USER_CS;
-
 #if 0
 	regs->eflags &= ~TF_MASK;
 #endif
diff -urNp linux-268/arch/ia64/ia32/ia32_support.c linux-270/arch/ia64/ia32/ia32_support.c
--- linux-268/arch/ia64/ia32/ia32_support.c
+++ linux-270/arch/ia64/ia32/ia32_support.c
@@ -23,12 +23,14 @@
 #include <asm/system.h>
 #include <asm/processor.h>
 #include <asm/ia32.h>
+#include <asm/uaccess.h>
 
 extern void die_if_kernel (char *str, struct pt_regs *regs, long err);
 
 struct exec_domain ia32_exec_domain;
-struct page *ia32_shared_page[(2*IA32_PAGE_SIZE + PAGE_SIZE - 1)/PAGE_SIZE];
-unsigned long *ia32_gdt;
+struct page *ia32_shared_page[(PAGE_ALIGN(IA32_PAGE_SIZE)/PAGE_SIZE) * NR_CPUS];
+unsigned long *ia32_boot_gdt;
+unsigned long *cpu_gdt_table[NR_CPUS];
 
 static unsigned long
 load_desc (u16 selector)
@@ -41,8 +43,8 @@ load_desc (u16 selector)
 		table = (unsigned long *) IA32_LDT_OFFSET;
 		limit = IA32_LDT_ENTRIES;
 	} else {
-		table = ia32_gdt;
-		limit = IA32_PAGE_SIZE / sizeof(ia32_gdt[0]);
+		table = cpu_gdt_table[smp_processor_id()];
+		limit = IA32_PAGE_SIZE / sizeof(ia32_boot_gdt[0]);
 	}
 	index = selector >> IA32_SEGSEL_INDEX_SHIFT;
 	if (index >= limit)
@@ -65,6 +67,33 @@ ia32_load_segment_descriptors (struct ta
 }
 
 void
+ia32_clone_tls(struct task_struct *child, struct pt_regs *childregs)
+{
+	struct desc_struct *desc;
+	struct ia32_user_desc info;
+	int idx;
+
+	if (copy_from_user(&info, (void *)(childregs->r14 & 0xffffffff),
+			   sizeof(info)))
+		return -EFAULT;
+	if (LDT_empty(&info))
+		return -EINVAL;
+
+	idx = info.entry_number;
+	if (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)
+		return -EINVAL;
+
+	desc = child->tls_array + idx - GDT_ENTRY_TLS_MIN;
+	desc->a = LDT_entry_a(&info);
+	desc->b = LDT_entry_b(&info);
+
+	/* XXX: can this be done in a cleaner way ? */
+	load_TLS(child, smp_processor_id());
+	ia32_load_segment_descriptors(child);
+	load_TLS(current, smp_processor_id());
+}
+
+void
 ia32_save_state (struct task_struct *t)
 {
 	unsigned long eflag, fsr, fcr, fir, fdr, csd, ssd;
@@ -86,6 +115,7 @@ ia32_save_state (struct task_struct *t)
 	t->thread.ssd = ssd;
 	ia64_set_kr(IA64_KR_IO_BASE, t->thread.old_iob);
 	ia64_set_kr(IA64_KR_TSSD, t->thread.old_k1);
+
 }
 
 void
@@ -93,7 +123,6 @@ ia32_load_state (struct task_struct *t)
 {
 	unsigned long eflag, fsr, fcr, fir, fdr, csd, ssd, tssd;
 	struct pt_regs *regs = ia64_task_regs(t);
-	int nr = smp_processor_id();	/* LDT and TSS depend on CPU number: */
 
 	eflag = t->thread.eflag;
 	fsr = t->thread.fsr;
@@ -102,7 +131,7 @@ ia32_load_state (struct task_struct *t)
 	fdr = t->thread.fdr;
 	csd = t->thread.csd;
 	ssd = t->thread.ssd;
-	tssd = load_desc(_TSS(nr));					/* TSSD */
+	tssd = load_desc(_TSS);					/* TSSD */
 
 	asm volatile ("mov ar.eflag=%0;"
 		      "mov ar.fsr=%1;"
@@ -117,8 +146,10 @@ ia32_load_state (struct task_struct *t)
 	ia64_set_kr(IA64_KR_IO_BASE, IA32_IOBASE);
 	ia64_set_kr(IA64_KR_TSSD, tssd);
 
-	regs->r17 = (_TSS(nr) << 48) | (_LDT(nr) << 32) | (__u32) regs->r17;
-	regs->r30 = load_desc(_LDT(nr));				/* LDTD */
+	regs->r17 = (_TSS << 48) | (_LDT << 32) | (__u32) regs->r17;
+	regs->r30 = load_desc(_LDT);				/* LDTD */
+	load_TLS(t, smp_processor_id());
+
 }
 
 /*
@@ -127,37 +158,45 @@ ia32_load_state (struct task_struct *t)
 void
 ia32_gdt_init (void)
 {
-	unsigned long *tss;
+	int cpu = smp_processor_id();
+
+	ia32_shared_page[cpu] = alloc_page(GFP_KERNEL);
+	cpu_gdt_table[cpu] = page_address(ia32_shared_page[cpu]);
+
+	printk("allocating GDT on cpu: %d\n", cpu);
+
+	/* Copy from the boot cpu's GDT */
+	memcpy(cpu_gdt_table[cpu], ia32_boot_gdt, PAGE_SIZE);
+}
+
+
+/*
+ * Setup IA32 GDT and TSS
+ */
+void
+ia32_boot_gdt_init (void)
+{
 	unsigned long ldt_size;
-	int nr;
 
 	ia32_shared_page[0] = alloc_page(GFP_KERNEL);
-	ia32_gdt = page_address(ia32_shared_page[0]);
-	tss = ia32_gdt + IA32_PAGE_SIZE/sizeof(ia32_gdt[0]);
-
-	if (IA32_PAGE_SIZE == PAGE_SIZE) {
-		ia32_shared_page[1] = alloc_page(GFP_KERNEL);
-		tss = page_address(ia32_shared_page[1]);
-	}
+	ia32_boot_gdt = page_address(ia32_shared_page[0]);
+	cpu_gdt_table[0] = ia32_boot_gdt;
 
 	/* CS descriptor in IA-32 (scrambled) format */
-	ia32_gdt[__USER_CS >> 3] = IA32_SEG_DESCRIPTOR(0, (IA32_PAGE_OFFSET-1) >> IA32_PAGE_SHIFT,
+	ia32_boot_gdt[__USER_CS >> 3] = IA32_SEG_DESCRIPTOR(0, (IA32_PAGE_OFFSET-1) >> IA32_PAGE_SHIFT,
 						       0xb, 1, 3, 1, 1, 1, 1);
 
 	/* DS descriptor in IA-32 (scrambled) format */
-	ia32_gdt[__USER_DS >> 3] = IA32_SEG_DESCRIPTOR(0, (IA32_PAGE_OFFSET-1) >> IA32_PAGE_SHIFT,
+	ia32_boot_gdt[__USER_DS >> 3] = IA32_SEG_DESCRIPTOR(0, (IA32_PAGE_OFFSET-1) >> IA32_PAGE_SHIFT,
 						       0x3, 1, 3, 1, 1, 1, 1);
 
-	/* We never change the TSS and LDT descriptors, so we can share them across all CPUs.  */
 	ldt_size = PAGE_ALIGN(IA32_LDT_ENTRIES*IA32_LDT_ENTRY_SIZE);
-	for (nr = 0; nr < NR_CPUS; ++nr) {
-		ia32_gdt[_TSS(nr) >> IA32_SEGSEL_INDEX_SHIFT]
-			= IA32_SEG_DESCRIPTOR(IA32_TSS_OFFSET, 235,
-					      0xb, 0, 3, 1, 1, 1, 0);
-		ia32_gdt[_LDT(nr) >> IA32_SEGSEL_INDEX_SHIFT]
-			= IA32_SEG_DESCRIPTOR(IA32_LDT_OFFSET, ldt_size - 1,
-					      0x2, 0, 3, 1, 1, 1, 0);
-	}
+	ia32_boot_gdt[TSS_ENTRY]
+		= IA32_SEG_DESCRIPTOR(IA32_TSS_OFFSET, 235,
+				      0xb, 0, 3, 1, 1, 1, 0);
+	ia32_boot_gdt[LDT_ENTRY]
+		= IA32_SEG_DESCRIPTOR(IA32_LDT_OFFSET, ldt_size - 1,
+				      0x2, 0, 3, 1, 1, 1, 0);
 }
 
 /*
diff -urNp linux-268/arch/ia64/ia32/sys_ia32.c linux-270/arch/ia64/ia32/sys_ia32.c
--- linux-268/arch/ia64/ia32/sys_ia32.c
+++ linux-270/arch/ia64/ia32/sys_ia32.c
@@ -74,8 +74,9 @@
 #define OFFSET4K(a)		((a) & 0xfff)
 #define PAGE_START(addr)	((addr) & PAGE_MASK)
 #define PAGE_OFF(addr)		((addr) & ~PAGE_MASK)
+#define MINSIGSTKSZ_IA32	2048
 
-extern asmlinkage long sys_execve (char *, char **, char **, struct pt_regs *);
+extern long sys_execve (char *, char **, char **, struct pt_regs *);
 extern asmlinkage long sys_mprotect (unsigned long, size_t, unsigned long);
 extern asmlinkage long sys_munmap (unsigned long, size_t);
 extern unsigned long arch_get_unmapped_area (struct file *, unsigned long, unsigned long,
@@ -93,7 +94,7 @@ asmlinkage unsigned long sys_brk(unsigne
 static DECLARE_MUTEX(ia32_mmap_sem);
 
 static int
-nargs (unsigned int arg, char **ap)
+nargs (unsigned int arg, char **ap, int max)
 {
 	unsigned int addr;
 	int n, err;
@@ -106,6 +107,8 @@ nargs (unsigned int arg, char **ap)
 		err = get_user(addr, (unsigned int *)A(arg));
 		if (err)
 			return err;
+		if (n > max)
+			return -E2BIG;
 		if (ap)
 			*ap++ = (char *) A(addr);
 		arg += sizeof(unsigned int);
@@ -125,10 +128,11 @@ sys32_execve (char *filename, unsigned i
 	int na, ne, len;
 	long r;
 
-	na = nargs(argv, NULL);
+	/* can actually allocate up to 2*MAX_ARG_PAGES */
+	na = nargs(argv, NULL, (MAX_ARG_PAGES*PAGE_SIZE) / sizeof(char *) - 1);
 	if (na < 0)
 		return na;
-	ne = nargs(envp, NULL);
+	ne = nargs(envp, NULL, (MAX_ARG_PAGES*PAGE_SIZE) / sizeof(char *) - 1);
 	if (ne < 0)
 		return ne;
 	len = (na + ne + 2) * sizeof(*av);
@@ -140,10 +144,10 @@ sys32_execve (char *filename, unsigned i
 	av[na] = NULL;
 	ae[ne] = NULL;
 
-	r = nargs(argv, av);
+	r = nargs(argv, av, na);
 	if (r < 0)
 		goto out;
-	r = nargs(envp, ae);
+	r = nargs(envp, ae, ne);
 	if (r < 0)
 		goto out;
 
@@ -201,13 +205,18 @@ extern asmlinkage long sys_newstat (char
 asmlinkage long
 sys32_newstat (char *filename, struct stat32 *statbuf)
 {
+	char *name;
 	int ret;
 	struct stat s;
 	mm_segment_t old_fs = get_fs();
 
+	name = getname(filename);
+	if (IS_ERR(name))
+		return PTR_ERR(name);
 	set_fs(KERNEL_DS);
-	ret = sys_newstat(filename, &s);
+	ret = sys_newstat(name, &s);
 	set_fs(old_fs);
+	putname(name);
 	if (putstat(statbuf, &s))
 		return -EFAULT;
 	return ret;
@@ -218,13 +227,18 @@ extern asmlinkage long sys_newlstat(char
 asmlinkage long
 sys32_newlstat (char *filename, struct stat32 *statbuf)
 {
+	char *name;
 	mm_segment_t old_fs = get_fs();
 	struct stat s;
 	int ret;
 
+	name = getname(filename);
+	if (IS_ERR(name))
+		return PTR_ERR(name);
 	set_fs(KERNEL_DS);
-	ret = sys_newlstat(filename, &s);
+	ret = sys_newlstat(name, &s);
 	set_fs(old_fs);
+	putname(name);
 	if (putstat(statbuf, &s))
 		return -EFAULT;
 	return ret;
@@ -465,8 +479,12 @@ ia32_do_mmap (struct file *file, unsigne
 	if (len == 0)
 		return addr;
 
-	if (len > IA32_PAGE_OFFSET || addr > IA32_PAGE_OFFSET - len)
-		return -EINVAL;
+	if (len > IA32_PAGE_OFFSET || addr > IA32_PAGE_OFFSET - len) {
+		if (flags & MAP_FIXED)
+			return -ENOMEM;
+		else
+ 			return -EINVAL;
+	}
 
 	if (OFFSET4K(offset))
 		return -EINVAL;
@@ -565,7 +583,7 @@ sys32_munmap (unsigned int start, unsign
 #if PAGE_SHIFT <= IA32_PAGE_SHIFT
 	ret = sys_munmap(start, end - start);
 #else
-	if (start > end)
+	if (start >= end)
 		return -EINVAL;
 
 	start = PAGE_ALIGN(start);
@@ -695,13 +713,18 @@ extern asmlinkage long sys_statfs(const 
 asmlinkage long
 sys32_statfs (const char *path, struct statfs32 *buf)
 {
+	const char *name;
 	int ret;
 	struct statfs s;
 	mm_segment_t old_fs = get_fs();
 
+	name = getname(path);
+	if (IS_ERR(name))
+		return PTR_ERR(name);
 	set_fs(KERNEL_DS);
-	ret = sys_statfs(path, &s);
+	ret = sys_statfs(name, &s);
 	set_fs(old_fs);
+	putname(name);
 	if (put_statfs(buf, &s))
 		return -EFAULT;
 	return ret;
@@ -1249,8 +1272,8 @@ sys32_writev (int fd, struct iovec32 *ve
 #define RESOURCE32(x) ((x > RLIM_INFINITY32) ? RLIM_INFINITY32 : x)
 
 struct rlimit32 {
-	int	rlim_cur;
-	int	rlim_max;
+	unsigned int	rlim_cur;
+	unsigned int	rlim_max;
 };
 
 extern asmlinkage long sys_getrlimit (unsigned int resource, struct rlimit *rlim);
@@ -2104,7 +2127,7 @@ struct shmid_ds32 {
 };
 
 struct shmid64_ds32 {
-	struct ipc64_perm shm_perm;
+	struct ipc64_perm32 shm_perm;
 	__kernel_size_t32 shm_segsz;
 	__kernel_time_t32 shm_atime;
 	unsigned int __unused1;
@@ -2187,6 +2210,9 @@ semctl32 (int first, int second, int thi
 	else
 		fourth.__pad = (void *)A(pad);
 	switch (third) {
+	      default:
+		err = -EINVAL;
+		break;
 	      case IPC_INFO:
 	      case IPC_RMID:
 	      case IPC_SET:
@@ -2254,7 +2280,7 @@ semctl32 (int first, int second, int thi
 static int
 do_sys32_msgsnd (int first, int second, int third, void *uptr)
 {
-	struct msgbuf *p = kmalloc(second + sizeof(struct msgbuf) + 4, GFP_USER);
+	struct msgbuf *p = kmalloc(second + sizeof(struct msgbuf), GFP_USER);
 	struct msgbuf32 *up = (struct msgbuf32 *)uptr;
 	mm_segment_t old_fs;
 	int err;
@@ -2296,12 +2322,12 @@ do_sys32_msgrcv (int first, int second, 
 		msgtyp = ipck.msgtyp;
 	}
 	err = -ENOMEM;
-	p = kmalloc(second + sizeof(struct msgbuf) + 4, GFP_USER);
+	p = kmalloc(second + sizeof(struct msgbuf), GFP_USER);
 	if (!p)
 		goto out;
 	old_fs = get_fs();
 	set_fs(KERNEL_DS);
-	err = sys_msgrcv(first, p, second + 4, msgtyp, third);
+	err = sys_msgrcv(first, p, second, msgtyp, third);
 	set_fs(old_fs);
 	if (err < 0)
 		goto free_then_out;
@@ -2334,21 +2360,21 @@ msgctl32 (int first, int second, void *u
 
 	      case IPC_SET:
 		if (version == IPC_64) {
-			err = get_user(m.msg_perm.uid, &up64->msg_perm.uid);
-			err |= get_user(m.msg_perm.gid, &up64->msg_perm.gid);
-			err |= get_user(m.msg_perm.mode, &up64->msg_perm.mode);
-			err |= get_user(m.msg_qbytes, &up64->msg_qbytes);
+			err = get_user(m64.msg_perm.uid, &up64->msg_perm.uid);
+			err |= get_user(m64.msg_perm.gid, &up64->msg_perm.gid);
+			err |= get_user(m64.msg_perm.mode, &up64->msg_perm.mode);
+			err |= get_user(m64.msg_qbytes, &up64->msg_qbytes);
 		} else {
-			err = get_user(m.msg_perm.uid, &up32->msg_perm.uid);
-			err |= get_user(m.msg_perm.gid, &up32->msg_perm.gid);
-			err |= get_user(m.msg_perm.mode, &up32->msg_perm.mode);
-			err |= get_user(m.msg_qbytes, &up32->msg_qbytes);
+			err = get_user(m64.msg_perm.uid, &up32->msg_perm.uid);
+			err |= get_user(m64.msg_perm.gid, &up32->msg_perm.gid);
+			err |= get_user(m64.msg_perm.mode, &up32->msg_perm.mode);
+			err |= get_user(m64.msg_qbytes, &up32->msg_qbytes);
 		}
 		if (err)
 			break;
 		old_fs = get_fs();
 		set_fs(KERNEL_DS);
-		err = sys_msgctl(first, second, &m);
+		err = sys_msgctl(first, second, &m64);
 		set_fs(old_fs);
 		break;
 
@@ -2428,7 +2454,6 @@ static int
 shmctl32 (int first, int second, void *uptr)
 {
 	int err = -EFAULT, err2;
-	struct shmid_ds s;
 	struct shmid64_ds s64;
 	struct shmid_ds32 *up32 = (struct shmid_ds32 *)uptr;
 	struct shmid64_ds32 *up64 = (struct shmid64_ds32 *)uptr;
@@ -2480,19 +2505,19 @@ shmctl32 (int first, int second, void *u
 
 	      case IPC_SET:
 		if (version == IPC_64) {
-			err = get_user(s.shm_perm.uid, &up64->shm_perm.uid);
-			err |= get_user(s.shm_perm.gid, &up64->shm_perm.gid);
-			err |= get_user(s.shm_perm.mode, &up64->shm_perm.mode);
+			err = get_user(s64.shm_perm.uid, &up64->shm_perm.uid);
+			err |= get_user(s64.shm_perm.gid, &up64->shm_perm.gid);
+			err |= get_user(s64.shm_perm.mode, &up64->shm_perm.mode);
 		} else {
-			err = get_user(s.shm_perm.uid, &up32->shm_perm.uid);
-			err |= get_user(s.shm_perm.gid, &up32->shm_perm.gid);
-			err |= get_user(s.shm_perm.mode, &up32->shm_perm.mode);
+			err = get_user(s64.shm_perm.uid, &up32->shm_perm.uid);
+			err |= get_user(s64.shm_perm.gid, &up32->shm_perm.gid);
+			err |= get_user(s64.shm_perm.mode, &up32->shm_perm.mode);
 		}
 		if (err)
 			break;
 		old_fs = get_fs();
 		set_fs(KERNEL_DS);
-		err = sys_shmctl(first, second, &s);
+		err = sys_shmctl(first, second, &s64);
 		set_fs(old_fs);
 		break;
 
@@ -2934,7 +2959,7 @@ get_fpreg (int regno, struct _fpreg_ia32
 	return;
 }
 
-static int
+int
 save_ia32_fpstate (struct task_struct *tsk, struct ia32_user_i387_struct *save)
 {
 	struct switch_stack *swp;
@@ -2996,7 +3021,7 @@ restore_ia32_fpstate (struct task_struct
 	return 0;
 }
 
-static int
+int
 save_ia32_fpxstate (struct task_struct *tsk, struct ia32_user_fxsr_struct *save)
 {
 	struct switch_stack *swp;
@@ -3390,10 +3415,18 @@ sys32_sigaltstack (ia32_stack_t *uss32, 
 			return -EFAULT;
 	uss.ss_sp = (void *) (long) buf32.ss_sp;
 	uss.ss_flags = buf32.ss_flags;
-	uss.ss_size = buf32.ss_size;
+	/* MINSIGSTKSZ is different for ia32 vs ia64. We lie here to pass the 
+           check and set it to the user requested value later */
+	if ((buf32.ss_flags != SS_DISABLE) && (buf32.ss_size < MINSIGSTKSZ_IA32)) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	uss.ss_size = MINSIGSTKSZ;
 	set_fs(KERNEL_DS);
 	ret = do_sigaltstack(uss32 ? &uss : NULL, &uoss, pt->r12);
+ 	current->sas_ss_size = buf32.ss_size;	
 	set_fs(old_fs);
+out:
 	if (ret < 0)
 		return(ret);
 	if (uoss32) {
@@ -3626,9 +3659,13 @@ sys32_fcntl64 (unsigned int fd, unsigned
 			return -EFAULT;
 		old_fs = get_fs();
 		set_fs(KERNEL_DS);
-		ret = sys_fcntl(fd, cmd, (unsigned long) &f);
+		ret = sys_fcntl(fd, (cmd == F_GETLK64) ? F_GETLK :
+			((cmd == F_SETLK64) ? F_SETLK : F_SETLKW),
+			(unsigned long) &f);
+
+
 		set_fs(old_fs);
-		if (cmd == F_GETLK && ia32_put_flock(&f, arg))
+		if (cmd == F_GETLK64 && ia32_put_flock(&f, arg))
 			return -EFAULT;
 		break;
 
@@ -3685,13 +3722,18 @@ putstat64 (struct stat64 *ubuf, struct s
 asmlinkage long
 sys32_stat64 (char *filename, struct stat64 *statbuf)
 {
+	char *name;
 	mm_segment_t old_fs = get_fs();
 	struct stat s;
 	long ret;
 
+	name = getname(filename);
+	if (IS_ERR(name))
+		return PTR_ERR(name);
 	set_fs(KERNEL_DS);
-	ret = sys_newstat(filename, &s);
+	ret = sys_newstat(name, &s);
 	set_fs(old_fs);
+	putname(name);
 	if (putstat64(statbuf, &s))
 		return -EFAULT;
 	return ret;
@@ -3700,13 +3742,18 @@ sys32_stat64 (char *filename, struct sta
 asmlinkage long
 sys32_lstat64 (char *filename, struct stat64 *statbuf)
 {
+	char *name;
 	mm_segment_t old_fs = get_fs();
 	struct stat s;
 	long ret;
 
+	name = getname(filename);
+	if (IS_ERR(name))
+		return PTR_ERR(name);
 	set_fs(KERNEL_DS);
-	ret = sys_newlstat(filename, &s);
+	ret = sys_newlstat(name, &s);
 	set_fs(old_fs);
+	putname(name);
 	if (putstat64(statbuf, &s))
 		return -EFAULT;
 	return ret;
@@ -4018,6 +4065,113 @@ out_error:
 	goto out;
 }
 
+/*
+ * Get a yet unused TLS descriptor index.
+ */
+static int get_free_idx(void)
+{
+	int idx;
+
+	for (idx = 0; idx < GDT_ENTRY_TLS_ENTRIES; idx++)
+		if (desc_empty(current->tls_array + idx))
+			return idx + GDT_ENTRY_TLS_MIN;
+	return -ESRCH;
+}
+
+/*
+ * Set a given TLS descriptor:
+ */
+asmlinkage int
+sys32_set_thread_area(struct ia32_user_desc *u_info)
+{
+	struct ia32_user_desc info;
+	struct desc_struct *desc;
+	int cpu, idx;
+
+	if (copy_from_user(&info, u_info, sizeof(info)))
+		return -EFAULT;
+	idx = info.entry_number;
+
+	/*
+	 * index -1 means the kernel should try to find and
+	 * allocate an empty descriptor:
+	 */
+	if (idx == -1) {
+		idx = get_free_idx();
+		if (idx < 0)
+			return idx;
+		if (put_user(idx, &u_info->entry_number))
+			return -EFAULT;
+	}
+
+	if (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)
+		return -EINVAL;
+
+	desc = current->tls_array + idx - GDT_ENTRY_TLS_MIN;
+
+	cpu = smp_processor_id();
+
+	if (LDT_empty(&info)) {
+		desc->a = 0;
+		desc->b = 0;
+	} else {
+		desc->a = LDT_entry_a(&info);
+		desc->b = LDT_entry_b(&info);
+	}
+	load_TLS(current, cpu);
+
+	return 0;
+}
+
+/*
+ * Get the current Thread-Local Storage area:
+ */
+
+#define GET_BASE(desc) ( \
+	(((desc)->a >> 16) & 0x0000ffff) | \
+	(((desc)->b << 16) & 0x00ff0000) | \
+	( (desc)->b        & 0xff000000)   )
+
+#define GET_LIMIT(desc) ( \
+	((desc)->a & 0x0ffff) | \
+	 ((desc)->b & 0xf0000) )
+
+#define GET_32BIT(desc)		(((desc)->b >> 23) & 1)
+#define GET_CONTENTS(desc)	(((desc)->b >> 10) & 3)
+#define GET_WRITABLE(desc)	(((desc)->b >>  9) & 1)
+#define GET_LIMIT_PAGES(desc)	(((desc)->b >> 23) & 1)
+#define GET_PRESENT(desc)	(((desc)->b >> 15) & 1)
+#define GET_USEABLE(desc)	(((desc)->b >> 20) & 1)
+
+asmlinkage int
+sys32_get_thread_area(struct ia32_user_desc *u_info)
+{
+	struct ia32_user_desc info;
+	struct desc_struct *desc;
+	int idx;
+
+	if (get_user(idx, &u_info->entry_number))
+		return -EFAULT;
+	if (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)
+		return -EINVAL;
+
+	desc = current->tls_array + idx - GDT_ENTRY_TLS_MIN;
+
+	info.entry_number = idx;
+	info.base_addr = GET_BASE(desc);
+	info.limit = GET_LIMIT(desc);
+	info.seg_32bit = GET_32BIT(desc);
+	info.contents = GET_CONTENTS(desc);
+	info.read_exec_only = !GET_WRITABLE(desc);
+	info.limit_in_pages = GET_LIMIT_PAGES(desc);
+	info.seg_not_present = !GET_PRESENT(desc);
+	info.useable = GET_USEABLE(desc);
+
+	if (copy_to_user(u_info, &info, sizeof(info)))
+		return -EFAULT;
+	return 0;
+}
+
 #ifdef	NOTYET  /* UNTESTED FOR IA64 FROM HERE DOWN */
 
 struct ncp_mount_data32 {
diff -urNp linux-268/arch/ia64/kernel/ivt.S linux-270/arch/ia64/kernel/ivt.S
--- linux-268/arch/ia64/kernel/ivt.S
+++ linux-270/arch/ia64/kernel/ivt.S
@@ -873,7 +873,7 @@ ENTRY(dispatch_to_ia32_handler)
 	alloc r15=ar.pfs,0,0,6,0	// must first in an insn group
 	;;
 	ld4 r8=[r14],8		// r8 == eax (syscall number)
-	mov r15=230		// number of entries in ia32 system call table
+	mov r15=271		// number of entries in ia32 system call table
 	;;
 	cmp.ltu.unc p6,p7=r8,r15
 	ld4 out1=[r14],8	// r9 == ecx
diff -urNp linux-268/arch/ia64/kernel/process.c linux-270/arch/ia64/kernel/process.c
--- linux-268/arch/ia64/kernel/process.c
+++ linux-270/arch/ia64/kernel/process.c
@@ -292,7 +292,7 @@ copy_thread (int nr, unsigned long clone
 	memcpy((void *) child_rbs, (void *) rbs, rbs_size);
 
 	if (user_mode(child_ptregs)) {
-		if (clone_flags & CLONE_SETTLS)
+		if ((clone_flags & CLONE_SETTLS) && (!IS_IA32_PROCESS(regs)))
 			child_ptregs->r13 = regs->r16;  /* see sys_clone2() in entry.S */
 		if (user_stack_base) {
 			child_ptregs->r12 = user_stack_base + user_stack_size - 16;
@@ -349,8 +349,11 @@ copy_thread (int nr, unsigned long clone
 	 * If we're cloning an IA32 task then save the IA32 extra
 	 * state from the current task to the new task
 	 */
-	if (IS_IA32_PROCESS(ia64_task_regs(current)))
+	if (IS_IA32_PROCESS(ia64_task_regs(current))) {
 		ia32_save_state(p);
+		if (clone_flags & CLONE_SETTLS)
+			ia32_clone_tls(p, child_ptregs);
+	}
 #endif
 
 #ifdef CONFIG_PERFMON
@@ -549,6 +552,15 @@ arch_kernel_thread (int (*fn)(void *), v
 
 	tid = clone(flags | CLONE_VM, 0);
 	if (parent != current) {
+#ifdef CONFIG_IA32_SUPPORT
+		if (IS_IA32_PROCESS(ia64_task_regs(current))) {
+			/* A kernel thread is always a 64-bit process. */
+			current->thread.map_base  = DEFAULT_MAP_BASE;
+			current->thread.task_size = DEFAULT_TASK_SIZE;
+			ia64_set_kr(IA64_KR_IO_BASE, current->thread.old_iob);
+			ia64_set_kr(IA64_KR_TSSD, current->thread.old_k1);
+		}
+#endif
 		result = (*fn)(arg);
 		_exit(result);
 	}
diff -urNp linux-268/arch/ia64/kernel/smpboot.c linux-270/arch/ia64/kernel/smpboot.c
--- linux-268/arch/ia64/kernel/smpboot.c
+++ linux-270/arch/ia64/kernel/smpboot.c
@@ -42,6 +42,7 @@
 #include <asm/sal.h>
 #include <asm/system.h>
 #include <asm/unistd.h>
+#include <asm/ia32.h>
 
 #define SMP_DEBUG 0
 
@@ -365,6 +366,10 @@ smp_callin (void)
 	local_irq_enable();
 	calibrate_delay();
 	local_cpu_data->loops_per_jiffy = loops_per_jiffy;
+#ifdef CONFIG_IA32_SUPPORT
+	ia32_gdt_init();
+#endif
+
 	/*
 	 * Allow the master to continue.
 	 */
diff -urNp linux-268/arch/ia64/mm/init.c linux-270/arch/ia64/mm/init.c
--- linux-268/arch/ia64/mm/init.c
+++ linux-270/arch/ia64/mm/init.c
@@ -27,6 +27,9 @@
 #include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/tlb.h>
+#ifdef CONFIG_IA32_SUPPORT
+#include <asm/ia32.h>
+#endif
 
 mmu_gather_t mmu_gathers[NR_CPUS];
 
@@ -653,6 +656,6 @@ mem_init (void)
 	put_gate_page(virt_to_page(__start_gate_section), GATE_ADDR);
 
 #ifdef CONFIG_IA32_SUPPORT
-	ia32_gdt_init();
+	ia32_boot_gdt_init();
 #endif
 }
diff -urNp linux-268/include/asm-ia64/ia32.h linux-270/include/asm-ia64/ia32.h
--- linux-268/include/asm-ia64/ia32.h
+++ linux-270/include/asm-ia64/ia32.h
@@ -6,6 +6,7 @@
 #ifdef CONFIG_IA32_SUPPORT
 
 #include <linux/param.h>
+#include <asm/processor.h>
 
 /*
  * 32 bit structures for IA32 support.
@@ -376,7 +377,6 @@ struct old_linux32_dirent {
 #define IA32_TSS_OFFSET		(IA32_PAGE_OFFSET + PAGE_SIZE)
 #define IA32_LDT_OFFSET		(IA32_PAGE_OFFSET + 2*PAGE_SIZE)
 
-#define USE_ELF_CORE_DUMP
 #define ELF_EXEC_PAGESIZE	IA32_PAGE_SIZE
 
 /*
@@ -394,20 +394,6 @@ void ia64_elf32_init(struct pt_regs *reg
 #define elf_addr_t	u32
 #define elf_caddr_t	u32
 
-/* ELF register definitions.  This is needed for core dump support.  */
-
-#define ELF_NGREG	128			/* XXX fix me */
-#define ELF_NFPREG	128			/* XXX fix me */
-
-typedef unsigned long elf_greg_t;
-typedef elf_greg_t elf_gregset_t[ELF_NGREG];
-
-typedef struct {
-	unsigned long w0;
-	unsigned long w1;
-} elf_fpreg_t;
-typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
-
 /* This macro yields a bitmask that programs can use to figure out
    what instruction set this CPU supports.  */
 #define ELF_HWCAP	0
@@ -431,15 +417,24 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_N
 #define __USER_CS      0x23
 #define __USER_DS      0x2B
 
-#define FIRST_TSS_ENTRY 6
-#define FIRST_LDT_ENTRY (FIRST_TSS_ENTRY+1)
-#define _TSS(n) ((((unsigned long) n)<<4)+(FIRST_TSS_ENTRY<<3))
-#define _LDT(n) ((((unsigned long) n)<<4)+(FIRST_LDT_ENTRY<<3))
+/*
+ * The per-cpu GDT has 32 entries: see <asm-i386/segment.h>
+ */
+#define GDT_ENTRIES 32
+
+#define GDT_SIZE (GDT_ENTRIES * 8)
+
+#define TSS_ENTRY 14
+#define LDT_ENTRY (TSS_ENTRY+1)
+
 
 #define IA32_SEGSEL_RPL		(0x3 << 0)
 #define IA32_SEGSEL_TI		(0x1 << 2)
 #define IA32_SEGSEL_INDEX_SHIFT	3
 
+#define _TSS ((unsigned long) TSS_ENTRY << IA32_SEGSEL_INDEX_SHIFT)
+#define _LDT ((unsigned long) LDT_ENTRY << IA32_SEGSEL_INDEX_SHIFT)
+
 #define IA32_SEG_BASE		16
 #define IA32_SEG_TYPE		40
 #define IA32_SEG_SYS		44
@@ -523,7 +518,41 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_N
 #define IA32_LDT_ENTRIES	8192		/* Maximum number of LDT entries supported. */
 #define IA32_LDT_ENTRY_SIZE	8		/* The size of each LDT entry. */
 
-struct ia32_modify_ldt_ldt_s {
+#define LDT_entry_a(info) \
+	((((info)->base_addr & 0x0000ffff) << 16) | ((info)->limit & 0x0ffff))
+
+#define LDT_entry_b(info) \
+	(((info)->base_addr & 0xff000000) | \
+	(((info)->base_addr & 0x00ff0000) >> 16) | \
+	((info)->limit & 0xf0000) | \
+	(((info)->read_exec_only ^ 1) << 9) | \
+	((info)->contents << 10) | \
+	(((info)->seg_not_present ^ 1) << 15) | \
+	((info)->seg_32bit << 22) | \
+	((info)->limit_in_pages << 23) | \
+	((info)->useable << 20) | \
+	0x7100)
+
+#define LDT_empty(info) (\
+	(info)->base_addr	== 0	&& \
+	(info)->limit		== 0	&& \
+	(info)->contents	== 0	&& \
+	(info)->read_exec_only	== 1	&& \
+	(info)->seg_32bit	== 0	&& \
+	(info)->limit_in_pages	== 0	&& \
+	(info)->seg_not_present	== 1	&& \
+	(info)->useable		== 0	)
+
+static inline void load_TLS(struct task_struct *t, unsigned int cpu)
+{
+	extern unsigned long *cpu_gdt_table[NR_CPUS];
+
+	memcpy(cpu_gdt_table[cpu] + GDT_ENTRY_TLS_MIN +0, &t->tls_array[0], sizeof(long));
+	memcpy(cpu_gdt_table[cpu] + GDT_ENTRY_TLS_MIN +1, &t->tls_array[1], sizeof(long));
+	memcpy(cpu_gdt_table[cpu] + GDT_ENTRY_TLS_MIN +2, &t->tls_array[2], sizeof(long));
+}
+
+struct ia32_user_desc {
 	unsigned int entry_number;
 	unsigned int base_addr;
 	unsigned int limit;
@@ -535,7 +564,9 @@ struct ia32_modify_ldt_ldt_s {
 	unsigned int useable:1;
 };
 
+extern void ia32_boot_gdt_init (void);
 extern void ia32_gdt_init (void);
+
 extern int ia32_setup_frame1 (int sig, struct k_sigaction *ka, siginfo_t *info,
 			       sigset_t *set, struct pt_regs *regs);
 extern void ia32_init_addr_space (struct pt_regs *regs);
@@ -544,6 +575,7 @@ extern int ia32_exception (struct pt_reg
 extern int ia32_intercept (struct pt_regs *regs, unsigned long isr);
 extern unsigned long ia32_do_mmap (struct file *, unsigned long, unsigned long, int, int, loff_t);
 extern void ia32_load_segment_descriptors (struct task_struct *task);
+extern void ia32_clone_tls(struct task_struct *child, struct pt_regs *childregs);
 
 #define ia32f2ia64f(dst,src) \
 	do { \
@@ -557,6 +589,23 @@ extern void ia32_load_segment_descriptor
 	asm volatile ("ldf.fill f6=[%2];; stfe [%1]=f6" : "=f"(f6): "r"(dst),  "r"(src) : "memory"); \
 	} while(0)
 
+struct user_regs_struct32 {
+	__u32 ebx, ecx, edx, esi, edi, ebp, eax;
+	unsigned short ds, __ds, es, __es;
+	unsigned short fs, __fs, gs, __gs;
+	__u32 orig_eax, eip;
+	unsigned short cs, __cs;
+	__u32 eflags, esp;
+	unsigned short ss, __ss;
+};
+
+/* Prototypes for use in elfcore32.h */
+int save_ia32_fpstate (struct task_struct *tsk, 
+                       struct ia32_user_i387_struct *save);
+
+int save_ia32_fpxstate (struct task_struct *tsk, 
+			struct ia32_user_fxsr_struct *save);
+
 #endif /* !CONFIG_IA32_SUPPORT */
 
 #endif /* _ASM_IA64_IA32_H */
diff -urNp linux-268/include/asm-ia64/processor.h linux-270/include/asm-ia64/processor.h
--- linux-268/include/asm-ia64/processor.h
+++ linux-270/include/asm-ia64/processor.h
@@ -252,6 +252,25 @@ typedef struct {
 
 struct siginfo;
 
+#ifdef CONFIG_IA32_SUPPORT
+struct desc_struct {
+	unsigned int a,b;
+};
+
+#define desc_empty(desc) \
+		(!((desc)->a + (desc)->b))
+
+#define desc_equal(desc1, desc2) \
+		(((desc1)->a == (desc2)->a) && ((desc1)->b == (desc2)->b))
+
+#define GDT_ENTRY_TLS_ENTRIES	3
+#define GDT_ENTRY_TLS_MIN	6
+#define GDT_ENTRY_TLS_MAX 	(GDT_ENTRY_TLS_MIN + GDT_ENTRY_TLS_ENTRIES - 1)
+
+#define TLS_SIZE (GDT_ENTRY_TLS_ENTRIES * 8)
+
+#endif
+
 struct thread_struct {
 	__u64 ksp;			/* kernel stack pointer */
 	unsigned long flags;		/* various flags */
@@ -271,6 +290,8 @@ struct thread_struct {
 	__u64 old_iob;			/* old IOBase value */
 # define INIT_THREAD_IA32	0, 0, 0x17800000037fULL, 0, 0, 0, 0, 0, 0,
 #else
+	__u64 csd;
+	__u64 ssd;
 # define INIT_THREAD_IA32
 #endif /* CONFIG_IA32_SUPPORT */
 #ifdef CONFIG_PERFMON
diff -urNp linux-268/include/linux/sched.h linux-270/include/linux/sched.h
--- linux-268/include/linux/sched.h
+++ linux-270/include/linux/sched.h
@@ -523,6 +523,12 @@ struct task_struct {
 
 	unsigned long ptrace_message;
 	siginfo_t *last_siginfo; /* For ptrace use.  */
+
+#ifndef __GENKSYMS__ /* preserve KMI/ABI ksyms compatibility for mod linkage */
+#if defined(CONFIG_IA64) && defined(CONFIG_IA32_SUPPORT)
+	struct desc_struct tls_array[GDT_ENTRY_TLS_ENTRIES];
+#endif
+#endif /* !__GENKSYMS__ */
 };
 
 /*
