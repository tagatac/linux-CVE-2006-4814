diff -urNp linux-115/Documentation/Configure.help linux-120/Documentation/Configure.help
--- linux-115/Documentation/Configure.help
+++ linux-120/Documentation/Configure.help
@@ -262,6 +262,12 @@ CONFIG_X86_SUMMIT
 
   If you don't have this computer, you may safely say N.
 
+Clustered APIC support
+CONFIG_X86_CLUSTERED_APIC
+  This option is required to support systems with more than 8 logical CPUs.
+
+  If you don't have such a computer, you may safely say N.
+
 IO-APIC support on uniprocessors
 CONFIG_X86_UP_IOAPIC
   An IO-APIC (I/O Advanced Programmable Interrupt Controller) is an
diff -urNp linux-115/arch/i386/config.in linux-120/arch/i386/config.in
--- linux-115/arch/i386/config.in
+++ linux-120/arch/i386/config.in
@@ -264,6 +264,7 @@ if [ "$CONFIG_SMP" != "y" ]; then
       define_bool CONFIG_X86_IO_APIC y
    fi
 else
+   bool 'Clustered APIC support' CONFIG_X86_CLUSTERED_APIC
    bool 'Multi-node NUMA system support' CONFIG_X86_NUMA
    if [ "$CONFIG_X86_NUMA" = "y" ]; then
       #Platform Choices
diff -urNp linux-115/arch/i386/kernel/acpitable.c linux-120/arch/i386/kernel/acpitable.c
--- linux-115/arch/i386/kernel/acpitable.c
+++ linux-120/arch/i386/kernel/acpitable.c
@@ -320,12 +320,16 @@ static int total_enabled_cpus __initdata
 int have_acpi_tables;
 
 extern void __init MP_processor_info(struct mpc_config_processor *);
+extern int xapic_support_disabled;
+extern unsigned int xapic_support;
 
 static void __init
 acpi_parse_lapic(struct acpi_table_lapic *local_apic)
 {
 	struct mpc_config_processor proc_entry;
 	int ix = 0;
+	static unsigned long apic_ver;
+	static int first_time = 1;
 
 	if (!local_apic)
 		return;
@@ -368,7 +372,16 @@ acpi_parse_lapic(struct acpi_table_lapic
 		proc_entry.mpc_featureflag = boot_cpu_data.x86_capability[0];
 		proc_entry.mpc_reserved[0] = 0;
 		proc_entry.mpc_reserved[1] = 0;
-		proc_entry.mpc_apicver = 0x10;	/* integrated APIC */
+		if (first_time) {
+			first_time = 0;
+			set_fixmap(FIX_APIC_BASE, APIC_DEFAULT_PHYS_BASE);
+			Dprintk("Local APIC ID %lx\n", apic_read(APIC_ID));
+			apic_ver = apic_read(APIC_LVR);
+			Dprintk("Local APIC Version %lx\n", apic_ver);
+			if (APIC_XAPIC_SUPPORT(apic_ver) && !xapic_support_disabled)
+				xapic_support = 1;
+		}
+		proc_entry.mpc_apicver = apic_ver;
 		MP_processor_info(&proc_entry);
 		total_enabled_cpus++;
 	} else {
diff -urNp linux-115/arch/i386/kernel/io_apic.c linux-120/arch/i386/kernel/io_apic.c
--- linux-115/arch/i386/kernel/io_apic.c
+++ linux-120/arch/i386/kernel/io_apic.c
@@ -34,15 +34,11 @@
 #include <asm/desc.h>
 #include <asm/smpboot.h>
 
-#undef APIC_LOCKUP_DEBUG
-
-#define APIC_LOCKUP_DEBUG
-
 static spinlock_t ioapic_lock = SPIN_LOCK_UNLOCKED;
 
 unsigned int int_dest_addr_mode = APIC_DEST_LOGICAL;
 unsigned char int_delivery_mode = dest_LowestPrio;
-
+extern unsigned int xapic_support;
 
 /*
  * # of IRQ routing registers
@@ -222,6 +218,17 @@ static int __init ioapic_setup(char *str
 
 __setup("apic", ioapic_setup);
 
+int xapic_support_disabled = 0;
+
+static int __init noxapic_setup(char *str)
+{
+	xapic_support_disabled = 1;
+	return 1;
+}
+
+__setup("noxapic", noxapic_setup);
+
+
 static int __init ioapic_pirq_setup(char *str)
 {
 	int i, max;
@@ -758,6 +765,7 @@ void __init print_IO_APIC(void)
 	struct IO_APIC_reg_00 reg_00;
 	struct IO_APIC_reg_01 reg_01;
 	struct IO_APIC_reg_02 reg_02;
+	struct IO_APIC_reg_03 reg_03;
 	unsigned long flags;
 
  	printk(KERN_DEBUG "number of MP IRQ sources: %d.\n", mp_irq_entries);
@@ -778,6 +786,8 @@ void __init print_IO_APIC(void)
 	*(int *)&reg_01 = io_apic_read(apic, 1);
 	if (reg_01.version >= 0x10)
 		*(int *)&reg_02 = io_apic_read(apic, 2);
+	if (reg_01.version >= 0x20)
+		*(int *)&reg_03 = io_apic_read(apic, 3);
 	spin_unlock_irqrestore(&ioapic_lock, flags);
 
 	printk("\n");
@@ -786,7 +796,7 @@ void __init print_IO_APIC(void)
 	printk(KERN_DEBUG ".......    : physical APIC id: %02X\n", reg_00.ID);
 	printk(KERN_DEBUG ".......    : Delivery Type: %X\n", reg_00.delivery_type);
 	printk(KERN_DEBUG ".......    : LTS          : %X\n", reg_00.LTS);
-	if (reg_00.__reserved_0 || reg_00.__reserved_1 || reg_00.__reserved_2)
+	if (reg_00.__reserved_1 || reg_00.__reserved_2)
 		UNEXPECTED_IO_APIC();
 
 	printk(KERN_DEBUG ".... register #01: %08X\n", *(int *)&reg_01);
@@ -797,7 +807,8 @@ void __init print_IO_APIC(void)
 		(reg_01.entries != 0x1f) && /* dual Xeon boards */
 		(reg_01.entries != 0x22) && /* bigger Xeon boards */
 		(reg_01.entries != 0x2E) &&
-		(reg_01.entries != 0x3F)
+		(reg_01.entries != 0x3F) &&
+		(reg_01.entries != 0x03)    /* AMD Golem */
 	)
 		UNEXPECTED_IO_APIC();
 
@@ -816,13 +827,31 @@ void __init print_IO_APIC(void)
 	if (reg_01.__reserved_1 || reg_01.__reserved_2)
 		UNEXPECTED_IO_APIC();
 
-	if (reg_01.version >= 0x10) {
+	/*
+	 * Some Intel chipsets with IO APIC VERSION of 0x1? don't have reg_02,
+	 * but the value of reg_02 is read as the previous read register
+	 * value, so ignore it if reg_02 == reg_01.
+	 */
+	if (reg_01.version >= 0x10 && *(int *)&reg_02 != *(int *)&reg_01) {
 		printk(KERN_DEBUG ".... register #02: %08X\n", *(int *)&reg_02);
 		printk(KERN_DEBUG ".......     : arbitration: %02X\n", reg_02.arbitration);
 		if (reg_02.__reserved_1 || reg_02.__reserved_2)
 			UNEXPECTED_IO_APIC();
 	}
 
+	/*
+	 * Some Intel chipsets with IO APIC VERSION of 0x2? don't have reg_02
+	 * or reg_03, but the value of reg_0[23] is read as the previous read
+	 * register value, so ignore it if reg_03 == reg_0[12].
+	 */
+	if (reg_01.version >= 0x20 && *(int *)&reg_03 != *(int *)&reg_02 &&
+	    *(int *)&reg_03 != *(int *)&reg_01) {
+		printk(KERN_DEBUG ".... register #03: %08X\n", *(int *)&reg_03);
+		printk(KERN_DEBUG ".......     : Boot DT    : %X\n", reg_03.boot_DT);
+		if (reg_03.__reserved_1)
+			UNEXPECTED_IO_APIC();
+	}
+
 	printk(KERN_DEBUG ".... IRQ redirection table:\n");
 
 	printk(KERN_DEBUG " NR Log Phy Mask Trig IRR Pol"
@@ -1081,7 +1110,8 @@ static void __init setup_ioapic_ids_from
 		
 		old_id = mp_ioapics[apic].mpc_apicid;
 
-		if (mp_ioapics[apic].mpc_apicid >= apic_broadcast_id) {
+		if (!xapic_support && 
+		    (mp_ioapics[apic].mpc_apicid >= apic_broadcast_id)) {
 			printk(KERN_ERR "BIOS bug, IO-APIC#%d ID is %d in the MPC table!...\n",
 				apic, mp_ioapics[apic].mpc_apicid);
 			printk(KERN_ERR "... fixing up to %d. (tell your hw vendor)\n",
@@ -1095,7 +1125,8 @@ static void __init setup_ioapic_ids_from
 		 * 'stuck on smp_invalidate_needed IPI wait' messages.
 		 * I/O APIC IDs no longer have any meaning for xAPICs and SAPICs.
 		 */
-		if ((clustered_apic_mode != CLUSTERED_APIC_XAPIC) &&
+		if (!xapic_support &&
+		    (clustered_apic_mode != CLUSTERED_APIC_XAPIC) &&
 		    (phys_id_present_map & (1 << mp_ioapics[apic].mpc_apicid))) {
 			printk(KERN_ERR "BIOS bug, IO-APIC#%d ID %d is already used!...\n",
 				apic, mp_ioapics[apic].mpc_apicid);
@@ -1137,12 +1168,15 @@ static void __init setup_ioapic_ids_from
 		spin_unlock_irqrestore(&ioapic_lock, flags);
 
 		/*
-		 * Sanity check
+		 * Sanity check.  Note that only the lowest-order 4 bits
+		 * are verified by the test below.  This is for handling
+		 * chipsets that implement 8-bit-wide modifications to
+		 * the ID while only providing 4-bit-wide data on reads.
 		 */
 		spin_lock_irqsave(&ioapic_lock, flags);
 		*(int *)&reg_00 = io_apic_read(apic, 0);
 		spin_unlock_irqrestore(&ioapic_lock, flags);
-		if (reg_00.ID != mp_ioapics[apic].mpc_apicid)
+		if ((reg_00.ID ^ mp_ioapics[apic].mpc_apicid) & 0xf)
 			panic("could not set ID!\n");
 		else
 			printk(" ok.\n");
@@ -1294,30 +1328,11 @@ static void end_level_ioapic_irq (unsign
 	ack_APIC_irq();
 
 	if (!(v & (1 << (i & 0x1f)))) {
-#ifdef APIC_LOCKUP_DEBUG
-		struct irq_pin_list *entry;
-#endif
-
 #ifdef APIC_MISMATCH_DEBUG
 		atomic_inc(&irq_mis_count);
 #endif
 		spin_lock(&ioapic_lock);
 		__mask_and_edge_IO_APIC_irq(irq);
-#ifdef APIC_LOCKUP_DEBUG
-		for (entry = irq_2_pin + irq;;) {
-			unsigned int reg;
-
-			if (entry->pin == -1)
-				break;
-			reg = io_apic_read(entry->apic, 0x10 + entry->pin * 2);
-			if (reg & 0x00004000)
-				printk(KERN_CRIT "Aieee!!!  Remote IRR"
-					" still set after unlock!\n");
-			if (!entry->next)
-				break;
-			entry = irq_2_pin + entry->next;
-		}
-#endif
 		__unmask_and_level_IO_APIC_irq(irq);
 		spin_unlock(&ioapic_lock);
 	}
@@ -1325,19 +1340,25 @@ static void end_level_ioapic_irq (unsign
 
 static void mask_and_ack_level_ioapic_irq (unsigned int irq) { /* nothing */ }
 
-static void set_ioapic_affinity (unsigned int irq, unsigned long mask)
+static void set_ioapic_affinity (unsigned int irq, unsigned long cpu_mask)
 {
+	unsigned int apicid_value = cpu_mask_to_apicid(cpu_mask) << 24;
+	struct irq_pin_list *entry = irq_2_pin + irq;
 	unsigned long flags;
-	/*
-	 * Only the first 8 bits are valid.
-	 */
-	mask = mask << 24;
-
+	int pin;
+	
 	spin_lock_irqsave(&ioapic_lock, flags);
-	__DO_ACTION(1, = mask, )
+	for (;;) {
+		pin = entry->pin;
+		if (pin == -1)
+			break;
+		io_apic_write(entry->apic, 0x10 + 1 + pin*2, apicid_value);
+		if (!entry->next)
+			break;
+		entry = irq_2_pin + entry->next;
+	}
 	spin_unlock_irqrestore(&ioapic_lock, flags);
 }
-
 /*
  * Level and edge triggered IO-APIC interrupts need different handling,
  * so we use two separate IRQ descriptors. Edge triggered IRQs can be
diff -urNp linux-115/arch/i386/kernel/mpparse.c linux-120/arch/i386/kernel/mpparse.c
--- linux-115/arch/i386/kernel/mpparse.c
+++ linux-120/arch/i386/kernel/mpparse.c
@@ -74,6 +74,8 @@ unsigned char esr_disable = 0;
 unsigned char clustered_apic_mode = CLUSTERED_APIC_NONE;
 unsigned int apic_broadcast_id = APIC_BROADCAST_ID_APIC;
 #endif
+extern int xapic_support_disabled;
+unsigned int xapic_support = 0;
 unsigned char raw_phys_apicid[NR_CPUS] = { [0 ... NR_CPUS-1] = BAD_APICID };
 
 /*
@@ -240,6 +242,8 @@ void __init MP_processor_info (struct mp
 		return;
 	}
 	ver = m->mpc_apicver;
+	if (APIC_XAPIC_SUPPORT(ver) && !xapic_support_disabled)
+		xapic_support = 1;
 
 	logical_cpu_present_map |= 1 << (num_processors-1);
  	phys_cpu_present_map |= apicid_to_phys_cpu_present(m->mpc_apicid);
@@ -589,15 +593,6 @@ static int __init smp_read_mpc(struct mp
 	}
 
 
-	printk("Enabling APIC mode: ");
-	if(clustered_apic_mode == CLUSTERED_APIC_NUMAQ)
-		printk("Clustered Logical.	");
-	else if(clustered_apic_mode == CLUSTERED_APIC_XAPIC)
-		printk("Physical.	");
-	else
-		printk("Flat.	");
-	printk("Using %d I/O APICs\n",nr_ioapics);
-
 	if (!num_processors)
 		printk(KERN_ERR "SMP mptable: no processors registered!\n");
 	return num_processors;
@@ -832,6 +827,35 @@ void __init get_smp_config (void)
 		BUG();
 
 	printk("Processors: %d\n", num_processors);
+	printk("xAPIC support %s present\n", (xapic_support?"is":"is not"));
+
+#ifdef CONFIG_X86_CLUSTERED_APIC
+	/*
+	 * Switch to Physical destination mode in case of generic
+	 * more than 8 CPU system, which has xAPIC support
+	 */
+#define FLAT_APIC_CPU_MAX	8
+	if ((clustered_apic_mode == CLUSTERED_APIC_NONE) &&
+	    (xapic_support) &&
+	    (num_processors > FLAT_APIC_CPU_MAX)) {
+		clustered_apic_mode = CLUSTERED_APIC_XAPIC;
+		apic_broadcast_id = APIC_BROADCAST_ID_XAPIC;
+		int_dest_addr_mode = APIC_DEST_PHYSICAL;
+		int_delivery_mode = dest_Fixed;
+		esr_disable = 1;
+		phys_cpu_present_map = logical_cpu_present_map;
+	}
+#endif
+
+	printk("Enabling APIC mode: ");
+	if (clustered_apic_mode == CLUSTERED_APIC_NUMAQ)
+		printk("Clustered Logical.	");
+	else if (clustered_apic_mode == CLUSTERED_APIC_XAPIC)
+		printk("Physical.	");
+	else
+		printk("Flat.	");
+	printk("Using %d I/O APICs\n",nr_ioapics);
+
 	/*
 	 * Only use the first configuration found.
 	 */
diff -urNp linux-115/arch/i386/kernel/pci-irq.c linux-120/arch/i386/kernel/pci-irq.c
--- linux-115/arch/i386/kernel/pci-irq.c
+++ linux-120/arch/i386/kernel/pci-irq.c
@@ -24,7 +24,7 @@
 
 int broken_hp_bios_irq9;
 int broken_440gx_bios;
-
+extern int pcibios_no_peer_tricks;
 static struct irq_routing_table *pirq_table;
 
 /*
@@ -691,7 +691,8 @@ void __init pcibios_irq_init(void)
 		pirq_table = pcibios_get_irq_routing_table();
 #endif
 	if (pirq_table) {
-		pirq_peer_trick();
+		if (!pcibios_no_peer_tricks)
+			pirq_peer_trick();
 		pirq_find_router();
 		if (pirq_table->exclusive_irqs) {
 			int i;
diff -urNp linux-115/arch/i386/kernel/pci-pc.c linux-120/arch/i386/kernel/pci-pc.c
--- linux-115/arch/i386/kernel/pci-pc.c
+++ linux-120/arch/i386/kernel/pci-pc.c
@@ -14,6 +14,7 @@
 
 #include <asm/segment.h>
 #include <asm/io.h>
+#include <asm/mpspec.h>
 #include <asm/smp.h>
 #include <asm/smpboot.h>
 
@@ -21,6 +22,7 @@
 
 unsigned int pci_probe = PCI_PROBE_BIOS | PCI_PROBE_CONF1 | PCI_PROBE_CONF2;
 
+int pcibios_no_peer_tricks = 0;
 int pcibios_last_bus = -1;
 struct pci_bus *pci_root_bus = NULL;
 struct pci_ops *pci_root_ops = NULL;
@@ -1138,6 +1140,32 @@ static void __devinit pcibios_fixup_peer
 	}
 }
 
+static void __devinit pci_scan_mptable(void)
+{ 
+#ifdef CONFIG_X86_LOCAL_APIC
+	int i; 
+
+	/* Handle ACPI here */
+	if (!smp_found_config) { 
+		printk(KERN_WARNING "PCI: Warning: no mptable. Scanning busses upto 0xff\n"); 
+		pcibios_last_bus = 0xfe; 
+		return;
+	} 
+
+	for (i = 0; i < MAX_MP_BUSSES; i++) {
+		int n = mp_bus_id_to_pci_bus[i]; 
+		if (n < 0 || n >= 0xff)
+			continue; 
+		if (pci_bus_exists(&pci_root_buses, n))
+			continue;
+		if (n > pcibios_last_bus)
+			pcibios_last_bus = n;
+		printk(KERN_INFO "PCI: Scanning bus %02x from mptable\n", n); 
+		pci_scan_bus(n, pci_root_ops, NULL); 
+	}
+#endif			
+} 
+
 /*
  * Exceptions for specific devices. Usually work-arounds for fatal design flaws.
  */
@@ -1417,6 +1445,7 @@ void __init pcibios_init(void)
 	}
 
 	pcibios_irq_init();
+	pci_scan_mptable(); 
 	pcibios_fixup_peer_bridges();
 	pcibios_fixup_irqs();
 	pcibios_resource_survey();
@@ -1464,6 +1493,9 @@ char * __devinit  pcibios_setup(char *st
 	} else if (!strcmp(str, "assign-busses")) {
 		pci_probe |= PCI_ASSIGN_ALL_BUSSES;
 		return NULL;
+	} else if (!strcmp(str, "nopeertricks")) {
+		pcibios_no_peer_tricks = 1;
+		return NULL;
 	} else if (!strncmp(str, "irqmask=", 8)) {
 		pcibios_irq_mask = simple_strtol(str+8, NULL, 0);
 		return NULL;
diff -urNp linux-115/include/asm-i386/apicdef.h linux-120/include/asm-i386/apicdef.h
--- linux-115/include/asm-i386/apicdef.h
+++ linux-120/include/asm-i386/apicdef.h
@@ -11,13 +11,14 @@
 #define		APIC_DEFAULT_PHYS_BASE	0xfee00000
  
 #define		APIC_ID		0x20
-#define			APIC_ID_MASK		(0x0F<<24)
-#define			GET_APIC_ID(x)		(((x)>>24)&0x0F)
+#define			APIC_ID_MASK		(0xFF<<24)
+#define			GET_APIC_ID(x)		(((x)>>24)&0xFF)
 #define		APIC_LVR	0x30
 #define			APIC_LVR_MASK		0xFF00FF
 #define			GET_APIC_VERSION(x)	((x)&0xFF)
 #define			GET_APIC_MAXLVT(x)	(((x)>>16)&0xFF)
 #define			APIC_INTEGRATED(x)	((x)&0xF0)
+#define			APIC_XAPIC_SUPPORT(x)	((x)>=0x14)
 #define		APIC_TASKPRI	0x80
 #define			APIC_TPRI_MASK		0xFF
 #define		APIC_ARBPRI	0x90
diff -urNp linux-115/include/asm-i386/io_apic.h linux-120/include/asm-i386/io_apic.h
--- linux-115/include/asm-i386/io_apic.h
+++ linux-120/include/asm-i386/io_apic.h
@@ -26,8 +26,7 @@ struct IO_APIC_reg_00 {
 		LTS		:  1,
 		delivery_type	:  1,
 		__reserved_1	:  8,
-		ID		:  4,
-		__reserved_0	:  4;
+		ID		:  8;
 } __attribute__ ((packed));
 
 struct IO_APIC_reg_01 {
@@ -44,6 +43,11 @@ struct IO_APIC_reg_02 {
 		__reserved_1	:  4;
 } __attribute__ ((packed));
 
+struct IO_APIC_reg_03 {
+	__u32	boot_DT		:  1,
+		__reserved_1	: 31;
+} __attribute__ ((packed));
+
 /*
  * # of IO-APICs and # of IRQ routing registers
  */
diff -urNp linux-115/include/asm-i386/mpspec.h linux-120/include/asm-i386/mpspec.h
--- linux-115/include/asm-i386/mpspec.h
+++ linux-120/include/asm-i386/mpspec.h
@@ -191,7 +191,7 @@ struct mpc_config_translation
 #define MAX_IRQ_SOURCES 256
 #endif /* CONFIG_MULTIQUAD */
 
-#define MAX_MP_BUSSES 32
+#define MAX_MP_BUSSES 260
 enum mp_bustype {
 	MP_BUS_ISA = 1,
 	MP_BUS_EISA,
diff -urNp linux-115/include/asm-i386/smp.h linux-120/include/asm-i386/smp.h
--- linux-115/include/asm-i386/smp.h
+++ linux-120/include/asm-i386/smp.h
@@ -94,7 +94,9 @@ extern void smp_store_cpu_info(int id);	
 static __inline int hard_smp_processor_id(void)
 {
 	/* we don't want to mark this access volatile - bad code generation */
-	return GET_APIC_ID(*(unsigned long *)(APIC_BASE+APIC_ID));
+	unsigned long ul = *(unsigned long *)(APIC_BASE+APIC_ID);
+	barrier();
+	return GET_APIC_ID(ul);
 }
 
 static __inline int logical_smp_processor_id(void)
diff -urNp linux-115/include/asm-i386/smpboot.h linux-120/include/asm-i386/smpboot.h
--- linux-115/include/asm-i386/smpboot.h
+++ linux-120/include/asm-i386/smpboot.h
@@ -124,10 +124,53 @@ static inline int target_cpus(void)
 			cpu = (cpu+1)%smp_num_cpus;
 			return cpu_to_physical_apicid(cpu);
 		default:
+			;
 	}
 	return cpu_online_map;
 }
+
+#define apicid_cluster(apicid) (apicid & 0xF0)
+
+static inline unsigned int cpu_mask_to_apicid (unsigned long cpumask)
+{
+	int num_bits_set;
+	int cpus_found = 0;
+	int cpu;
+	int apicid;	
+
+	if (clustered_apic_mode == CLUSTERED_APIC_NONE)
+		return (unsigned int) cpumask;
+
+	num_bits_set = hweight32(cpumask); 
+	/* Return id to all */
+	if (num_bits_set == 32)
+		return (int) 0xFF;
+	/* 
+	 * The cpus in the mask must all be on the apic cluster.  If are not 
+	 * on the same apicid cluster return default value of TARGET_CPUS. 
+	 */
+	cpu = ffs(cpumask)-1;
+	if (clustered_apic_mode == CLUSTERED_APIC_XAPIC)
+		return cpu_to_physical_apicid(cpu);
+	apicid = cpu_to_logical_apicid(cpu);
+	while (cpus_found < num_bits_set) {
+		if (cpumask & (1 << cpu)) {
+			int new_apicid = cpu_to_logical_apicid(cpu);
+			if (apicid_cluster(apicid) != 
+					apicid_cluster(new_apicid)){
+				printk ("%s: Not a valid mask!\n",__FUNCTION__);
+				return 0xFF;
+			}
+			apicid = apicid | new_apicid;
+			cpus_found++;
+		}
+		cpu++;
+	}
+	return apicid;
+}
+
 #else
-#define target_cpus() (0xFF)
+# define target_cpus() (0xFF)
+# define cpu_mask_to_apicid(cpumask) (cpumask)
 #endif
 #endif
