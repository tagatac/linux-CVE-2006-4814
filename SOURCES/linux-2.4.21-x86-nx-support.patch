diff -urNp linux-120/arch/i386/kernel/head.S linux-123/arch/i386/kernel/head.S
--- linux-120/arch/i386/kernel/head.S
+++ linux-123/arch/i386/kernel/head.S
@@ -75,6 +75,34 @@ startup_32:
 	movl %cr4,%eax		# Turn on paging options (PSE,PAE,..)
 	orl cr4_bits,%eax
 	movl %eax,%cr4
+
+	btl     $5, %eax        # check if PAE is enabled
+	jnc     6f
+
+	/* Check if extended functions are implemented */               
+	movl    $0x80000000, %eax
+	cpuid
+	cmpl    $0x80000000, %eax
+	jbe     6f
+	mov     $0x80000001, %eax
+	cpuid
+	/* Execute Disable bit supported? */     
+	btl     $20, %edx
+	jnc     6f
+
+	/* Setup EFER (Extended Feature Enable Register) */
+	movl    $0xc0000080, %ecx
+	rdmsr
+ 
+	btsl    $11, %eax
+	/* Make changes effective */
+	wrmsr
+
+6:
+	/* cpuid clobbered ebx, set it up again: */
+	xorl %ebx,%ebx
+	incl %ebx
+
 	jmp 3f
 1:
 #endif
diff -urNp linux-120/arch/i386/kernel/i386_ksyms.c linux-123/arch/i386/kernel/i386_ksyms.c
--- linux-120/arch/i386/kernel/i386_ksyms.c
+++ linux-123/arch/i386/kernel/i386_ksyms.c
@@ -198,3 +198,8 @@ EXPORT_SYMBOL(xquad_portio);
 EXPORT_SYMBOL(edd);
 EXPORT_SYMBOL(eddnr);
 #endif
+
+extern unsigned long long __PAGE_KERNEL;
+EXPORT_SYMBOL_GPL(__PAGE_KERNEL);
+extern unsigned long long __supported_pte_mask;
+EXPORT_SYMBOL_GPL(__supported_pte_mask);
diff -urNp linux-120/arch/i386/kernel/setup.c linux-123/arch/i386/kernel/setup.c
--- linux-120/arch/i386/kernel/setup.c
+++ linux-123/arch/i386/kernel/setup.c
@@ -784,6 +784,9 @@ static void __init parse_cmdline_early (
 				to--;
 			if (!memcmp(from+4, "nopentium", 9)) {
 				from += 9+4;
+				/* all PSE CPUs handle WP well: */
+				if (cpu_has_pse)
+					boot_cpu_data.wp_works_ok = 1;
 				clear_bit(X86_FEATURE_PSE, &boot_cpu_data.x86_capability);
 				set_bit(X86_FEATURE_PSE, &disabled_x86_caps);
 			} else if (!memcmp(from+4, "exactmap", 8)) {
@@ -2731,6 +2734,50 @@ static int __init id_and_try_enable_cpui
 	return have_cpuid_p();	/* Check to see if CPUID now enabled? */
 }
 
+
+int disable_nx __initdata = 0;
+u64 __supported_pte_mask = ~_PAGE_NX;
+int use_nx = 0;
+
+/*
+ * noexec = on|off
+ *
+ * Control non executable mappings.
+ *
+ * on      Enable
+ * off     Disable (disables exec-shield too)
+ */
+static int __init nonx_setup(char *str)
+{
+	if (!strncmp(str, "on",2) && cpu_has_nx) { 
+		__supported_pte_mask |= _PAGE_NX; 
+ 		disable_nx = 0; 
+	} else if (!strncmp(str,"off",3)) { 
+		disable_nx = 1;
+		__supported_pte_mask &= ~_PAGE_NX; 
+		exec_shield = 0;
+        } 
+        return 1;
+} 
+
+__setup("noexec=", nonx_setup); 
+
+void __init check_efer(void)
+{
+	unsigned long l,h;
+
+	if (cpu_has_nx) {
+		rdmsr(MSR_EFER, l, h);
+		if (!(l & EFER_NX) || disable_nx) {
+			__supported_pte_mask &= ~_PAGE_NX;
+			use_nx = 0;
+		}
+	} else	{
+		__supported_pte_mask &= ~_PAGE_NX;
+		use_nx = 0;
+	}
+}
+
 /*
  * This does the hard work of actually picking apart the CPU stuff...
  */
@@ -2874,6 +2921,7 @@ void __init identify_cpu(struct cpuinfo_
 
 	/* Init Machine Check Exception if available. */
 	mcheck_init(c);
+	check_efer();
 
 	/* If the model name is still unset, do table lookup. */
 	if ( !c->x86_model_id[0] ) {
@@ -2981,7 +3029,7 @@ static int show_cpuinfo(struct seq_file 
 		/* AMD-defined */
 		NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL,
 		NULL, NULL, NULL, "syscall", NULL, NULL, NULL, NULL,
-		NULL, NULL, NULL, NULL, NULL, NULL, "mmxext", NULL,
+		NULL, NULL, NULL, NULL, "nx", NULL, "mmxext", NULL,
 		NULL, NULL, NULL, NULL, NULL, "lm", "3dnowext", "3dnow",
 
 		/* Transmeta-defined */
diff -urNp linux-120/arch/i386/mm/fault.c linux-123/arch/i386/mm/fault.c
--- linux-120/arch/i386/mm/fault.c
+++ linux-123/arch/i386/mm/fault.c
@@ -306,6 +306,21 @@ no_context:
 
 	bust_spinlocks(1);
 
+#ifdef CONFIG_X86_PAE
+	{
+		pgd_t *pgd;
+		pmd_t *pmd;
+
+		asm("movl %%cr3,%0":"=r" (pgd));
+
+		pgd = init_mm.pgd + pgd_index(address);
+		if (pgd_present(*pgd)) {
+			pmd = pmd_offset(pgd, address);
+			if (pmd_val(*pmd) & _PAGE_NX)
+				printk("kernel tried to access NX-protected page - exploit attempt? (uid: %d)\n", current->uid);
+		}
+	}
+#endif
 	if (address < PAGE_SIZE)
 		printk(KERN_ALERT "Unable to handle kernel NULL pointer dereference");
 	else
diff -urNp linux-120/include/asm-i386/cpufeature.h linux-123/include/asm-i386/cpufeature.h
--- linux-120/include/asm-i386/cpufeature.h
+++ linux-123/include/asm-i386/cpufeature.h
@@ -47,6 +47,7 @@
 /* AMD-defined CPU features, CPUID level 0x80000001, word 1 */
 /* Don't duplicate feature flags which are redundant with Intel! */
 #define X86_FEATURE_SYSCALL	(1*32+11) /* SYSCALL/SYSRET */
+#define X86_FEATURE_NX		(1*32+20) /* Execute Disable */
 #define X86_FEATURE_MMXEXT	(1*32+22) /* AMD MMX extensions */
 #define X86_FEATURE_LM		(1*32+29) /* Long Mode (x86-64) */
 #define X86_FEATURE_3DNOWEXT	(1*32+30) /* AMD 3DNow! extensions */
diff -urNp linux-120/include/asm-i386/module.h linux-123/include/asm-i386/module.h
--- linux-120/include/asm-i386/module.h
+++ linux-123/include/asm-i386/module.h
@@ -4,7 +4,8 @@
  * This file contains the i386 architecture specific module code.
  */
 
-#define module_map(x)		vmalloc(x)
+#define module_map(x)		__vmalloc((x), GFP_KERNEL | __GFP_HIGHMEM, \
+					  PAGE_KERNEL_EXEC)
 #define module_unmap(x)		vfree(x)
 #define module_arch_init(x)	(0)
 #define arch_init_modules(x)	do { } while (0)
diff -urNp linux-120/include/asm-i386/msr.h linux-123/include/asm-i386/msr.h
--- linux-120/include/asm-i386/msr.h
+++ linux-123/include/asm-i386/msr.h
@@ -181,6 +181,13 @@
 #define MSR_K7_FID_VID_CTL		0xC0010041
 #define MSR_K7_VID_STATUS		0xC0010042
 
+#define MSR_EFER 			0xc0000080	/* extended feature register */
+
+/* EFER bits: */ 
+#define _EFER_NX 11  			/* Execute Disable enable */
+
+#define EFER_NX (1<<_EFER_NX)
+
 /* Centaur-Hauls/IDT defined MSRs. */
 #define MSR_IDT_FCR1			0x107
 #define MSR_IDT_FCR2			0x108
diff -urNp linux-120/include/asm-i386/page.h linux-123/include/asm-i386/page.h
--- linux-120/include/asm-i386/page.h
+++ linux-123/include/asm-i386/page.h
@@ -37,24 +37,41 @@
  * These are used to make use of C type-checking..
  */
 #if CONFIG_X86_PAE
+extern unsigned long long __supported_pte_mask;
 typedef struct { unsigned long pte_low, pte_high; } pte_t;
 typedef struct { unsigned long long pmd; } pmd_t;
 typedef struct { unsigned long long pgd; } pgd_t;
+typedef struct { unsigned long pgprot; } pgprot_t;
 #define pte_val(x)	((x).pte_low | ((unsigned long long)(x).pte_high << 32))
 #else
 typedef struct { unsigned long pte_low; } pte_t;
 typedef struct { unsigned long pmd; } pmd_t;
 typedef struct { unsigned long pgd; } pgd_t;
+typedef struct { unsigned long pgprot; } pgprot_t;
 #define pte_val(x)	((x).pte_low)
 #endif
 #define PTE_MASK	PAGE_MASK
 
-typedef struct { unsigned long pgprot; } pgprot_t;
-
 #define pmd_val(x)	((x).pmd)
 #define pgd_val(x)	((x).pgd)
 #define pgprot_val(x)	((x).pgprot)
 
+/* Materialize both the hard and soft NX bits for a given PTE */
+#ifdef CONFIG_X86_PAE
+#define __PAGE_BIT_NX		9
+#define __PAGE_BIT_NX_PTE	63
+static inline unsigned long long pgprot_nx(pgprot_t x)
+{
+	unsigned long long 	p;
+
+	p = ((unsigned long long)(x).pgprot & __supported_pte_mask) & (1ULL << __PAGE_BIT_NX);
+
+	return p | (p << (__PAGE_BIT_NX_PTE - __PAGE_BIT_NX));
+}
+#else
+#define pgprot_nx(x)	(0ULL)
+#endif
+
 #define __pte(x) ((pte_t) { (x) } )
 #define __pmd(x) ((pmd_t) { (x) } )
 #define __pgd(x) ((pgd_t) { (x) } )
diff -urNp linux-120/include/asm-i386/pgtable-3level.h linux-123/include/asm-i386/pgtable-3level.h
--- linux-120/include/asm-i386/pgtable-3level.h
+++ linux-123/include/asm-i386/pgtable-3level.h
@@ -92,12 +92,15 @@ static inline int pte_same(pte_t a, pte_
 #define pte_page(x)	(mem_map+(((x).pte_low >> PAGE_SHIFT) | ((x).pte_high << (32 - PAGE_SHIFT))))
 #define pte_none(x)	(!(x).pte_low && !(x).pte_high)
 
+extern unsigned long long __supported_pte_mask;
+
 static inline pte_t __mk_pte(unsigned long page_nr, pgprot_t pgprot)
 {
 	pte_t pte;
 
-	pte.pte_high = page_nr >> (32 - PAGE_SHIFT);
-	pte.pte_low = (page_nr << PAGE_SHIFT) | pgprot_val(pgprot);
+ 	pte.pte_high = (page_nr >> (32 - PAGE_SHIFT)) | (unsigned long)(pgprot_nx(pgprot) >> 32);
+ 	pte.pte_high &= (__supported_pte_mask >> 32);
+ 	pte.pte_low = ((page_nr << PAGE_SHIFT) | pgprot_val(pgprot) | (unsigned long)pgprot_nx(pgprot));
 	return pte;
 }
 
diff -urNp linux-120/include/asm-i386/pgtable.h linux-123/include/asm-i386/pgtable.h
--- linux-120/include/asm-i386/pgtable.h
+++ linux-123/include/asm-i386/pgtable.h
@@ -183,6 +183,8 @@ extern void pgtable_cache_init(void);
 #define _PAGE_BIT_DIRTY		6
 #define _PAGE_BIT_PSE		7	/* 4 MB (or 2MB) page, Pentium+, if present.. */
 #define _PAGE_BIT_GLOBAL	8	/* Global TLB entry PPro+ */
+#define _PAGE_BIT_NX		9	/* "soft" NX bit */
+#define _PAGE_BIT_NX_PTE	63
 
 #define _PAGE_PRESENT	0x001
 #define _PAGE_RW	0x002
@@ -195,6 +197,11 @@ extern void pgtable_cache_init(void);
 #define _PAGE_GLOBAL	0x100	/* Global TLB entry PPro+ */
 
 #define _PAGE_PROTNONE	0x080	/* If not present */
+#ifdef CONFIG_X86_PAE
+#define _PAGE_NX        (1ULL<<_PAGE_BIT_NX)
+#else
+#define _PAGE_NX	0
+#endif
 
 #define _PAGE_TABLE	(_PAGE_PRESENT | _PAGE_RW | _PAGE_USER | _PAGE_ACCESSED | _PAGE_DIRTY)
 #define _KERNPG_TABLE	(_PAGE_PRESENT | _PAGE_RW | _PAGE_ACCESSED | _PAGE_DIRTY)
@@ -202,15 +209,25 @@ extern void pgtable_cache_init(void);
 
 #define PAGE_NONE	__pgprot(_PAGE_PROTNONE | _PAGE_ACCESSED)
 #define PAGE_SHARED	__pgprot(_PAGE_PRESENT | _PAGE_RW | _PAGE_USER | _PAGE_ACCESSED)
-#define PAGE_COPY	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED)
-#define PAGE_READONLY	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED)
 
-#define __PAGE_KERNEL \
+#define PAGE_SHARED_EXEC  __pgprot(_PAGE_PRESENT | _PAGE_RW | _PAGE_USER | _PAGE_ACCESSED)
+#define PAGE_COPY_NOEXEC  __pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED | _PAGE_NX)
+#define PAGE_COPY PAGE_COPY_NOEXEC
+#define PAGE_COPY_EXEC	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED)
+#define PAGE_READONLY	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED | _PAGE_NX)
+#define PAGE_READONLY_EXEC	__pgprot(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED)
+
+#define _PAGE_KERNEL \
+	(_PAGE_PRESENT | _PAGE_RW | _PAGE_DIRTY | _PAGE_ACCESSED | _PAGE_NX)
+#define _PAGE_KERNEL_EXEC \
 	(_PAGE_PRESENT | _PAGE_RW | _PAGE_DIRTY | _PAGE_ACCESSED)
-#define __PAGE_KERNEL_NOCACHE \
-	(_PAGE_PRESENT | _PAGE_RW | _PAGE_DIRTY | _PAGE_PCD | _PAGE_ACCESSED)
-#define __PAGE_KERNEL_RO \
-	(_PAGE_PRESENT | _PAGE_DIRTY | _PAGE_ACCESSED)
+
+extern unsigned long long __PAGE_KERNEL;
+extern unsigned long long __PAGE_KERNEL_EXEC;
+
+#define __PAGE_KERNEL_RO		(__PAGE_KERNEL & ~_PAGE_RW)
+#define __PAGE_KERNEL_NOCACHE		(__PAGE_KERNEL | _PAGE_PCD)
+#define __PAGE_KERNEL_LARGE		(__PAGE_KERNEL | _PAGE_PSE)
 
 #ifdef CONFIG_X86_PGE
 # define MAKE_GLOBAL(x) __pgprot((x) | _PAGE_GLOBAL)
@@ -240,19 +257,19 @@ extern void pgtable_cache_init(void);
 #define __P001	PAGE_READONLY
 #define __P010	PAGE_COPY
 #define __P011	PAGE_COPY
-#define __P100	PAGE_READONLY
-#define __P101	PAGE_READONLY
-#define __P110	PAGE_COPY
-#define __P111	PAGE_COPY
+#define __P100	PAGE_READONLY_EXEC
+#define __P101	PAGE_READONLY_EXEC
+#define __P110	PAGE_COPY_EXEC
+#define __P111	PAGE_COPY_EXEC
 
 #define __S000	PAGE_NONE
 #define __S001	PAGE_READONLY
 #define __S010	PAGE_SHARED
 #define __S011	PAGE_SHARED
-#define __S100	PAGE_READONLY
-#define __S101	PAGE_READONLY
-#define __S110	PAGE_SHARED
-#define __S111	PAGE_SHARED
+#define __S100	PAGE_READONLY_EXEC
+#define __S101	PAGE_READONLY_EXEC
+#define __S110	PAGE_SHARED_EXEC
+#define __S111	PAGE_SHARED_EXEC
 
 /*
  * Define this if things work differently on an i386 and an i486:
@@ -314,10 +331,21 @@ static inline void ptep_mkdirty(pte_t *p
 static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 {
 	pte.pte_low &= _PAGE_CHG_MASK;
+#ifndef CONFIG_X86_PAE
 	pte.pte_low |= pgprot_val(newprot);
+#else
+	pte.pte_low |= (pgprot_val(newprot) & __supported_pte_mask);
+	/*
+	 * Chop off the NX bit (if present), and add the NX portion of
+	 * the newprot (if present):
+	 */
+	pte.pte_high &= -1 ^ (1 << (_PAGE_BIT_NX_PTE - 32));
+	pte.pte_high |= (pte.pte_low & _PAGE_NX) << (_PAGE_BIT_NX_PTE - _PAGE_BIT_NX - 32);
+#endif
 	return pte;
 }
 
+
 #define page_pte(page) page_pte_prot(page, __pgprot(0))
 
 #define pmd_page(pmd) \
diff -urNp linux-120/include/asm-i386/processor.h linux-123/include/asm-i386/processor.h
--- linux-120/include/asm-i386/processor.h
+++ linux-123/include/asm-i386/processor.h
@@ -101,6 +101,7 @@ extern struct cpuinfo_x86 cpu_data[];
 #define cpu_has_xmm	(test_bit(X86_FEATURE_XMM,  boot_cpu_data.x86_capability))
 #define cpu_has_fpu	(test_bit(X86_FEATURE_FPU,  boot_cpu_data.x86_capability))
 #define cpu_has_apic	(test_bit(X86_FEATURE_APIC, boot_cpu_data.x86_capability))
+#define cpu_has_nx	(test_bit(X86_FEATURE_NX, boot_cpu_data.x86_capability))
 
 extern char ignore_irq13;
 
@@ -429,6 +430,8 @@ struct thread_struct {
 	{~0, } /* ioperm */					\
 }
 
+extern int use_nx;
+
 #define start_thread(regs, new_eip, new_esp) do {		\
 	__asm__("movl %0,%%fs ; movl %0,%%gs": :"r" (0));	\
 	set_fs(USER_DS);					\
diff -urNp linux-120/kernel/sysctl.c linux-123/kernel/sysctl.c
--- linux-120/kernel/sysctl.c
+++ linux-123/kernel/sysctl.c
@@ -180,6 +180,10 @@ static ctl_table kern_table[] = {
 	 0644, NULL, &proc_dointvec},
 	{KERN_PANIC, "print_fatal_signals", &print_fatal_signals, sizeof(int),
 	 0644, NULL, &proc_dointvec},
+#ifdef __i386__
+	{KERN_PANIC, "use-nx", &use_nx, sizeof(int),
+	 0644, NULL, &proc_dointvec},
+#endif
 	{KERN_CORE_USES_PID, "core_uses_pid", &core_uses_pid, sizeof(int),
 	 0644, NULL, &proc_dointvec},
 	{KERN_CORE_USES_PID, "core_setuid_ok", &core_setuid_ok, sizeof(int),
