diff -urNp linux-7000/arch/i386/kernel/irq.c linux-7010/arch/i386/kernel/irq.c
--- linux-7000/arch/i386/kernel/irq.c
+++ linux-7010/arch/i386/kernel/irq.c
@@ -152,7 +152,7 @@ int get_irq_list(char *buf)
 #else
 		for (j = 0; j < smp_num_cpus; j++)
 			p += sprintf(p, "%10u ",
-				kstat.irqs[cpu_logical_map(j)][i]);
+				kstat_percpu[cpu_logical_map(j)].irqs[i]);
 #endif
 		p += sprintf(p, " %14s", irq_desc[i].handler->typename);
 		p += sprintf(p, "  %s", action->name);
@@ -592,7 +592,7 @@ asmlinkage unsigned int do_IRQ(struct pt
 	}
 #endif
 
-	kstat.irqs[cpu][irq]++;
+	kstat_percpu[cpu].irqs[irq]++;
 	spin_lock(&desc->lock);
 	desc->handler->ack(irq);
 	/*
diff -urNp linux-7000/arch/i386/kernel/visws_apic.c linux-7010/arch/i386/kernel/visws_apic.c
--- linux-7000/arch/i386/kernel/visws_apic.c
+++ linux-7010/arch/i386/kernel/visws_apic.c
@@ -324,7 +324,7 @@ static void do_piix4_master_IRQ(unsigned
 	/*
 	 * handle this 'virtual interrupt' as a Cobalt one now.
 	 */
-	kstat.irqs[smp_processor_id()][irq]++;
+	kstat_percpu[smp_processor_id()].irqs[irq]++;
 	do_cobalt_IRQ(realirq, regs);
 
 	spin_lock(&irq_controller_lock);
diff -urNp linux-7000/arch/ia64/kernel/irq.c linux-7010/arch/ia64/kernel/irq.c
--- linux-7000/arch/ia64/kernel/irq.c
+++ linux-7010/arch/ia64/kernel/irq.c
@@ -175,7 +175,7 @@ int get_irq_list(char *buf)
 #else
 		for (j = 0; j < smp_num_cpus; j++)
 			p += sprintf(p, "%10u ",
-				kstat.irqs[cpu_logical_map(j)][i]);
+				kstat_percpu[cpu_logical_map(j)].irqs[i]);
 #endif
 		p += sprintf(p, " %14s", idesc->handler->typename);
 		p += sprintf(p, "  %s", action->name);
@@ -619,7 +619,7 @@ unsigned int do_IRQ(unsigned long irq, s
 	struct irqaction * action;
 	unsigned int status;
 
-	kstat.irqs[cpu][irq]++;
+	kstat_percpu[cpu].irqs[irq]++;
 
 	if (desc->status & IRQ_PER_CPU) {
 		/* no locking required for CPU-local interrupts: */
diff -urNp linux-7000/arch/ppc64/kernel/irq.c linux-7010/arch/ppc64/kernel/irq.c
--- linux-7000/arch/ppc64/kernel/irq.c
+++ linux-7010/arch/ppc64/kernel/irq.c
@@ -376,7 +376,7 @@ int get_irq_list(char *buf)
 #ifdef CONFIG_SMP
        for (j = 0; j < smp_num_cpus; j++)
            len += sprintf(buf+len, "%10u ",
-               kstat.irqs[cpu_logical_map(j)][i]);
+               kstat_percpu[cpu_logical_map(j)].irqs[i]);
 #else
        len += sprintf(buf+len, "%10u ", kstat_irqs(i));
 #endif /* CONFIG_SMP */
@@ -420,7 +420,7 @@ int show_interrupts(struct seq_file *p, 
 #ifdef CONFIG_SMP
 		for (j = 0; j < smp_num_cpus; j++)
 			seq_printf(p, "%10u ",
-				kstat.irqs[cpu_logical_map(j)][i]);
+				kstat_percpu[cpu_logical_map(j)].irqs[i]);
 #else		
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif /* CONFIG_SMP */
@@ -472,7 +472,7 @@ void ppc_irq_dispatch_handler(struct pt_
 	int cpu = smp_processor_id();
 	irq_desc_t *desc = irq_desc + irq;
 
-	kstat.irqs[cpu][irq]++;
+	kstat_percpu[cpu].irqs[irq]++;
 	spin_lock(&desc->lock);
 	ack_irq(irq);	
 	/*
diff -urNp linux-7000/arch/x86_64/kernel/irq.c linux-7010/arch/x86_64/kernel/irq.c
--- linux-7000/arch/x86_64/kernel/irq.c
+++ linux-7010/arch/x86_64/kernel/irq.c
@@ -175,7 +175,7 @@ int get_irq_list(char *buf)
 #else
 		for (j = 0; j < smp_num_cpus; j++)
 			p += sprintf(p, "%10u ",
-				kstat.irqs[cpu_logical_map(j)][i]);
+				kstat_percpu[cpu_logical_map(j)].irqs[i]);
 #endif
 		p += sprintf(p, " %14s", irq_desc[i].handler->typename);
 		p += sprintf(p, "  %s", action->name);
@@ -609,7 +609,7 @@ asmlinkage unsigned int do_IRQ(struct pt
 	stack_overflow_check(regs); 
 #endif
 	       
-	kstat.irqs[cpu][irq]++;
+	kstat_percpu[cpu].irqs[irq]++;
 	spin_lock(&desc->lock);
 	desc->handler->ack(irq);
 	/*
diff -urNp linux-7000/drivers/block/ll_rw_blk.c linux-7010/drivers/block/ll_rw_blk.c
--- linux-7000/drivers/block/ll_rw_blk.c
+++ linux-7010/drivers/block/ll_rw_blk.c
@@ -685,13 +685,13 @@ inline void drive_stat_acct (kdev_t dev,
 	if ((index >= DK_MAX_DISK) || (major >= DK_MAX_MAJOR))
 		return;
 
-	kstat.dk_drive[major][index] += new_io;
+	kstat_percpu[smp_processor_id()].dk_drive[major][index] += new_io;
 	if (rw == READ) {
-		kstat.dk_drive_rio[major][index] += new_io;
-		kstat.dk_drive_rblk[major][index] += nr_sectors;
+		kstat_percpu[smp_processor_id()].dk_drive_rio[major][index] += new_io;
+		kstat_percpu[smp_processor_id()].dk_drive_rblk[major][index] += nr_sectors;
 	} else if (rw == WRITE) {
-		kstat.dk_drive_wio[major][index] += new_io;
-		kstat.dk_drive_wblk[major][index] += nr_sectors;
+		kstat_percpu[smp_processor_id()].dk_drive_wio[major][index] += new_io;
+		kstat_percpu[smp_processor_id()].dk_drive_wblk[major][index] += nr_sectors;
 	} else
 		printk(KERN_ERR "drive_stat_acct: cmd not R/W?\n");
 }
@@ -1294,10 +1294,10 @@ void submit_bh_rsector(int rw, struct bu
 
 	switch (rw) {
 		case WRITE:
-			kstat.pgpgout += count;
+			kstat_percpu[smp_processor_id()].pgpgout += count;
 			break;
 		default:
-			kstat.pgpgin += count;
+			kstat_percpu[smp_processor_id()].pgpgin += count;
 			break;
 	}
 }
@@ -1425,10 +1425,10 @@ queue_next:
 
 	switch (rw) {
 		case WRITE:
-			kstat.pgpgout += size >> 9;
+			kstat_percpu[smp_processor_id()].pgpgout += size >> 9;
 			break;
 		default:
-			kstat.pgpgin += size >> 9;
+			kstat_percpu[smp_processor_id()].pgpgin += size >> 9;
 			break;
 	}
 
diff -urNp linux-7000/drivers/md/md.c linux-7010/drivers/md/md.c
--- linux-7000/drivers/md/md.c
+++ linux-7010/drivers/md/md.c
@@ -3480,8 +3480,8 @@ static int is_mddev_idle(mddev_t *mddev)
 		if ((idx >= DK_MAX_DISK) || (major >= DK_MAX_MAJOR))
 			continue;
 
-		curr_events = kstat.dk_drive_rblk[major][idx] +
-						kstat.dk_drive_wblk[major][idx] ;
+		curr_events = kstat_sum(dk_drive_rblk[major][idx]) +
+				kstat_sum(dk_drive_wblk[major][idx]);
 		curr_events -= sync_io[major][idx];
 		if ((curr_events - rdev->last_events) > 32) {
 			rdev->last_events = curr_events;
diff -urNp linux-7000/fs/proc/proc_misc.c linux-7010/fs/proc/proc_misc.c
--- linux-7000/fs/proc/proc_misc.c
+++ linux-7010/fs/proc/proc_misc.c
@@ -333,14 +333,14 @@ static int kstat_read_proc(char *page, c
 	for (i = 0 ; i < smp_num_cpus; i++) {
 		int cpu = cpu_logical_map(i), j;
 
-		user += kstat.per_cpu_user[cpu];
-		nice += kstat.per_cpu_nice[cpu];
-		system += kstat.per_cpu_system[cpu];
-		idle += kstat.per_cpu_idle[cpu];
-		iowait += kstat.per_cpu_iowait[cpu];
+		user += kstat_percpu[cpu].user;
+		nice += kstat_percpu[cpu].nice;
+		system += kstat_percpu[cpu].system;
+		idle += kstat_percpu[cpu].idle;
+		iowait += kstat_percpu[cpu].iowait;
 #if !defined(CONFIG_ARCH_S390)
 		for (j = 0 ; j < NR_IRQS ; j++)
-			sum += kstat.irqs[cpu][j];
+			sum += kstat_percpu[cpu].irqs[j];
 #endif
 	}
 
@@ -351,19 +351,19 @@ static int kstat_read_proc(char *page, c
 		proc_sprintf(page, &off, &len,
 			"cpu%d %u %u %u %u %u\n",
 			i,
-			kstat.per_cpu_user[cpu_logical_map(i)],
-			kstat.per_cpu_nice[cpu_logical_map(i)],
-			kstat.per_cpu_system[cpu_logical_map(i)],
-			kstat.per_cpu_idle[cpu_logical_map(i)],
-			kstat.per_cpu_iowait[cpu_logical_map(i)]);
+			kstat_percpu[cpu_logical_map(i)].user,
+			kstat_percpu[cpu_logical_map(i)].nice,
+			kstat_percpu[cpu_logical_map(i)].system,
+			kstat_percpu[cpu_logical_map(i)].idle,
+			kstat_percpu[cpu_logical_map(i)].iowait);
 	proc_sprintf(page, &off, &len,
 		"page %u %u\n"
 		"swap %u %u\n"
 		"intr %u",
-			kstat.pgpgin >> 1,
-			kstat.pgpgout >> 1,
-			kstat.pswpin,
-			kstat.pswpout,
+			kstat_sum(pgpgin) >> 1,
+			kstat_sum(pgpgout) >> 1,
+			kstat_sum(pswpin),
+			kstat_sum(pswpout),
 			sum
 	);
 #if !defined(CONFIG_ARCH_S390) && !defined(CONFIG_ALPHA)
@@ -376,18 +376,18 @@ static int kstat_read_proc(char *page, c
 
 	for (major = 0; major < DK_MAX_MAJOR; major++) {
 		for (disk = 0; disk < DK_MAX_DISK; disk++) {
-			int active = kstat.dk_drive[major][disk] +
-				kstat.dk_drive_rblk[major][disk] +
-				kstat.dk_drive_wblk[major][disk];
+			int active = kstat_sum(dk_drive[major][disk]) +
+				kstat_sum(dk_drive_rblk[major][disk]) +
+				kstat_sum(dk_drive_wblk[major][disk]);
 			if (active)
 				proc_sprintf(page, &off, &len,
 					"(%u,%u):(%u,%u,%u,%u,%u) ",
 					major, disk,
-					kstat.dk_drive[major][disk],
-					kstat.dk_drive_rio[major][disk],
-					kstat.dk_drive_rblk[major][disk],
-					kstat.dk_drive_wio[major][disk],
-					kstat.dk_drive_wblk[major][disk]
+					kstat_sum(dk_drive[major][disk]),
+					kstat_sum(dk_drive_rio[major][disk]),
+					kstat_sum(dk_drive_rblk[major][disk]),
+					kstat_sum(dk_drive_wio[major][disk]),
+					kstat_sum(dk_drive_wblk[major][disk])
 			);
 		}
 	}
diff -urNp linux-7000/include/linux/kernel_stat.h linux-7010/include/linux/kernel_stat.h
--- linux-7000/include/linux/kernel_stat.h
+++ linux-7010/include/linux/kernel_stat.h
@@ -15,12 +15,8 @@
 #define DK_MAX_MAJOR 16
 #define DK_MAX_DISK 16
 
-struct kernel_stat {
-	unsigned int per_cpu_user[NR_CPUS],
-	             per_cpu_nice[NR_CPUS],
-	             per_cpu_system[NR_CPUS],
-	             per_cpu_iowait[NR_CPUS],
-	             per_cpu_idle[NR_CPUS];
+struct kernel_stat_percpu {
+	unsigned int user, nice, system, iowait, idle;
 	unsigned int dk_drive[DK_MAX_MAJOR][DK_MAX_DISK];
 	unsigned int dk_drive_rio[DK_MAX_MAJOR][DK_MAX_DISK];
 	unsigned int dk_drive_wio[DK_MAX_MAJOR][DK_MAX_DISK];
@@ -29,13 +25,23 @@ struct kernel_stat {
 	unsigned int pgpgin, pgpgout;
 	unsigned int pswpin, pswpout;
 #if defined (__hppa__) 
-	unsigned int irqs[NR_CPUS][NR_IRQ_REGS][IRQ_PER_REGION];
+	unsigned int irqs[NR_IRQ_REGS][IRQ_PER_REGION];
 #elif !defined(CONFIG_ARCH_S390)
-	unsigned int irqs[NR_CPUS][NR_IRQS];
+	unsigned int irqs[NR_IRQS];
 #endif
-};
+} ____cacheline_aligned;
 
-extern struct kernel_stat kstat;
+extern struct kernel_stat_percpu kstat_percpu[NR_CPUS] ____cacheline_aligned;
+
+#define kstat_sum(field)						\
+({									\
+	unsigned int __cpu, sum = 0;					\
+									\
+	for (__cpu = 0 ; __cpu < smp_num_cpus ; __cpu++)		\
+		sum += kstat_percpu[cpu_logical_map(__cpu)].field;	\
+									\
+	sum;								\
+})
 
 extern unsigned long nr_context_switches(void);
 
@@ -45,10 +51,11 @@ extern unsigned long nr_context_switches
  */
 static inline int kstat_irqs (int irq)
 {
+
 	int i, sum=0; 
 
 	for (i = 0 ; i < smp_num_cpus ; i++)
-		sum += kstat.irqs[i][IRQ_REGION(irq)][IRQ_OFFSET(irq)];
+		sum += kstat_percpu[i].irqs[IRQ_REGION(irq)][IRQ_OFFSET(irq)];
  
 	return sum;
 }
@@ -56,15 +63,7 @@ static inline int kstat_irqs (int irq)
 /*
  * Number of interrupts per specific IRQ source, since bootup
  */
-extern inline int kstat_irqs (int irq)
-{
-	int i, sum=0;
-
-	for (i = 0 ; i < smp_num_cpus ; i++)
-		sum += kstat.irqs[cpu_logical_map(i)][irq];
-
-	return sum;
-}
+# define kstat_irqs(irq) kstat_sum(irqs[irq])
 #endif
 
 #endif /* _LINUX_KERNEL_STAT_H */
diff -urNp linux-7000/kernel/ksyms.c linux-7010/kernel/ksyms.c
--- linux-7000/kernel/ksyms.c
+++ linux-7010/kernel/ksyms.c
@@ -519,7 +519,7 @@ EXPORT_SYMBOL(do_settimeofday);
 EXPORT_SYMBOL(loops_per_jiffy);
 #endif
 
-EXPORT_SYMBOL(kstat);
+EXPORT_SYMBOL(kstat_percpu);
 EXPORT_SYMBOL(nr_context_switches);
 
 /* misc */
diff -urNp linux-7000/kernel/sched.c linux-7010/kernel/sched.c
--- linux-7000/kernel/sched.c
+++ linux-7010/kernel/sched.c
@@ -1238,19 +1238,19 @@ void scheduler_tick(int user_ticks, int 
 
 	if (p == cpu_idle_ptr(cpu)) {
 		if (local_bh_count(cpu) || local_irq_count(cpu) > 1)
-			kstat.per_cpu_system[cpu] += sys_ticks;
+			kstat_percpu[cpu].system += sys_ticks;
 		else if (atomic_read(&rq->nr_iowait) > 0)
-			kstat.per_cpu_iowait[cpu] += sys_ticks;
+			kstat_percpu[cpu].iowait += sys_ticks;
 		else
-			kstat.per_cpu_idle[cpu] += sys_ticks;
+			kstat_percpu[cpu].idle += sys_ticks;
 		rebalance_tick(rq, cpu, 1);
 		return;
 	}
 	if (TASK_NICE(p) > 0)
-		kstat.per_cpu_nice[cpu] += user_ticks;
+		kstat_percpu[cpu].nice += user_ticks;
 	else
-		kstat.per_cpu_user[cpu] += user_ticks;
-	kstat.per_cpu_system[cpu] += sys_ticks;
+		kstat_percpu[cpu].user += user_ticks;
+	kstat_percpu[cpu].system += sys_ticks;
 
 	/* Task might have expired already, but not scheduled off yet */
 	spin_lock(&rq->lock);
diff -urNp linux-7000/kernel/timer.c linux-7010/kernel/timer.c
--- linux-7000/kernel/timer.c
+++ linux-7010/kernel/timer.c
@@ -25,7 +25,7 @@
 
 #include <asm/uaccess.h>
 
-struct kernel_stat kstat;
+struct kernel_stat_percpu kstat_percpu[NR_CPUS] ____cacheline_aligned;
 
 /*
  * Timekeeping variables
diff -urNp linux-7000/mm/page_io.c linux-7010/mm/page_io.c
--- linux-7000/mm/page_io.c
+++ linux-7010/mm/page_io.c
@@ -44,9 +44,9 @@ static int rw_swap_page_base(int rw, swp
 
 	if (rw == READ) {
 		ClearPageUptodate(page);
-		kstat.pswpin++;
+		kstat_percpu[smp_processor_id()].pswpin++;
 	} else
-		kstat.pswpout++;
+		kstat_percpu[smp_processor_id()].pswpout++;
 
 	get_swaphandle_info(entry, &offset, &dev, &swapf);
 	if (dev) {
